{"pages":[{"title":"关于我","text":"泰戈尔说过，只有经历地狱般的磨炼，才能炼出创造天堂的力量；只有流过血的手指，才能弹出世间的绝唱。梦想是世间的绝唱，只有不甘于现状的挣扎才能不断演奏出不平凡的乐章。 当一个人无法甘于平凡，就会让自己特别。不是特别好，就是特别差，结果取决于你自己。 保持一颗平常心 心怀梦想,永远向前 找到牛人,共同进步 丢掉那些自己给自己所谓的束缚,没有你做不到的,超越自己 抛弃建议,寻找事实 真正的大师永远,怀着一颗学徒的心","link":"/about/index.html"},{"title":"categories","text":"","link":"/categories/index.html"},{"title":"tags","text":"","link":"/tags/index.html"}],"posts":[{"title":"Golang 神级版本管理工具","text":"对于 Golang 开发而言,Golang 语言版本的迭代速度是惊人的,几乎每几个月就需要更新一次小版本。对于 Golang 程序员来说,最渴望的特性莫过于 Go 2.0 的新特性,现在 Go 的版本已经是 1.14,相信在不久的将来会盼望到 2.0 的到来。但是 Golang 采用的是逐步迭代小版本,最终演化为最终版本,作为 Golang 程序员需要对每一个小版本的特性进行学习,因此管理 Go 版本的工具是迫在眉睫的问题,现在为大家介绍一个神级版本管理工具。 一、GVM要介绍一个开源项目为 gvm,在 github 上有5000 star。使用 gvm 不需要在关心下载完新版本的 Go 后,自己还需要手动配置环境变量。 1.安装 gvm安装 gvm 的前置条件是我们已经有之前的 go 版本,假如你和我是一样的操作系统,可以运行brew install go先安装一个较老的版本。然后运行下面的 bash 命令。 1bash &lt; &lt;(curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer) 或者,如果你正在使用的zsh只是改变bash到zsh。 2.命令介绍运行gvm list查看已经安装的版本,和当前使用的版本123456gvm gos (installed) go1.12.6=&gt; go1.13 go1.14 system 运行gvm listall命令,查看当前 Go 所有的版本1234567891011gvm gos (available) go1 go1.0.1 go1.0.2 .... .... go1.14 go1.14beta1 go1.14rc1 go1.14.1 .... 运行gvm install go1.14命令安装当前最新的稳定版本。这里需要注意一下的是最好让 vpn 代理命令行,可以更快的下载 Go 让vpn 代理命令行 1export all_proxy=socks5://127.0.0.1:1086 安装 go1.14 12345➜ ~ gvm install go1.14Updating Go source...Installing go1.14... * Compiling...go1.14 successfully installed! 安装成功了! 运行go env查看当前版本信息,看看我们是否已经安装成功。 1234567891011121314151617181920GO111MODULE=\"\"GOARCH=\"amd64\"GOBIN=\"/Users/zhubowen/go/bin/\"GOCACHE=\"/Users/zhubowen/Library/Caches/go-build\"GOENV=\"/Users/zhubowen/Library/Application Support/go/env\"GOEXE=\"\"GOFLAGS=\"\"GOHOSTARCH=\"amd64\"GOHOSTOS=\"darwin\"GONOPROXY=\"\"GONOSUMDB=\"\"GOOS=\"darwin\"GOPATH=\"/Users/zhubowen/go\"GOPRIVATE=\"\"GOPROXY=\"https://goproxy.io\"GOROOT=\"/Users/zhubowen/.gvm/gos/go1.13\"GOSUMDB=\"sum.golang.org\"GOTMPDIR=\"\"GOTOOLDIR=\"/Users/zhubowen/.gvm/gos/go1.13/pkg/tool/darwin_amd64\".... 看到环境变量还是原先之前的,没有变化。因为我们还没有使用 go1.14。 运行命令gvm use go1.1412➜ ~ gvm use go1.14Now using version go1.14 用go env查看我们是否使用成功。 1GOPATH=\"/Users/zhubowen/.gvm/pkgsets/go1.14/global\" 看到了里面一点变化,这如果不是你想要的,因为我之前的 GOPATH 目录都有已经下好的东西,还有兼容之前版本的项目。 运行命令gvm pkgenv该命令默认是设置的system空间目录下的环境变量，设置如下： 将我们自己的环境变量往下面假如，覆盖上面的一些配置即可 123456# go settingsexport GOPATH=\"/Users/zhubowen/go\"export GOPROXY=https://goproxy.cn,directexport GOPRIVATE=\"github.com/echoingtech/*\"export GOSUMDB=offexport GOBIN=\"${GOPATH}/bin\" 再次运行go env运行结果如下: 同时将如下配置写入到 ~/.bash_profile 文件中，让 GVM 开机自启。 12345# gvm settings[[ -s \"/Users/zhubowen/.gvm/scripts/gvm\" ]] &amp;&amp; source \"/Users/zhubowen/.gvm/scripts/gvm\"export GOVERSION=go1.14gvm install ${GOVERSION}gvm use ${GOVERSION} 二、总结以上就是我对 gvm 的实践。非常简单和实用的工具,gvm 工具可以节省我们很多时间管理和配置 Go 的版本,值得每一个人花费一点小小的时间去学习它。","link":"/2020/06/12/Go/Golang%E7%A5%9E%E7%BA%A7%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/"},{"title":"Colly 官方文档学习从入门到入土","text":"一、介绍 Colly 是用于构建 Web 爬虫的 Golang 框架。使用 Colly ,你可以构建各种复杂的 Web 抓取工具,从简单的抓取工具到处理数百万个网页的复杂的异步网站抓取工具。 Colly 提供了一个 API,用于执行网络请求和处理接收到的内容（例如,与 HTML 文档的 DOM 树进行交互）。 如何安装Colly 只有一个前置条件,那就是 Golang 编程语言。你可以使用其安装指南进行安装。 安装 Colly在终端上键入以下命令,然后按 Enter 键安装 Colly 。 1go get -u github.com/gocolly/colly/... 入门使用Colly之前,请确保你具有最新版本。有关更多详细信息,请参见安装指南。 让我们从一些简单的例子开始。 首先,你需要将Colly导入你的代码库： 1import \"github.com/gocolly/colly\" CollectorColly的主要实体是一个 Collector 对象。Collector 在Collector作业运行时管理网络通信并负责执行附加的回调。要使用 colly ,你必须初始化一个 Collector： 1c := colly.NewCollector() 回调你可以将不同类型的回调函数附加到上,Collector 以控制收集作业或检索信息。请查看包装文档中的相关部分。 将回调添加到 Collector12345678910111213141516171819202122232425262728293031c.OnRequest(func(r *colly.Request) { fmt.Println(\"Visiting\", r.URL)})c.OnError(func(_ *colly.Response, err error) { log.Println(\"Something went wrong:\", err)})c.OnResponseHeaders(func(r *colly.Response) { fmt.Println(\"Visited\", r.Request.URL)})c.OnResponse(func(r *colly.Response) { fmt.Println(\"Visited\", r.Request.URL)})c.OnHTML(\"a[href]\", func(e *colly.HTMLElement) { e.Request.Visit(e.Attr(\"href\"))})c.OnHTML(\"tr td:nth-of-type(1)\", func(e *colly.HTMLElement) { fmt.Println(\"First column of a table row:\", e.Text)})c.OnXML(\"//h1\", func(e *colly.XMLElement) { fmt.Println(e.Text)})c.OnScraped(func(r *colly.Response) { fmt.Println(\"Finished\", r.Request.URL)}) 1.OnRequest在请求之前调用 2.OnError如果请求期间发生错误,则调用 3.OnResponseHeaders在收到响应标头后调用 4.OnResponse收到回复后调用 5.OnHTMLOnResponse如果收到的内容是HTML ,则在之后调用 6.OnXMLOnHTML如果接收到的内容是HTML或XML ,则在之后调用 7.OnScrapedOnXML回调后调用 配置Colly 是一个高度可定制的抓取框架。它具有合理的默认值,并提供了很多选项来更改它们。 Collector 配置Collector属性的完整列表可以在这里找到。建议使用初始化 Collector 的方法colly.NewCollector(options...)。 使用默认设置创建Collector： 1c1 := colly.NewCollector() 创建另一个 Collector 并更改User-Agent和url重新访问选项： 1234c2 := colly.NewCollector( colly.UserAgent(\"xy\"), colly.AllowURLRevisit(),) 通过覆盖 Collector 的属性,可以在抓取作业的任何时候更改配置。 一个很好的例子是User-Agent切换器,它会在每个请求上更改User-Agent： 123456789101112131415const letterBytes = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\"func RandomString() string { b := make([]byte, rand.Intn(10)+10) for i := range b { b[i] = letterBytes[rand.Intn(len(letterBytes))] } return string(b)}c := colly.NewCollector()c.OnRequest(func(r *colly.Request) { r.Headers.Set(\"User-Agent\", RandomString())}) 通过环境变量进行配置可以通过环境变量来更改 Collector 的默认配置。这使我们可以微调 Collector 而无需重新编译。环境解析是 Collector 初始化的最后一步,因此初始化之后的每个配置更改都会覆盖从环境解析的配置。 环境配置变量 COLLY_ALLOWED_DOMAINS (comma separated list of domains) COLLY_CACHE_DIR (string) COLLY_DETECT_CHARSET (y/n) COLLY_DISABLE_COOKIES (y/n) COLLY_DISALLOWED_DOMAINS (comma separated list of domains) COLLY_IGNORE_ROBOTSTXT (y/n) COLLY_FOLLOW_REDIRECTS (y/n) COLLY_MAX_BODY_SIZE (int) COLLY_MAX_DEPTH (int - 0 means infinite) COLLY_PARSE_HTTP_ERROR_RESPONSE (y/n) COLLY_USER_AGENT (string) HTTP 配置 Colly 使用 Golang 的默认 http 客户端作为网络层。可以通过更改默认的 HTTP roundtripper 来调整 HTTP 选项。 12345678910111213c := colly.NewCollector()c.WithTransport(&amp;http.Transport{ Proxy: http.ProxyFromEnvironment, DialContext: (&amp;net.Dialer{ Timeout: 30 * time.Second, KeepAlive: 30 * time.Second, DualStack: true, }).DialContext, MaxIdleConns: 100, IdleConnTimeout: 90 * time.Second, TLSHandshakeTimeout: 10 * time.Second, ExpectContinueTimeout: 1 * time.Second,} 二、最佳实践使用多个 Collector如果任务足够复杂或具有不同类型的子任务,建议使用多个 Collector 来执行一个抓取作业。一个很好的例子是 Coursera 课程抓取工具,其中使用了两个 Collector -一个解析列表视图并处理分页,另一个则收集课程详细信息。 Colly 具有一些内置方法来支持多个 Collector 的使用。 Tips:用于Collector.ID调试以区分不同的 Collector 克隆采集器Clone()如果 Collector 具有类似的配置,则可以使用 Collector 的方法。Clone()复制具有相同配置但没有附加回调的 Collector 。 123456c := colly.NewCollector( colly.UserAgent(\"myUserAgent\"), colly.AllowedDomains(\"foo.com\", \"bar.com\"),)// Custom User-Agent and allowed domains are cloned to c2c2 := c.Clone() 在 Collector 之间传递自定义数据使用 Collector 的Request()功能可以与其他 Collector 共享上下文。 共享上下文示例： 1234c.OnResponse(func(r *colly.Response) { r.Ctx.Put(r.Headers.Get(\"Custom-Header\")) c2.Request(\"GET\", \"https://foo.com/\", nil, r.Ctx, nil)}) 调试有时将一些log.Println()函数调用放置到你的回调中就足够了,但有时却不是。 Colly 具有用于 Collector 调试的内置功能。提供了调试器接口和其他类型的调试器实现。 将调试器附加到Collector附加基本的日志调试器需要 Colly 仓库中的debug（github.com/gocolly/colly/debug）包。 123456789import ( \"github.com/gocolly/colly\" \"github.com/gocolly/colly/debug\")func main() { c := colly.NewCollector(colly.Debugger(&amp;debug.LogDebugger{})) // [..]} 实现自定义调试器你可以通过实现 debug.Debugger 接口来创建任何类型的自定义调试器。一个很好的例子是 LogDebugger 。 分布式抓取分布式抓取可以根据抓取任务的要求以不同的方式实现。大多数时候,足以扩展网络通信层,这可以使用代理和 Colly 的代理切换器轻松实现。 代理切换器当 HTTP 请求在多个代理之间分发时,使用代理切换器的抓取仍然保持集中。 Colly 支持通过其SetProxyFunc()成员进行代理切换。可以SetProxyFunc()使用的签名将任何自定义函数传递给func(*http.Request) (*url.URL, error)。 Tips:带有-D标志的 SSH 服务器可以用作 socks5 代理。 Colly 具有内置的代理切换器,可根据每个请求轮流代理列表。 用法12345678910111213141516171819package mainimport ( \"github.com/gocolly/colly\" \"github.com/gocolly/colly/proxy\")func main() { c := colly.NewCollector() if p, err := proxy.RoundRobinProxySwitcher( \"socks5://127.0.0.1:1337\", \"socks5://127.0.0.1:1338\", \"http://127.0.0.1:8080\", ); err == nil { c.SetProxyFunc(p) } // ...} 实现自定义代理切换器： 1234567891011var proxies []*url.URL = []*url.URL{ &amp;url.URL{Host: \"127.0.0.1:8080\"}, &amp;url.URL{Host: \"127.0.0.1:8081\"},}func randomProxySwitcher(_ *http.Request) (*url.URL, error) { return proxies[random.Intn(len(proxies))], nil}// ...c.SetProxyFunc(randomProxySwitcher) 分布式抓取器要管理独立的和分布式抓取器,最好的办法是将刮板包装在服务器中。服务器可以是任何类型的服务,例如 HTTP ,TCP 服务器或 Google App Engine 。使用自定义存储来实现集中和持久的 cookie 以及访问的 url 处理。 Tips: Colly 具有内置的 Google App Engine 支持。如果你从 App Engine 标准环境中使用 Colly ,请不要忘记调用Collector.Appengine(*http.Request)。 可以在此处找到示例实现。 分布式存储默认情况下,访问的 URL 和 cookie 数据存储在内存中。这对于短寿命的刮板作业很方便,但是在处理大规模或长期运行的爬行作业时可能是一个严重的限制。 Colly 能够用实现了Colly / storage.Storage接口的任何存储后端替换默认的内存存储。检查现有存储。 储存后端 Colly 有一个内存中的存储后端,用于存储 cookie 和访问的 URL ,但是任何实现 Colly / storage.Storage 的自定义存储后端都可以覆盖它。 现有的存储后端 内存后端: Colly 的默认后端。使用Collector.SetStorage（）覆盖。 Redis 后端:有关详细信息,请参见redis示例。 boltdb 后端 SQLite3 后端 MongoDB 后端 PostgreSQL 后端 爬虫程序配置 Colly 的默认配置经过优化,可以在一项作业中抓取较少数量的站点。如果你想抓取数百万个网站,则此设置不是最佳选择。以下是一些调整： 使用永久性存储后端默认情况下, Colly 将 cookie 和访问的 URL 存储在内存中。你可以用任何自定义后端替换内置的内存中存储后端。在这里查看更多详细信息。 将异步用于具有递归调用的长时间运行的作业默认情况下,在请求未完成时 Colly 会阻塞,因此Collector.Visit从回调递归调用会产生不断增长的堆栈。有了Collector.Async = true这可避免。（不要忘了c.Wait()与异步一起使用。） 禁用或限制连接保持活动状态 Colly 使用 HTTP 保持活动来提高抓取速度。它需要打开文件描述符,因此长时间运行的作业很容易达到max-fd限制。 可以使用以下代码禁用 HTTP Keep-alive： 1234c := colly.NewCollector()c.WithTransport(&amp;http.Transport{ DisableKeepAlives: true,}) 扩展扩展是 Colly 随附的小型帮助程序实用程序。插件列表可在此处获得。 用法以下示例启用了随机 User-Agent 切换器和 Referrer setter 扩展,并访问了 httpbin.org 两次。 123456789101112131415161718192021222324import ( \"log\" \"github.com/gocolly/colly\" \"github.com/gocolly/colly/extensions\")func main() { c := colly.NewCollector() visited := false extensions.RandomUserAgent(c) extensions.Referer(c) c.OnResponse(func(r *colly.Response) { log.Println(string(r.Body)) if !visited { visited = true r.Request.Visit(\"/get?q=2\") } }) c.Visit(\"http://httpbin.org/get\")} 三、例子基本123456789101112131415161718192021222324252627282930313233package mainimport ( \"fmt\" \"github.com/gocolly/colly\")func main() { // Instantiate default collector c := colly.NewCollector( // Visit only domains: hackerspaces.org, wiki.hackerspaces.org colly.AllowedDomains(\"hackerspaces.org\", \"wiki.hackerspaces.org\"), ) // On every a element which has href attribute call callback c.OnHTML(\"a[href]\", func(e *colly.HTMLElement) { link := e.Attr(\"href\") // Print link fmt.Printf(\"Link found: %q -&gt; %s\\n\", e.Text, link) // Visit link found on page // Only those links are visited which are in AllowedDomains c.Visit(e.Request.AbsoluteURL(link)) }) // Before making a request print \"Visiting ...\" c.OnRequest(func(r *colly.Request) { fmt.Println(\"Visiting\", r.URL.String()) }) // Start scraping on https://hackerspaces.org c.Visit(\"https://hackerspaces.org/\")} 错误处理1234567891011121314151617181920212223242526package mainimport ( \"fmt\" \"github.com/gocolly/colly\")func main() { // Create a collector c := colly.NewCollector() // Set HTML callback // Won't be called if error occurs c.OnHTML(\"*\", func(e *colly.HTMLElement) { fmt.Println(e) }) // Set error handler c.OnError(func(r *colly.Response, err error) { fmt.Println(\"Request URL:\", r.Request.URL, \"failed with response:\", r, \"\\nError:\", err) }) // Start scraping c.Visit(\"https://definitely-not-a.website/\") } 登陆1234567891011121314151617181920212223242526package mainimport ( \"log\" \"github.com/gocolly/colly\")func main() { // create a new collector c := colly.NewCollector() // authenticate err := c.Post(\"http://example.com/login\", map[string]string{\"username\": \"admin\", \"password\": \"admin\"}) if err != nil { log.Fatal(err) } // attach callbacks after login c.OnResponse(func(r *colly.Response) { log.Println(\"response received\", r.StatusCode) }) // start scraping c.Visit(\"https://example.com/\")} 最大深度12345678910111213141516171819202122232425262728package mainimport ( \"fmt\" \"github.com/gocolly/colly\")func main() { // Instantiate default collector c := colly.NewCollector( // MaxDepth is 1, so only the links on the scraped page // is visited, and no further links are followed colly.MaxDepth(1), ) // On every a element which has href attribute call callback c.OnHTML(\"a[href]\", func(e *colly.HTMLElement) { link := e.Attr(\"href\") // Print link fmt.Println(link) // Visit link found on page e.Request.Visit(link) }) // Start scraping on https://en.wikipedia.org c.Visit(\"https://en.wikipedia.org/\")} 文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package mainimport ( \"fmt\" \"io/ioutil\" \"net/http\" \"os\" \"time\" \"github.com/gocolly/colly\")func generateFormData() map[string][]byte { f, _ := os.Open(\"gocolly.jpg\") defer f.Close() imgData, _ := ioutil.ReadAll(f) return map[string][]byte{ \"firstname\": []byte(\"one\"), \"lastname\": []byte(\"two\"), \"email\": []byte(\"onetwo@example.com\"), \"file\": imgData, }}func setupServer() { var handler http.HandlerFunc = func(w http.ResponseWriter, r *http.Request) { fmt.Println(\"received request\") err := r.ParseMultipartForm(10000000) if err != nil { fmt.Println(\"server: Error\") w.WriteHeader(500) w.Write([]byte(\"&lt;html&gt;&lt;body&gt;Internal Server Error&lt;/body&gt;&lt;/html&gt;\")) return } w.WriteHeader(200) fmt.Println(\"server: OK\") w.Write([]byte(\"&lt;html&gt;&lt;body&gt;Success&lt;/body&gt;&lt;/html&gt;\")) } go http.ListenAndServe(\":8080\", handler)}func main() { // Start a single route http server to post an image to. setupServer() c := colly.NewCollector(colly.AllowURLRevisit(), colly.MaxDepth(5)) // On every a element which has href attribute call callback c.OnHTML(\"html\", func(e *colly.HTMLElement) { fmt.Println(e.Text) time.Sleep(1 * time.Second) e.Request.PostMultipart(\"http://localhost:8080/\", generateFormData()) }) // Before making a request print \"Visiting ...\" c.OnRequest(func(r *colly.Request) { fmt.Println(\"Posting gocolly.jpg to\", r.URL.String()) }) // Start scraping c.PostMultipart(\"http://localhost:8080/\", generateFormData()) c.Wait()} 并行123456789101112131415161718192021222324252627282930313233343536373839package mainimport ( \"fmt\" \"github.com/gocolly/colly\")func main() { // Instantiate default collector c := colly.NewCollector( // MaxDepth is 2, so only the links on the scraped page // and links on those pages are visited colly.MaxDepth(2), colly.Async(true), ) // Limit the maximum parallelism to 2 // This is necessary if the goroutines are dynamically // created to control the limit of simultaneous requests. // // Parallelism can be controlled also by spawning fixed // number of go routines. c.Limit(&amp;colly.LimitRule{DomainGlob: \"*\", Parallelism: 2}) // On every a element which has href attribute call callback c.OnHTML(\"a[href]\", func(e *colly.HTMLElement) { link := e.Attr(\"href\") // Print link fmt.Println(link) // Visit link found on page on a new thread e.Request.Visit(link) }) // Start scraping on https://en.wikipedia.org c.Visit(\"https://en.wikipedia.org/\") // Wait until threads are finished c.Wait()} 代理切换器12345678910111213141516171819202122232425262728293031package mainimport ( \"bytes\" \"log\" \"github.com/gocolly/colly\" \"github.com/gocolly/colly/proxy\")func main() { // Instantiate default collector c := colly.NewCollector(colly.AllowURLRevisit()) // Rotate two socks5 proxies rp, err := proxy.RoundRobinProxySwitcher(\"socks5://127.0.0.1:1337\", \"socks5://127.0.0.1:1338\") if err != nil { log.Fatal(err) } c.SetProxyFunc(rp) // Print the response c.OnResponse(func(r *colly.Response) { log.Printf(\"%s\\n\", bytes.Replace(r.Body, []byte(\"\\n\"), nil, -1)) }) // Fetch httpbin.org/ip five times for i := 0; i &lt; 5; i++ { c.Visit(\"https://httpbin.org/ip\") }} 队列123456789101112131415161718192021222324252627282930313233package mainimport ( \"fmt\" \"github.com/gocolly/colly\" \"github.com/gocolly/colly/queue\")func main() { url := \"https://httpbin.org/delay/1\" // Instantiate default collector c := colly.NewCollector() // create a request queue with 2 consumer threads q, _ := queue.New( 2, // Number of consumer threads &amp;queue.InMemoryQueueStorage{MaxSize: 10000}, // Use default queue storage ) c.OnRequest(func(r *colly.Request) { fmt.Println(\"visiting\", r.URL) }) for i := 0; i &lt; 5; i++ { // Add URLs to the queue q.AddURL(fmt.Sprintf(\"%s?n=%d\", url, i)) } // Consume URLs q.Run(c)} 随机延迟12345678910111213141516171819202122232425262728293031323334353637package mainimport ( \"fmt\" \"time\" \"github.com/gocolly/colly\" \"github.com/gocolly/colly/debug\")func main() { url := \"https://httpbin.org/delay/2\" // Instantiate default collector c := colly.NewCollector( // Attach a debugger to the collector colly.Debugger(&amp;debug.LogDebugger{}), colly.Async(true), ) // Limit the number of threads started by colly to two // when visiting links which domains' matches \"*httpbin.*\" glob c.Limit(&amp;colly.LimitRule{ DomainGlob: \"*httpbin.*\", Parallelism: 2, RandomDelay: 5 * time.Second, }) // Start scraping in four threads on https://httpbin.org/delay/2 for i := 0; i &lt; 4; i++ { c.Visit(fmt.Sprintf(\"%s?n=%d\", url, i)) } // Start scraping on https://httpbin.org/delay/2 c.Visit(url) // Wait until threads are finished c.Wait()} 速率限制1234567891011121314151617181920212223242526272829303132333435package mainimport ( \"fmt\" \"github.com/gocolly/colly\" \"github.com/gocolly/colly/debug\")func main() { url := \"https://httpbin.org/delay/2\" // Instantiate default collector c := colly.NewCollector( // Turn on asynchronous requests colly.Async(true), // Attach a debugger to the collector colly.Debugger(&amp;debug.LogDebugger{}), ) // Limit the number of threads started by colly to two // when visiting links which domains' matches \"*httpbin.*\" glob c.Limit(&amp;colly.LimitRule{ DomainGlob: \"*httpbin.*\", Parallelism: 2, //Delay: 5 * time.Second, }) // Start scraping in five threads on https://httpbin.org/delay/2 for i := 0; i &lt; 5; i++ { c.Visit(fmt.Sprintf(\"%s?n=%d\", url, i)) } // Wait until threads are finished c.Wait()} Reids 后端1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package mainimport ( \"log\" \"github.com/gocolly/colly\" \"github.com/gocolly/colly/queue\" \"github.com/gocolly/redisstorage\")func main() { urls := []string{ \"http://httpbin.org/\", \"http://httpbin.org/ip\", \"http://httpbin.org/cookies/set?a=b&amp;c=d\", \"http://httpbin.org/cookies\", } c := colly.NewCollector() // create the redis storage storage := &amp;redisstorage.Storage{ Address: \"127.0.0.1:6379\", Password: \"\", DB: 0, Prefix: \"httpbin_test\", } // add storage to the collector err := c.SetStorage(storage) if err != nil { panic(err) } // delete previous data from storage if err := storage.Clear(); err != nil { log.Fatal(err) } // close redis client defer storage.Client.Close() // create a new request queue with redis storage backend q, _ := queue.New(2, storage) c.OnResponse(func(r *colly.Response) { log.Println(\"Cookies:\", c.Cookies(r.Request.URL.String())) }) // add URLs to the queue for _, u := range urls { q.AddURL(u) } // consume requests q.Run(c)} 请求上下文123456789101112131415161718192021222324252627package mainimport ( \"fmt\" \"github.com/gocolly/colly\")func main() { // Instantiate default collector c := colly.NewCollector() // Before making a request put the URL with // the key of \"url\" into the context of the request c.OnRequest(func(r *colly.Request) { r.Ctx.Put(\"url\", r.URL.String()) }) // After making a request get \"url\" from // the context of the request c.OnResponse(func(r *colly.Response) { fmt.Println(r.Ctx.Get(\"url\")) }) // Start scraping on https://en.wikipedia.org c.Visit(\"https://en.wikipedia.org/\")} 爬虫服务器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package mainimport ( \"encoding/json\" \"log\" \"net/http\" \"github.com/gocolly/colly\")type pageInfo struct { StatusCode int Links map[string]int}func handler(w http.ResponseWriter, r *http.Request) { URL := r.URL.Query().Get(\"url\") if URL == \"\" { log.Println(\"missing URL argument\") return } log.Println(\"visiting\", URL) c := colly.NewCollector() p := &amp;pageInfo{Links: make(map[string]int)} // count links c.OnHTML(\"a[href]\", func(e *colly.HTMLElement) { link := e.Request.AbsoluteURL(e.Attr(\"href\")) if link != \"\" { p.Links[link]++ } }) // extract status code c.OnResponse(func(r *colly.Response) { log.Println(\"response received\", r.StatusCode) p.StatusCode = r.StatusCode }) c.OnError(func(r *colly.Response, err error) { log.Println(\"error:\", r.StatusCode, err) p.StatusCode = r.StatusCode }) c.Visit(URL) // dump results b, err := json.Marshal(p) if err != nil { log.Println(\"failed to serialize response:\", err) return } w.Header().Add(\"Content-Type\", \"application/json\") w.Write(b)}func main() { // example usage: curl -s 'http://127.0.0.1:7171/?url=http://go-colly.org/' addr := \":7171\" http.HandleFunc(\"/\", handler) log.Println(\"listening on\", addr) log.Fatal(http.ListenAndServe(addr, nil))} 网址过滤器12345678910111213141516171819202122232425262728293031323334353637package mainimport ( \"fmt\" \"regexp\" \"github.com/gocolly/colly\")func main() { // Instantiate default collector c := colly.NewCollector( // Visit only root url and urls which start with \"e\" or \"h\" on httpbin.org colly.URLFilters( regexp.MustCompile(\"http://httpbin\\\\.org/(|e.+)$\"), regexp.MustCompile(\"http://httpbin\\\\.org/h.+\"), ), ) // On every a element which has href attribute call callback c.OnHTML(\"a[href]\", func(e *colly.HTMLElement) { link := e.Attr(\"href\") // Print link fmt.Printf(\"Link found: %q -&gt; %s\\n\", e.Text, link) // Visit link found on page // Only those links are visited which are matched by any of the URLFilter regexps c.Visit(e.Request.AbsoluteURL(link)) }) // Before making a request print \"Visiting ...\" c.OnRequest(func(r *colly.Request) { fmt.Println(\"Visiting\", r.URL.String()) }) // Start scraping on http://httpbin.org c.Visit(\"http://httpbin.org/\")}","link":"/2020/04/28/Go/Colly%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F/"},{"title":"Go如何编写Grpc测试","text":"我重写了公司原有的代码，对pb文件进行了更改，为了保持原有的功能保持正确性，我不得不进行测试，但是我没有找到任何一个关于Golang Grpc的测试，通过查找，可以不用开启Grcp客户端进行测试，只需要通过反射就可以调用到Grcp的方法，并进行测试。 一、导包导入我们编写的文件，他们都在同一目录下 12345678910111213141516171819package pb_testimport ( \"context\" \"sync\" \"testing\" pb2 \"github.com/echoingtech/uc/proto\" \"github.com/echoingtech/uc/service/user\" \"github.com/echoingtech/uc/config\" \"github.com/echoingtech/uc/domain\" \"github.com/echoingtech/uc/presentation/mysql\" \"github.com/micro/go-micro/registry/memory\" \"github.com/micro/go-micro/server\" \"github.com/micro/go-micro/server/grpc\" gc \"google.golang.org/grpc\") 二、初始化配置文件初始化配置文件，我们可以在init方法中进行初始化，或者使用TestMain方法进行测试化。我选择了init方法，因为我不要那么复杂的初始化，并且比较容易编写。 12345678910111213141516171819var userHandler pb2.UserHandlerfunc init() { config.LoadConfig() engineGroup := config.GetDB() var ( userRepository domain.UserRepository qqRepository domain.QQRepository wechatRepository domain.WechatRepository ) { userRepository = mysql.NewUserRepository(engineGroup) qqRepository = mysql.NewQqRepository(engineGroup) wechatRepository = mysql.NewWechatRepository(engineGroup) } userService := user.NewService(userRepository, qqRepository, wechatRepository) userHandler = NewUserAdapter} 这里解释一下userHandler是我们通过pb文件生成的接口，而NewUserAdapter则是我们的实现类。通过依赖注入的方式使我们可以很方便的测试任何方法。 三、编写测试服务我们注册一个服务，这个服务不需要通过网络。我们只需要在内存中通信就可以了，这可以的节省资源，并且启动很迅速。开启服务后我们通过s.Start()启动服务，并通过gc.Dial(s.Options().Address, gc.WithInsecure())进行拨号。现在我们可以进行测试了。 123456789101112131415161718192021222324252627282930313233343536373839func TestGRPCServer(t *testing.T) { r := memory.NewRegistry() s := grpc.NewServer( server.Name(\"foo\"), server.Registry(r), ) if err := pb2.RegisterUserHandler(s, userHandler); err != nil { t.Fatalf(\"failed to start: %v\", err) } if err := s.Start(); err != nil { t.Fatalf(\"failed to start: %v\", err) } // check registration services, err := r.GetService(\"foo\") if err != nil || len(services) == 0 { t.Fatalf(\"failed to get service: %v # %d\", err, len(services)) } defer func() { if err := s.Stop(); err != nil { t.Fatalf(\"failed to stop: %v\", err) } }() cc, err := gc.Dial(s.Options().Address, gc.WithInsecure()) if err != nil { t.Fatalf(\"failed to dial server: %v\", err) } var wg sync.WaitGroup wg.Add(1) go getUserInfo(t, &amp;wg, cc) wg.Add(1) go getQQInfo(t, &amp;wg, cc) wg.Add(1) go getWechatInfo(t, &amp;wg, cc) wg.Wait()} 四、通过异步的方式加速测试我们通过sync.WaitGroup或者是用goroutine和chan的组合，可以轻易的编写出异步的测试代码。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152func getUserInfo(t *testing.T, wg *sync.WaitGroup, cc *gc.ClientConn) { func() { defer wg.Done() userRsp := pb2.UserResponse{} if err := cc.Invoke(context.Background(), \"/User/GetUser\", &amp;pb2.GetUserRequest{UserId: 86617739354963979}, &amp;userRsp); err != nil { t.Fatalf(\"error calling server: %v\", err) } if userRsp.Code == 1 { t.Fatalf(\"Got unexpected response %v\", userRsp.Data) } else { t.Log(userRsp.Data) } }()}func getQQInfo(t *testing.T, wg *sync.WaitGroup, cc *gc.ClientConn) { func() { defer wg.Done() userRsp := pb2.GetOpenIdResponse{} if err := cc.Invoke(context.Background(), \"/User/GetOpenId\", &amp;pb2.GetOpenIdRequest{ UserId: 86617739354963979, Source: pb2.LoginSource_QQ, AppId: \"1109882002\", }, &amp;userRsp); err != nil { t.Fatalf(\"error calling server: %v\", err) } if userRsp.Code == 1 { t.Fatalf(\"Got unexpected response %v\", userRsp.Message) } else { t.Log(userRsp.OpenId) } }()}func getWechatInfo(t *testing.T, wg *sync.WaitGroup, cc *gc.ClientConn) { func() { defer wg.Done() userRsp := pb2.GetOpenIdResponse{} if err := cc.Invoke(context.Background(), \"/User/GetOpenId\", &amp;pb2.GetOpenIdRequest{ UserId: 86617739354963979, Source: pb2.LoginSource_Weixin, AppId: \"wxaf7362726f135b5c\", }, &amp;userRsp); err != nil { t.Fatalf(\"error calling server: %v\", err) } if userRsp.Code == 1 { t.Fatalf(\"Got unexpected response %v\", userRsp.Message) } else { t.Log(userRsp.OpenId) } }()} 通过反射规则调用，规则是文件名/方法名，并且开头字母大写。 五、总结到现在为止，已经不错了。我们可以很方便的测试我们编写的pb文件，并且这种测试是可以进行一次配置，多次测试的。通过异步使得测试更有效率，但是异步看起来还有些丑陋，可以使用goroutine和chan模式做一些简化。","link":"/2020/06/05/Go/Go%E5%A6%82%E4%BD%95%E7%BC%96%E5%86%99Grpc%E6%B5%8B%E8%AF%95/"},{"title":"Go 限流算法实战","text":"由于 API 接口无法控制调用方的行为,因此当遇到瞬时请求量激增时,会导致接口占用过多服务器资源,使得其他请求响应速度降低或是超时,更有甚者可能导致服务器宕机。 限流指对应用服务的请求进行限制,例如某一接口的请求限制为 100 个每秒, 对超过限制的请求则进行快速失败或丢弃。 限流可以应对： 热点业务带来的突发请求； 调用方 bug 导致的突发请求； 恶意攻击请求。 因此,对于公开的接口最好采取限流措施。 一、限流的算法实现限流有很多办法,在程序中时通常是根据每秒处理的事务数 (Transactionpersecond) 来衡量接口的流量。 本文介绍几种最常用的限流算法： 固定窗口计数器； 滑动窗口计数器； 漏桶； 令牌桶。 1、固定窗口计数器算法 固定窗口计数器算法概念如下： 将时间划分为多个窗口； 在每个窗口内每有一次请求就将计数器加一； 如果计数器超过了限制数量,则本窗口内所有的请求都被丢弃当时间到达下一个窗口时,计数器重置。 固定窗口计数器是最为简单的算法,但这个算法有时会让通过请求量允许为限制的两倍。考虑如下情况：限制 1 秒内最多通过 5 个请求,在第一个窗口的最后半秒内通过了 5 个请求,第二个窗口的前半秒内又通过了 5 个请求。这样看来就是在 1 秒内通过了 10 个请求。 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package fixed_window_counterimport ( \"sync\" \"sync/atomic\" \"time\" ratelimit_kit \"github.com/ulovecode/ratelimit-kit\")var ( once sync.Once)var _ ratelimit_kit.RateLimiter = &amp;fixedWindowCounter{}type fixedWindowCounter struct { snippet time.Duration currentRequests int32 allowRequests int32}func New(snippet time.Duration, allowRequests int32) *fixedWindowCounter { return &amp;fixedWindowCounter{snippet: snippet, allowRequests: allowRequests}}func (l *fixedWindowCounter) Take() error { once.Do(func() { go func() { for { select { case &lt;-time.After(l.snippet): atomic.StoreInt32(&amp;l.currentRequests, 0) } } }() }) curRequest := atomic.LoadInt32(&amp;l.currentRequests) if curRequest &gt;= l.allowRequests { return ratelimit_kit.ErrExceededLimit } if !atomic.CompareAndSwapInt32(&amp;l.currentRequests, curRequest, curRequest+1) { return ratelimit_kit.ErrExceededLimit } return nil} 2、滑动窗口计数器算法 滑动窗口计数器算法概念如下： 将时间划分为多个区间； 在每个区间内每有一次请求就将计数器加一维持一个时间窗口,占据多个区间； 每经过一个区间的时间,则抛弃最老的一个区间,并纳入最新的一个区间； 如果当前窗口内区间的请求计数总和超过了限制数量,则本窗口内所有的请求都被丢弃。 滑动窗口计数器是通过将窗口再细分,并且按照时间 “ 滑动 “,这种算法避免了固定窗口计数器带来的双倍突发请求,但时间区间的精度越高,算法所需的空间容量就越大。 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071package sliding_window_counterimport ( \"sync\" \"sync/atomic\" \"time\" ratelimit_kit \"github.com/ulovecode/ratelimit-kit\")var ( once sync.Once)var _ ratelimit_kit.RateLimiter = &amp;slidingWindowCounter{}type slidingWindowCounter struct { incurRequests int32 durationRequests chan int32 accuracy time.Duration snippet time.Duration currentRequests int32 allowRequests int32}func New(accuracy time.Duration, snippet time.Duration, allowRequests int32) *slidingWindowCounter { return &amp;slidingWindowCounter{durationRequests: make(chan int32, snippet/accuracy/1000), accuracy: accuracy, snippet: snippet, allowRequests: allowRequests}}func (l *slidingWindowCounter) Take() error { once.Do(func() { go sliding(l) go calculate(l) }) curRequest := atomic.LoadInt32(&amp;l.currentRequests) if curRequest &gt;= l.allowRequests { return ratelimit_kit.ErrExceededLimit } if !atomic.CompareAndSwapInt32(&amp;l.currentRequests, curRequest, curRequest+1) { return ratelimit_kit.ErrExceededLimit } atomic.AddInt32(&amp;l.incurRequests, 1) return nil}func sliding(l *slidingWindowCounter) { for { select { case &lt;-time.After(l.accuracy): t := atomic.SwapInt32(&amp;l.incurRequests, 0) l.durationRequests &lt;- t } }}func calculate(l *slidingWindowCounter) { for { &lt;-time.After(l.accuracy) if len(l.durationRequests) == cap(l.durationRequests) { break } } for { &lt;-time.After(l.accuracy) t := &lt;-l.durationRequests if t != 0 { atomic.AddInt32(&amp;l.currentRequests, -t) } }} 3、漏桶算法 漏桶算法概念如下： 将每个请求视作 “ 水滴 “ 放入 “ 漏桶 “ 进行存储； “漏桶 “ 以固定速率向外 “ 漏 “ 出请求来执行如果 “ 漏桶 “ 空了则停止 “ 漏水”； 如果 “ 漏桶 “ 满了则多余的 “ 水滴 “ 会被直接丢弃。 漏桶算法多使用队列实现,服务的请求会存到队列中,服务的提供方则按照固定的速率从队列中取出请求并执行,过多的请求则放在队列中排队或直接拒绝。 漏桶算法的缺陷也很明显,当短时间内有大量的突发请求时,即便此时服务器没有任何负载,每个请求也都得在队列中等待一段时间才能被响应。 代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243package leaky_barrelimport ( \"sync\" \"time\" ratelimit_kit \"github.com/ulovecode/ratelimit-kit\")var ( once sync.Once)var _ ratelimit_kit.RateLimiter = &amp;leakyBarrel{}type leakyBarrel struct { snippet time.Duration allowRequests int32 barrelSize chan struct{}}func New(snippet time.Duration, barrelSize int, allowRequests int32) *leakyBarrel { return &amp;leakyBarrel{snippet: snippet, barrelSize: make(chan struct{}, int(allowRequests)/barrelSize), allowRequests: allowRequests}}func (t *leakyBarrel) Take() error { once.Do(func() { go func() { for { select { case &lt;-time.After(time.Duration(t.snippet.Nanoseconds() / int64(t.allowRequests))): t.barrelSize &lt;- struct{}{} } } }() }) select { case &lt;-t.barrelSize: return nil default: } return ratelimit_kit.ErrExceededLimit} 4、令牌桶算法 令牌桶算法概念如下： 令牌以固定速率生成； 生成的令牌放入令牌桶中存放,如果令牌桶满了则多余的令牌会直接丢弃,当请求到达时,会尝试从令牌桶中取令牌,取到了令牌的请求可以执行； 如果桶空了,那么尝试取令牌的请求会被直接丢弃。 令牌桶算法既能够将所有的请求平均分布到时间区间内,又能接受服务器能够承受范围内的突发请求,因此是目前使用较为广泛的一种限流算法。 代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243package token_bucketimport ( \"sync\" \"time\" ratelimit_kit \"github.com/ulovecode/ratelimit-kit\")var ( once sync.Once)var _ ratelimit_kit.RateLimiter = &amp;tokenBucket{}type tokenBucket struct { snippet time.Duration token chan struct{} allowRequests int32}func New(snippet time.Duration, allowRequests int32) *tokenBucket { return &amp;tokenBucket{snippet: snippet, token: make(chan struct{}, allowRequests), allowRequests: allowRequests}}func (t *tokenBucket) Take() error { once.Do(func() { go func() { for { select { case &lt;-time.After(time.Duration(t.snippet.Nanoseconds() / int64(t.allowRequests))): t.token &lt;- struct{}{} } } }() }) select { case &lt;-t.token: return nil default: } return ratelimit_kit.ErrExceededLimit} 全部代码在github地址如下https://github.com/ulovecode/ratelimit-kit","link":"/2020/05/06/Go/Go%E9%99%90%E6%B5%81%E7%AE%97%E6%B3%95%E5%AE%9E%E6%88%98/"},{"title":"我对于 Golang 设计模式中不同的理解","text":"设计模式,自打我开始学习编程起,这就是一个津津乐道的话题。怎么编写好味道的代码,如何写出合适的设计代码帮助项目更容易理解,代码更简洁,这是我在项目中常常思考的问题。在golang 中有和其他语言不同的区别。例如函数作为一等公民,goroutine , chan 等特性,对于这些特性我思考如何能够编写适用于 golang 中的设计模式,而不是一味的套用着老思想的设计模式,以下是针对开源项目 go-patterns 的理解。 习惯型1. 函数可选项 允许使用默认设置和惯用替代创建干净的API 选项 123456789101112131415161718192021222324252627282930313233type Options struct { UID int GID int Flags int Contents string Permissions os.FileMode}type Option func(*Options)func UID(userID int) Option { return func(args *Options) { args.UID = userID }}func GID(groupID int) Option { return func(args *Options) { args.GID = groupID }}func Contents(c string) Option { return func(args *Options) { args.Contents = c }}func Permissions(perms os.FileMode) Option { return func(args *Options) { args.Permissions = perms }} 构造器 123456789101112131415161718192021222324252627func New(filepath string, setters ...Option) error { // Default Options args := &amp;Options{ UID: os.Getuid(), GID: os.Getgid(), Contents: \"\", Permissions: 0666, Flags: os.O_CREATE | os.O_EXCL | os.O_WRONLY, } for _, setter := range setters { setter(args) } f, err := os.OpenFile(filepath, args.Flags, args.Permissions) if err != nil { return err } else { defer f.Close() } if _, err := f.WriteString(args.Contents); err != nil { return err } return f.Chown(args.UID, args.GID)} 调用一下： 123456789emptyFile, err := file.New(\"/tmp/empty.txt\")if err != nil { panic(err)}fillerFile, err := file.New(\"/tmp/file.txt\", file.UID(1000), file.Contents(\"Lorem Ipsum Dolor Amet\"))if err != nil { panic(err)} 上面给出了一个关于函数选项模式的例子,这样做有什么好处呢？使程序看起来更加简洁,假如我们不按照这样的方式写,会是什么情况? 12345678910111213141516171819202122func New(filepath string,uid,filepath,Flags string ........... ) error { // Default Options args := &amp;Options{ UID: os.Getuid(), GID: os.Getgid(), Contents: \"\", Permissions: 0666, Flags: os.O_CREATE | os.O_EXCL | os.O_WRONLY, } f, err := os.OpenFile(filepath, args.Flags, args.Permissions) if err != nil { return err } else { defer f.Close() } if _, err := f.WriteString(args.Contents); err != nil { return err } return f.Chown(args.UID, args.GID)} 可以看出来,函数可选项模式,使调用函数的参数列表更加简洁,并且参数列表的设置顺序不再是按照函数的形参列表的顺序,传入选项的顺序与函数已经无关了。并且通过选项形式,我们不用再去一一对应我们这个地方需要放什么参数,我门只需要调用可选项里面的函数即可,函数名轻而易举的就可以告诉我们这个参数是什么作用。 使用场景：对配置进行初始化的时候(当我们认为需要配置的参数特别多的时候,我认为这种模式应该会非常有帮助) 行为型2. 策略模式 通过策略行为设计模式,可以在运行时选择算法的行为。 下面是一个例子对整数进行操作的可互换运算符对象的实现 操作符接口 1234567891011type Operator interface { Apply(int, int) int}type Operation struct { Operator Operator}func (o *Operation) Operate(leftValue, rightValue int) int { return o.Operator.Apply(leftValue, rightValue)} 加法运算符 12345type Addition struct{}func (Addition) Apply(lval, rval int) int { return lval + rval} 12add := Operation{Addition{}}add.Operate(3, 5) // 8 乘法运算符 12345type Multiplication struct{}func (Multiplication) Apply(lval, rval int) int { return lval * rval} 123mult := Operation{Multiplication{}}mult.Operate(3, 5) // 15 调用的过程应该就是向一个Operation类传入一个实现了Operator接口的类,然后调用Operation对象的方法,Operation类 本身也实现Operator接口,相当于采用委托的方式对子类进行动态选择。 策略模式与模板模式相似,但粒度不同,策略模式的变化是在类级别,模版方法是在方法级别。 使用场景：在程序运行过程中可以动态的选择执行的类。 3. 观察者模式 提供特定以通知事件/数据更改 事件本身,观察者,通知者 12345678910111213141516171819202122232425262728293031type ( // Event defines an indication of a point-in-time occurrence. Event struct { // Data in this case is a simple int, but the actual // implementation would depend on the application. Data int64 } // Observer defines a standard interface for instances that wish to list for // the occurrence of a specific event. Observer interface { // OnNotify allows an event to be \"published\" to interface implementations. // In the \"real world\", error handling would likely be implemented. OnNotify(Event) } // Notifier is the instance being observed. Publisher is perhaps another decent // name, but naming things is hard. Notifier interface { // Register allows an instance to register itself to listen/observe // events. Register(Observer) // Deregister allows an instance to remove itself from the collection // of observers/listeners. Deregister(Observer) // Notify publishes new events to listeners. The method is not // absolutely necessary, as each implementation could define this itself // without losing functionality. Notify(Event) }) 事件观察者的的实现,事件通知者的实现 1234567891011121314151617181920212223242526272829type ( eventObserver struct{ id int } eventNotifier struct{ // Using a map with an empty struct allows us to keep the observers // unique while still keeping memory usage relatively low. observers map[Observer]struct{} })func (o *eventObserver) OnNotify(e Event) { fmt.Printf(\"*** Observer %d received: %d\\n\", o.id, e.Data)}func (o *eventNotifier) Register(l Observer) { o.observers[l] = struct{}{}}func (o *eventNotifier) Deregister(l Observer) { delete(o.observers, l)}func (p *eventNotifier) Notify(e Event) { for o := range p.observers { o.OnNotify(e) }} 观察者应该具有一定的结构,逻辑,将观察者注册到其所对应到通知者对象上,采用遍历到方式,对观察者者进行遍历,观察者被通知到后调用自身的业务逻辑方法。 使用如下 12345678910111213141516171819202122func main() { // Initialize a new Notifier. n := eventNotifier{ observers: map[Observer]struct{}{}, } // Register a couple of observers. n.Register(&amp;eventObserver{id: 1}) n.Register(&amp;eventObserver{id: 2}) // A simple loop publishing the current Unix timestamp to observers. stop := time.NewTimer(10 * time.Second).C tick := time.NewTicker(time.Second).C for { select { case &lt;- stop: return case t := &lt;-tick: n.Notify(Event{Data: t.UnixNano()}) } }} 将观察者全部都注册到通知者上,使用for select语句对所有所有已经被注册到通知者对象上进行通知消息。 应用场景:通知者会在符合某种条件下去通知观察者,观察者根据消息产生一些系列的逻辑。 并发型4. 生成器模式 一次产生一个值序列 生成器 1234567891011121314func Count(start int, end int) chan int { ch := make(chan int) go func(ch chan int) { for i := start; i &lt;= end ; i++ { // Blocks on the operation ch &lt;- i } close(ch) }(ch) return ch} 通过 一个goroutine异步创建好需要的对象,减少创建过程中带来的性能损耗 使用 1234567891011fmt.Println(\"No bottles of beer on the wall\")for i := range Count(1, 99) { fmt.Println(\"Pass it around, put one up,\", i, \"bottles of beer on the wall\") // Pass it around, put one up, 1 bottles of beer on the wall // Pass it around, put one up, 2 bottles of beer on the wall // ... // Pass it around, put one up, 99 bottles of beer on the wall}fmt.Println(100, \"bottles of beer on the wall\") 打印 1-99 的数。 应用场景：创建对象需要耗费大量资源,或者解耦创建过程与调用过程,开发者不需要关心创建了什么,只需要做创建过程。 5. 并发模式 并发完成大量独立任务 信息结果 123456// A md5Result is the product of reading and summing a file using MD5.type md5Result struct { path string sum [md5.Size]byte err error} 并发 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// sumFiles starts goroutines to walk the directory tree at root and digest each// regular file. These goroutines send the results of the digests on the md5Result// channel and send the md5Result of the walk on the error channel. If done is// closed, sumFiles abandons its work.func sumFiles(done &lt;-chan struct{}, root string) (&lt;-chan md5Result, &lt;-chan error) { // For each regular file, start a goroutine that sums the file and sends // the md5Result on c. Send the md5Result of the walk on errc. c := make(chan md5Result) errc := make(chan error, 1) go func() { // HL var wg sync.WaitGroup err := filepath.Walk(root, func(path string, info os.FileInfo, err error) error { if err != nil { return err } if !info.Mode().IsRegular() { return nil } wg.Add(1) go func() { // HL data, err := ioutil.ReadFile(path) select { case c &lt;- md5Result{path, md5.Sum(data), err}: // HL case &lt;-done: // HL } wg.Done() }() // Abort the walk if done is closed. select { case &lt;-done: // HL return errors.New(\"walk canceled\") default: return nil } }) // Walk has returned, so all calls to wg.Add are done. Start a // goroutine to close c once all the sends are done. go func() { // HL wg.Wait() close(c) // HL }() // No select needed here, since errc is buffered. errc &lt;- err // HL }() return c, errc} 并发模式的关键要素就是使用chan和goroutine 配合使用,创建一个goroutine运行需要执行的作业内容,遍历作业,对其每个耗时较长的任务进行异步处理,并判断是否接收到了中断信息,如果有中断信息就直接返回错误,并将错误传入到errc管道中, 这样作业内容就可以停止。对作业内容结果进行处理填入到chan中,并用WaitGroup记录其作业状态,当作业内容全部执行了,就关闭chan,不允许可写。 针对上面代码进行简化操作的逻辑就是: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950func Walk(jobs Job,walkFn WalkFunc) error { for job range jobs { err = walkFn(job) if err != nil{ break } } return err}func work(done &lt;-chan struct{},jobs Job) (&lt;-chan result, &lt;-chan error) { // For each regular file, start a goroutine that sums the file and sends // the md5Result on c. Send the md5Result of the walk on errc. c := make(chan result) errc := make(chan error, 1) go func() { // HL var wg sync.WaitGroup for job range jobs err := Walk(jobs,func() error { if err != nil { return err } wg.Add(1) go func() { // HL data, err := doJob() select { case c &lt;- data // HL //case &lt;-done: // HL } wg.Done() }() // Abort the walk if done is closed. select { case &lt;-done: // HL return errors.New(\"walk canceled\") default: return nil } }) // Walk has returned, so all calls to wg.Add are done. Start a // goroutine to close c once all the sends are done. go func() { // HL wg.Wait() close(c) // HL }() // No select needed here, since errc is buffered. errc &lt;- err // HL }() return c, errc} 抽出一个通用逻辑来,应该就是这样的,适用于各种场景。 应用场景: io操作,网络操作 等等耗时事件长的任务。 6. 固定并发模式 在资源有限的情况下完成大量独立任务 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990// walkFiles starts a goroutine to walk the directory tree at root and send the// path of each regular file on the string channel. It sends the result of the// walk on the error channel. If done is closed, walkFiles abandons its work.func walkFiles(done &lt;-chan struct{}, root string) (&lt;-chan string, &lt;-chan error) { paths := make(chan string) errc := make(chan error, 1) go func() { // HL // Close the paths channel after Walk returns. defer close(paths) // HL // No select needed for this send, since errc is buffered. errc &lt;- filepath.Walk(root, func(path string, info os.FileInfo, err error) error { // HL if err != nil { return err } if !info.Mode().IsRegular() { return nil } select { case paths &lt;- path: // HL case &lt;-done: // HL return errors.New(\"walk canceled\") } return nil }) }() return paths, errc}// A result is the product of reading and summing a file using MD5.type result struct { path string sum [md5.Size]byte err error}// digester reads path names from paths and sends digests of the corresponding// files on c until either paths or done is closed.func digester(done &lt;-chan struct{}, paths &lt;-chan string, c chan&lt;- result) { for path := range paths { // HLpaths data, err := ioutil.ReadFile(path) select { case c &lt;- result{path, md5.Sum(data), err}: case &lt;-done: return } }}// MD5All reads all the files in the file tree rooted at root and returns a map// from file path to the MD5 sum of the file's contents. If the directory walk// fails or any read operation fails, MD5All returns an error. In that case,// MD5All does not wait for inflight read operations to complete.func MD5All(root string) (map[string][md5.Size]byte, error) { // MD5All closes the done channel when it returns; it may do so before // receiving all the values from c and errc. done := make(chan struct{}) defer close(done) paths, errc := walkFiles(done, root) // Start a fixed number of goroutines to read and digest files. c := make(chan result) // HLc var wg sync.WaitGroup const numDigesters = 20 wg.Add(numDigesters) for i := 0; i &lt; numDigesters; i++ { go func() { digester(done, paths, c) // HLc wg.Done() }() } go func() { wg.Wait() close(c) // HLc }() // End of pipeline. OMIT m := make(map[string][md5.Size]byte) for r := range c { if r.err != nil { return nil, r.err } m[r.path] = r.sum } // Check whether the Walk failed. if err := &lt;-errc; err != nil { // HLerrc return nil, err } return m, nil} 和上面并发模式有点像,区别是固定量并发数量 1234567891011121314var paths = make(chan string)paths = getJobs()const numDigesters = 20wg.Add(numDigesters)for i := 0; i &lt; numDigesters; i++ { go func() { digester(done, paths, c) // HLc wg.Done() }()}go func() { wg.Wait() close(c) // HLc}() 抽出主要逻辑,清晰的可以看出来其用途为固定量并发 goroutine 数为 20 个。 应用场景: cpu 操作,io操作,网络操作 等等耗时事件长的任务,以及为了防止任务吞掉系统全部资源,限制并发量。 创造型7 .建造者模式 使用简单对象构建复杂对象 1234567891011121314151617181920212223242526272829303132333435package cartype Speed float64const ( MPH Speed = 1 KPH = 1.60934)type Color stringconst ( BlueColor Color = \"blue\" GreenColor = \"green\" RedColor = \"red\")type Wheels stringconst ( SportsWheels Wheels = \"sports\" SteelWheels = \"steel\")type Builder interface { Color(Color) Builder Wheels(Wheels) Builder TopSpeed(Speed) Builder Build() Car}type Car interface { Drive() error Stop() error} 使用 1234567assembly := car.NewBuilder().Paint(car.RedColor)familyCar := assembly.Wheels(car.SportsWheels).TopSpeed(50 * car.MPH).Build()familyCar.Drive()sportsCar := assembly.Wheels(car.SteelWheels).TopSpeed(150 * car.MPH).Build()sportsCar.Drive() 应用场景: 构建复杂对象。 7. 工厂模式 将对象的实例化推迟到用于创建实例的专用功能 1234567891011121314151617181920package datatype StorageType intconst ( DiskStorage StorageType = 1 &lt;&lt; iota TempStorage MemoryStorage)func NewStore(t StorageType) Store { switch t { case MemoryStorage: return newMemoryStorage( /*...*/ ) case DiskStorage: return newDiskStorage( /*...*/ ) default: return newTempStorage( /*...*/ ) }} 使用 12345s, _ := data.NewStore(data.MemoryStorage)f, _ := s.Open(\"file\")n, _ := f.Write([]byte(\"data\"))defer f.Close() 使用工厂方法,用户可以指定所需的存储类型。工厂模式就是对开闭原则的一个最好诠释,只增加工厂类,不修改原类。 使用场景:对一类问题产生变化的可能性,有多种变化,选择。 7. 对象池模式 例化并维护一组相同类型的对象实例 对象池 12345678910111213package pooltype Pool chan *Objectfunc New(total int) *Pool { p := make(Pool, total) for i := 0; i &lt; total; i++ { p &lt;- new(Object) } return &amp;p} 使用 1234567891011p := pool.New(2)select {case obj := &lt;-p: obj.Do( /*...*/ ) p &lt;- objdefault: // No more objects left — retry later or fail return} 再 Golang 中已经有专门的sync.Pool封装好了 ,不需要自己单独写。 应用场景:对象初始化很多的情况下,由于对象已预先初始化,因此可以对象不需要再进行初始化,对耗时较长的创建对象是一个好的选择。,如果需要性能,而不是节省资源,维护对象池,不是一个好的选择。 8. 单利模式 将类型的实例化限制为一个对象 单利模式 1234567891011121314151617package singletontype singleton map[string]stringvar ( once sync.Once instance singleton)func New() singleton { once.Do(func() { instance = make(singleton) }) return instance} 使用 12345678s := singleton.New()s[\"this\"] = \"that\"s2 := singleton.New()fmt.Println(\"This is \", s2[\"this\"])// This is that 使用once语义可以保证内容只被一次,从而保证对象是单利的。 应用场景:单利类在初始创建后,就不应该被再操作,所以我认为单利类只是一堆包含数据的结构体,初始后状态不可变,可以被重复使用,而不用产生大量的对象,减少 GC 压力。 建造模式8. 装饰器模式静态地或动态地向对象添加行为 装饰 12345678910111213type Object func(int) intfunc LogDecorate(fn Object) Object { return func(n int) int { log.Println(\"Starting the execution with the integer\", n) result := fn(n) log.Println(\"Execution is completed with the result\", result) return result }} 使用 1234567func Double(n int) int { return n * 2}f := LogDecorate(Double)f(5) Double这个函数作为被装饰对象,使用LogDecorate装饰要被装饰的函数,老实说,我看着这个函数有点像 Spring 里面的 AOP 代理模式,感觉和代理模式也很像,但是是函数级别,并且处理结果可以再被处理,所以说是装饰模式也可以。 应用场景：拓展一个方法原有的功能 8. 代理模式提供对象的代理对象以控制其动作 123456789101112131415161718192021222324252627282930// To use proxy and to object they must implement same methodstype IObject interface { ObjDo(action string)}// Object represents real objects which proxy will delegate datatype Object struct { action string}// ObjDo implements IObject interface and handel's all logicfunc (obj *Object) ObjDo(action string) { // Action behavior fmt.Printf(\"I can, %s\", action)}// ProxyObject represents proxy object with intercepts actionstype ProxyObject struct { object *Object}// ObjDo are implemented IObject and intercept action before send in real Objectfunc (p *ProxyObject) ObjDo(action string) { if p.object == nil { p.object = new(Object) } if action == \"Run\" { p.object.ObjDo(action) // Prints: I can, Run }} 简单的用一句话来说就是将被代理对象传入代理对象,然后执行被代理对象的方法,并且执行代理对象自身的一些操作。 同步模式9. 信号量模式允许控制对公共资源的访问 1234567891011121314151617181920212223242526272829303132333435363738394041424344package semaphorevar ( ErrNoTickets = errors.New(\"semaphore: could not aquire semaphore\") ErrIllegalRelease = errors.New(\"semaphore: can't release the semaphore without acquiring it first\"))// Interface contains the behavior of a semaphore that can be acquired and/or released.type Interface interface { Acquire() error Release() error}type implementation struct { sem chan struct{} timeout time.Duration}func (s *implementation) Acquire() error { select { case s.sem &lt;- struct{}{}: return nil case &lt;-time.After(s.timeout): return ErrNoTickets }}func (s *implementation) Release() error { select { case _ = &lt;-s.sem: return nil case &lt;-time.After(s.timeout): return ErrIllegalRelease } return nil}func New(tickets int, timeout time.Duration) Interface { return &amp;implementation{ sem: make(chan struct{}, tickets), timeout: timeout, }} 信号量模式也好理解,就是同一时刻只有一个任务可以被执行,所以chan是一个阻塞chan, 当任务结束就是释放chan里面的元素,保持活跃,可以接受的状态。 应用场景:在该模式下,接收请求和执行下游依赖在同一个线程内完成,不存在线程上下文切换所带来的性能开销。 性能分析型10. 记时模式包装函数并记录执行 123456789101112package profileimport ( \"time\" \"log\")func Duration(invocation time.Time, name string) { elapsed := time.Since(invocation) log.Printf(\"%s lasted %s\", name, elapsed)} 使用 123456789101112func BigIntFactorial(x big.Int) *big.Int { // Arguments to a defer statement is immediately evaluated and stored. // The deferred function receives the pre-evaluated values when its invoked. defer profile.Duration(time.Now(), \"IntFactorial\") y := big.NewInt(1) for one := big.NewInt(1); x.Sign() &gt; 0; x.Sub(x, one) { y.Mul(y, x) } return x.Set(y)} 通过defer的妙用,将当前函数的开始时间可以记住,然后通过defer在函数执行完后才会调用defer函数。这样就达成了记时的作用,可以统计这段函数花费了多长时间,感觉很妙。 应用场景:进行基准测试的时候可以使用。 消息型11. 扇入消息传递模式 扇入是一种消息传递模式,用于为工作（客户端：源,服务器：目标）之间的工作创建漏斗。 我们可以使用Go channel 对扇入进行建模。 12345678910111213141516171819202122232425262728// Merge different channels in one channelfunc Merge(cs ...&lt;-chan int) &lt;-chan int { var wg sync.WaitGroup out := make(chan int) // Start an send goroutine for each input channel in cs. send // copies values from c to out until c is closed, then calls wg.Done. send := func(c &lt;-chan int) { for n := range c { out &lt;- n } wg.Done() } wg.Add(len(cs)) for _, c := range cs { go send(c) } // Start a goroutine to close out once all the send goroutines are // done. This must start after the wg.Add call. go func() { wg.Wait() close(out) }() return out} 简单的说就是用多个goroutine异步写入多个chan里面的消息到另一个chan,所以叫Merge过程。 应用场景:对数据进行整合。 12. 扇入消息传递模式 扇出是一种消息传递模式,用于在工（生产者：源,消费者：目的地）之间分配工作。 123456789101112131415161718192021222324252627282930313233343536// Split a channel into n channels that receive messages in a round-robin fashion.func Split(ch &lt;-chan int, n int) []&lt;-chan int { cs := make([]chan int) for i := 0; i &lt; n; i++ { cs = append(cs, make(chan int)) } // Distributes the work in a round robin fashion among the stated number // of channels until the main channel has been closed. In that case, close // all channels and return. distributeToChannels := func(ch &lt;-chan int, cs []chan&lt;- int) { // Close every channel when the execution ends. defer func(cs []chan&lt;- int) { for _, c := range cs { close(c) } }(cs) for { for _, c := range cs { select { case val, ok := &lt;-ch: if !ok { return } c &lt;- val } } } } go distributeToChannels(ch, cs) return cs} 将一个chan的内容拆分到多个chan里面 （通过 goroutine 并发模式） 应用场景:拆分一堆任务成多个任务。 13. 发布和订阅消息传递模式 发布-订阅是一种消息传递模式,用于在消息之间进行消息传递不同的组件,而这些组件不了解彼此的身份。 消息,发布者 1234567891011121314151617181920type Message struct { // Contents}type Subscription struct { ch chan&lt;- Message Inbox chan Message}func (s *Subscription) Publish(msg Message) error { if _, ok := &lt;-s.ch; !ok { return errors.New(\"Topic has been closed\") } s.ch &lt;- msg return nil} 订阅者 1234567891011121314151617181920type Topic struct { Subscribers []Session MessageHistory []Message}func (t *Topic) Subscribe(uid uint64) (Subscription, error) { // Get session and create one if it's the first // Add session to the Topic &amp; MessageHistory // Create a subscription}func (t *Topic) Unsubscribe(Subscription) error { // Implementation}func (t *Topic) Delete() error { // Implementation} 123456789type User struct { ID uint64 Name string}type Session struct { User User Timestamp time.Time} 观察者和发布订阅模式的区别是,观察者模式的通知对象只有一个,而发布订阅模式,一个订阅着可以订阅多个发布者对象。发布订阅模式需要进行手动消费,而观察者模式则自动触发操作。 应用场景:发布订阅者模式更适合多对多消息变化的应用场景。 稳定模式14. 熔断器模式 类似于电熔丝,可防止在连接电路电流过大时引发火灾,这导致电线加热并燃烧,断路器的设计模式是“故障优先”关闭电路,请求/响应关系或机制的机制在软件开发的情况下提供服务,以防止更大的失败。 操作计数器 circuit.Counter是一个简单的计数器,用于记录成功或失败的状态电路和时间戳,并计算连续的失败。 1234567891011121314151617181920package circuitimport ( \"time\")type State intconst ( UnknownState State = iota FailureState SuccessState)type Counter interface { Count(State) ConsecutiveFailures() uint32 LastActivity() time.Time Reset()} 1234567891011121314151617181920package circuitimport ( \"time\")type State intconst ( UnknownState State = iota FailureState SuccessState)type Counter interface { Count(State) ConsecutiveFailures() uint32 LastActivity() time.Time Reset()} 使用`circuit.Breaker’闭包来包装Circuit,该闭包保留内部操作计数器。如果电路连续故障超过指定阈值,它将返回快速错误。一段时间后,它重试该请求并记录下来。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package circuitimport ( \"context\" \"time\")type Circuit func(context.Context) errorfunc Breaker(c Circuit, failureThreshold uint32) Circuit { // 一个计数器 cnt := NewCounter() return func(ctx context) error { // 计数器超过阀值 if cnt.ConsecutiveFailures() &gt;= failureThreshold { // 判断是否可以重试的条件 canRetry := func(cnt Counter) { backoffLevel := Cnt.ConsecutiveFailures() - failureThreshold // Calculates when should the circuit breaker resume propagating requests // to the service shouldRetryAt := cnt.LastActivity().Add(time.Seconds * 2 &lt;&lt; backoffLevel) return time.Now().After(shouldRetryAt) } // 不返回错误,继续执行。 if !canRetry(cnt) { // Fails fast instead of propagating requests to the circuit since // not enough time has passed since the last failure to retry return ErrServiceUnavailable } } // Unless the failure threshold is exceeded the wrapped service mimics the // old behavior and the difference in behavior is seen after consecutive failures if err := c(ctx); err != nil { cnt.Count(FailureState) return err } cnt.Count(SuccessState) return nil }} 上面这个例子太简单了,概括为熔断器超过阀值时（可提供一定的尝试次数）,不直接执行方法,直接返回错误,防止更大的破坏,等过一段时间后自动恢复。 应用场景:微服务之间的调用,为了下游服务阻塞上游服务卡住,直接将下游服务断开,快速失败,避免其他服务也不能正常使用。","link":"/2020/04/07/Go/%E6%88%91%E5%AF%B9%E4%BA%8EGolang%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B8%AD%E4%B8%8D%E5%90%8C%E7%9A%84%E7%90%86%E8%A7%A3/"},{"title":"Manjaro 常用软件及设置","text":"Manjaro Linux是基于Arch Linux 的 Linux 发行版,使用 Xfce 和 KDE Plasma 作为默认桌面环境,和 Arch 一样,采用滚动更新。其目标是为PC 提供易于使用的自由的操作系统 一、设置更新源在 终端 执行下面的命令从官方的源列表中对中国源进行测速和设置1sudo pacman-mirrors -gb testing -c China 加Arch Linux CN源在 /etc/pacman.conf 文件末尾添加两行：12[archlinuxcn]Server = https://mirrors.ustc.edu.cn/archlinuxcn/$arch 安装aria2并加速源下载1.首先在终端中执行下面的命令安装aria21sudo pacman -S aria2 2.修改/etc/pacman.conf,在 [option] 增加或修改为下面的内容：1XferCommand = /usr/bin/aria2c --allow-overwrite=true -c --file-allocation=falloc --log-level=error -m2 --max-connection-per-server=5 --max-file-not-found=5 --min-split-size=5M --no-conf --remote-time=true --summary-interval=60 -t10 -d / -o %o %u 二、系统设置更新系统1sudo pacman -Syyu 安装中文输入法安装fcitx框架1sudo pacman -S --noconfirm fcitx-im kcm-fcitx fcitx-sogoupinyin 配置 ~/.xprofile 文件使输入法可以在kde的窗口中输入1sudo echo -e \"export GTK_IM_MODULE=fcitx\\nexport QT_IM_MODULE=fcitx\\nexport XMODIFIERS=@im=fcitx\"&gt;&gt;~/.xprofile 三、常用设置登录后开启数字锁1yaourt -S --noconfirm systemd-numlockontty&amp;&amp;sudo systemctl enable numLockOnTty.service 四、常用软件YaourtYaourt可用于查找软件包(包括[core] [extra] [community] AUR的软件包,pacman只能查找非AUR的软件包)。1sudo pacman -S --noconfirm yaourt 日常软件netease-cloud-music 网易云音乐； smplayer 视频播放器； google-chrome 谷歌浏览器； notepadqq 像notepad++文本编辑； sublime-text-dev-zh-cn 强大的开发必备文本编辑器；(有能力采用付费许可证) masterpdfeditor 对linux用户免费的PDF浏览及编辑器,支持实时预览； remarkable 卓越且功能齐全的 Markdown 编辑器； uget 媲美迅雷的下载工具； filezilla 强大的FTP工具； shadowsocks-qt5 翻墙工具,配合浏览器插件SwitchyOmega使用； deepin-screenshot 深度截图工具； shutter 强大的截图工具,gnome-web-photo配合使用； variety 随即更换壁纸的应用； ccal 终端农历日历,终端启动ccal； 1yaourt -Sy --noconfirm netease-cloud-music smplayer smplayer-skins smplayer-themes google-chrome sublime-text-dev-zh-cn masterpdfeditor remarkable uget filezilla shadowsocks-qt5 deepin-screenshot shutter Xmind1yaourt -Sy --noconfirm xmind #需要网络 Fish安装Fish1sudo pacman -S fish 更换默认的shell1chsh -s /usr/bin/fish Git 1sudo pacman -S git","link":"/2018/11/08/Linux/Manjaro-%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E5%8F%8A%E8%AE%BE%E7%BD%AE/"},{"title":"使用 Git 代理为 Github 提速","text":"git clone一个github上的仓库,太慢,经常连接失败,如何解决呢？下面我从网上找到一些解决方法,并且亲自实践过,可行,在这里分享给大家。 走 HTTP 代理12git config --global http.proxy \"http://127.0.0.1:8080\"git config --global https.proxy \"http://127.0.0.1:8080\" 走 socks5 代理（如 Shadowsocks）12git config --global http.proxy \"socks5://127.0.0.1:1080\"git config --global https.proxy \"socks5://127.0.0.1:1080\" 取消设置12git config --global --unset http.proxygit config --global --unset https.proxy SSH 形式修改~/.ssh/config文件（不存在则新建）： 123456789# 这里必须是 github.com，因为这个跟我们 clone 代码时的链接有关Host github.com # 如果用默认端口，这里是 github.com，如果想用443端口，这里就是 ssh.github.com 详见 https://help.github.com/articles/using-ssh-over-the-https-port/ HostName github.com User git # 走 HTTP 代理 # ProxyCommand socat - PROXY:127.0.0.1:%h:%p,proxyport=1087 # 如果是 socks5 代理，则把下面这行取消注释，并把 7891 改成自己 socks5 代理的端口 ProxyCommand nc -v -x 127.0.0.1:7891 %h %p","link":"/2020/02/27/Linux/%E4%BD%BF%E7%94%A8Git%E4%BB%A3%E7%90%86%E4%B8%BAGithub%E6%8F%90%E9%80%9F/"},{"title":"深入理解Rust所有权与借用","text":"在 rust 中，一个变量的状态只可能是两种，一种是拥有变量的所有权，一种是拥有该变量的借用。当我们想使用变量但是又不想转移变量的所有权时我们会使用借用。有什么区别呢？如果一个变量拥有对该变量的所有权，代表可以对该变量进行任何操作，可以将旧的变量隐藏，重新声明一个可变或者不可变的变量，又或者重新转移给新的一个变量。但是借用变量不可能将一个可变变量或者不可变量重新变为其对抗的属性，也就是说，借用变量不能拥有该变量的全部控制权。 所有权使用所有权隐藏一个旧变量，将其由一个不可变变量变为一个可变的变量。 隐藏123456fn main() { let a = String::from(\"abc\"); let mut a = a; a.push_str(\"d\"); println!(\"{:?}\", a)} 结果：&quot;abcd&quot; 重新声明使用所有权重新声明一个变量，将其由一个不可变变量变为一个可变的变量。 123456fn main() { let a = String::from(\"abc\"); let mut a = a; a.push_str(\"d\"); println!(\"{:?}\", a)} 结果：&quot;abcd&quot; 上面两种情况下旧的变量旧不能使用了，因为他们的所有权已经被转移，这样是为了防止一个变量被释放两次。 可变转为不可变123456fn main() { let mut a = String::from(\"abc\"); let b = &amp; a; b.push_str(\"d\"); println!(\"{:?}\", b)} 结果: error[E0596]: cannot borrow `*b` as mutable, as it is behind a `&amp;` reference --&gt; src/main.rs:295:5 | 294 | let b = &amp; a; | --- help: consider changing this to be a mutable reference: `&amp;mut a` 295 | b.push_str(&quot;d&quot;); | ^ `b` is a `&amp;` reference, so the data it refers to cannot be borrowed as mutable 借用一个owner下有多个的不可变借用的情况rust 中的借用很像读写锁，可以同时被多个不可变变量持有借用或者只被一个可变变量借用。但是假如owner变量本身就是不可变的那么被借用后也一定是不可变的。 正确: 1234567fn main() { let a = String::from(\"abc\"); let b = &amp;a; let c = &amp;a; println!(\"{:?}\", b); println!(\"{:?}\", c);} 结果:// &quot;abc&quot; // &quot;abc&quot; 一个owner下有多个的可变借用的情况错误: 1234567fn main() { let mut a = String::from(\"abc\"); let b = &amp;mut a; let c = &amp;mut a; println!(\"{:?}\", b); println!(\"{:?}\", c);} 结果： error[E0499]: cannot borrow `a` as mutable more than once at a time --&gt; src/main.rs:302:13 | 301 | let b = &amp;mut a; | ------ first mutable borrow occurs here 302 | let c = &amp;mut a; | ^^^^^^ second mutable borrow occurs here 303 | println!(&quot;{:?}&quot;, b); | - first borrow later used here 一个owner下有一个的可变借用和一个不可变变借用的情况1234567fn main() { let mut a = String::from(\"abc\"); let b = &amp;mut a; let c = &amp;a; println!(\"{:?}\", b); println!(\"{:?}\", c);} 结果： error[E0502]: cannot borrow `a` as immutable because it is also borrowed as mutable --&gt; src/main.rs:302:13 | 301 | let b = &amp;mut a; | ------ mutable borrow occurs here 302 | let c = &amp;a; | ^^ immutable borrow occurs here 303 | println!(&quot;{:?}&quot;, b); | - mutable borrow later used here 一个owner下有一个的可变借用 123456 fn main() { let mut a = String::from(\"abc\"); let b = &amp;mut a; b.push_str(\"d\"); println!(\"{:?}\", b)} 结果：&quot;abcd&quot; 结论rust 所有权是与借用机制可以帮助rust避免使用gc回收，通过在变量在函数作用结束时来结束变量的声明周期，通过该机制可以做到不使用gc。借用机制可以防止我们在编写多线程的时候能够避免竞态，从根源上来避免错误。","link":"/2020/08/22/Rust/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Rust%E6%89%80%E6%9C%89%E6%9D%83%E4%B8%8E%E5%80%9F%E7%94%A8/"},{"title":"得到 Golang 程序的汇编代码的方法","text":"有多种方式可以获得Go程序的汇编代码, 尽管输出的格式有些不同,但是都是方便阅读的汇编代码,可以帮助我们更好的了解程序的底层运行方式。 方法一: go tool compile使用go tool compile -N -l -S once.go生成汇编代码： 12345678910111213141516171819➜ awesomeProject go tool compile -N -l -S main.go\"\".main STEXT size=165 args=0x0 locals=0x58 0x0000 00000 (main.go:22) TEXT \"\".main(SB), ABIInternal, $88-0 0x0000 00000 (main.go:22) MOVQ (TLS), CX 0x0009 00009 (main.go:22) CMPQ SP, 16(CX) 0x000d 00013 (main.go:22) JLS 155 0x0013 00019 (main.go:22) SUBQ $88, SP 0x0017 00023 (main.go:22) MOVQ BP, 80(SP) 0x001c 00028 (main.go:22) LEAQ 80(SP), BP 0x0021 00033 (main.go:22) FUNCDATA $0, gclocals·7d2d5fca80364273fb07d5820a76fef4(SB) 0x0021 00033 (main.go:22) FUNCDATA $1, gclocals·d2eb33d7ca216c70530f751d6fdafd01(SB) 0x0021 00033 (main.go:22) FUNCDATA $3, gclocals·9fb7f0986f647f17cb53dda1484e0f7a(SB) 0x0021 00033 (main.go:23) PCDATA $2, $1 0x0021 00033 (main.go:23) PCDATA $0, $0 0x0021 00033 (main.go:23) LEAQ \"\"..autotmp_2+24(SP), AX 0x0026 00038 (main.go:23) PCDATA $0, $1 0x0026 00038 (main.go:23) MOVQ AX, \"\"..autotmp_1+48(SP) 0x002b 00043 (main.go:23) PCDATA $2, $0 .... 方法二: go tool objdump首先先编译程序:go tool compile -N -l once.go, 使用go tool objdump once.o反汇编出代码 (或者使用go tool objdump -s Do once.o反汇编特定的函数： 1234567891011121314151617181920➜ awesomeProject go tool compile -N -l main.go➜ awesomeProject go tool objdump main.oTEXT %22%22.main(SB) gofile../Users/zhubowen/golangProjects/awesomeProject/main.go main.go:22 0x4cf 65488b0c2500000000 MOVQ GS:0, CX [5:9]R_TLS_LE main.go:22 0x4d8 483b6110 CMPQ 0x10(CX), SP main.go:22 0x4dc 0f8688000000 JBE 0x56a main.go:22 0x4e2 4883ec58 SUBQ $0x58, SP main.go:22 0x4e6 48896c2450 MOVQ BP, 0x50(SP) main.go:22 0x4eb 488d6c2450 LEAQ 0x50(SP), BP main.go:23 0x4f0 488d442418 LEAQ 0x18(SP), AX main.go:23 0x4f5 4889442430 MOVQ AX, 0x30(SP) main.go:23 0x4fa 8400 TESTB AL, 0(AX) main.go:23 0x4fc 488b0500000000 MOVQ 0(IP), AX [3:7]R_PCREL:%22%22.statictmp_0 main.go:23 0x503 4889442418 MOVQ AX, 0x18(SP) main.go:23 0x508 0f100500000000 MOVUPS 0(IP), X0 [3:7]R_PCREL:%22%22.statictmp_0+8 main.go:23 0x50f 0f11442420 MOVUPS X0, 0x20(SP) main.go:23 0x514 488b442430 MOVQ 0x30(SP), AX .... 方法三: go build -gcflags -S使用go build -gcflags -S once.go也可以得到汇编代码： 12345678910111213141516171819202122232425262728293031323334➜ awesomeProject go build -gcflags -S main.go# command-line-arguments\"\".main STEXT size=112 args=0x0 locals=0x38 0x0000 00000 (/Users/zhubowen/golangProjects/awesomeProject/main.go:22) TEXT \"\".main(SB), ABIInternal, $56-0 0x0000 00000 (/Users/zhubowen/golangProjects/awesomeProject/main.go:22) MOVQ (TLS), CX 0x0009 00009 (/Users/zhubowen/golangProjects/awesomeProject/main.go:22) CMPQ SP, 16(CX) 0x000d 00013 (/Users/zhubowen/golangProjects/awesomeProject/main.go:22) JLS 105 0x000f 00015 (/Users/zhubowen/golangProjects/awesomeProject/main.go:22) SUBQ $56, SP 0x0013 00019 (/Users/zhubowen/golangProjects/awesomeProject/main.go:22) MOVQ BP, 48(SP) 0x0018 00024 (/Users/zhubowen/golangProjects/awesomeProject/main.go:22) LEAQ 48(SP), BP 0x001d 00029 (/Users/zhubowen/golangProjects/awesomeProject/main.go:22) FUNCDATA $0, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x001d 00029 (/Users/zhubowen/golangProjects/awesomeProject/main.go:22) FUNCDATA $1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x001d 00029 (/Users/zhubowen/golangProjects/awesomeProject/main.go:22) FUNCDATA $3, gclocals·9fb7f0986f647f17cb53dda1484e0f7a(SB) 0x001d 00029 (/Users/zhubowen/golangProjects/awesomeProject/main.go:23) PCDATA $2, $0 0x001d 00029 (/Users/zhubowen/golangProjects/awesomeProject/main.go:23) PCDATA $0, $0 0x001d 00029 (/Users/zhubowen/golangProjects/awesomeProject/main.go:23) MOVQ \"\".statictmp_0(SB), AX 0x0024 00036 (/Users/zhubowen/golangProjects/awesomeProject/main.go:23) MOVQ AX, \"\"..autotmp_2+24(SP) 0x0029 00041 (/Users/zhubowen/golangProjects/awesomeProject/main.go:23) MOVUPS \"\".statictmp_0+8(SB), X0 0x0030 00048 (/Users/zhubowen/golangProjects/awesomeProject/main.go:23) MOVUPS X0, \"\"..autotmp_2+32(SP) 0x0035 00053 (/Users/zhubowen/golangProjects/awesomeProject/main.go:24) CALL runtime.printlock(SB) 0x003a 00058 (/Users/zhubowen/golangProjects/awesomeProject/main.go:24) PCDATA $2, $1 0x003a 00058 (/Users/zhubowen/golangProjects/awesomeProject/main.go:24) LEAQ \"\"..autotmp_2+24(SP), AX 0x003f 00063 (/Users/zhubowen/golangProjects/awesomeProject/main.go:24) PCDATA $2, $0 0x003f 00063 (/Users/zhubowen/golangProjects/awesomeProject/main.go:24) MOVQ AX, (SP) 0x0043 00067 (/Users/zhubowen/golangProjects/awesomeProject/main.go:24) MOVQ $3, 8(SP) 0x004c 00076 (/Users/zhubowen/golangProjects/awesomeProject/main.go:24) MOVQ $3, 16(SP) 0x0055 00085 (/Users/zhubowen/golangProjects/awesomeProject/main.go:24) CALL runtime.printslice(SB) 0x005a 00090 (/Users/zhubowen/golangProjects/awesomeProject/main.go:24) CALL runtime.printunlock(SB) 0x005f 00095 (/Users/zhubowen/golangProjects/awesomeProject/main.go:25) MOVQ 48(SP), BP 0x0064 00100 (/Users/zhubowen/golangProjects/awesomeProject/main.go:25) ADDQ $56, SP .... 总结 go tool compile和go build -gcflags -S生成的是过程中的汇编。 最终的机器码的汇编可以通过go tool objdump生成。","link":"/2020/03/02/Go/%E5%BE%97%E5%88%B0Golang%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%B1%87%E7%BC%96%E4%BB%A3%E7%A0%81%E7%9A%84%E6%96%B9%E6%B3%95%20/"},{"title":"Golang 面试题","text":"整理了一些面试题,关于go语言面试会考的东西,顺便整理自己的知识体系。 一、语言机制 select是随机的还是顺序的？ 先说答案,select会随机选择一个可用通道做收发操作。为什么呢？在源码中每一个select对应一个hselect结构,每个hselect结构下面都有个scase的数组记录每个case,在scase中记录着ch chan的结构也就是channel的结构pollorder将元素从新排列,scase就被乱序了。 2.Go语言局部变量分配在栈还是堆？ 视逃逸分析结果而定,Go语言编译器会自动决定把一个变量放在栈还是放在堆,编译器会做逃逸分析,当发现变量的作用域没有跑出函数范围,就可以在栈上,反之则必须分配在堆。 参考资料 : GO语言变量逃逸分析 3.Go语言逃逸分析有那集中场景? 指针逃逸 : 典型的逃逸case,函数返回局部变量的指针。 间接赋值 : 对某个引用类对象中的引用类成员进行赋值。Go 语言中的引用类数据类型有 func, interface, slice, map, chan, *Type(指针)。 栈空间不足逃逸 : 当对象大小超过的栈帧大小时（详见go内存分配）,变量对象发生逃逸被分配到堆上。 闭包引用逃逸 : 外部函数引用内部函数变量,发生逃逸,分配到堆上。 动态类型逃逸 : 当对象不确定大小或者被作为不确定大小的参数时发生逃逸。 切片或map赋值 : 在给切片或者map赋值对象指针（与对象共享内存地址时）,对象会逃逸到堆上。但赋值对象值或者返回对象值切片是不会发生逃逸的。 不要盲目使用变量的指针作为函数参数,虽然它会减少复制操作。但其实当参数为变量自身的时候,复制是在栈上完成的操作,开销远比变量逃逸后动态地在堆上分配内存少的多。 4.简述一下你对Go垃圾回收机制的理解？ v1.1 STWv1.3 Mark STW, Sweep 并行v1.5 三色标记法v1.8 hybrid write barrier(混合写屏障：优化STW) 参考资料 : Go实时GC——三色算法理论与实践, Golang 垃圾回收剖析 5.简述一下golang的协程调度原理? M(machine): 关联了一个内核线程。P(processor): 代表了M所需的上下文环境,也是处理用户级代码逻辑的处理器。G(goroutine): 调度系统的最基本单位goroutine,存储了goroutine的执行stack信息、goroutine状态以及goroutine的任务函数等。 参考资料 : Go并发原理 6.简单介绍下 golang 中 make 和 new 的区别？ new(T)是为一个 T 类型的新值分配空间, 并将此空间初始化为 T 的零值, 并返回这块内存空间的地址, 也就是 T 类型的指针 *T, 该指针指向 T 类型值占用的那块内存. make(T)返回的是初始化之后的 T (引用类型本身), 且只能用于 slice, map, channel 三种类型. make(T, args) 返回初始化之后 T 类型的值, 且此新值并不是 T 类型的零值, 也不是 T 类型的指针 *T, 而是 T 类型值经过初始化之后的引用. 参考资料 : Go语言中new和make的区别 7.介绍下你平时都是怎么调试 golang 的 bug 以及性能问题的? panic 调用栈 pprof 火焰图(配合压测) 使用go run -race或者go build -race来进行竞争检测 查看系统 磁盘IO/网络IO/内存占用/CPU 占用(配合压测) 8.如何获取 go 程序运行时的协程数量, gc 时间, 对象数, 堆栈信息? 调用接口runtime.ReadMemStats可以获取以上所有信息, 注意: 调用此接口会触发 STW(Stop The World) 9.介绍下 golang 的 runtime 机制? runtime 负责管理任务调度,垃圾收集,以及运行环境。go提供了一些高级的功能,如goroutine, channel, 以及Garbage collection。这些高级功能需要一个runtime的支持. runtime和用户编译后的代码被linker静态链接起来,形成一个可执行文件。这个文件从操作系统角度来说是一个user space的独立的可执行文件。 从运行的角度来说,这个文件由2部分组成,一部分是用户的代码,另一部分就是runtime。runtime通过接口函数调用来管理goroutine, channel及其他一些高级的功能。从用户代码发起的调用操作系统API的调用都会被runtime拦截并处理。 Go runtime的一个重要的组成部分是goroutine scheduler。他负责追踪,调度每个goroutine运行,实际上是从应用程序的process所属的thread pool中分配一个thread来执行这个goroutine。因此,和java虚拟机中的Java thread和OS thread映射概念类似,每个goroutine只有分配到一个OS thread才能运行。 10.goroutine池是否像其他语言中的线程池一样有意义？ 视情况而定,调度程序中的状态成本可以忽略不计,但是goroutine保持的状态重新创建的成本可能很高。后一点可用作将goroutine保留在池中的理由。但是,另一方面,在大多数情况下,将执行类似任务的goroutine的资源组池化（而不是goroutine本身）更容易。 参考资料 : Does a goroutine pool make sense like thread pools in other languages?","link":"/2020/04/02/%E9%9D%A2%E8%AF%95/Golang%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"title":"(译) Epoll,Select,Poll系统架构之间的实际差异","text":"在设计具有非阻塞套接字I / O的高性能网络应用程序时,架构师需要决定使用哪种轮询方法来监视这些套接字生成的事件。有几种这样的方法,每种方法的用例都不同。选择正确的方法对于满足应用需求可能至关重要。 本文重点介绍了轮询方法之间的差异,并提供了使用的建议。 目录 使用select进行轮询 使用poll进行轮询 使用epoll进行轮询 使用libevent进行轮询 使用select轮询从套接字仍被称为伯克利套接字的时代起,老的,值得信赖的劳动力。它并没有成为第一个规范,因为当时没有非阻塞I / O的概念,但它确实使它大约八十年代,并且在它的界面中没有任何改变。 要使用select,开发人员需要使用描述符和要监视的事件初始化并填充几个fd_set结构,然后调用select （）。典型的工作流程如下： 123456789101112131415161718192021222324252627282930313233343536fd_set fd_in, fd_out;struct timeval tv; // Reset the setsFD_ZERO( &amp;fd_in );FD_ZERO( &amp;fd_out ); // Monitor sock1 for input eventsFD_SET( sock1, &amp;fd_in ); // Monitor sock2 for output eventsFD_SET( sock2, &amp;fd_out ); // Find out which socket has the largest numeric value as select requires itint largest_sock = sock1 &gt; sock2 ? sock1 : sock2; // Wait up to 10 secondstv.tv_sec = 10;tv.tv_usec = 0; // Call the selectint ret = select( largest_sock + 1, &amp;fd_in, &amp;fd_out, NULL, &amp;tv ); // Check if select actually succeedif ( ret == -1 ) // report error and abortelse if ( ret == 0 ) // timeout; no event detectedelse{ if ( FD_ISSET( sock1, &amp;fd_in ) ) // input event on sock1 if ( FD_ISSET( sock2, &amp;fd_out ) ) // output event on sock2} 当设计和开发选择界面时,没有人可能期望会有多线程应用程序服务于数千个连接。因此,select带来了相当多的设计缺陷,这使得它不适合作为现代网络应用中的轮询机制。主要缺点包括： select修改传递的fd_sets,这样就不能重用它们。即使您不需要更改任何内容 - 例如,如果其中一个描述符接收到数据并需要接收更多数据 - 整个集合必须重新创建（argh！）或通过FD_COPY从备份副本恢复。每次调用select时都必须这样做。 要找出引发事件的描述符,您必须手动迭代集合中的所有描述符,并在每个描述符上调用FD_ISSET。如果你有2,000个这样的描述符,并且只有其中一个是活动的 - 而且可能是最后一个 - 你每次等待都会浪费CPU周期。 我刚刚提到了2000个描述符吗？好吧,选择不能支持那么多。至少在Linux上。支持的描述符的最大数量由FD_SETSIZE常量定义,Linux很高兴地将其定义为1024.虽然某些操作系统允许您通过在包含sys / select.h之前重新定义FD_SETSIZE来破解此限制,但这不是可移植的。实际上,Linux会忽略这种黑客攻击并且限制将保持不变。 在等待时,您无法从其他线程修改描述符集。假设一个线程正在执行上面的代码。现在假设你有一个管家线程,它决定了sock1等待输入数据的时间太长了,现在是时候切断电源线了。由于此套接字可以重用于另一个付费工作客户端,因此管家线程想要关闭套接字。但是套接字位于fd_set中,select正在等待。 现在当这个套接字关闭时会发生什么？男人选择有答案,你不会喜欢它。答案是,“如果select（）监视的文件描述符在另一个线程中关闭,则结果未指定”。 如果另一个线程突然决定通过sock1发送内容,则会出现同样的问题。在select返回之前,无法开始监视输出事件的套接字。 等待的事件的选择是有限的; 例如,要检测远程套接字是否已关闭,您必须a）监视它以进行输入; b）实际尝试从套接字读取数据以检测闭包（读取将返回0）。如果你想从这个套接字读取,这很好,但是如果你现在发送一个文件并且不关心任何输入怎么办？ 当填充描述符列表以计算最大描述符编号并将其作为函数参数提供时,select会给您带来额外负担。 当然,操作系统开发人员在设计poll方法时会认识到这些缺点并解决了大部分问题。因此您可能会问,是否有任何理由使用select？为什么不把它存放在计算机科学博物馆的架子上？然后你可能会高兴地知道是的,有两个原因,对你来说可能非常重要或根本不重要。 第一个原因是便携性。select已经存在很长时间了,你可以确定每个具有网络支持和非阻塞套接字的平台都有一个工作选择实现,而它可能根本没有轮询。不幸的是,我不是在谈论管和ENIAC; poll仅适用于Windows Vista及更高版本,其中包括Windows XP - 尽管有微软的压力,截至2013年9月仍有34％的用户使用此版本。另一个选择是仍然在这些平台上使用poll并使用select模拟它 那些没有它的人; 您是否认为合理的投资取决于您自己。 第二个原因是更具异国情调,并且与选择可以 - 理论上 - 以1纳秒的精度处理超时的事实有关,而poll和epoll都只能处理1毫秒的精度。这可能不是桌面或服务器系统的问题,时钟甚至不能以如此精确的速度运行,但在与某些硬件组件交互时可能需要在实时嵌入式平台上运行。如降低控制棒关闭核反应堆 - 在这种情况下,请使用选择,以确保我们都安全！ 上面的情况可能是你必须使用select而不能使用其他任何东西的唯一情况。但是,如果您正在编写一个永远不必处理多个套接字（例如200）的应用程序,则使用poll和select之间的区别不是基于性能,而是基于个人偏好或其他因素。 使用poll进行轮询poll是一种较新的轮询方法,可能是在有人真正尝试编写高性能网络服务器之后立即创建的。它的设计要好得多,并且不会遇到大多数选择的问题。在绝大多数情况下,您将在poll和epoll / libevent之间进行选择。 要使用poll,开发人员需要初始化struct pollfd的成员具有要监视的描述符和事件的结构,并调用轮询（）。典型的工作流程如下： 1234567891011121314151617181920212223242526272829// The structure for two eventsstruct pollfd fds[2]; // Monitor sock1 for inputfds[0].fd = sock1;fds[0].events = POLLIN; // Monitor sock2 for outputfds[1].fd = sock2;fds[1].events = POLLOUT; // Wait 10 secondsint ret = poll( &amp;fds, 2, 10000 );//检查轮询是否实际成功if（ret == -1） //报告错误并中止else if（ret == 0） // timeout; 任何情况下,检测到的else{ //如果我们检测的情况下,零出来,所以我们可以重用该结构 if（PFD [0] .revents＆POLLIN） PFD [0] .revents = 0; //在sock1上输入事件 if（pfd [1] .revents＆POLLOUT） pfd [1] .revents = 0; //上sock2输出事件} poll主要用于修复select has has的挂起问题,因此它具有以下优点： poll可以监视的描述符数量没有硬性限制,因此1024的限制不适用于此处。 它不会修改struct pollfd数据中传递的数据。因此,只要将生成事件的描述符的revents成员设置为零,就可以在poll（）调用之间重用它。 IEEE规范声明“在每个pollfd结构中,poll（）应清除revents成员,除了应用程序通过设置上面列出的事件之一请求报告条件,poll（）应设置相应的位如果请求的条件为真,则在revents中“。但是根据我的经验,至少有一个平台没有遵循这个建议,并且Linux上的man 2 poll也没有做出这样的保证（尽管 man 3 ppoll）。 与select相比,它允许更精细的事件控制。例如,它可以检测远程对等关闭,而无需监视读取事件。 还存在一些缺点,这些缺点在选择部分的末尾已经提到过。值得注意的是,早于Vista的Microsoft Windows上不存在poll;在Vista及以上它被称为WSAPoll虽然原型是相同的,它可以简单地定义为：123#if defined (WIN32)static inline int poll( struct pollfd *pfd, int nfds, int timeout) { return WSAPoll ( pfd, nfds, timeout ); }#endif 并且,如上所述,轮询超时具有1ms的精度,这在大多数情况下也不太可能成为问题。然而,poll仍有一些问题需要牢记： 与select一样,仍然无法找出哪些描述符触发了事件而没有遍历整个列表并检查revents。更糟糕的是,内核空间也是如此,因为内核必须遍历文件描述符列表以找出受监视的套接字,并再次遍历整个列表以设置事件。 与select类似,无法动态修改集合或关闭正在轮询的套接字（参见上文）。 但请记住,对于大多数客户端网络应用程序而言,这些问题可能被认为是不重要的 - 唯一的例外是P2P等客户端软件,可能需要处理数千个打开的连接。即使对于某些服务器应用程序,这些问题也许并不重要因此,除非您有上述具体原因,否则poll应该是您的默认选择。更多,如果以下情况属实,poll应该是您首选的方法,即使是epoll： 您需要支持的不仅仅是Linux,并且不想使用像libevent这样的epoll包装器（epoll仅适用于Linux）; 您的应用程序需要一次监控少于1000个套接字（您不太可能看到使用epoll的任何好处）; 您的应用程序需要一次监视超过1000个套接字,但连接非常短暂（这是一个接近的情况,但很可能在这种情况下,您不太可能看到使用epoll的任何好处,因为加速将这些新描述符添加到集合中会浪费事件等待 - 见下文 您的应用程序的设计方式不是在另一个线程等待它们时更改事件（即您没有使用kqueue或IO完成端口移植应用程序）。 使用epoll进行轮询epoll是Linux（也是Linux）中最新,最好,最新的轮询方法。好吧,它实际上是在2002年添加到内核中的,所以它并不是那么新。它与poll和select不同,它保留了内核中当前监视的描述符和相关事件的信息,并导出API以添加/删除/修改它们。 要使用epoll,需要做更多的准备工作。开发人员需要： 通过调用epoll_create创建epoll描述符;使用所需事件和上下文数据指针初始化struct epoll结构。上下文可以是任何东西,epoll将此值直接传递给返回的事件结构。我们在那里存储了一个指向Connection类的指针。 调用epoll_ctl（… EPOLL_CTL_ADD）将描述符添加到监视集中 调用epoll_wait（）等待我们保留存储空间的20个事件。与以前的方法不同,此调用接收空结构,并仅使用触发事件填充它。例如,如果有200个描述符,其中5个具有待处理的事件,则epoll_wait将返回5,并且仅初始化pevents结构的前五个成员。如果50个描述符有待处理的事件,则前20个将被复制,30个将被留在队列中,它们不会丢失。 迭代返回的项目。这将是一个短暂的迭代,因为返回的唯一事件是被触发的事件。 典型的工作流程如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445//创建epoll描述符。每个应用程序只需要一个,并用于监视所有套接字。//函数参数被忽略（它不是之前,但现在它是）,所以把你最喜欢的数字放在int pollingfd = epoll_create（0xCAFE）; if（pollingfd &lt;0） //报告错误//初始化epoll结构以防将来添加更多成员epoll_event ev = {0}; //将连接类实例与事件相关联。你可以关联任何你想要的东西,epoll不会使用这些信息。我们存储一个连接类指针,pConnection1 ev.data.ptr = pConnection1; //监视输入,并且在事件发生后不自动重新设置描述符ev.events = EPOLLIN | EPOLLONESHOT;//将描述符添加到监视列表中。我们可以做到这一点,即使另一个线程//在epoll_wait中等待 - 将正确添加描述符if ( epoll_ctl( epollfd, EPOLL_CTL_ADD, pConnection1-&gt;getSocket(), &amp;ev ) != 0 ) //报告错误//等等,将正确添加描述符最多20个事件（假设我们之前可能已经添加了200个套接字）struct epoll_event pevents [20]; //等待10秒int ready = epoll_wait（pollingfd,pevents,20,10000）;//检查epoll是否实际成功if（ret == -1） //报告错误并中止else if（ret == 0） // timeout; 没有检测到事件else { //检查是否检测到任何事件 for （int i = 0; i &lt;ret; i ++） { if（pevents [i] .events＆EPOLLIN） { //取回我们的连接指针 Connection * c =（连接*）pevents [i] .data.ptr; C-&gt; handleReadEvent（）; } } } 仅仅看一下实施就应该给你一个epoll的缺点,我们将提到第一个。使用起来比较复杂,并且需要编写更多代码,与其他轮询方法相比,它需要更多的库调用。 然而,epoll在性能和功能方面比select / poll有一些明显的优势： epoll仅返回触发事件的描述符列表。无需再遍历10,000个描述符来找到触发事件的描述符！您可以将有意义的上下文附加到受监视的事件而不是套接字文件描述符。在我们的示例中,我们附加了可以直接调用的类指针,从而节省了另一个查找。 即使epoll_wait函数中有另一个线程,您也可以随时添加套接字或将其从监视中删除。您甚至可以修改描述符事件。一切都会正常工作,这种行为得到支持和记录。这为您提供了更大的实施灵活性。 由于内核知道所有监视描述符,因此即使没有人调用epoll_wait,它也可以注册发生在它们上的事件。这允许实现诸如边缘触发之类的有趣特征,这将在单独的文章中描述。 使用epoll_wait（）可以让多个线程在同一个epoll队列上等待,这是select / poll无法做到的。实际上,不仅可以使用epoll,而且可以使用边缘触发模式中的推荐方法。 但是你需要记住epoll不是一个“更好的poll”,与poll相比它也有缺点： 更改事件标志（即从READ到WRITE）需要epoll_ctl系统调用,而在使用poll时,这是一个完全在用户空间完成的简单位掩码操作。使用epoll将5,000个套接字从读取切换到写入将需要5,000个系统调用,因此需要上下文切换（截至2014年调用epoll_ctl仍然无法进行批处理,并且每个描述符必须单独更改）,而在轮询中则需要单个循环pollfd结构。 每个accept（）ed套接字都需要添加到集合中,与上面相同,epoll必须通过调用epoll_ctl来完成- 这意味着每个新连接套接字有两个必需的系统调用,而不是一个用于轮询。如果您的服务器有许多短期连接可以发送或接收很少的流量,则epoll可能需要比轮询更长的时间才能为其提供服务。 epoll完全是Linux域,虽然其他平台有类似的机制,但它们并不完全相同 - 例如,边缘触发非常独特（FreeBSD的kqueue也支持它）。 高性能处理逻辑更复杂,因此更难以调试,特别是对于边缘触发,如果错过额外的读/写,则容易出现死锁。 因此,如果满足以下条件,则只应使用epoll： 您的应用程序运行线程轮询,通过少数线程处理许多网络连接。您将在单线程应用程序中失去大部分epoll权益,并且很可能不会超过poll。 你希望有相当数量的插座来监控（至少1000个）; 使用较少数量的epoll不太可能比poll具有任何性能优势,实际上可能会使性能更差; 你的关系相对长寿; 如上所述,在新连接发送几个字节的数据并且由于将描述符添加到epoll集所需的额外系统调用而立即断开连接的情况下,epoll将比轮询慢。 您的应用程序依赖于其他特定于Linux的功能（因此,如果突然弹出可移植性问题,epoll将不是唯一的障碍）,或者您可以为其他受支持的系统提供包装器。在最后一种情况下,你应该强烈考虑解放。 如果上述所有项目均不正确,则应使用poll来更好地为您服务。 使用libevent进行轮询libebent是一个库,它将本文（以及其他一些）中列出的轮询方法包装在统一的API中。它的主要优点是它允许您编写一次代码并在许多操作系统上编译和运行它而无需更改代码。重要的是要理解libevent它只是一个构建在现有轮询方法之上的包装器,因此它继承了轮询方法所具有的问题。它不会使Linux上的选择支持超过1024个套接字,或者允许epoll在没有系统调用/上下文切换的情况下修改轮询事件。因此,了解每种方法的优缺点仍然很重要。 必须提供对截然不同的方法的功能的访问,libevent有一个相当复杂的API,比poll或甚至epoll更难使用。然而,如果你需要支持FreeBSD（epoll和kqueue）,那么使用libevent比编写两个单独的后端更容易。因此,如果符合以下条件,则应考虑使用它 您的申请要求表明您必须使用epoll,仅使用 poll是不够的（如果poll能够满足您的需求,那么libevent极不可能为您提供任何好处） 您需要支持除Linux之外的其他操作系统,或者可能期望将来出现这种需求。同样,这取决于您的应用程序的其他功能 - 如果它与许多其他特定于Linux的东西捆绑在一起,那么使用libevent而不是epoll将无法实现任何功能。 原文 Select / poll / epoll: practical difference for system architects","link":"/2019/08/06/Network/Epoll,Select,Poll%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E4%B9%8B%E9%97%B4%E7%9A%84%E5%AE%9E%E9%99%85%E5%B7%AE%E5%BC%82(%E8%AF%91%E6%96%87)/"},{"title":"五月面试指南","text":"五月份关于序章科技,腾讯云和腾讯视频,晓信科技的面试题以及答案,抽空整理成博文与大家分享一下。 一 、TCP相关基础知识三次握手过程刚开始客户端处于 Closed 的状态,服务端处于 Listen 状态,进行三次握手： 第一次握手：客户端给服务端发一个 SYN 报文,并指明客户端的初始化序列号 ISN(c)。此时客户端处于SYN_SENT状态。 首部的同步位SYN=1,初始序号seq=x,SYN=1的报文段不能携带数据,但要消耗掉一个序号。 第二次握手：服务器收到客户端的 SYN 报文之后,会以自己的 SYN 报文作为应答,并且也是指定了自己的初始化序列号 ISN(s)。同时会把客户端的 ISN + 1 作为ACK 的值,表示自己已经收到了客户端的 SYN,此时服务器处于SYN_RCVD的状态。 在确认报文段中SYN=1,ACK=1,确认号ack=x+1,初始序号seq=y。 第三次握手：客户端收到 SYN 报文之后,会发送一个 ACK 报文,当然,也是一样把服务器的 ISN + 1 作为 ACK 的值,表示已经收到了服务端的 SYN 报文,此时客户端处于ESTABLISHED状态。服务器收到 ACK 报文之后,也处于ESTABLISHED状态,此时,双方已建立起了连接。 确认报文段ACK=1,确认号ack=y+1,序号seq=x+1（初始为seq=x,第二个报文段所以要+1）,ACK报文段可以携带数据,不携带数据则不消耗序号。 四次挥手的过程刚开始双方都处于 ESTABLISHED 状态,假如是客户端先发起关闭请求。四次挥手的过程如下： 第一次挥手：客户端发送一个 FIN 报文,报文中会指定一个序列号。此时客户端处于FIN_WAIT1状态。 即发出连接释放报文段（FIN=1,序号seq=u）,并停止再发送数据,主动关闭TCP连接,进入FIN_WAIT1（终止等待1）状态,等待服务端的确认。 第二次挥手：服务端收到 FIN 之后,会发送 ACK 报文,且把客户端的序列号值 +1 作为 ACK 报文的序列号值,表明已经收到客户端的报文了,此时服务端处于CLOSE_WAIT状态。 即服务端收到连接释放报文段后即发出确认报文段（ACK=1,确认号ack=u+1,序号seq=v）,服务端进入CLOSE_WAIT（关闭等待）状态,此时的TCP处于半关闭状态,客户端到服务端的连接释放。客户端收到服务端的确认后,进入FIN_WAIT2（终止等待2）状态,等待服务端发出的连接释放报文段。 第三次挥手：如果服务端也想断开连接了,和客户端的第一次挥手一样,发给 FIN 报文,且指定一个序列号。此时服务端处于LAST_ACK的状态。 即服务端没有要向客户端发出的数据,服务端发出连接释放报文段（FIN=1,ACK=1,序号seq=w,确认号ack=u+1）,服务端进入LAST_ACK（最后确认）状态,等待客户端的确认。 第四次挥手：客户端收到 FIN 之后,一样发送一个 ACK 报文作为应答,且把服务端的序列号值 +1 作为自己 ACK 报文的序列号值,此时客户端处于TIME_WAIT状态。需要过一阵子以确保服务端收到自己的 ACK 报文之后才会进入CLOSED状态,服务端收到 ACK 报文之后,就处于关闭连接了,处于CLOSED状态。 即客户端收到服务端的连接释放报文段后,对此发出确认报文段（ACK=1,seq=u+1,ack=w+1）,客户端进入TIME_WAIT（时间等待）状态。此时TCP未释放掉,需要经过时间等待计时器设置的时间2MSL后,客户端才进入CLOSED状态。 三次握手过程中可以携带数据吗？第一次握手不可以放数据,其中一个简单的原因就是会让服务器更加容易受到攻击了。而对于第三次的话,此时客户端已经处于 ESTABLISHED 状态。对于客户端来说,他已经建立起连接了,并且也已经知道服务器的接收、发送能力是正常的了,所以能携带数据。 什么是半连接队列？服务器第一次收到客户端的 SYN 之后,就会处于SYN_RCVD状态,此时双方还没有完全建立其连接,服务器会把此种状态下请求连接放在一个队列里,我们把这种队列称之为半连接队列。 TCP是通过什么机制保障可靠性的? 应用数据被分割成TCP认为最适合发送的数据块。这和UDP完全不同,应用程序产生的数据报长度将保持不变。 超时重传 需要确认 保持首部和数据的检验和 数据后重新排序 丢弃重复 流量控制 从四个方面进行回答,ACK确认机制、超时重传、滑动窗口以及流量控制,深入的话要求详细讲出流量控制的机制。 tcp为什么要三次握手和四次挥手？三次握手： 第一次握手: 确认客户端的发送能力、服务端的接收能力是正常的。 第二次握手: 客户端可以知道客户端的接收,发送能力正常,服务器自己的发送、接收能力也正常。但是服务器端还不知道。 第三次握手: 服务端可以知道客户端的接收,能力正常,服务器自己的发送、接收能力也正常。 四次挥手： 原因是因为tcp是全双工模式 ，接收到FIN时意味将没有数据再发来,但是还是可以继续发送数据。 tcp怎么保证有序传输的？ 为了保证数据包的可靠传递,发送方必须把已发送的数据包保留在缓冲区； 并为每个已发送的数据包启动一个超时定时器； 如在定时器超时之前收到了对方发来的应答信息（可能是对本包的应答,也可以是对本包后续包的应答）,则释放该数据包占用的缓冲区; 否则,重传该数据包,直到收到应答或重传次数超过规定的最大次数为止。 接收方收到数据包后,先进行CRC校验,如果正确则把数据交给上层协议,然后给发送方发送一个累计应答包,表明该数据已收到,并且可以携带数据。 ISN(Initial Sequence Number)是怎么生成的？ISN = M + F(localhost, localport, remotehost, remoteport). M是一个计时器,这个计时器每隔4毫秒加1。 F是一个Hash算法,根据源IP、目的IP、源端口、目的端口生成一个随机数值。要保证hash算法不能被外部轻易推算得出,用MD5算法是一个比较好的选择。 TCP初始化序列号不能设置为一个固定值,因为这样容易被攻击者猜出后续序列号,从而遭到攻击。 二、 操作系统描述线程、进程以及协程的区别? 描述线程、进程以及协程的定义和区别,顺便描述Go语言中三者的使用。一、定义 1、进程 进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动,进程是系统进行资源分配和调度的一个独立单位。每个进程都有自己的独立内存空间,不同进程通过进程间通信来通信。由于进程比较重量,占据独立的内存,所以上下文进程间的切换开销（栈、寄存器、虚拟内存、文件句柄等）比较大,但相对比较稳定安全。 2、线程 线程是进程的一个实体,是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位.线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈),但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源。线程间通信主要通过共享内存,上下文切换很快,资源开销较少,但相比进程不够稳定容易丢失数据。 3、协程 协程是一种用户态的轻量级线程,协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。协程调度切换时,将寄存器上下文和栈保存到其他地方,在切回来的时候,恢复先前保存的寄存器上下文和栈,直接操作栈则基本没有内核切换的开销,可以不加锁的访问全局变量,所以上下文的切换非常快。 二、区别： 1、进程多与线程比较 线程是指进程内的一个执行单元,也是进程内的可调度实体。线程与进程的区别:1) 地址空间:线程是进程内的一个执行单元,进程内至少有一个线程,它们共享进程的地址空间,而进程有自己独立的地址空间2) 资源拥有:进程是资源分配和拥有的单位,同一个进程内的线程共享进程的资源3) 线程是处理器调度的基本单位,但进程不是4) 二者均可并发执行 5) 每个独立的线程有一个程序运行的入口、顺序执行序列和程序的出口,但是线程不能够独立执行,必须依存在应用程序中,由应用程序提供多个线程执行控制 2、协程多与线程进行比较 1) 协程能保留上一次调用时的状态,每次过程重入时,就相当于进入上一次调用的状态。 2)协程切换完全在用户空间进行,线程切换涉及特权模式切换,需要在内核空间完成。 为什么在用户态和内核态之间切换调度成本比较高？三、 网络编程相关基础网络IO模型有哪些? 同步模型（synchronous IO） 阻塞IO（bloking IO） 非阻塞IO（non-blocking IO） 多路复用IO（multiplexing IO） 信号驱动式IO（signal-driven IO） 异步IO（asynchronous IO） 具体描述： https://www.jianshu.com/p/486b0965c296 I/O多路复用中select/poll/epoll的区别？ Select 工作原理: 从用户空间拷贝fd_set到内核空间,也即从当前程序拷贝fd_set数组进内核。 对所有的fd进行一次poll操作,即把当前进程挂载到fd上。 poll操作过程中select会唤醒所有的队列中节点,进行遍历,得到它们的掩码（不同的掩码表示不同的就绪状态）。 如果所有设备返回的掩码都没有显示任何的事件触发,就去掉回调函数的函数指针,进入有限时的睡眠状态,再恢复和不断做poll,再作有限时的睡眠,直到其中一个设备有事件触发为止。 只要有事件触发,系统调用返回,将fd_set从内核空间拷贝到用户空间,回到用户态,用户就可以对相关的fd作进一步的读或者写操作了。 三个缺点： select最大的缺陷就是单个进程所打开的FD是有一定限制的,它由FD_SETSIZE设置,默认值是1024。 对socket进行扫描时是线性扫描,即采用轮询的方法,效率较低。 需要维护一个用来存放大量fd的数据结构,这样会使得用户空间和内核空间在传递该结构时复制开销大。 poll poll本质上和select没有区别,但它没有最大连接数的限制,原因是它是基于链表来存储的。poll还有一个特点是“水平触发”,如果报告了fd后,没有被处理,那么下次poll时会再次报告该fd。 epoll 基本原理： epoll支持水平触发和边缘触发,最大的特点在于边缘触发,它只告诉进程哪些fd刚刚变为就绪态,并且只会通知一次。还有一个特点是,epoll使用“事件”的就绪通知方式,通过epoll_ctl注册fd,一旦该fd就绪,内核就会采用类似callback的回调机制来激活该fd,epoll_wait便可以收到通知。 优点： 没有最大并发连接的限制,能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口）。 效率提升,不是轮询的方式,不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数；即Epoll最大的优点就在于它只管你“活跃”的连接,而跟连接总数无关,因此在实际的网络环境中,Epoll的效率就会远远高于select和poll。 内存拷贝,利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。 LT（level trigger）和ET（edge trigger） LT模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序,应用程序可以不立即处理该事件。下次调用epoll_wait时,会再次响应应用程序并通知此事件。 ET模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序,应用程序必须立即处理该事件。如果不处理,下次调用epoll_wait时,不会再次响应应用程序并通知此事件。 四、 HTTP 相关基础客户端访问url到服务器,整个过程会经历哪些？ https://blog.fundebug.com/2019/02/28/what-happens-from-url-to-webpage/ 描述HTTPS和HTTP的区别。 https://juejin.im/entry/58d7635e5c497d0057fae036 HTTP1.0、HTTP1.1 和 HTTP2.0 的区别。 https://juejin.im/entry/5981c5df518825359a2b9476 RESTful 风格 API 有什么优点和缺点 https://www.lanhusoft.com/Article/626.html 对比 GraphQL 与RESTFUL两种HTTP API的差异 https://www.jianshu.com/p/2ad286397f7a 五、 数据库和中间件的基础知识5.1 Redis描述一下redis有哪些数据结构。基础的数据结构有5种,String/List/Hash/Set/Zset,高级数据结构HyperLogLog/BitMap/BloomFilter/GeoHash。 Redis的LRU实现 https://zhuanlan.zhihu.com/p/34133067 Redis的持久化机制 https://juejin.im/post/5befacfa5188254e3b31934e zset跳表的数据结构 https://redisbook.readthedocs.io/en/latest/internal-datastruct/skiplist.html 跳跃表实现 Redis的分布式锁 https://juejin.im/post/5cc165816fb9a03202221dd5 5.2 MysqlMVCC 实现原理? 通过在每行记录后面保存两个隐藏的列来实现的。 行的创建时间。 行的过期时间（或删除时间）。 当然存储的并不是实际的时间值,而是系统版本号（system version number）。每开始一个新的事务,系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号,用来和查询到的每行记录的版本号进行比较。 SELECT 只查找版本早于当前事务版本的数据行。 行的删除版本要么未定义,要么大于当前事务版本号。 INSERT为新插入的每一行保存当前系统版本号作为行版本号。 DELETE为删除的每一行保存当前系统版本号作为行删除标识。 UPDATE为插入一行新记录,保存当前系统版本号作为行版本号,同时保存当前系统版本号到原来的行作为行删除标识。 Sql 如何优化? https://www.ulovecode.com/2020/05/03/数据库/mysql/高性能mysql(4)/#more 5.3 KafakKafka的复制机制 https://colobu.com/2017/11/02/kafka-replication/ 消息中间件选型分析 https://www.infoq.cn/article/kafka-vs-rabbitmq Kafka中的选举 https://xie.infoq.cn/article/e64e4881675ca585b67ab914a Kafka为什么吞吐量大、速度快？ https://blog.csdn.net/kzadmxz/article/details/101576401 HW机制 http://objcoding.com/2019/10/31/kafka-hw/ 六、 算法以及数学题及智力题 K 个一组翻转链表 随机打乱一个数组 毒蘑菇最大体力 两数相加 给出一个数字 n,代表 n 个人的序号,偶数是女生奇数是男生,假设 n 人想出去团建,行政需要帮忙订房间每个房间 2 个人,男女不能同房,要写一个函数 randomRoom 随机出配出所有房间的人。 一个路口30分钟内有车通过的概率是90%,则5分钟内有车通过的概率是多少？ 12箱黄金,每箱100块,每块一两。有个贪官,把某一箱的每块都磨去一钱。请称一次找到不足量的那个箱子。 七、 架构秒杀业务 如何设计秒杀系统？ - 网易云的回答 - 知乎 https://www.zhihu.com/question/54895548/answer/259218876 DNS 负载均衡算法 https://blog.csdn.net/lonelymanontheway/article/details/89222159 水平扩展和垂直扩展 https://zhuanlan.zhihu.com/p/24830094 每秒100W请求,架构如何优化 https://blog.csdn.net/shenjian58/article/details/100681683 Redis分布式锁服务器挂了怎么办? https://xiaomi-info.github.io/2019/12/17/redis-distributed-lock/","link":"/2020/05/18/%E9%9D%A2%E8%AF%95/%E4%BA%94%E6%9C%88%E9%9D%A2%E8%AF%95%E6%8C%87%E5%8D%97/"},{"title":"Etcd 中 Raft 协议源码的不完全分析（1）","text":"etcd 是 CoreOS 团队于2013年6月发起的开源项目,它的目标是构建一个高可用的分布式键值(key-value)数据库。etcd 内部采用 raft 协议作为一致性, 现在就来看看 raft 在 etcd 中是如何实现的。必须先阅读 raft 协议的论文,再对协议论文有深刻理解的情况下,理解实现会更加轻松。 一、分析流程阅读readMe.md文件 运行单节点raftexample首先启动一个raftexample的单成员集群： 1raftexample --id 1 --cluster http://127.0.0.1:12379 --port 12380 每个raftexample进程都维护一个raft实例和一个键值服务器。进程的逗号分隔对等体（–cluster）列表,其对等列表（–id）的raft ID索引和http键值服务器端口（–port）通过命令行传递。 接下来,将值（“hello”）存储到键（“my-key”）： 1curl -L http://127.0.0.1:12380/my-key -XPUT -d hello 最后,检索存储的密钥： 1curl -L http://127.0.0.1:12380/my-key 运行本地群集首先安装[goreman]（https://github.com/mattn/goreman）,它管理基于Procfile的应用程序。 [Procfile脚本]（./ Procfile）将设置本地示例集群。从以下开始： 1goreman start 这将带来三个raftexample实例。 现在可以将键值对写入集群的任何成员,并同样从任何成员中检索它。 容错要测试群集恢复,首先启动群集并写入值“foo”： 12goreman startcurl -L http://127.0.0.1:12380/my-key -XPUT -d foo 接下来,删除节点并将值替换为“bar”以检查群集可用性： 123goreman run stop raftexample2curl -L http://127.0.0.1:12380/my-key -XPUT -d barcurl -L http://127.0.0.1:32380/my-key 最后,重新启动节点并使用更新后的值“bar”验证它是否恢复： 12goreman run start raftexample2curl -L http://127.0.0.1:22380/my-key 动态集群重新配置可以使用对REST API的请求将节点添加到正在运行的集群中或从中删除节点。 例如,假设我们有一个使用命令启动的3节点集群： 123raftexample --id 1 --cluster http://127.0.0.1:12379,http://127.0.0.1:22379,http://127.0.0.1:32379 --port 12380raftexample --id 2 --cluster http://127.0.0.1:12379,http://127.0.0.1:22379,http://127.0.0.1:32379 --port 22380raftexample --id 3 --cluster http://127.0.0.1:12379,http://127.0.0.1:22379,http://127.0.0.1:32379 --port 32380 可以通过发出POST来添加ID为4的第四个节点： 1curl -L http://127.0.0.1:12380/4 -XPOST -d http://127.0.0.1:42379 然后使用–join选项可以像其他节点一样启动新节点： 1raftexample --id 4 --cluster http://127.0.0.1:12379,http://127.0.0.1:22379,http://127.0.0.1:32379,http://127.0.0.1:42379 --port 42380 --join 新节点应加入群集,并能够为密钥/值请求提供服务。 我们可以使用DELETE请求删除节点： 1curl -L http://127.0.0.1:12380/3 -XDELETE 一旦集群处理了此请求,节点3就应该自行关闭。 设计raftexample由三个组件组成：一个由raft支持的键值存储,一个REST API服务器和一个基于etcd的raft实现的raft共识服务器。 支持raft的键值存储是一个键值映射,它包含所有已提交的键值。该存储桥接了raft服务器和REST服务器之间的通信。键值更新通过存储发送到raft服务器。一旦raft报告提交更新,存储就会更新其地图。 REST服务器通过访问raft支持的键值存储来公开当前的raft共识。GET命令在存储中查找键并返回值（如果有）。键值PUT命令向存储发出更新提议。 raft服务器与其集群对等方达成共识。当REST服务器提交提议时,raft服务器将提议发送给其对等方。当raft达成共识时,服务器通过提交通道发布所有已提交的更新。对于raftexample,此提交通道由键值存储使用。 二、介绍raft库代码结构及核心数据结构为什么要首先介绍核心数据结构,如果不介绍核心数据结构就可能看不懂后面我的分析,每一个Msg具体代表什么含义,所以先看核心数据结构,这里只需要大概浏览一遍就可以了,忘记了可以在这里看。 MsgHup消息 成员 类型 作用 type MsgHup 不用于节点间通信,仅用于发送给本节点让本节点进行选举 to uint64 消息接收者的节点ID from uint64 本节点ID MsgBeat消息 成员 类型 作用 type MsgBeat 不用于节点间通信 ,仅用于leader节点在heartbeat定时器到期时向集群中其他节点发送心跳消息 to uint64 消息接收者的节点ID from uint64 本节点ID MsgProp消息 成员 类型 作用 type MsgProp raft库使用者提议（propose）数据 to uint64 消息接收者的节点ID from uint64 本节点ID entries Entry 日志条目数组 MsgApp/MsgSnap消息MsgApp消息 成员 类型 作用 type MsgApp 用于leader向集群中其他节点同步数据的消息 to uint64 消息接收者的节点ID from uint64 本节点ID entries Entry 日志条目数组 logTerm uint64 日志所处的任期ID index uint64 索引ID MsgSnap消息 成员 类型 作用 type MsgSnap 用于leader向follower同步数据用的快照消息 to uint64 消息接收者的节点ID from uint64 本节点ID snapshot Snapshot 快照数据 MsgAppResp消息 成员 类型 作用 type MsgAppResp 集群中其他节点针对leader的MsgApp/MsgSnap消息的应答消息 to uint64 消息接收者的节点ID from uint64 本节点ID index uint64 日志索引ID,用于节点向leader汇报自己已经commit的日志数据ID reject bool 是否拒绝同步日志的请求 rejectHint uint64 拒绝同步日志请求时返回的当前节点日志ID,用于被拒绝方快速定位到下一次合适的同步日志位置 MsgVote/MsgPreVote消息 成员 类型 作用 type MsgVote/MsgPreVote 节点投票给自己以进行新一轮的选举 to uint64 消息接收者的节点ID from uint64 本节点ID term uint64 任期ID index uint64 日志索引ID,用于节点向leader汇报自己已经commit的日志数据ID logTerm uint64 日志所处的任期ID context bytes 上下文数据 MsgVoteResp/MsgPreVoteResp消息 成员 类型 作用 type MsgVoteResp/MsgPreVoteResp 投票应答消息 to uint64 消息接收者的节点ID from uint64 本节点ID reject bool 是否拒绝 三、分析源码按照上面README.md文档开始分析,首先把单个实例跑起来。然后根据源码的顺序一个一个的看。 main12345678910111213141516171819func main() { // 用于节点之间通信 cluster := flag.String(\"cluster\", \"http://127.0.0.1:9021\", \"comma separated cluster peers\") id := flag.Int(\"id\", 1, \"node ID\") // 用于 key value kvport := flag.Int(\"port\", 9121, \"key-value server port\") join := flag.Bool(\"join\", false, \"join an existing cluster\") flag.Parse() proposeC := make(chan string) defer close(proposeC) confChangeC := make(chan raftpb.ConfChange) defer close(confChangeC) var kvs *kvstore getSnapshot := func() ([]byte, error) { return kvs.getSnapshot() } commitC, errorC, snapshotterReady := newRaftNode(*id, strings.Split(*cluster, \",\"), *join, getSnapshot, proposeC, confChangeC) kvs = newKVStore(&lt;-snapshotterReady, proposeC, commitC, errorC) serveHttpKVAPI(kvs, *kvport, confChangeC, errorC)} proposeC创建一个提议channel,用于提议请求的通信 confChangeC创建一个配置更改的channel,用于配置更改的通信 newRaftNode创建raft协议的node节点,然后返回一个提交的channel,和一个错误通知的channel snapshotterReady用于等待快照创建完毕,然后执行newKVStore方法创建一个key存储容器 serveHttpKVAPI创建一个http服务 main.newKVStore12345678func newKVStore(snapshotter *snap.Snapshotter, proposeC chan&lt;- string, commitC &lt;-chan *string, errorC &lt;-chan error) *kvstore { s := &amp;kvstore{proposeC: proposeC, kvStore: make(map[string]string), snapshotter: snapshotter} // 回应日志进入到key value map s.readCommits(commitC, errorC) //从raft读取提交到kvStore映射直到错误 go s.readCommits(commitC, errorC) return s} 创建一个KV存储对象,读取提交信息到kv存储容器中 123456type kvstore struct { proposeC chan&lt;- string // channel for proposing updates mu sync.RWMutex kvStore map[string]string // current committed key-value pairs snapshotter *snap.Snapshotter} proposeC是一个提议channel,sync.RWMutex因为是在多个 go 协程中运行的,所以需要加锁,存储实际上就是一个map类型 1234type Snapshotter struct { lg *zap.Logger dir string} Snapshotter类型则是一个zap类型的日志,会持久化到磁盘中 123456789101112131415161718192021222324252627282930func (s *kvstore) readCommits(commitC &lt;-chan *string, errorC &lt;-chan error) { for data := range commitC { if data == nil { snapshot, err := s.snapshotter.Load() if err == snap.ErrNoSnapshot { return } if err != nil { log.Panic(err) } log.Printf(\"loading snapshot at term %d and index %d\", snapshot.Metadata.Term, snapshot.Metadata.Index) if err := s.recoverFromSnapshot(snapshot.Data); err != nil { log.Panic(err) } continue } var dataKv kv dec := gob.NewDecoder(bytes.NewBufferString(*data)) if err := dec.Decode(&amp;dataKv); err != nil { log.Fatalf(\"raftexample: could not decode message (%v)\", err) } s.mu.Lock() s.kvStore[dataKv.Key] = dataKv.Val s.mu.Unlock() } if err, ok := &lt;-errorC; ok { log.Fatal(err) }} 根据提交然后加载快照中的信息,从快照中的信息恢复到kv存储容器中,然后再从commit日志中恢复信息 main.serveHttpKVAPI12345678910111213141516171819202122// serveHttpKVAPI starts a key-value server with a GET/PUT API and listens.func serveHttpKVAPI(kv *kvstore, port int, confChangeC chan&lt;- raftpb.ConfChange, errorC &lt;-chan error) { // httpKAPi 因为实现了serverhttp方法所以可以传入作为handler srv := http.Server{ Addr: \":\" + strconv.Itoa(port), // 只需要关心httpKVAPI的实现就可以了 Handler: &amp;httpKVAPI{ store: kv, confChangeC: confChangeC, }, } go func() { // 打开监听端口 if err := srv.ListenAndServe(); err != nil { log.Fatal(err) } }() // exit when raft goes down if err, ok := &lt;-errorC; ok { log.Fatal(err) }} 开启http服务 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586func (h *httpKVAPI) ServeHTTP(w http.ResponseWriter, r *http.Request) { key := r.RequestURI defer r.Body.Close() //HttpServer主循环: //接收用户提交的数据： //如果是PUT请求： //将数据写入到proposeC中 //如果是POST请求： //将配置变更数据写入到confChangeC中 switch { // 如果方式put方法 更新某个key case r.Method == \"PUT\": v, err := ioutil.ReadAll(r.Body) if err != nil { log.Printf(\"Failed to read on PUT (%v)\\n\", err) http.Error(w, \"Failed on PUT\", http.StatusBadRequest) return } // 建议 != 事实 // 在这里调用了key value 的更新建议 h.store.Propose(key, string(v)) //乐观的无需等Raft的确认。值尚未提交,因此键上的后续GET可能返回旧值 w.WriteHeader(http.StatusNoContent) // 如果方式get方法 查找某个key case r.Method == \"GET\": if v, ok := h.store.Lookup(key); ok { // 查看某一个key的配置 w.Write([]byte(v)) } else { http.Error(w, \"Failed to GET\", http.StatusNotFound) } case r.Method == \"POST\": url, err := ioutil.ReadAll(r.Body) if err != nil { log.Printf(\"Failed to read on POST (%v)\\n\", err) http.Error(w, \"Failed on POST\", http.StatusBadRequest) return } nodeId, err := strconv.ParseUint(key[1:], 0, 64) if err != nil { log.Printf(\"Failed to convert ID for conf change (%v)\\n\", err) http.Error(w, \"Failed on POST\", http.StatusBadRequest) return } cc := raftpb.ConfChange{ // 删除传入的添加 Type: raftpb.ConfChangeAddNode, NodeID: nodeId, Context: url, } // 更新配置 h.confChangeC &lt;- cc //如上所述,乐观地认为raft会应用变化 w.WriteHeader(http.StatusNoContent) case r.Method == \"DELETE\": nodeId, err := strconv.ParseUint(key[1:], 0, 64) if err != nil { log.Printf(\"Failed to convert ID for conf change (%v)\\n\", err) http.Error(w, \"Failed on DELETE\", http.StatusBadRequest) return } cc := raftpb.ConfChange{ // 删除传入的nodeid Type: raftpb.ConfChangeRemoveNode, NodeID: nodeId, } // 删除配置 h.confChangeC &lt;- cc //如上,乐观地认为筏将应用conf更改 w.WriteHeader(http.StatusNoContent) default: w.Header().Set(\"Allow\", \"PUT\") w.Header().Add(\"Allow\", \"GET\") w.Header().Add(\"Allow\", \"POST\") w.Header().Add(\"Allow\", \"DELETE\") http.Error(w, \"Method not allowed\", http.StatusMethodNotAllowed) }} 可以分为两类,一类是属性信息,第二类是节点配置的信息 1.属性信息 PUT通过h.store.Propose(key, string(v))该方法往s.proposeC中提交建议 GET通过h.store.Lookup(key)在v, ok := s.kvStore[key]集合中查找数据,然后返回 2.节点配置的信息 POST 因为设置的Type: raftpb.ConfChangeAddNode信息为添加类型,再由h.confChangeC &lt;- cc传输到配置更改的channel,实现添加节点 DELTE因为设置的Type: raftpb.ConfChangeRemoveNode信息为添加类型,再由h.confChangeC &lt;- cc传输到配置更改的channel,实现删除节点 main.newRaftNode12345678910111213141516171819202122232425262728func newRaftNode(id int, peers []string, join bool, getSnapshot func() ([]byte, error), proposeC &lt;-chan string, confChangeC &lt;-chan raftpb.ConfChange) (&lt;-chan *string, &lt;-chan error, &lt;-chan *snap.Snapshotter) { commitC := make(chan *string) errorC := make(chan error) rc := &amp;raftNode{ proposeC: proposeC, confChangeC: confChangeC, commitC: commitC, errorC: errorC, id: id, peers: peers, join: join, waldir: fmt.Sprintf(\"raftexample-%d\", id), snapdir: fmt.Sprintf(\"raftexample-%d-snap\", id), getSnapshot: getSnapshot, snapCount: defaultSnapshotCount, stopc: make(chan struct{}), httpstopc: make(chan struct{}), httpdonec: make(chan struct{}), snapshotterReady: make(chan *snap.Snapshotter, 1), // WAL回应后填充的其余结构 } go rc.startRaft() return commitC, errorC, rc.snapshotterReady} 创建一个raft的node节点,然后启用协程开启调用startRaft(),启动raft协议,后面的方法会等待snapshotterReady快照信息准备完毕 main.newRaftNode.startRaft1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768func (rc *raftNode) startRaft() { // 创建快照目录 if !fileutil.Exist(rc.snapdir) { if err := os.Mkdir(rc.snapdir, 0750); err != nil { log.Fatalf(\"raftexample: cannot create dir for snapshot (%v)\", err) } } rc.snapshotter = snap.New(zap.NewExample(), rc.snapdir) rc.snapshotterReady &lt;- rc.snapshotter // 是否存在wal日志 oldwal := wal.Exist(rc.waldir) rc.wal = rc.replayWAL() rpeers := make([]raft.Peer, len(rc.peers)) // 为遍历每一个peer节点都设置id 从1开始设置 for i := range rpeers { rpeers[i] = raft.Peer{ID: uint64(i + 1)} } // 创建配置文件 弹性时间戳为10 心跳为1 用内存都方式存储 节点之间最大消息大小为1024*1024字节 乐观复制中最大追加消息数为256条 未提交的最大条目数量 c := &amp;raft.Config{ ID: uint64(rc.id), ElectionTick: 10, HeartbeatTick: 1, Storage: rc.raftStorage, MaxSizePerMsg: 1024 * 1024, MaxInflightMsgs: 256, MaxUncommittedEntriesSize: 1 &lt;&lt; 30, } // 如果存在wal日志 if oldwal { // 就根据之前的配置来恢复这个节点 rc.node = raft.RestartNode(c) } else { // 否则就启动node节点 startPeers := rpeers // 如果是参加节点,那么当前节点就不启动 if rc.join { startPeers = nil } // 启动node节点 rc.node = raft.StartNode(c, startPeers) } // raft传输 rc.transport = &amp;rafthttp.Transport{ Logger: zap.NewExample(), ID: types.ID(rc.id), ClusterID: 0x1000, Raft: rc, ServerStats: stats.NewServerStats(\"\", \"\"), LeaderStats: stats.NewLeaderStats(strconv.Itoa(rc.id)), ErrorC: make(chan error), } // 传输服务启动 rc.transport.Start() // 添加传输的对等节点,如果不是本身节点,就添加 for i := range rc.peers { if i+1 != rc.id { rc.transport.AddPeer(types.ID(i+1), []string{rc.peers[i]}) } } // 启动HTTP服务 go rc.serveRaft() // 开始监听各个channel然后消费 go rc.serveChannels()} 是否本地时候存在快照信息 如果有快照就读取之前快照信息 否则就在本地初始化创建一个快照 是否本地存在wal日志, 如果存在wal日志,就根据之前的配置来恢复这个节点 否则就创建node节点,启动node节点 启动传输服务启动,并将对等节点放入到要传入的服务中 启动节点之间需要的tcp连接 监听各个节点给他发送的消息 12345678910111213141516171819202122func (t *Transport) Start() error { var err error // stream 流 一般是维护节点状态,以及心跳 t.streamRt, err = newStreamRoundTripper(t.TLSInfo, t.DialTimeout) if err != nil { return err } // pipeline流 通常传输较大到数据,例如快照 t.pipelineRt, err = NewRoundTripper(t.TLSInfo, t.DialTimeout) if err != nil { return err } t.remotes = make(map[types.ID]*remote) t.peers = make(map[types.ID]Peer) t.pipelineProber = probing.NewProber(t.pipelineRt) t.streamProber = probing.NewProber(t.streamRt) if t.DialRetryFrequency == 0 { t.DialRetryFrequency = rate.Every(100 * time.Millisecond) } return nil} 创建一个传输服务,分为stream类型,和pipeline类型, 其中stream类型是一个长链接,而pipeline类型是一个短链接类型。 12streamRt http.RoundTripper // roundTripper used by streamspipelineRt http.RoundTripper // roundTripper used by pipelines stream类型 用来发送心跳和日志的信息 pipeline类型 用来传输快照 用来发送心跳和日志的信息(仅当stream类型不可用是,才会使用) 123456789101112131415161718192021func (rc *raftNode) serveRaft() { // 解析节点地址 url, err := url.Parse(rc.peers[rc.id-1]) if err != nil { log.Fatalf(\"raftexample: Failed parsing URL (%v)\", err) } // 打开可以停止的tcp连接 ln, err := newStoppableListener(url.Host, rc.httpstopc) if err != nil { log.Fatalf(\"raftexample: Failed to listen rafthttp (%v)\", err) } //transport.Handler方法放回一个实现来net.http包下的handler接口,调用其服务Serve接口 err = (&amp;http.Server{Handler: rc.transport.Handler()}).Serve(ln) select { case &lt;-rc.httpstopc: default: log.Fatalf(\"raftexample: Failed to serve rafthttp (%v)\", err) } close(rc.httpdonec)} 时间这个方法只是打开了一个tcp连接,然后将rc.transport.Handler()传入 1234567891011func (t *Transport) Handler() http.Handler { pipelineHandler := newPipelineHandler(t, t.Raft, t.ClusterID) streamHandler := newStreamHandler(t, t, t.Raft, t.ID, t.ClusterID) snapHandler := newSnapshotHandler(t, t.Raft, t.Snapshotter, t.ClusterID) mux := http.NewServeMux() mux.Handle(RaftPrefix, pipelineHandler) mux.Handle(RaftStreamPrefix+\"/\", streamHandler) mux.Handle(RaftSnapshotPrefix, snapHandler) mux.Handle(ProbingPrefix, probing.NewHandler()) return mux} 传入了四种handler,分别对应四种类型 1234RaftPrefix = \"/raft\" ProbingPrefix = path.Join(RaftPrefix, \"probing\") RaftStreamPrefix = path.Join(RaftPrefix, \"stream\") RaftSnapshotPrefix = path.Join(RaftPrefix, \"snapshot\") 管道类型,探测类型,流类型,快照类型,至于每一个类型handler的httpServer实现,我这里就不讲了。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788func (rc *raftNode) serveChannels() { // 拿到快照 snap, err := rc.raftStorage.Snapshot() if err != nil { panic(err) } rc.confState = snap.Metadata.ConfState rc.snapshotIndex = snap.Metadata.Index rc.appliedIndex = snap.Metadata.Index defer rc.wal.Close() ticker := time.NewTicker(100 * time.Millisecond) defer ticker.Stop() //通过raft发送提案 go func() { confChangeCount := uint64(0) for rc.proposeC != nil &amp;&amp; rc.confChangeC != nil { select { // 消费数据 case prop, ok := &lt;-rc.proposeC: if !ok { rc.proposeC = nil } else { //阻止直到被raft状态机接受 // 调用node的建议操作 rc.node.Propose(context.TODO(), []byte(prop)) } // 配置变更 case cc, ok := &lt;-rc.confChangeC: if !ok { rc.confChangeC = nil } else { confChangeCount++ cc.ID = confChangeCount rc.node.ProposeConfChange(context.TODO(), cc) } } } //客户关闭渠道;如果还没有关掉raft close(rc.stopc) }() //在raft状态机更新时的事件循环 for { select { case &lt;-ticker.C: rc.node.Tick() //将raft条目存储到wal,然后通过提交通道发布 case rd := &lt;-rc.node.Ready(): rc.wal.Save(rd.HardState, rd.Entries) // 如果快照不为空 if !raft.IsEmptySnap(rd.Snapshot) { // 保存快照状态 rc.saveSnap(rd.Snapshot) // 应用快照状态 rc.raftStorage.ApplySnapshot(rd.Snapshot) // 发布快照 rc.publishSnapshot(rd.Snapshot) } // 添加条目到本地存储 rc.raftStorage.Append(rd.Entries) // 发送消息 rc.transport.Send(rd.Messages) // 发布条目 if ok := rc.publishEntries(rc.entriesToApply(rd.CommittedEntries)); !ok { // 如果没有成功就停止节点 rc.stop() return } //可能触发快照 rc.maybeTriggerSnapshot() // 通知进行下一步 rc.node.Advance() case err := &lt;-rc.transport.ErrorC: rc.writeError(err) return case &lt;-rc.stopc: rc.stop() return } }} 其中有有两个 for 循环,一个是来接收提议和配置更改的信息 ,一个是类处理node节点之间的信息 接收提议和配置更改的信息的for循环 case prop, ok := &lt;-rc.proposeC: 然后调用rc.node.Propose(context.TODO(), []byte(prop))发送提议 case cc, ok := &lt;-rc.confChangeC: 然后调用rc.node.ProposeConfChange(context.TODO(), cc)发送配置更改 处理node节点之间的信息的 for 循环 case &lt;-ticker.C:使用rc.node.Tick()用来处理超时和心跳的逻辑 rd := &lt;-rc.node.Ready():返回当前时间点状态的通道,将条目存储到wal,然后通过提交通道发布,然后调用Advance它准备节点返回下一个可用的Ready。 case err := &lt;-rc.transport.ErrorC:使用rc.writeError(err)产生错误就把错误写到通道里 case &lt;-rc.stopc: 停止该节点 12345678func RestartNode(c *Config) Node { r := newRaft(c) n := newNode() n.logger = c.Logger go n.run(r) return &amp;n} 如果重启节点,就从配置中恢复节点的状态 123456789101112131415161718192021222324252627282930313233343536373839// StartNode 返回一个新的Node给定配置和一个raft对等列表。//它将每个给定对等体的ConfChangeAddNode条目附加到初始日志。func StartNode(c *Config, peers []Peer) Node { // 创建一个raft协议 r := newRaft(c) // 成为第1任期的追随者并应用第1任期的初始配置条目 r.becomeFollower(1, None) for _, peer := range peers { cc := pb.ConfChange{Type: pb.ConfChangeAddNode, NodeID: peer.ID, Context: peer.Context} d, err := cc.Marshal() if err != nil { panic(\"unexpected marshal error\") } e := pb.Entry{Type: pb.EntryConfChange, Term: 1, Index: r.raftLog.lastIndex() + 1, Data: d} r.raftLog.append(e) } //将这些初始条目标记为已提交。 // TODO（bdarnell）：这些条目仍然不稳定;我们需要保留吗？ //提交&lt;unstable的不变量？ 持久化存储和非持久化存储,它们之间的分界线就是lastIndex r.raftLog.committed = r.raftLog.lastIndex() //现在应用它们,主要是为了让应用程序可以调用Campaign //在测试中的StartNode之后立即执行。请注意,这些节点将 //被添加到raft两次：此处和应用程序准备就绪 //循环调用ApplyConfChange。必须追求对addNode的调用 //所有对raftLog.append的调用都是在这些之后设置progress.next // bootstrapping条目（如果我们尝试附加这些条目,则会出错 //条目,因为它们已经提交了）。 //我们没有设置raftLog.applied,所以应用程序就可以了 //通过Ready.CommittedEntries观察所有conf更改。 for _, peer := range peers { // 添加节点 r.addNode(peer.ID) } n := newNode() n.logger = c.Logger // 运行raft协议 go n.run(r) return &amp;n} 首先创建一个raft协议,成为第1任期的追随者并应用第1任期的初始配置条目,将领导者设置为空 并将条目添到wal中 添加对等节点 运行run方法,调用处理过程 main.newRaftNode.startRaft.run该方法是一个相当重要的方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165func (n *node) run(r *raft) { var propc chan msgWithResult var readyc chan Ready var advancec chan struct{} var prevLastUnstablei, prevLastUnstablet uint64 var havePrevLastUnstablei bool var prevSnapi uint64 var applyingToI uint64 var rd Ready // None 是没有领导者时使用的占位符节点ID。 lead := None prevSoftSt := r.softState() prevHardSt := emptyState // raft Node //raftNode结构体主循环： //如果proposeC中有数据写入： //调用node.Propose向raft库提交数据 //如果confChangeC中有数据写入： //调用node.Node.ProposeConfChange向raft库提交配置变更数据 //如果tick定时器到期： //调用node.Tick函数进行raft库的定时操作 //如果node.Ready()函数返回的Ready结构体channel有数据变更： //依次处理Ready结构体中各成员数据 //处理完毕之后调用node.Advance函数进行收尾处理 for { if advancec != nil { readyc = nil } else { // 这里做一个准备,msg 是从这里开始创建的 rd = newReady(r, prevSoftSt, prevHardSt) if rd.containsUpdates() { readyc = n.readyc } else { readyc = nil } } if lead != r.lead { // 如果有leader节点 if r.hasLeader() { if lead == None { r.logger.Infof(\"raft.node: %x elected leader %x at term %d\", r.id, r.lead, r.Term) } else { r.logger.Infof(\"raft.node: %x changed leader from %x to %x at term %d\", r.id, lead, r.lead, r.Term) } // 处理消息结果集 propc = n.propc // 如果没有leader节点 } else { r.logger.Infof(\"raft.node: %x lost leader %x at term %d\", r.id, lead, r.Term) propc = nil } // 设置当前的leader鸡诶单 lead = r.lead } select { // TODO：如果存在配置,可能缓冲配置建议（方式 // 在raft文中描述） // 目前它在静默中被丢弃。 // 从处理结果集中拿到消息 case pm := &lt;-propc: m := pm.m m.From = r.id // 修改状态机的状态 err := r.Step(m) if pm.result != nil { pm.result &lt;- err close(pm.result) } // 从接受的消息 case m := &lt;-n.recvc: // 从未知发件人中筛选出响应消息。 if pr := r.getProgress(m.From); pr != nil || !IsResponseMsg(m.Type) { // 修改状态机状态 r.Step(m) } // 从配置消息中 case cc := &lt;-n.confc: if cc.NodeID == None { select { case n.confstatec &lt;- pb.ConfState{ Nodes: r.nodes(), Learners: r.learnerNodes()}: case &lt;-n.done: } break } switch cc.Type { // 添加节点 case pb.ConfChangeAddNode: r.addNode(cc.NodeID) // 添加学习者节点 case pb.ConfChangeAddLearnerNode: r.addLearner(cc.NodeID) // 移除节点 case pb.ConfChangeRemoveNode: // 删除本地节点时阻止传入的建议 if cc.NodeID == r.id { propc = nil } r.removeNode(cc.NodeID) // 更新节点 case pb.ConfChangeUpdateNode: default: panic(\"unexpected conf type\") } select { case n.confstatec &lt;- pb.ConfState{ Nodes: r.nodes(), Learners: r.learnerNodes()}: case &lt;-n.done: } // 心跳和选举的timeout case &lt;-n.tickc: r.tick() // Ready是各种准备好的变更 case readyc &lt;- rd: if rd.SoftState != nil { prevSoftSt = rd.SoftState } if len(rd.Entries) &gt; 0 { prevLastUnstablei = rd.Entries[len(rd.Entries)-1].Index prevLastUnstablet = rd.Entries[len(rd.Entries)-1].Term havePrevLastUnstablei = true } if !IsEmptyHardState(rd.HardState) { prevHardSt = rd.HardState } if !IsEmptySnap(rd.Snapshot) { prevSnapi = rd.Snapshot.Metadata.Index } if index := rd.appliedCursor(); index != 0 { applyingToI = index } r.msgs = nil r.readStates = nil r.reduceUncommittedSize(rd.CommittedEntries) advancec = n.advancec // 确认Ready已经处理完的 case &lt;-advancec: if applyingToI != 0 { r.raftLog.appliedTo(applyingToI) applyingToI = 0 } if havePrevLastUnstablei { r.raftLog.stableTo(prevLastUnstablei, prevLastUnstablet) havePrevLastUnstablei = false } r.raftLog.stableSnapTo(prevSnapi) advancec = nil // 状态变更的消息 case c := &lt;-n.status: c &lt;- getStatus(r) // 是否有停止节点的消息 case &lt;-n.stop: close(n.done) return } }} raftNode结构体主循环： 如果proposeC中有数据写入（外部通信）:调用状态机进行处理 如果recvc中有数据写入(内部通信),调用状态机进行处理 如果confChangeC中有数据写入：调用node.Node.ProposeConfChange向raft库提交配置变更数据 如果tick定时器到期：,调用node.Tick函数进行raft库的定时操作 如果node.Ready()函数返回的Ready结构体channel有数据变更：依次处理Ready结构体中各成员数据 处理完毕之后调用node.Advance函数,进行持久化或者快照操作 如果状态有变更就变更状态 监听节点是否停止的消息 main.newRaftNode.startRaft.Step状态机器处理过程,这是raft的核心逻辑 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157// 状态机器理过程func (r *raft) Step(m pb.Message) error { //处理消息任期,这可能导致我们踩到追随者。 switch { // 如果任期为0 case m.Term == 0: // local message // 如果传入消息的任期大于当前节点的任期 //1.首先该函数会判断msg.Term是否大于本节点的Term,如果消息的任期号更大则说明是一次新的选举。这种情况下将根据msg.Context是否等于“CampaignTransfer”字符串来确定是不是一次由于leader迁移导致的强制选举过 // 程。同时也会根据当前的electionElapsed是否小于electionTimeout来确定是否还在租约期以内。如果既不是强制leader选举又在租约期以内,那么节点将忽略该消息的处理,在论文4.2.3部分论述这样做的原因,是为了避免 // 已经离开集群的节点在不知道自己已经不在集群内的情况下,仍然频繁的向集群内节点发起选举导致耗时在这种无效的选举流程中。如果以上检查流程通过了,说明可以进行选举了,如果消息类型还不是MsgPreVote类型,那么此时节 // 点会切换到follower状态且认为发送消息过来的节点msg.From是新的leader。 case m.Term &gt; r.Term: // 如果是 投票或者 与投票类型 if m.Type == pb.MsgVote || m.Type == pb.MsgPreVote { // 当context为campaignTransfer时表示强制要求进行竞选 force := bytes.Equal(m.Context, []byte(campaignTransfer)) // 判断当前是否在租约期以内,判断的条件包括：checkQuorum为true,当前节点保存的leader不为空,没有到选举超时,前面这三个条件同时满足。 inLease := r.checkQuorum &amp;&amp; r.lead != None &amp;&amp; r.electionElapsed &lt; r.electionTimeout if !force &amp;&amp; inLease { // 如果非强制,而且又在租约期以内,就不做任何处理 // 非强制又在租约期内可以忽略选举消息,见论文的4.2.3,这是为了阻止已经离开集群的节点再次发起投票请求 // If a server receives a RequestVote request within the minimum election timeout // of hearing from a current leader, it does not update its term or grant its vote r.logger.Infof(\"%x [logterm: %d, index: %d, vote: %x] ignored %s from %x [logterm: %d, index: %d] at term %d: lease is not expired (remaining ticks: %d)\", r.id, r.raftLog.lastTerm(), r.raftLog.lastIndex(), r.Vote, m.Type, m.From, m.LogTerm, m.Index, r.Term, r.electionTimeout-r.electionElapsed) return nil } } // 如果是与投票类型 switch { case m.Type == pb.MsgPreVote: // 在应答一个prevote消息时不对任期term做修改 // Never change our term in response to a PreVote case m.Type == pb.MsgPreVoteResp &amp;&amp; !m.Reject: //我们将在未来发送带有期限的投票前请求。如果 //投票前获得批准,当我们获得投票时,我们将增加我们的期限 //法定人数如果不是,则该任期来自节点 //拒绝了我们的投票,所以我们应该成为新的追随者期限 default: r.logger.Infof(\"%x [term: %d] received a %s message with higher term from %x [term: %d]\", r.id, r.Term, m.Type, m.From, m.Term) // 如果是日志复制复制,或者心跳,或者快照信息 认为发送过来的节点是新的leader if m.Type == pb.MsgApp || m.Type == pb.MsgHeartbeat || m.Type == pb.MsgSnap { // 成为发送消息方等的跟随者 r.becomeFollower(m.Term, m.From) } else { // 当前节点领导者设置为空,并更新任期为传入消息的任期,因为传入消息任期是大的 r.becomeFollower(m.Term, None) } } // 如果传入消息的任期小于当前节点的任期 case m.Term &lt; r.Term: // check quorum eader 向集群的所有节点发起广播,如果还能收到大多数节点的响应,处理读请求。 if (r.checkQuorum || r.preVote) &amp;&amp; (m.Type == pb.MsgHeartbeat || m.Type == pb.MsgApp) { //我们收到了来自低任期领导的消息。有可能的 //这些消息只是在网络中被延迟了,但是这可以 //也表示此节点在网络中提升了其任期编号 //分区,它现在无法赢得选举或重新加入 //旧词的多数。如果checkQuorum为false,则为 //通过递增任期编号来响应MsgVote来处理 //更高的任期,但如果checkQuorum为真,我们可能无法推进该任期 // MsgVote并且必须生成其他消息以推进该任期。互联网 //这两个功能的结果是最小化由中断引起的 //已从群集配置中删除的节点：a //删除的节点将发送将被忽略的MsgVotes（或MsgPreVotes）, //但它不会收到MsgApp或MsgHeartbeat,所以它不会创建 //通过通知领导者此节点的活动性来增加破坏性任期。 //以上评论也适用于预投票 // //当追随者被隔离时,很快就会开始选举结束 //比起领导者更高的学期,虽然不会得到足够的 //投票赢得大选。当它重新获得连接时,这种反应 //使用更高级别的“pb.MsgAppResp”会迫使领导者下台。 //但是,这种中断是不可避免的 //新选举这可以通过预投票阶段来预防。 r.send(pb.Message{To: m.From, Type: pb.MsgAppResp}) } else if m.Type == pb.MsgPreVote { //在预投票启用之前,可能有更高期限的候选人, //但更少的日志。更新到Pre-Vote后,群集可能会死锁 //我们删除较低期限的邮件。 r.logger.Infof(\"%x [logterm: %d, index: %d, vote: %x] rejected %s from %x [logterm: %d, index: %d] at term %d\", r.id, r.raftLog.lastTerm(), r.raftLog.lastIndex(), r.Vote, m.Type, m.From, m.LogTerm, m.Index, r.Term) r.send(pb.Message{To: m.From, Term: r.Term, Type: pb.MsgPreVoteResp, Reject: true}) } else { //忽略其他情况 r.logger.Infof(\"%x [term: %d] ignored a %s message with lower term from %x [term: %d]\", r.id, r.Term, m.Type, m.From, m.Term) } return nil } switch m.Type { // 选举信息 case pb.MsgHup: if r.state != StateLeader { ents, err := r.raftLog.slice(r.raftLog.applied+1, r.raftLog.committed+1, noLimit) if err != nil { r.logger.Panicf(\"unexpected error getting unapplied entries (%v)\", err) } if n := numOfPendingConf(ents); n != 0 &amp;&amp; r.raftLog.committed &gt; r.raftLog.applied { r.logger.Warningf(\"%x cannot campaign at term %d since there are still %d pending configuration changes to apply\", r.id, r.Term, n) return nil } r.logger.Infof(\"%x is starting a new election at term %d\", r.id, r.Term) if r.preVote { r.campaign(campaignPreElection) } else { r.campaign(campaignElection) } } else { r.logger.Debugf(\"%x ignoring MsgHup because already leader\", r.id) } //2.在raft.Step函数的后面,会判断消息类型是MsgVote或者MsgPreVote来进一步进行处理。其判断条件是以下两个条件同时成立： //2.1.当前没有给任何节点进行过投票（r.Vote == None ）,或者消息的任期号更大（m.Term &gt; r.Term ）,或者是之前已经投过票的节点（r.Vote == m.From)）。这个条件是检查是否可以还能给该节点投票。 //2.2.同时该节点的日志数据是最新的（r.raftLog.isUpToDate(m.Index, m.LogTerm) ）。这个条件是检查这个节点上的日志数据是否足够的新。 只有在满足以上两个条件的情况下,节点才投票给这个消息节点,将修改raft.Vote为消息发送者ID。如果不满足条件,将应答msg.Reject=true,拒绝该节点的投票消息。 case pb.MsgVote, pb.MsgPreVote: //如果是在续租之内那么就忽视 if r.isLearner { // TODO：学习者可能需要投票,如果节点在交换时失败。 r.logger.Infof(\"%x [logterm: %d, index: %d, vote: %x] ignored %s from %x [logterm: %d, index: %d] at term %d: learner can not vote\", r.id, r.raftLog.lastTerm(), r.raftLog.lastIndex(), r.Vote, m.Type, m.From, m.LogTerm, m.Index, r.Term) return nil } //之前已经投过票的节点 canVote := r.Vote == m.From || // 当前没有给任何节点进行过投票,并且没有领导者...... (r.Vote == None &amp;&amp; r.lead == None) || // 消息i和一个预投票,并且消息的任期号更大 (m.Type == pb.MsgPreVote &amp;&amp; m.Term &gt; r.Term) // r.raftLog.isUpToDate该节点的日志数据是最新的 if canVote &amp;&amp; r.raftLog.isUpToDate(m.Index, m.LogTerm) { r.logger.Infof(\"%x [logterm: %d, index: %d, vote: %x] cast %s for %x [logterm: %d, index: %d] at term %d\", r.id, r.raftLog.lastTerm(), r.raftLog.lastIndex(), r.Vote, m.Type, m.From, m.LogTerm, m.Index, r.Term) r.send(pb.Message{To: m.From, Term: m.Term, Type: voteRespMsgType(m.Type)}) if m.Type == pb.MsgVote { r.electionElapsed = 0 r.Vote = m.From } } else { r.logger.Infof(\"%x [logterm: %d, index: %d, vote: %x] rejected %s from %x [logterm: %d, index: %d] at term %d\", r.id, r.raftLog.lastTerm(), r.raftLog.lastIndex(), r.Vote, m.Type, m.From, m.LogTerm, m.Index, r.Term) // 否则拒绝投票 r.send(pb.Message{To: m.From, Term: r.Term, Type: voteRespMsgType(m.Type), Reject: true}) } default: err := r.step(r, m) if err != nil { return err } } return nil} 当条件是: 如果任期为0,不做处理 如果消息任期大于当前节点的任期 如果是预投票或者和投票类型 如果非强制,而且又在租约期以内,就不做任何处理（见论文的4.2.3,这是为了阻止已经离开集群的节点再次发起投票请求） ⚠️结束 如果是MsgPreVote类型,在应答一个prevote消息时不对任期term做修改 (防止分区导致的,领导人重新选举) 如果是MsgPreVoteResp类型并且没有拒绝 如果上面两者都不是的话 如果是领导者给跟随者发的消息或者收到了心跳或者收到了快照信息,就将当前节点,设置为跟随者。（根据论文 5.2 领导人选举 这一节） 否则就将领导者设置为空,因为不满足上面的条件不应当处理 如果传入消息的任期小于当前节点的任期 在等待投票的时候,候选人可能会从其他的服务器接收到声明它是领导人的附加日志项 RPC。如果这个领导人的任期号（包含在此次的 RPC中）不小于候选人当前的任期号,那么候选人会承认领导人合法并回到跟随者状态 （根据论文 5.2 领导人选举 这一节） 如果是MsgPreVote类型,会拒绝,因为候选人的任期没有当前节点的任期大,日志不是最新的。 否则忽略其他类型 ⚠️结束 如果是选举类型 （该类型只会由本节点发送给自己） 如果状态不是领导者 如果待处理的配置更改要应用,因此无法进行选举 ⚠️结束 如果状态是预投票,就开始预选举 如果状态是正式投票,就开始正式选举 如果是领导者就是忽略这条消息 如果是预投票或者和投票类型 如果该节点是学习者,学习者不能投票 ⚠️结束 如果 （1.)之前已经投过票的节点 或者 2.)当前没有给任何节点进行过投票,并且没有领导者 或者 3.)消息是预投票,并且消息的任期号更大）并且（该节点的日志数据是最新的） 就投票给这个消息节点,将修改raft.Vote为消息发送者ID 否则 将应答msg.Reject=true,拒绝该节点的投票消息 如果上面两种状态都不是,就进入特有身份处理步骤中 stepLeader stepCandidate stepFollower 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284func stepLeader(r *raft, m pb.Message) error { //这些消息类型不需要m.From的任何进展。 switch m.Type { case pb.MsgBeat: r.bcastHeartbeat() return nil // leader的定时器函数,在超过选举时间时,如果当前打开了raft.checkQuorum开关,那么leader将给自己发送一条MsgCheckQuorum消息,对该消息的处理是： // 检查集群中所有节点的状态,如果超过半数的节点都不活跃了,那么leader也切换到follower状态。 case pb.MsgCheckQuorum: if !r.checkQuorumActive() { r.logger.Warningf(\"%x stepped down to follower since quorum is not active\", r.id) r.becomeFollower(r.Term, None) } return nil // raft库的使用者向raft库propose数据时,最后会封装成这个类型的消息来进行提交,不同类型的节点处理还不尽相同。 case pb.MsgProp: if len(m.Entries) == 0 { r.logger.Panicf(\"%x stepped empty MsgProp\", r.id) } if _, ok := r.prs[r.id]; !ok { //如果我们当前不是范围的成员（即此节点） //作为领导者从配置中删除了）, //删除任何新提案。 return ErrProposalDropped } if r.leadTransferee != None { r.logger.Debugf(\"%x [term %d] transfer leadership to %x is in progress; dropping proposal\", r.id, r.Term, r.leadTransferee) return ErrProposalDropped } for i, e := range m.Entries { if e.Type == pb.EntryConfChange { if r.pendingConfIndex &gt; r.raftLog.applied { r.logger.Infof(\"propose conf %s ignored since pending unapplied configuration [index %d, applied %d]\", e.String(), r.pendingConfIndex, r.raftLog.applied) m.Entries[i] = pb.Entry{Type: pb.EntryNormal} } else { r.pendingConfIndex = r.raftLog.lastIndex() + uint64(i) + 1 } } } if !r.appendEntry(m.Entries...) { return ErrProposalDropped } r.bcastAppend() return nil // 其中,entries数组只会有一条数据,带上的是应用层此次请求的标识数据,在follower收到MsgReadIndex消息进行应答时,同样需要把这个数据原样带回返回给leader,详细的线性读一致性的实现在后面展开分析。 case pb.MsgReadIndex: if r.quorum() &gt; 1 { // 首先如果该leader在成为新的leader之后没有提交过任何值,那么会直接返回不做处理。 if r.raftLog.zeroTermOnErrCompacted(r.raftLog.term(r.raftLog.committed)) != r.Term { //当此领导者未在其任期内提交任何日志条目时,拒绝只读请求。 return nil } //思考：使用一个内部定义的上下文而不是用户给定的上下文。 //我们可以用任期和索引来表示,而不是用户提供的值。 //这将允许多次读取捎带在同一条消息上。 switch r.readOnly.option { case ReadOnlySafe: // 保存该MsgreadIndex请求到来时的commit索引。 r.readOnly.addRequest(r.raftLog.committed, m) // 向集群中所有其他节点广播一个心跳消息MsgHeartbeat,并且在其中带上该读请求的唯一标识。 r.bcastHeartbeatWithCtx(m.Entries[0].Data) case ReadOnlyLeaseBased: ri := r.raftLog.committed if m.From == None || m.From == r.id { // from local member r.readStates = append(r.readStates, ReadState{Index: r.raftLog.committed, RequestCtx: m.Entries[0].Data}) } else { r.send(pb.Message{To: m.From, Type: pb.MsgReadIndexResp, Index: ri, Entries: m.Entries}) } } } else { // there is only one voting member (the leader) in the cluster if m.From == None || m.From == r.id { // from leader itself r.readStates = append(r.readStates, ReadState{Index: r.raftLog.committed, RequestCtx: m.Entries[0].Data}) } else { //来自学习者成员 r.send(pb.Message{To: m.From, Type: pb.MsgReadIndexResp, Index: r.raftLog.committed, Entries: m.Entries}) } } return nil } // All other message types require a progress for m.From (pr). pr := r.getProgress(m.From) if pr == nil { r.logger.Debugf(\"%x no progress available for %x\", r.id, m.From) return nil } switch m.Type { //在节点收到leader的MsgApp/MsgSnap消息时,可能出现leader上的数据与自身节点数据不一致的情况,这种情况下会返回reject为true的MsgAppResp消息,同时rejectHint字段是本节点raft最后一条日志的索引ID。 //而index字段则返回的是当前节点的日志索引ID,用于向leader汇报自己已经commit的日志数据ID,这样leader就知道下一次同步数据给这个节点时,从哪条日志数据继续同步了。 //leader节点在收到MsgAppResp消息的处理流程大体如下（stepLeader函数中MsgAppResp case的处理流程）。 //首先,收到节点的MsgAppResp消息,说明该节点是活跃的,因此保存节点状态的RecentActive成员置为true。 //接下来,再根据msg.Reject的返回值,即节点是否拒绝了这次数据同步,来区分两种情况进行处理。 //msg.Reject为true的情况 //如果msg.Reject为true,说明节点拒绝了前面的MsgApp/MsgSnap消息,根据msg.RejectHint成员回退leader上保存的关于该节点的日志记录状态。比如leader前面认为从日志索引为10的位置开始向节点A同步数据,但是节点A拒绝了这次数据同步,同时返回RejectHint为2,说明节点A告知leader在它上面保存的最大日志索引ID为2,这样下一次leader就可以直接从索引为2的日志数据开始同步数据到节点A。而如果没有这个RejectHint成员,leader只能在每次被拒绝数据同步后都递减1进行下一次数据同步,显然这样是低效的。 // //1.因为上面节点拒绝了这次数据同步,所以节点的状态可能存在一些异常,此时如果leader上保存的节点状态为ProgressStateReplicate,那么将切换到ProgressStateProbe状态（关于这几种状态,下面会谈到）。 // //2.前面已经按照msg.RejectHint修改了leader上关于该节点日志状态的索引数据,接着再次尝试按照这个新的索引数据向该节点再次同步数据。 //msg.Reject为false的情况 //这种情况说明这个节点通过了leader的这一次数据同步请求,这种情况下根据msg.Index来判断在leader中保存的该节点日志数据索引是否发生了更新,如果发生了更新那么就说明这个节点通过了新的数据,这种情况下会做以下的几个操作。 // //1.修改节点状态 // //1.1如果该节点之前在ProgressStateProbe状态,说明之前处于探测状态,此时可以切换到ProgressStateReplicate,开始正常的接收leader的同步数据了。 //1.2如果之前处于ProgressStateSnapshot状态,即还在同步副本,说明节点之前可能落后leader数据比较多才采用了接收副本的状态。这里还需要多做一点解释,因为在节点落后leader数据很多的情况下,可能leader会多次通过snapshot同步数据给节点,而当 pr.Match &gt;= pr.PendingSnapshot的时候,说明通过快照来同步数据的流程完成了,这时可以进入正常的接收同步数据状态了,这就是函数Progress.needSnapshotAbort要做的判断。 //1.3.如果之前处于ProgressStateReplicate状态,此时可以修改leader关于这个节点的滑动窗口索引,释放掉这部分数据索引,好让节点可以接收新的数据了。关于这个滑动窗口设计,见下面详细解释。 //2.判断是否有新的数据可以提交（commit）了。因为raft的提交数据的流程是这样的：首先节点将数据提议（propose）给leader,leader在将数据写入到自己的日志成功之后,再通过MsgApp把这些提议的数据广播给集群中的其他节点,在某一条日志数据收到超过半数（qurom）的节点同意之后,才认为是可以提交（commit）的。因此每次leader节点在收到一条MsgAppResp类型消息,同时msg.Reject又是false的情况下,都需要去检查当前有哪些日志是超过半数的节点同意的,再将这些可以提交（commit）的数据广播出去。而在没有数据可以提交的情况下,如果之前节点处于暂停状态,那么将继续向该节点同步数据。 // //3.最后还要做一个跟leader迁移相关的操作。如果该消息节点是准备迁移过去的新leader节点（raft.leadTransferee == msg.From）,而且此时该节点上的Match索引已经跟旧的leader的日志最大索引一致,说明新旧节点的日志数据已经同步,可以正式进行集群leader迁移操作了。 case pb.MsgAppResp: pr.RecentActive = true if m.Reject { r.logger.Debugf(\"%x received msgApp rejection(lastindex: %d) from %x for index %d\", r.id, m.RejectHint, m.From, m.Index) if pr.maybeDecrTo(m.Index, m.RejectHint) { r.logger.Debugf(\"%x decreased progress of %x to [%s]\", r.id, m.From, pr) if pr.State == ProgressStateReplicate { pr.becomeProbe() } r.sendAppend(m.From) } } else { oldPaused := pr.IsPaused() if pr.maybeUpdate(m.Index) { switch { case pr.State == ProgressStateProbe: pr.becomeReplicate() case pr.State == ProgressStateSnapshot &amp;&amp; pr.needSnapshotAbort(): r.logger.Debugf(\"%x snapshot aborted, resumed sending replication messages to %x [%s]\", r.id, m.From, pr) // Transition back to replicating state via probing state // (which takes the snapshot into account). If we didn't // move to replicating state, that would only happen with // the next round of appends (but there may not be a next // round for a while, exposing an inconsistent RaftStatus). pr.becomeProbe() pr.becomeReplicate() case pr.State == ProgressStateReplicate: pr.ins.freeTo(m.Index) } if r.maybeCommit() { r.bcastAppend() } else if oldPaused { // If we were paused before, this node may be missing the // latest commit index, so send it. r.sendAppend(m.From) } // We've updated flow control information above, which may // allow us to send multiple (size-limited) in-flight messages // at once (such as when transitioning from probe to // replicate, or when freeTo() covers multiple messages). If // we have more entries to send, send as many messages as we // can (without sending empty messages for the commit index) for r.maybeSendAppend(m.From, false) { } // Transfer leadership is in progress. if m.From == r.leadTransferee &amp;&amp; pr.Match == r.raftLog.lastIndex() { r.logger.Infof(\"%x sent MsgTimeoutNow to %x after received MsgAppResp\", r.id, m.From) r.sendTimeoutNow(m.From) } } } //leader中会定时向集群中其他节点发送心跳消息,该消息的作用除了探测节点的存活情况之外,还包括： // //commit成员：leader选择min[节点上的Match,leader日志最大提交索引],用于告知节点哪些日志可以进行提交（commit）。 //context：与线性一致性读相关,后面会进行解释。 case pb.MsgHeartbeatResp: pr.RecentActive = true pr.resume() // free one slot for the full inflights window to allow progress. if pr.State == ProgressStateReplicate &amp;&amp; pr.ins.full() { pr.ins.freeFirstOne() } if pr.Match &lt; r.raftLog.lastIndex() { r.sendAppend(m.From) } // leader在接收到MsgHeartbeatResp消息后,如果其中有ctx字段,说明该MsgHeartbeatResp消息对应的MsgHeartbeat消息,是收到ReadIndex时leader消息为了确认自己还是集群leader发送的心跳消息 if r.readOnly.option != ReadOnlySafe || len(m.Context) == 0 { return nil } // 首先会调用r.readOnly.recvAck(m)函数,根据消息中的ctx字段,到全局的pendingReadIndex中查找是否有保存该ctx的带处理的readIndex请求,如果有就在acks map中记录下该follower已经进行了应答。 ackCount := r.readOnly.recvAck(m) // 当ack数量超过了集群半数时,意味着该leader仍然还是集群的leader,此时调用r.readOnly.advance(m)函数 if ackCount &lt; r.quorum() { return nil } // 将该readIndex之前的所有readIndex请求都认为是已经成功进行确认的了,所有成功确认的readIndex请求,将会加入到readStates数组中,同时leader也会向follower发送MsgReadIndexResp。 rss := r.readOnly.advance(m) for _, rs := range rss { req := rs.req if req.From == None || req.From == r.id { // from local member r.readStates = append(r.readStates, ReadState{Index: rs.index, RequestCtx: req.Entries[0].Data}) } else { r.send(pb.Message{To: req.From, Type: pb.MsgReadIndexResp, Index: rs.index, Entries: req.Entries}) } } //仅leader处理这类消息： //1.如果reject为false：表示接收快照成功,将切换该节点状态到探测状态。 //2.否则接收失败。 case pb.MsgSnapStatus: if pr.State != ProgressStateSnapshot { return nil } if !m.Reject { pr.becomeProbe() r.logger.Debugf(\"%x snapshot succeeded, resumed sending replication messages to %x [%s]\", r.id, m.From, pr) } else { pr.snapshotFailure() pr.becomeProbe() r.logger.Debugf(\"%x snapshot failed, resumed sending replication messages to %x [%s]\", r.id, m.From, pr) } //如果快照完成,请在发送之前等待来自远程节点的msgAppResp //淘汰下一个msgApp。 //如果快照失败,请在下次尝试之前等待心跳间隔 pr.pause() // 仅leader才处理这类消息,leader如果判断该节点此时处于正常接收数据的状态（ProgressStateReplicate）,那么就切换到探测状态。 case pb.MsgUnreachable: //在乐观复制期间,如果远程无法访问, // MsgApp很有可能丢失。 if pr.State == ProgressStateReplicate { pr.becomeProbe() } r.logger.Debugf(\"%x failed to send message to %x because it is unreachable [%s]\", r.id, m.From, pr) //3.这类消息follower将转发给leader处理,因为follower并没有修改集群配置状态的权限。 //leader在收到这类消息时,是以下的处理流程。 //3.1.如果当前的raft.leadTransferee成员不为空,说明有正在进行的leader迁移流程。此时会判断是否与这次迁移是同样的新leader ID,如果是则忽略该消息直接返回；否则将终止前面还没有完毕的迁移流程。 //3.2.如果这次迁移过去的新节点,就是当前的leader ID,也直接返回不进行处理。 //到了这一步就是正式开始这一次的迁移leader流程了,一个节点能成为一个集群的leader,其必要条件是上面的日志与当前leader的一样多,所以这里会判断是否满足这个条件,如果满足那么发送MsgTimeoutNow消息给新的leader通知该节点进行leader迁移,否则就先进行日志同步操作让新的leader追上旧leader的日志数据。 case pb.MsgTransferLeader: // 如果是学习者 就不能进行转发给leader if pr.IsLearner { r.logger.Debugf(\"%x is learner. Ignored transferring leadership\", r.id) return nil } leadTransferee := m.From lastLeadTransferee := r.leadTransferee if lastLeadTransferee != None { // 判断是否已经有相同节点的leader转让流程在进行中 if lastLeadTransferee == leadTransferee { r.logger.Infof(\"%x [term %d] transfer leadership to %x is in progress, ignores request to same node %x\", r.id, r.Term, leadTransferee, leadTransferee) // 如果是,直接返回 return nil } // 否则中断之前的转让流程 r.abortLeaderTransfer() r.logger.Infof(\"%x [term %d] abort previous transferring leadership to %x\", r.id, r.Term, lastLeadTransferee) } // 判断是否转让过来的leader是否本节点,如果是也直接返回,因为本节点已经是leader了 if leadTransferee == r.id { r.logger.Debugf(\"%x is already leader. Ignored transferring leadership to self\", r.id) return nil } //将领导权转移给第三方。 r.logger.Infof(\"%x [term %d] starts to transfer leadership to %x\", r.id, r.Term, leadTransferee) //转移领导应该在一个electionTimeout中完成,所以重置r.electionElapsed。 r.electionElapsed = 0 r.leadTransferee = leadTransferee if pr.Match == r.raftLog.lastIndex() { // 如果日志已经匹配了,那么就发送timeoutnow协议过去 r.sendTimeoutNow(leadTransferee) r.logger.Infof(\"%x sends MsgTimeoutNow to %x immediately as %x already has up-to-date log\", r.id, leadTransferee, leadTransferee) } else { // 否则继续追加日志 r.sendAppend(leadTransferee) } } return nil} case pb.MsgBeat:向所有跟随者,广播心跳,⚠️结束 case pb.MsgCheckQuorum: 检查是否有一半以上的跟随者在自己的状态机中处于活跃,⚠️结束 case pb.MsgProp:raft库的使用者向raft库propose数据时,最后会封装成这个类型的消息来进行提交,不同类型的节点处理还不尽相同。⚠️结束 case pb.MsgReadIndex: 如果总节点人数大于一个,也就是除了自己还有其他节点 首先如果该leader在成为新的leader之后没有提交过任何值,那么会直接返回不做处理。 然后检查只读类型是ReadOnlySafe还是ReadOnlyLeaseBased, 如果是ReadOnlySafe, 保存该MsgreadIndex请求到来时的commit索引,向集群中所有其他节点广播一个心跳消息MsgHeartbeat,并且在其中带上该读请求的唯一标识。 如果是ReadOnlyLeaseBased 如果消息是当前成员,如果没有提交过任何数据,那么在它所在的这个任期（term）内的commit索引当时是并不知道的,因此在成为leader之后,需要马上提交一个no-op的空日志,这样拿到该任期的第一个commit索引。 否则就发送消息回应给跟随者 否则 如果消息是当前成员,如果没有提交过任何数据,那么在它所在的这个任期（term）内的commit索引当时是并不知道的,因此在成为leader之后,需要马上提交一个no-op的空日志,这样拿到该任期的第一个commit索引。 否则就回应该消息,因为是因为是来自学习者 ⚠️结束 获取跟随者的进度 case pb.MsgAppResp: msg.Reject为true的情况,说明节点拒绝了前面的MsgApp/MsgSnap消息,根据msg.RejectHint成员回退leader上保存的关于该节点的日志记录状态。比如leader前面认为从日志索引为10的位置开始向节点A同步数据,但是节点A拒绝了这次数据同步,同时返回RejectHint为2,说明节点A告知leader在它上面保存的最大日志索引ID为2,这样下一次leader就可以直接从索引为2的日志数据开始同步数据到节点A。而如果没有这个RejectHint成员,leader只能在每次被拒绝数据同步后都递减1进行下一次数据同步,显然这样是低效的。 因为上面节点拒绝了这次数据同步,所以节点的状态可能存在一些异常,此时如果leader上保存的节点状态为ProgressStateReplicate,那么将切换到ProgressStateProbe状态（关于这几种状态,下面会谈到）。 前面已经按照msg.RejectHint修改了leader上关于该节点日志状态的索引数据,接着再次尝试按照这个新的索引数据向该节点再次同步数据。 msg.Reject为false的情况 更新进度,如果不是过时的 如果该节点之前在ProgressStateProbe状态,说明之前处于探测状态,此时可以切换到ProgressStateReplicate,开始正常的接收leader的同步数据了。 如果之前处于ProgressStateSnapshot状态,即还在同步副本,说明节点之前可能落后leader数据比较多才采用了接收副本的状态。这里还需要多做一点解释,因为在节点落后leader数据很多的情况下,可能leader会多次通过snapshot同步数据给节点,而当 pr.Match &gt;= pr.PendingSnapshot的时候,说明通过快照来同步数据的流程完成了,这时可以进入正常的接收同步数据状态了,这就是函数Progress.needSnapshotAbort要做的判断。 如果之前处于ProgressStateReplicate状态,此时可以修改leader关于这个节点的滑动窗口索引,释放掉这部分数据索引,好让节点可以接收新的数据了。关于这个滑动窗口设计,见下面详细解释。 判断是否有新的数据可以提交（commit）了。因为raft的提交数据的流程是这样的：首先节点将数据提议（propose）给leader,leader在将数据写入到自己的日志成功之后,再通过MsgApp把这些提议的数据广播给集群中的其他节点,在某一条日志数据收到超过半数（qurom）的节点同意之后,才认为是可以提交（commit）的。因此每次leader节点在收到一条MsgAppResp类型消息,同时msg.Reject又是false的情况下,都需要去检查当前有哪些日志是超过半数的节点同意的,再将这些可以提交（commit）的数据广播出去。而在没有数据可以提交的情况下,如果之前节点处于暂停状态,那么将继续向该节点同步数据。 最后还要做一个跟leader迁移相关的操作。如果该消息节点是准备迁移过去的新leader节点（raft.leadTransferee == msg.From）,而且此时该节点上的Match索引已经跟旧的leader的日志最大索引一致,说明新旧节点的日志数据已经同步,可以正式进行集群leader迁移操作了。 case pb.MsgHeartbeatResp: 将进度设置为活跃 为完整滑动窗口释放一个插槽以允许进度 如果消息节点是日志索引是落后的就发送追加 leader在接收到MsgHeartbeatResp消息后,如果其中有ctx字段,说明该MsgHeartbeatResp消息对应的MsgHeartbeat消息,是收到ReadIndex时leader消息为了确认自己还是集群leader发送的心跳消息 通知raft状态机收到的只读结构对只读请求附加的心跳的确认上下文,根据消息中的ctx字段,到全局的pendingReadIndex中查找是否有保存该ctx的带处理的readIndex请求,如果有就在acks map中记录下该follower已经进行了应答 当ack数量超过了集群半数时,意味着该leader仍然还是集群的leader,此时调用r.readOnly.advance(m)函数 将该readIndex之前的所有readIndex请求都认为是已经成功进行确认的了,所有成功确认的readIndex请求,将会加入到readStates数组中,同时leader也会向follower发送MsgReadIndexResp。 case pb.MsgSnapStatus:仅leader处理这类消息 如果reject为false：表示接收快照成功,将切换该节点状态到探测状态。 否则接收失败,将切换该节点状态到探测状态。 当Paused为true时,raft应暂停向此对等方发送复制消息。 case pb.MsgUnreachable:在乐观复制期间,如果远程无法访问,MsgApp很有可能丢失。 如果远程节点状态变为复制状态,就变为探测状态 case pb.MsgTransferLeader:这类消息follower将转发给leader处理,因为follower并没有修改集群配置状态的权限。 如果是学习者 就不能进行转发给leader 如果当前的raft.leadTransferee成员不为空,说明有正在进行的leader迁移流程。此时会判断是否与这次迁移是同样的新leader ID,如果是则忽略该消息直接返回；否则将终止前面还没有完毕的迁移流程。 判断是否转让过来的leader是否本节点,如果是也直接返回,因为本节点已经是leader了 如果日志已经匹配了,那么就发送timeoutnow协议过去 否则继续追加日志到新的领导者1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// stepCandidate 由StateCandidate和StatePreCandidate共享;不同的是//它们是否响应MsgVoteResp或MsgPreVoteResp。func stepCandidate(r *raft, m pb.Message) error { // 只处理与我们的候选资格相对应的投票回复 (当在StateCandidate, 在这个任期中,我们可能会收到陈旧的MsgPreVoteResp消息从我们的 pre-candidate 状态). var myVoteRespType pb.MessageType if r.state == StatePreCandidate { myVoteRespType = pb.MsgPreVoteResp } else { myVoteRespType = pb.MsgVoteResp } switch m.Type { case pb.MsgProp: r.logger.Infof(\"%x no leader at term %d; dropping proposal\", r.id, r.Term) return ErrProposalDropped case pb.MsgApp: r.becomeFollower(m.Term, m.From) // always m.Term == r.Term r.handleAppendEntries(m) case pb.MsgHeartbeat: r.becomeFollower(m.Term, m.From) // always m.Term == r.Term r.handleHeartbeat(m) case pb.MsgSnap: r.becomeFollower(m.Term, m.From) // always m.Term == r.Term r.handleSnapshot(m) case myVoteRespType: //1.节点调用raft.poll函数,其中传入msg.Reject参数表示发送者是否同意这次选举,根据这些来计算当前集群中有多少节点给这次选举投了同意票。 //2.如果有半数的节点同意了,如果选举类型是PreVote,那么进行Vote状态正式进行一轮选举；否则该节点就成为了新的leader,调用raft.becomeLeader函数切换状态,然后开始同步日志数据给集群中其他节点了。 //3.而如果半数以上的节点没有同意,那么重新切换到follower状态。 // 计算当前集群中有多少节点给自己投了票 gr := r.poll(m.From, m.Type, !m.Reject) r.logger.Infof(\"%x [quorum:%d] has received %d %s votes and %d vote rejections\", r.id, r.quorum(), gr, m.Type, len(r.votes)-gr) switch r.quorum() { case gr: // 如果进行投票的节点数量正好是半数以上节点数量 //如果选举类型是PreVote,那么进行Vote状态正式进行一轮选举； if r.state == StatePreCandidate { r.campaign(campaignElection) //vote状态正式的一轮选举 } else { // 变成leader r.becomeLeader() r.bcastAppend() } case len(r.votes) - gr: // 如果是半数以上节点拒绝了投票 // 变成follower // pb.MsgPreVoteResp包含未来候选人的期限 // m.Term &gt; r.Term; reuse r.Term r.becomeFollower(r.Term, None) } case pb.MsgTimeoutNow: r.logger.Debugf(\"%x [term %d state %v] ignored MsgTimeoutNow from %x\", r.id, r.Term, r.state, m.From) } return nil} pb.MsgProp:如果是提议属性消息,那么就直接放弃,因为在候选人阶段是不能够添加日志。 pb.MsgApp:如果收到领导人消息,直接将当前节点转为跟随者,并且向领导人发送当前的commitid pb.MsgHeartbeat:如果收到心跳,也变为跟随者,然后处理心跳 pb.MsgSnap:如果收到快照,也变为跟随者,然后处理快照 case myVoteRespType: 节点调用raft.poll函数,其中传入msg.Reject参数表示发送者是否同意这次选举,根据这些来计算当前集群中有多少节点给这次选举投了同意票。 如果有半数的节点同意了,如果选举类型是PreVote,那么进行Vote状态正式进行一轮选举；否则该节点就成为了新的leader,调用raft.becomeLeader函数切换状态,然后开始同步日志数据给集群中其他节点了。 而如果半数以上的节点没有同意,那么重新切换到follower状态。 case pb.MsgTimeoutNow:忽略这条信息,因为状态不对。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758func stepFollower(r *raft, m pb.Message) error { switch m.Type { case pb.MsgProp: if r.lead == None { r.logger.Infof(\"%x no leader at term %d; dropping proposal\", r.id, r.Term) return ErrProposalDropped } else if r.disableProposalForwarding { r.logger.Infof(\"%x not forwarding to leader %x at term %d; dropping proposal\", r.id, r.lead, r.Term) return ErrProposalDropped } m.To = r.lead r.send(m) case pb.MsgApp: r.electionElapsed = 0 r.lead = m.From r.handleAppendEntries(m) case pb.MsgHeartbeat: r.electionElapsed = 0 r.lead = m.From r.handleHeartbeat(m) case pb.MsgSnap: r.electionElapsed = 0 r.lead = m.From r.handleSnapshot(m) case pb.MsgTransferLeader: if r.lead == None { r.logger.Infof(\"%x no leader at term %d; dropping leader transfer msg\", r.id, r.Term) return nil } m.To = r.lead r.send(m) // 新的leader节点,在还未迁移之前仍然是follower,在收到这条消息后,就可以进行迁移了,此时会调用前面分析MsgVote时说过的campaign函数,传入的参数是campaignTransfer,表示这是一次由于迁移leader导致的选举流程。 case pb.MsgTimeoutNow: if r.promotable() { r.logger.Infof(\"%x [term %d] received MsgTimeoutNow from %x and starts an election to get leadership.\", r.id, r.Term, m.From) // Leadership transfers never use pre-vote even if r.preVote is true; we // know we are not recovering from a partition so there is no need for the // extra round trip. r.campaign(campaignTransfer) } else { r.logger.Infof(\"%x received MsgTimeoutNow from %x but is not promotable\", r.id, m.From) } case pb.MsgReadIndex: if r.lead == None { r.logger.Infof(\"%x no leader at term %d; dropping index reading msg\", r.id, r.Term) return nil } m.To = r.lead r.send(m) case pb.MsgReadIndexResp: if len(m.Entries) != 1 { r.logger.Errorf(\"%x invalid format of MsgReadIndexResp from %x, entries count: %d\", r.id, m.From, len(m.Entries)) return nil } r.readStates = append(r.readStates, ReadState{Index: m.Index, RequestCtx: m.Entries[0].Data}) } return nil} case pb.MsgProp:将消息转发给领导人 case pb.MsgApp:收到了领导人了消息,重置弹性超时时间,并且添加日志 case pb.MsgHeartbeat:收到心跳,重置弹性超时时间,处理心跳 case pb.MsgSnap:收到快照,重置弹性超时时间,处理快照 case pb.MsgTransferLeader:转移领导人 case pb.MsgTimeoutNow:新的leader节点,在还未迁移之前仍然是follower,在收到这条消息后,就可以进行迁移了,此时会调用前面分析MsgVote时说过的campaign函数,传入的参数是campaignTransfer,表示这是一次由于迁移leader导致的选举流程。 case pb.MsgReadIndex:像领导人发送读请求 case pb.MsgReadIndexResp:从远程条目里面,添加到本地条目到读状态数组 四、总结源码还是比较难的,还有一些地方我还需要仔细分析,在后面会慢慢加上去,目前就先分析主要流程。最核心的代码依然是在状态机中,Step()函数,以及三个身份的步骤的状态函数。","link":"/2019/09/12/Go/Etcd%E4%B8%ADRaft%E5%8D%8F%E8%AE%AE%E6%BA%90%E7%A0%81%E7%9A%84%E4%B8%8D%E5%AE%8C%E5%85%A8%E5%88%86%E6%9E%90%EF%BC%881%EF%BC%89/"},{"title":"Manacher算法","text":"在计算机科学中，最长回文子串或最长对称因子问题是在一个字符串中查找一个最长的连续的回文的子串，例如“banana”最长回文子串是“anana”。最长回文子串并不一定是唯一的，比如“abracadabra”，没有超过3的回文子串，但是有两个回文字串长度都是3：“ada”和“aca”。在一些应用中，我们求出全部的极大回文子串（不被其他回文串包含的回文子串）。 一、算法由来Manacher于[1]发现了一种线性时间算法，可以在列出给定字符串中从任意位置开始的所有回文子串。并且，Apostolico, Breslauer &amp; Galil [2]发现，同样的算法也可以在任意位置查找全部极大回文子串，并且时间复杂度是线性的。因此，他们提供了一种时间复杂度为线性的最长回文子串解法。另外，Jeuring (1994)[3], Gusfield (1997)[4]发现了基于后缀树的算法。也存在已知的高效并行算法。 在不使用Manacher算法的情况下，使用暴力方法对每一个字符进行向外扩的操作（中心扩展法），直到遇到不匹配的字符就停下来，继续查看下一个字符串，Mancher算法则是基于中心扩展法的基础之上，对扩出来的信息进行处理，这里是 Manacher 算法的精髓。 二、算法思想Manacher核心步骤有三步: 处理字符串奇偶数之间的差异，统一都变为奇数字符串。 是否有通过中心扩展法记录的最大边界直接能够得到当前字符串的最大回文字符串（加速扩过程）。 进行中心扩展法。 处理字符串奇偶数之间的差异如果不处理字符串的奇偶之间的差异会怎么样？ 我们举个例子ababa这是一个奇数，我们通过中心扩展法，向外不断扩展，直到找到不匹配的位置。在 0 位置的时候我们无法向外扩展因此直接得到 s[0] 的位置最远能扩 0 个位置。在 1 位置的时候， 由字符串 b向外扩展 ，s[0] a 和 s[2] a 相等，得到 s[1] 位置最远能扩 1 个位置。在 2 位置的时候， 由字符串 b向外扩展 ，s[1] b 和 s[3] b 相等，s[0] a 和 s[4] a 相等，得到 s[2] 位置最远能扩 2 个位置。s[3]的情况和s[1]相同，s[4]的情况和s[0]相同，因此ababa最大回文字符串为ababa。 我们再来举一个偶数的例子 abba。在 0 位置的时候我们无法向外扩展因此直接得到 s[0] 的位置最远能扩 0 个位置。在 1 位置的时候我们无法向外扩展因此直接得到 s[1] 的位置最远能扩 0 个位置。在 2 位置的时候我们无法向外扩展因此直接得到 s[2] 的位置最远能扩 0 个位置。在 3 位置的时候我们无法向外扩展因此直接得到 s[3] 的位置最远能扩 0 个位置。实际上我们这个字符串的最大回文字符串是abba!因此我们需要做奇偶处理。 怎么进行做奇偶处理？ 在字符串的开头，中间，结尾插入特殊标记符#，用任何不常用的字符都可以，并不会影响结果。例如字符串abba进行处理之后，为#a#b#b#a#。 12345678910111213func manacherSring(s string) []rune { runes := []rune(s) res := make([]rune, len(s)*2+1) for index, i := 0, 0; i &lt; len(res); i++ { if (i &amp; 1) == 0 { res[i] = '#' } else { res[i] = runes[index] index++ } } return res} 加速扩过程加速扩过程，我们需要记录三个变量。 维护一个数组 pArr,该数组维护了一个当前字符串所能扩的最大位置。例如#a#b#a#b#a#对应的 pArr 数组为 {1,2,1,4,1,6,1,4,1,2,1} 维护一个 pR 变量，这个变量记录当前扩展能扩展到最远地方，例如#a#b#a#b#a#， 在没有遍历之前初始值为 -1，当 s[0] 时，#的最长回文半径为1,最多向外扩展0个位置，因此 pR 为1。当 s[1] 时，a的最长回文半径为2,最多向外扩展2个位置，因此 pR 为3。当 s[2] 时，#的最长回文半径为1,最多向外扩展0个位置，因此 pR 为3,pR不必之前的大,保持不变。当 s[3] 时，b的最长回文半径为4,最多向外扩展3个位置，因此 pR 为7。当 s[4] 时，#的最长回文半径为1,最多向外扩展0个位置，因此 pR 为5,pR比之前的小,保持不变。当 s[5] 时，a的最长回文半径为6,最多向外扩展5个位置，因此 pR 为11,此时已经到达整个字符数组的结尾，所以之后的过程中pR将不再变化。当 s[7] 时，#的最长回文半径为1,最多向外扩展0个位置，因此 pR 为8,pR比之前的小,保持不变。当 s[8] 时，b的最长回文半径为4,最多向外扩展3个位置，因此 pR 为8,pR比之前的小,保持不变。当 s[9] 时，#的最长回文半径为1,最多向外扩展0个位置，因此 pR 为10,pR比之前的小,保持不变。当 s[10] 时，a的最长回文半径为2,最多向外扩展1个位置，因此 pR 为11,pR不必之前的大,保持不变。 整数index。这个变量表示最近一次更新pR时（pR只会在有更大的pR时才会更新），可以说index就是当前能扩到最有边界的回文中心。 如何用这三个变量进行扩过程呢？ index 是当前包括i的最大扩展的中心位置，其边界我们叫做左大和右大，i 是当前要扩展的位置，因为 i 在扩展中心内，index是一个大回文字符串，那么 i 的回文字符串也应该有 i’ 镜像的回文字符串。在情况 1 下，以 i 为中心的回文字符串被完全包括在大字符串内，那么 i 的扩展到最大的位置一定是 i 的右小边界，不可能超过右小边界，因为 i 字符串完全以 index 为中心扩展，如果可以再向右扩，镜像 i’ 早就应该扩了。在情况 2 下， i 的镜像 i’ 的左小’超过了左大边界，i的字符串最多能扩到右大边界，因为 i 以 index 为镜像，如果 i 能扩到超出右大的边界，同时 i‘ 镜像和 i 的字符串是回文的，index 为什么不继续向外扩展了，因为当前能扩展的最大最位置为右大，因此 i 必定不能向外扩展，i能扩展到的最大值为右大位置。情况下，i’ 的 镜像左小‘ 和左大重叠的时候，这个时候 i 以右大为边界可能可以继续向外扩展，这种情况是左小‘的左边一个字符不等于右小’的右边一个字符，整个index字符串没有向外扩，说明左大左边一个字符不等于右大右边一个字符，但是因为右小没有超过右大，左小左边的字符串是有可能等于右小右边的字符串，向外扩展的情况是未知的。 进行中心扩展法进行处理之后，我们就可以进行扩展 三、算法实现12345678910111213141516171819202122232425func maxLcpsLength(s string) int { if s == \"\" { return 0 } runes := manacherSring(s) pArr := make([]int, 0, len(runes)) var index, pR, max = -1, -1, math.MinInt32 for i := 0; i &lt; len(runes); i++ { pArr[i] = 1 if pR &gt; i { pArr[i] = pArr[2*index-i] if pArr[2*index-i] &gt; pR-i { pArr[i] = pR - i } } for ; i+pArr[i] &lt; len(runes) &amp;&amp; i-pArr[i] &gt; -1 &amp;&amp; runes[i+pArr[i]] == runes[i-pArr[i]]; pArr[i]++ { } if i+pArr[i] &gt; pR { pR = i + pArr[i] index = i } max = int(math.Max(float64(max), float64(pArr[i]))) } return max-1} 2*index-i 找到镜像位置，假如 j 是 i的镜像位置，那么 i + j = 2 * index , j = 2 * index-i 四、Manacher 算法的复杂度每次迭代均会使pR增加 ，在算法运行过程中从不减小。所以扩出去检查的次数就是O（N）的级别。","link":"/2020/07/29/Algorithm/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/Manacher%E7%AE%97%E6%B3%95/"},{"title":"二叉树神级遍历方法","text":"二叉树遍历的方法有很多,例如：前序遍历,中序遍历,后序遍历。但是时间复杂度却只能做到 O(N), 空间时间复杂度 O(N)。今天要介绍是 morris 遍历,时间复杂度可以做到 O(N),空间时间复杂度可以做到 O(1)。 一、Morris 遍历1. 该算法是如何做到空间时间复杂度为 O（1）在我们之前学习过的算法中,遍历二叉树的算法都会使用到栈空间,假如不递归,也会使用栈结构,所以空间时间复杂度是 O（N）无法避免。而 Morris 遍历则是使用当前节点的左节点的最右节点指向当前节点,来保证可以回到上层,所以不用使用栈空间结构。​ 2. 算法流程 从根节点开始遍历 首先看左节点是否为空 如果为空 否则直接遍历右节点 如果左节点不为空,则找到左节点的最右节点 如果最右节点指向的是当前节点,则将其置为空 如果最右节点指向的是空,那么就将最右节点指向当前节点,直接进入下一次循环,从步骤 1 向右遍历 3. Morris 遍历是如何遍历完下层,然后回到上一层在之前说的算法流程中提过,将当前左节点的最右指针指向,这一次是第一次遍历到这个位置,当遍历到下层的时候,没有最左节点的时候,就会顺着我们定义好的右节点指向上一层节点移动,这个时候就回到了上层,然后往右遍历,会遍历到最右节点第二次。所以该节点会被遍历到两次。 二、 代码实现morris 遍历123456789101112131415161718192021def morris(node: TreeNode): cur = node while cur is not None: mostRight: TreeNode = cur.left # 没有左节点 if mostRight is not None: # 找到最右左节点 while mostRight.right is not None and mostRight.right is not cur: mostRight = mostRight.right if mostRight.right is None: # 1 mostRight.right = cur cur = cur.left continue else: # 2 mostRight.right = None else # 3 pass cur = cur.right 和我说算法流程一样,我就不解释了。解释一下遍历的位置,1 位置遍历到是每一个节点的起始节点,可以说是父母节点,2 位置则是第二次遍历的位置,此时子节点已经遍历完毕,该位置为后根节点 ,3 位置可以说是右节点的遍历。 根据 morris 遍历,我们可以加工出前序遍历,中序遍历,后序遍历。 前序遍历123456789101112131415161718192021def preMorris(node: TreeNode, f): cur = node while cur is not None: mostRight: TreeNode = cur.left # 没有左节点 if mostRight is not None: # 找到最右左节点 while mostRight.right is not None and mostRight.right is not cur: mostRight = mostRight.right # 指回cur节点 if mostRight.right is None: mostRight.right = cur f(cur.val) cur = cur.left continue # 如果当前最右节点指向cur 后打印 else: mostRight.right = None else: f(cur.val) cur = cur.right 根据我一开始的解释,应该能看的很明白,先遍历先根节点（包括左节点）,后遍历右节点。 中序遍历123456789101112131415161718192021def orderMorris(node: TreeNode, f): cur = node while cur is not None: mostRight: TreeNode = cur.left # 没有左节点 if mostRight is not None: # 找到最右左节点 while mostRight.right is not None and mostRight.right is not cur: mostRight = mostRight.right # 指回cur节点 if mostRight.right is None: mostRight.right = cur cur = cur.left continue # 如果当前最右节点指向cur 后打印 else: mostRight.right = None else: pass f(cur.val) cur = cur.right 中序遍历可以直接使用最外面一层,最外一层的遍历方式就是,查找到最左节点后,这个时候才会走到中序遍历的过程,这个时候遍历的就是最左节点,然后最左节点的右节点指向上一层节点（父母节点）,也就是根节点,然后根节点,首先会将mostRight.right置为空,然后执行cur = cur.right往右遍历。此时遍历到的节点就是左根右,符合中序遍历,然后递推到整个过程就会将整棵树遍历完。 后序遍历123456789101112131415161718192021222324252627282930313233343536373839def reverseEdge(mostRight) -&gt; TreeNode: pre = None while mostRight is not None: next = mostRight.right mostRight.right = pre pre = mostRight mostRight = next return predef printEdge(mostRight, f): head: TreeNode = reverseEdge(mostRight) while head is not None: f(head.val) reverseEdge(head)def postmorris(node: TreeNode, f): cur = node while cur is not None: mostRight: TreeNode = cur.left # 没有左节点 if mostRight is not None: # 找到最右左节点 while mostRight.right is not None and mostRight.right is not cur: mostRight = mostRight.right # 指回cur节点 if mostRight.right is None: # 1 mostRight.right = cur cur = cur.left continue # 如果当前最右节点指向cur 后打印 else: # 2 printEdge(mostRight, f) mostRight.right = None cur = cur.right printEdge(node, f) 后序遍历会稍微复杂点,其只用用到了第二次遍历,这个时候已经遍历到最左位置,过程为翻转最右链表,然后遍历,翻转回来,那么得到的结果就是左节点先被遍历到,然后是右节点,然后遍历到上一层后的节点就是根节点,那么顺序就是左右根。翻转第一次为了得到后序遍历顺序,翻转第二次,防止破坏原来的数据结构。遍历到最后只有head节点的右链表,因为head节点没有上层节点,所以head永远都不会进入 1 和 2 。所以最后我们需要手动遍历head节点。 三、总结morris 遍历作为一种不错的优化手段,其后序遍历较为复杂外,前序遍历和中序遍历都很简单,在这两种遍历的情况下,可以优先选择这种遍历。后序遍历的话,对空间复杂度有要求的话,则可以使用。当然其实都可以在日常使用这种遍历方式去遍历二叉树,因为也都不是很复杂。","link":"/2020/04/09/Algorithm/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%A5%9E%E7%BA%A7%E9%81%8D%E5%8E%86%E6%96%B9%E6%B3%95/"},{"title":"TOP-K 问题的终极算法 - BFPRT 算法","text":"TOP-K 问题,从一堆无序数据里面找到前 K 大（当然也可以是前 K 小的数。我可以用堆排序或者快速排序可以做到,但是时间复杂度为 O（NlogN）, 这里就不多说了。BFPRT 算法,该算法于1973年由 Blum、Floyd、Pratt、Rivest 和 Tarjan 联合发明,其中蕴含的深刻思想改变了世界。BFPRT 算法解决了这样一个问题,在时间复杂度 O（N）内,从无序的数组中找到第 K 小的数。 1.BFPRT 算法的核心思想假设 BFPRT 算法的函数是selectK(des []int, start int, end int, i int) int,该函数的功能为在arr中找到第k小的数,然后返回该数。selectK(des []int, start int, end int, i int) int的过程如下： 将arr中的n个元素划分成n/5组,每组5个元素,如果最后的组不够5个元素,那么最后剩下的元素为一组（n%5个元素）。 对每个组进行插入排序,只针对每个组最多5个元素之间的组内排序,组与组之间并不排序。排序后找到每个组的中位数,如果组的元素个数为偶数,这里规定找到下中位数(位置处于排好序数组右边的中位数)。 步骤2中一共会找到n/5个中位数,让这些中位数组成一个新的数组,记为 midArray 。递归调用selectK （midArray, 0, len(midArray)-1, len(midArray)/2）,意义是找到 mArr 数组中的中位数,即 midArray 中第（midArray.length/2）小的数。 假设步骤3中递归调用selectK （midArray, 0, len(midArray)-1, len(midArray)/2）后,返回的数为 x 。根据这个 x 划分整个 arr 数组（partition过程）,划分的过程为：在arr中,比 x 小的数都在 x 的左边,大于 x 的数都在 x 的右边,x 在中间。划分完成后,x 在 arr 中的位置记为 i。 如果 i==k ,说明x为整个数组中第 k 小的数,直接返回。 如果 i＜k,说明 x 处在第 k 小的数的左边,应该在 x 的右边寻找第 k 小的数,所以递归调用selectK函数,在右半区寻找第 i 小的数。 如果 i＞k,说明 x 处在第 k 小的数的右边,应该在 x 的左边寻找第k小的数,所以递归调用selectK函数,在左半区寻找第 k 小的数。 2.BFPRT 算法怎么找到第K大的数BFPRT 算法又叫中位数的中位数算法,一次中位数的运算可以找到第50%的数，根据当前中位数在数组中的位置K’，可以判断当前第50%大的数是不是第K的数。如果 K’ &lt; K ，则往右半区查找。因为在合并后，K’位置左边的数一定比所有小于K’位置的数小，K’位置右边的数一定比所有小于K’位置的数大。所以当 K’ = K 时,就是第 K 大的数。 3.BFPRT 算法实现 主函数过程如下:从当前数组中找到第 K 大中位数,然后对数组进行划分,比 x 小的数都在x的左边,大于 x 的数都在 x 的右边,x在中间。x在arr中的位置记为i。如果 i==k,说明x为整个数组中第 k 小的数,直接返回。如果 i＜k,说明 x 处在第 k 小的数的左边,应该在 x 的右边寻找第 k 小的数,所以递归调用selectK函数,在右半区寻找第 i 小的数。如果 i＞k,说明 x 处在第 k 小的数的右边,应该在 x 的左边寻找第k小的数,所以递归调用selectK函数,在左半区寻找第 k 小的数。 123456789101112131415161718func selectK(arr []int, start int, end int, i int) int { if start == end { return arr[start] } midNumber := getMinNumberByArray(arr, start, end) rangeMid := getRangMidPosition(arr, start, end, midNumber) //println(\"=========================\") //fmt.Println(\"arr = \",arr) //fmt.Println(\"midNumber = \",midNumber) //println(\"pivotRange = \", rangeMid[0], \" \", rangeMid[1]) if i &gt;= rangeMid[0] &amp;&amp; i &lt;= rangeMid[1] { return arr[i] } else if i &gt;= rangeMid[0] { return selectK(arr, rangeMid[1]+1, end, i) } else { return selectK(arr, start, rangeMid[0]-1, i) }} 从原始数组中找到算出中位数数组的长度大小,如果最后剩余长度小于5,则单独划分成一组,通过getMid函数,得到每小组的中位数。然后再对中位数数组继续调用selectK方法,找到中位数组的中位数,直到start == end为止,返回的数 x 就是当前数组中位数的值。 12345678910111213141516func getMinNumberByArray(arr []int, begin, end int) int { var midArray []int num := end - begin + 1 if num%5 == 0 { midArray = make([]int, num/5) } else { midArray = make([]int, num/5+1) } for i := 0; i &lt; len(midArray); i++ { s := begin + i*5 e := s + 4 midArray[i] = getMid(arr, s, int(math.Min(float64(e), float64(end)))) } return selectK(midArray, 0, len(midArray)-1, len(midArray)/2)} 得到当前段数组的中位数过程,首先进行插入排序,保证这是一个有序数组,如果当前数组是偶数,sum/2得出的就直接是下中位数,如果数组不是偶数,则使用下中位数mid := sum/2 + sum%2。 123456func getMid(arr []int, s int, e int) int { insertSort(arr, s, e) sum := s + e mid := sum/2 + sum%2 return arr[mid]} 插入排序过程如下 1234567891011func insertSort(arr []int, s int, e int) { for i := s + 1; i != e+1; i++ { for j := i; j != s; j-- { if arr[j-1] &gt; arr[j] { arr[j-1], arr[j] = arr[j], arr[j-1] } else { break } } }} 得到数组的中位数后,然后对数组进行划分,比 x 小的数都在 x 的左边,大于 x 的数都在x的右边,值为 x 在中间 small 到 big的区域,这样就不用重复计算这些数据。 123456789101112131415161718func getRangMidPosition(arr []int, start int, end int, midNumber int) [2]int { small := start big := end cur := start for cur != big+1 { if arr[cur] &lt; midNumber { arr[cur], arr[small] = arr[small], arr[cur] cur++ small++ } else if arr[cur] &gt; midNumber { arr[cur], arr[big] = arr[big], arr[cur] big-- } else { cur++ } } return [2]int{small, big}} 我们通过一组数据来具体的说明算法是如何工作的,下面给出一组测试案例 1234567891011121314151617181920212223func Test_getMinKByBF(t *testing.T) { type args struct { arr []int k int } tests := []struct { name string args args want int }{ {name: \"\", args: struct { arr []int k int }{arr: []int{6, 9, 1, 3, 1, 2, 2, 5, 6, 1, 3, 5, 9, 7, 2, 5, 6, 1, 9}, k: 16}, want: 7}, } for _, tt := range tests { t.Run(tt.name, func(t *testing.T) { if got := getMinKByBFPRT(tt.args.arr, tt.args.k); got != tt.want { t.Errorf(\"getMinKByBFPRT() = %v, want %v\", got, tt.want) } }) }} 因此数组是从 0 开始的,那么在数组中的位置是 15 12345func getMinKByBFPRT(arr []int, k int) int { des := make([]int, len(arr)) copy(des, arr) return selectK(des, 0, len(arr)-1, k-1)} 运行结果如下： 12345678910111213141516171819202122232425=========================arr = [2 3 5 6]midNumber = 5pivotRange = 2 2i = 2=========================arr = [1 1 3 1 1 2 2 2 3 5 5 5 7 9 6 9 6 9 6]midNumber = 5pivotRange = 9 11i = 15=========================arr = [7 9]midNumber = 9pivotRange = 1 1i = 1=========================arr = [1 1 3 1 1 2 2 2 3 5 5 5 6 6 7 6 9 9 9]midNumber = 9pivotRange = 16 18i = 15=========================arr = [1 1 3 1 1 2 2 2 3 5 5 5 6 6 6 7 9 9 9]midNumber = 6pivotRange = 12 14i = 15 首先找到无序数组6, 9, 1, 3, 1, 2, 2, 5, 6, 1, 3, 5, 9, 7, 2, 5, 6, 1, 9的中位数,进入递归,递归后的划分原来的中位数数组为[2 3 5 6],并且已经被中位数 5 划分了,返回 5,5 就是原来无序数组的中位数。 从递归回到主函数后,根据找到的中位数 5 ,划分数组,划分后的位置在[9,11]比我们要找到第 16 大数小,所以排除左边区域,从右边开始找。 和上面解释一样,找到了 新无序数组的中位数组的中位数,返回 9 ,位置在[16,18]比 15 大 ,往前查找,最终找到了位置[12,14]比 15 大,往前后查找,start == end,此时start位置 15 就是第 16 小的数。","link":"/2020/04/04/Algorithm/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/TOP-K%E9%97%AE%E9%A2%98%E7%9A%84%E7%BB%88%E6%9E%81%E7%AE%97%E6%B3%95-BFPRT%E7%AE%97%E6%B3%95/"},{"title":"完全弄懂 KMP 算法","text":"在大学时期,学习 KMP 算法感觉自己好似懂,但是好似又不懂,书里看的云里雾里不知所起然,最近对算法重新进行学习,对于 KMP 算法有了更深刻的理解。 一、KMP 算法1.算法由来 KMP 算法是由D.E. Knuth、J.H.Morris和V.R. Pratt提出的,可在一个主文本字符串S内查找一个词W的出现位置。此算法通过运用对这个词在不匹配时本身就包含足够的信息来确定下一个匹配将在哪里开始的发现,从而避免重新检查先前匹配的字符。这个算法是由高德纳和沃恩·普拉特在1974年构思,同年詹姆斯·H·莫里斯也独立地设计出该算法,最终由三人于1977年联合发表。该算法减少了BF算法中i回溯所进行的无谓操作,极大地提高了字符串匹配算法的效率。 [1],由D.E.Knuth,J.H.Morris和V.R.Pratt提出的,因此人们称它为克努特—莫里斯—普拉特操作（简称KMP算法）。 2.算法的核心思想KMP算法的核心是利用匹配失败后的信息,尽量减少模式串与主串的匹配次数以达到快速匹配的目的。具体实现就是通过一个next()函数实现,函数本身包含了模式串的局部匹配信息。KMP算法的时间复杂度O(m+n)。 3.解释我们BF算法就是通过逐个扫描,从主串到模版串进行注意匹配,而 kmp 算法做的就是减少从头开始匹配的过程,来避免多次进行不必要的匹配。那么假设我们已经得到了模板串的滑动数组,该数组作用就是当从某一个位置匹配失败时,可以迅速的找到之前一个类似的匹配位置。因此我们可以根据 BF 算法轻易的写出关于kmp算法的雏形。 1234567891011121314151617181920func kmpMatch(s string, m string) int { next := getNextArray(m) mlen, slen := len(m), len(s) si, mi := 0, 0 for si &lt; slen &amp;&amp; mi &lt; mlen { if s[si] == m[mi] { si++ mi++ } else if next[mi] == -1 { si++ } else { mi = next[mi] } } index := -1 if mi == mlen { index = si - mlen } return index} 我可以根据字符串遍历的程度,要判断是否匹配成功,如果模版串遍历完成,遍历索引等于模版字符串的长度,那么就说明在主串中找到了包含模版串。否则就能知道是主串已经遍历完成,但是模版串还没有遍历完成。 在整个for循环中,如果主串的位置,和模板串的字符匹配,那么就进行下一个位置的匹配。如果滑动数组已经滑动到最开始的位置,那么直接将主串向前滑动一步,此时模板串已经处于索引为0处。如果以上两种情况都不是,那么认为滑动数组还没有滑动到索引为0的位置,认为当前位置可以继续尝试匹配,那么让滑动数组回到上一个认为可以滑动的位置,再进行匹配。 下面我门讨论一下如何得到next数组: 图上给出的就是一个next数组,其中当前值代表的是之前有多少个字符串与开头字符串相匹配,可以看到i=0时,没有字符串和它匹配,并且是开头就特殊标记为 -1,i=1时,我们定义滑动数组为前缀数组与后缀数组（不包含第一个字符）的匹配,所以当前i=1位置,如果即使是a,值也为0。所以将当前位置值设置为0。再来看i=2时 ,next[1]为0,那么表示从头开始匹配,s[0](a)位置与s[1](b)位置不匹配,那么之前没有匹配的字符串,所以当前值也填为0。i=3时,这个时候可以看到s[0](a)位置与s[2](a)位置匹配,所以当前位置可以设置为1,反复如此,求出next数组。 那么上图就画出了匹配情况m[k]与m[j]匹配情况与不匹配的情况。 1234567891011121314151617181920212223func getNextArray(m string) []int { if len(m) &lt;= 2 { return []int{-1, 0} } next := make([]int, len(m)) next[0] = -1 next[1] = 0 pos := 2 cn := 0 for pos &lt; len(next) { if m[pos-1] == m[cn] { cn++ next[pos] = cn pos++ } else if cn &gt; 0 { cn = next[cn] } else { next[pos] = 0 pos++ } } return next} next[0]规定为-1,只是一个特殊的标记这是滑动数组的开头,并且之前也可能会有相匹配的字符串,一般为负数就可以,通常为-1。m[1]来说,m[0],但next数组的定义要求任何子串的后缀不能包括第一个字符（m[0]）,m[1]之前的字符串只有长度为0的后缀字符串,next[1]为0。 创建一个变量cn,作用是记录当前匹配的长度。创建一个遍历pos,作用是推进下标前进,判断当前位置之前有几个字符串于之匹配。这样实际上是两个指针cn指针代表当前匹配的长度,pos指针则是主指针,推动数组下标前进,更新当前匹配了之前有多少个字符串相匹配。 在for循环内,从位置index = 2开始匹配。 如果当前位置的前一个位置的字符 和m[cn]字符相等,那么将当前将记录当前匹配长度的cn++,同时将该pos位置的值设置为当前匹配的长度,然后将pos++,进行下一轮匹配。 否则,如果当前记录的匹配长度没有到0,那么将cn指针的位置回退到前一个位置进行匹配。 否则,如果当前cn指针的位置已经到0,那么就将pos位置的值设置为0,因为之前没有任何一个位置匹配,同时pos++,进行下一轮匹配。","link":"/2020/04/03/Algorithm/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E5%AE%8C%E5%85%A8%E5%BC%84%E6%87%82KMP%E7%AE%97%E6%B3%95/"},{"title":"跳跃表实现","text":"跳跃列表是一种数据结构。它允许快速查询一个有序连续元素的数据链表。跳跃列表的平均查找和插入时间复杂度都是O(log n),优于普通队列的O(n)。 白话跳跃表我们知道如果是普通的链表,查找为O(n),插入也会O(n),如果是数据量过大的情况下,肯定是无法忍受的,怎么办？给链表加索引,比如说给100个数里面随机给10个数加索引,如果索引分布均匀的话,那么时间复杂是不是最多查找11次？,如果11次还嫌长了怎么办？继续提升索引,提升索引这个比例我们设置为50%,这样可以保证索引在每一层都能分布均匀,且上一层的索引数,差不多是下一层的两倍。听我这样讲是不是感觉很像平衡树的样子,是不是过程看起来很像。 跳跃表和平衡树的区别跳跃列表不像平衡树等数据结构那样提供对最坏情况的性能保证：由于用来建造跳跃列表采用随机选取元素进入更高层的方法,在小概率情况下会生成一个不平衡的跳跃列表（最坏情况例如最底层仅有一个元素进入了更高层,此时跳跃列表的查找与普通列表一致）。但是在实际中它通常工作良好,随机化平衡方案也比平衡二叉查找树等数据结构中使用的确定性平衡方案容易实现。跳跃列表在并行计算中也很有用：插入可以在跳跃列表不同的部分并行地进行,而不用对数据结构进行全局的重新平衡。 跳跃表实现原理 从上面skiplist的创建和插入过程可以看出,每一个节点的层数（level）是随机出来的,而且新插入一个节点不会影响其它节点的层数。因此,插入操作只需要修改插入节点前后的指针,而不需要对很多节点都进行调整。这就降低了插入操作的复杂度。实际上,这是skiplist的一个很重要的特性,这让它在插入性能上明显优于平衡树 代码实现下面我粘贴的是维基百科的伪代码实现,具体实现过程和伪代码差不多,提升节点采用是50%概率提升,来保证跳表索引高度为 log n。 伪代码如下12345678910111213141516make all nodes level 1j ← 1while the number of nodes at level j &gt; 1 do for each i'th node at level j do if i is odd if i is not the last node at level j randomly choose whether to promote it to level j+1 else do not promote end if else if i is even and node i-1 was not promoted promote it to level j+1 end if repeat j ← j + 1repeat 使用 golang 实现跳跃表node 节点 12345678910111213141516171819202122232425262728293031package jumptabletype Node struct { key int value interface{} up, down, left, right *Node level int}func newNode(k int, v interface{}) *Node { return &amp;Node{ key: k, value: v, }}func (n *Node) equals(node *Node) bool { if node == nil { return false } if n.key != node.key { return false } if n.value != node.value { return false } if n.level != node.level { return false } return true} 跳跃表 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130package jumptableimport ( \"math/rand\" \"time\")type jumpTable struct { header *Node r *rand.Rand}func New() *jumpTable { return &amp;jumpTable{ r: rand.New(rand.NewSource(time.Now().UnixNano())), header: newNode(-int(^uint(0) &gt;&gt; 1), nil), }}func (jt *jumpTable) Search(k int) *Node { println(\"walkPreviousNode\") node, count := walkPreviousNode(jt.header, k) println(\"共需要\", count, \"步\") return node}func (jt *jumpTable) Insert(k int, v interface{}) { sn := jt.header newN := newNode(k, v) node, _ := walkPreviousNode(sn, k) if node.key == k { node.value = v return } currentLevel := 0 newN.level = currentLevel jt.setNode(newN, node) lowNode := newN for jt.isPromotion() { println(\"isPromotion\") currentLevel++ upNewN := setUpNewDownNode(currentLevel, k, v, newN) if jt.header.level &lt; currentLevel { updateHeader(jt, upNewN) } leftUpNode := findLeftUpNode(lowNode, upNewN) if leftUpNode != nil { jt.setNode(upNewN, leftUpNode) } newN = upNewN }}func updateHeader(jt *jumpTable, upNew *Node) { jt.header = upNew}func setUpNewDownNode(level int, k int, v interface{}, newN *Node) *Node { upNew := newNode(k, v) upNew.level = level newN.up = upNew upNew.down = newN return upNew}func findLeftUpNode(newN *Node, upNew *Node) *Node { var leftUpNode *Node leftNewNode := newN.leftleftBreak: for leftNewNode != nil { leftNewUpNode := leftNewNode.up for leftNewUpNode != nil { if leftNewUpNode.level == upNew.level { leftUpNode = leftNewUpNode break leftBreak } leftNewUpNode = leftNewUpNode.up } leftNewNode = leftNewNode.left } return leftUpNode}// new 后面插入curfunc (jt *jumpTable) setNode(q *Node, p *Node) { q.left = p if p.right != nil { q.right = p.right p.right.left = q } p.right = q}func walkPreviousNode(curNode *Node, k int) (*Node, int) { println(\"k:\", k, \" level\", curNode.level) count := 0 for curNode.key &lt; k { count++ if curNode.right == nil { break } println(\"curNode.key &lt; k \", curNode.key, \"--&gt;\", curNode.right.key) curNode = curNode.right } for curNode.key &gt; k { count++ if curNode.left == nil { break } println(\"curNode.key &gt; k \", curNode.key, \"--&gt;\", curNode.left.key) curNode = curNode.left } if curNode.down != nil { var newCount int println(\"curNode.down \", curNode.key, \"--&gt;\", curNode.down.key) curNode, newCount = walkPreviousNode(curNode.down, k) count += newCount } return curNode, count}func (jt *jumpTable) isPromotion() bool { n := jt.r.Intn(2) if n == 0 { return false } return true} 进行测试 123456789101112131415161718192021222324package jumptableimport ( \"math/rand\" \"testing\" \"time\")func TestJumpTable_Insert(t *testing.T) { for i:=0 ;i &lt;1;i++ { table := New() r := rand.New(rand.NewSource(time.Now().UnixNano())) table.Insert(13, nil) for i := 0; i &lt; 1000; i++ { table.Insert(r.Intn(100000), nil) } node := table.Search(13) if node.key != 13{ panic(\"\") } println(node.key) }} walkPreviousNode k: 13 level 12 curNode.down 18542 --&gt; 18542 k: 13 level 11 curNode.down 18542 --&gt; 18542 k: 13 level 10 curNode.down 18542 --&gt; 18542 k: 13 level 9 curNode.down 18542 --&gt; 18542 k: 13 level 8 curNode.key &gt; k 18542 --&gt; 2659 curNode.down 2659 --&gt; 2659 k: 13 level 7 curNode.down 2659 --&gt; 2659 k: 13 level 6 curNode.down 2659 --&gt; 2659 k: 13 level 5 curNode.down 2659 --&gt; 2659 k: 13 level 4 curNode.down 2659 --&gt; 2659 k: 13 level 3 curNode.key &gt; k 2659 --&gt; 1626 curNode.down 1626 --&gt; 1626 k: 13 level 2 curNode.down 1626 --&gt; 1626 k: 13 level 1 curNode.key &gt; k 1626 --&gt; 1436 curNode.down 1436 --&gt; 1436 k: 13 level 0 curNode.key &gt; k 1436 --&gt; 1270 curNode.key &gt; k 1270 --&gt; 996 curNode.key &gt; k 996 --&gt; 964 curNode.key &gt; k 964 --&gt; 957 curNode.key &gt; k 957 --&gt; 848 curNode.key &gt; k 848 --&gt; 792 curNode.key &gt; k 792 --&gt; 759 curNode.key &gt; k 759 --&gt; 671 curNode.key &gt; k 671 --&gt; 513 curNode.key &gt; k 513 --&gt; 413 curNode.key &gt; k 413 --&gt; 99 curNode.key &gt; k 99 --&gt; 28 curNode.key &gt; k 28 --&gt; 13 共需要 28 步 13 可以看见差不多时间复杂度是O(log n) 总结 作为一种简单的数据结构,在大多数应用中Skip lists能够代替平衡树。Skiplists算法非常容易实现、扩展和修改。Skip lists和进行过优化的平衡树有着同样高的性能,Skip lists的性能远远超过未经优化的平衡二叉树。","link":"/2019/06/02/Algorithm/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E8%B7%B3%E8%B7%83%E8%A1%A8%E5%AE%9E%E7%8E%B0/"},{"title":"手撕红黑树","text":"红黑树,作为一种复杂的数据结构,曾经也是令我抓狂。但是该结构也是相当重要的结构,在 Java 的 TreeMap 中的实现就是红黑树这个高级数据结构。本文会对红黑树算法可行性进行证明,并且给出最终实现,以下理解若有出入,希望能够指出。 一、如何保持平衡左旋右旋过程如下: 左旋转 替代 Y 结点为 X 结点的位置,先将 Y 结点的父母结点设置为 X 结点的父结点,并设置 X 的父结点的子结点（根据 X 是 X 父结点的子结点位置来设置为左或者右结点）,如果 X 的父结点为空,则设置 Y 的父结点也为空。 原先的结点布局为 X 的子结点为 a 和 Y ,Y 的子结点为 b 和 c。旋转后结点布局应该为 X 的子结点为 a 和 b ,y 的子结点为 X 和 c。 其结点设置过程为设置 X 的 左结点为 a,右结点为 b,并将 a 和 b 的父结点设置 X 。 同理如下可以设置 Y 的结点也这样。 右旋转原理同左旋转过程。 旋转过程可行性分析假如树本身就是一棵平衡二叉树,只是进行旋转操作,在左旋转过程中,变换的操作为将 Y 的左结点设置为 X 的右结点,将 X 设置为 Y 的左结点。 根据二叉平衡树的定义,其根结点大于所有的左结点,小于所有的右结点。那么 b 结点肯定比 X 大,但是比 Y 小。所以 b 可以作为 X 的右结点。因为 Y 结点比 X 大所以,X 肯定可以作为 Y 的左结点。 并且 b 结点也是比 Y小的。所以 Y 的左子树上所有结点的值。肯定比 Y 小,证明完毕。其右旋转过程同理。 代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152// y 替换 xfunc (t *Tree) leftRotate(x *Node) { // Default node inserted will be a red node y := x.right // 设置 y 的左结点到 x 下 x.right = y.left if y.left != nil { y.left.parent = x } // 设置 y 的父结点为 x 父结点 y.parent = x.parent // x 是根结点 // this is root if x.parent == nil { t.root = y } else { // 将 x 的父结点指向 y if x == x.parent.left { x.parent.left = y } else { x.parent.right = y } } // 设置 y 的 左结点为 x y.left = x // 设置 x 的 父结点为 y x.parent = y}func (t *Tree) rightRotate(x *Node) { y := x.left x.left = y.right if y.right != nil { y.right.parent = x } y.parent = x.parent // this is root if x.parent == nil { t.root = y } else { if x == x.parent.right { x.parent.right = y } else { x.parent.left = y } } y.right = x x.parent = y} 二、红黑树定义 性质1：每个结点要么是黑色,要么是红色。 性质2：根结点是黑色。 性质3：每个叶子结点（NIL）是黑色。 性质4：每个红色结点的两个子结点一定都是黑色。 性质5：任意一结点到每个叶子结点的路径都包含数量相同的黑结点。 如何保证其平衡性？根据性质4和性质5可以推导出,不存在两个连续的红色结点,最短路径的结点一定都是黑色结点,之外所有的路径都包含红色结点,每个结点的路径都保证数量相同的黑色结点,这就保证了最长路径最多为最短路径的两倍。 三、插入因为在插入之后,会改变红黑树的结构,红黑树可能变的不平衡,所以需要在插入过程之后修复二叉树的平衡性。 其中共有四种情况会违反红黑树的第四条性质: 我画出违反红黑树的四种情况如上图所示。其中图一需要右旋转过程,图二需要左旋转过程修复。图三需要先进行左旋转然后进行右旋转过程。图四需要先进行右旋转然后进行左旋转过程修复。修复后的情况为 Y 为红色结点,X 和 Z 都是黑色结点,满足红黑树的来满足第四条性质。 其中在违反红黑树的四种情况下。其中 X 插入的颜色为红色,在这种情况下如果 X 的 父结点是红色,那么违反了性质 4 ： 每个红色结点到两个结点一定都是黑色。在其前提下,又要分为两种情况判断其 X 的 Uncle 结点的颜色。 假如 Uncle 结点是红色,那么性质 5 并没有被违反,因此只需要重新设置结点的颜色即可,将 P 结点设置为黑色,将 G 结点设置为红色,将 U 结点设置为黑色。在这样的情况下满足性质 4 和性质 5。并且不需要关心 X 结点是 P 结点的左结点还是右结点,P 是 G 结点的左结点还是右结点。图中所列出的只是其中一种情况。因为将 G 结点设置为红色了,所以需要递推检查 G 的结点是否满足性质 4 和 性质 5。 假如 Uncle 结点是黑色结点,X 是红色结点,因此性质 5 也被破坏了。其修复过程为,假如 X 是 P 的右结点,需要进行左旋转操作为第二步操作。在这种情况下将 G 结点设置为红色,将 P 结点设置为黑色,然后进行右旋转过程。此时 P 结点被设置为根结点, P 结点为黑色,因此 P 结点满足性质 4 ,不用在继续往上递推修复。同时整个树满足性质 4 和 性质 5 （因为每个叶子（NIL）为黑色）。同时上面情况的对称情况同理。 实现假如不考虑红黑树的修复,代码如下: 根据 value 找到合适的插入位置 将插入结点的父结点设置为 y 根据 y 结点为空将该结点设置为根结点。 如果 y 结点不为空,就判断 y 结点 value 值 和 x 的 value 值的大小,来找到插入的位置。 将 x 结点设置为红色。 修复 1234567891011121314151617181920212223242526272829303132333435func (t *Tree) insert(item *Node) { var y *Node x := t.root for x != nil { y = x if item.key &lt; x.key { // insert value into the left node x = x.left } else if item.key &gt; x.key { // insert value into the left node x = x.right } else { // value exists return } } t.size++ item.parent = y item.color = RED if y == nil { item.color = BLACK t.root = item return } else if item.key &lt; y.key { y.left = item } else { y.right = item } // Checking RBT conditions and repairing the node t.insertRepairNode(item)} 插入修复过程如下: 123456789101112131415161718192021222324252627282930313233343536373839404142func (t *Tree) insertRepairNode(x *Node) { // N's parent (P) is not black var y *Node for x != t.root &amp;&amp; x.parent.color == RED { if x.parent == x.grandparent().left { y = x.grandparent().right if y != nil &amp;&amp; y.color == RED { x.parent.color = BLACK y.color = BLACK x.grandparent().color = RED x = x.grandparent() } else { if x == x.parent.right { x = x.parent t.leftRotate(x) } x.parent.color = BLACK x.grandparent().color = RED t.rightRotate(x.grandparent()) } } else { y = x.grandparent().left if y != nil &amp;&amp; y.color == RED { x.parent.color = BLACK y.color = BLACK x.grandparent().color = RED x = x.grandparent() } else { if x == x.parent.left { x = x.parent t.rightRotate(x) } x.parent.color = BLACK x.grandparent().color = RED t.leftRotate(x.grandparent()) } } } // N is the root node, i.e., first node of red–black tree t.root.color = BLACK} 因为在上面的分析过程中,已经分析,此处就不再分析。 四、删除删除过程分为删除节点和修复删除造成的结点不平衡。 删除思路 其删除思路可以简单概括为找到距离删除结点最近的值。 如果左结点为空,直接用右结点替代 如果右结点为空,直接用左结点替代 如果左右结点都不为空 找到离被删除结点最近的值（后继或者前驱） 被删除右结点不为空,则找到被删除结点的右结点的最左结点,该结点是比该被删结点刚刚大的值。 否则往上不断查找子结点是父结点的左结点,那么被找到父结点一定是比被删除结点刚刚大的值。 将前驱或者后继的值复制给被删除结点,然后删除前驱或者后继结点（如果存在子结点,就将子结点的parent设置为被删除前驱或者后继结点的parent,并将其parent指回子结点。如果没有子结点（这种情况只会存在于后驱结点）,就不用设置 ）。 如果被删除的结点是黑色结点要进行修复。因为违反了性质 5,必定造成被删除结点路径的黑色结点少一个。 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798func (t *Tree) Delete(key int64) { z := t.Search(key) if z == nil { return } t.delete(z)}func (t *Tree) Search(key int64) *Node { x := t.root if x == nil { return nil } for x != nil { switch { case key == x.key: return x case key &lt; x.key: x = x.left case key &gt; x.key: x = x.right } } return nil}func (t *Tree) delete(z *Node) { var x, y *Node y = z if z.left == nil { x = z.right t.replace(z, z.right) } else if z.right == nil { x = z.left t.replace(z, z.left) } else { y = z.successor() z.key = y.key z.value = y.value if y.left != nil { x = y.left } else if y.right != nil { x = y.right } if x != nil { x.parent = y.parent } if y.parent == nil { t.root = x } else { if y == y.parent.left { y.parent.left = x } else { y.parent.right = x } } } if y.color == BLACK { t.deleteRepairNode(x) } t.size-- y.parent = nil y.left = nil y.right = nil}func (t *Tree) replace(a, b *Node) { if a.parent == nil { t.root = b } else if a == a.parent.left { a.parent.left = b } else { a.parent.right = b } if b != nil { b.parent = a.parent }}func (n *Node) successor() *Node { if n.right != nil { return n.right.minimum() } y := n.parent for y != nil &amp;&amp; n == y.right { n = y y = y.parent } return y} 删除修复思路 其删除修复过程,主要因为破坏了性质 5,我认为维基百科讲的较为复杂,但是图确实非常好。所以我会用里面的几张图。 令替代了被删除结点位置的结点为 x 情况1: x 成为新的根结点,那么不用修复只需要将 x 设置成黑色结点 ,来保证性质 2。 情况2: x 的兄弟结点为红色,那么将兄弟结点设置为黑色,将 p 结点设置为红色,对 p 结点进行左旋转,并重新设置 x 的兄弟结点的符号。该情况可能会满足 4,5,6 情况。 情况3: p 是黑色结点,兄弟结点的两个子结点都为黑色结点,将兄弟结点设置为红色。那么 p 的左子树和右子树到达叶子结点的黑色结点数是相同的,但是经过 p 的结点比不经过 p 的结点少了一个黑色结点,所以令x = x.parent要向上处理 p 结点。 情况4: p 是红色结点,兄弟结点的两个子结点都为黑色结点,兄弟结点设置为红色,那么将 p 设置为红色结点,满足性质 4,相当于将 p 的左子树和右子树同时都将黑色结点数都减少一个,但是 p 本身变成了一个黑色结点,这样经过 p 和 不经过 p 都是同样的黑色结点。 情况5: 兄弟结点的左结点为红色,对兄弟结点进行右旋转。此时兄弟结点变成了原来兄弟结点的左结点的右结点,满足情况6。 情况6: 兄弟结点的右结点为红色,将兄弟结点的颜色设置为和 p 结点一致,将兄弟结点的右结点设置为黑色,然后进行左旋转。其过程就是给左子树增加一个黑色结点。满足性质 5。 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778func (t *Tree) deleteRepairNode(x *Node) { if x == nil { return } var w *Node for x != t.root &amp;&amp; x.color == BLACK { if x == x.parent.left { w = x.sibling() // case2 if w.color == RED { w.color = BLACK x.parent.color = RED t.leftRotate(x.parent) w = x.parent.right } // case3 4 这里是因为违反了性质五 if w.left.color == BLACK &amp;&amp; w.right.color == BLACK { w.color = RED x = x.parent } else { // case5 if w.right.color == BLACK { w.left.color = BLACK w.color = RED t.rightRotate(w) w = x.parent.right } // case6 w.color = x.parent.color x.parent.color = BLACK w.right.color = BLACK t.leftRotate(x.parent) // 退出循环 x = t.root } // 对称情况 } else { w = x.sibling() if w.color == RED { w.color = BLACK x.parent.color = RED t.rightRotate(x.parent) w = x.parent.left } if w.left.color == BLACK &amp;&amp; w.right.color == BLACK { w.color = RED x = x.parent } else { if w.left.color == BLACK { w.right.color = BLACK w.color = RED t.leftRotate(w) w = x.parent.left } w.color = x.parent.color x.parent.color = BLACK w.left.color = BLACK t.rightRotate(x.parent) x = t.root } } } // case1 x.color = BLACK}func (n *Node) sibling() *Node { p := n.father() // No parent means no sibling if p == nil { return nil } if n == p.left { return p.right } return p.left} 代码中我已经标明了case1 ~ case6,还有其对称情况。上面已经说过了,这里就不再说了。 五、总结红黑树插入过程较为复杂,但是只要清楚破坏性质 4 的四种情况,应该就很容理解。对于删除过程后面会继续补充完整。其删除过程看起来很复杂,其实只不过是穷举了五种情况n.parent(),n.sibling(),n.sibling().left,n.sibling().right为红色结点和全部都为黑色结点,顺序为S A P SL SR在这五种情况下的修复过程而已,仔细一想其实还好,没有很复杂。","link":"/2020/04/11/Algorithm/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E6%B7%B1%E5%85%A5%E6%8E%A2%E7%A9%B6%E7%BA%A2%E9%BB%91%E6%A0%91/"},{"title":"Go源码分析(2) - errors","text":"错误类型处理在go中是非常重要的,但是代码不多,本文将分析源码内容。 errors.goerror是一个内建的类型,实现了error接口 123type error interface { Error() string} errors包下通过New创建一个error对象,事实上返回的就是一个实现了error接口类型的结构体,其中Error（）返回了该错误信息的内容。 12345678910111213// New returns an error that formats as the given text.func New(text string) error { return &amp;errorString{text}}// errorString is a trivial implementation of error.type errorString struct { s string}func (e *errorString) Error() string { return e.s} warp.go在warp文件下,有三个方法,分别为Unwrap(err error) error,Is(err, target error) bool,As(err error, target interface{}) bool,都是在1.13新加入的方法。 Unwrap(err error) error使用该方法,需要传入的error类型实现Unwrap() error 通过判断是否实现了Unwrap() error 是,调用Unwrap()方法,返回err 否,返回nil 123456789101112// Unwrap returns the result of calling the Unwrap method on err, if err's// type contains an Unwrap method returning error.// Otherwise, Unwrap returns nil.func Unwrap(err error) error { u, ok := err.(interface { Unwrap() error }) if !ok { return nil } return u.Unwrap()} Is(err, target error) bool判断该错误类型是否和目标类型是一致类型 如果目标类型为nil,则判断被比较类型是否也是nil 通过一个for循环不断判断 如果目标类型能被比较并且被比较类型和目标类型值相等就返回true 如果被比较类型实现了Is(error) bool接口,则调用接口方法,判断是否是相等的 解包被比较类型,继续下一轮循环,或者解包到最里层都没有寻找到被比较类型与目标类型可匹配 12345678910111213141516171819202122232425// Is reports whether any error in err's chain matches target.//// An error is considered to match a target if it is equal to that target or if// it implements a method Is(error) bool such that Is(target) returns true.func Is(err, target error) bool { if target == nil { return err == target } isComparable := reflectlite.TypeOf(target).Comparable() for { if isComparable &amp;&amp; err == target { return true } if x, ok := err.(interface{ Is(error) bool }); ok &amp;&amp; x.Is(target) { return true } // TODO: consider supporing target.Is(err). This would allow // user-definable predicates, but also may allow for coping with sloppy // APIs, thereby making it easier to get away with them. if err = Unwrap(err); err == nil { return false } }} As(err error, target interface{}) boolAs方法应将目标设置为其值,如果err匹配目标指向的类型,则返回true。 如果目标类型为nil,或者不是指针类型,或者该类型没有实现error接口,则panic 通过一个for循环不断判断 如果被比较类型能被目标类型赋值,就进行赋值,返回true 如果被比较类型实现了As(interface{}) bool接口,则调用接口方法,进行赋值,并返回true 解包被比较类型,继续下一轮循环,或者解包到最里层都没有寻找到实现的As方法都没有赋值成功 123456789101112131415161718192021222324252627282930313233343536// As finds the first error in err's chain that matches the type to which target// points, and if so, sets the target to its value and returns true. An error// matches a type if it is assignable to the target type, or if it has a method// As(interface{}) bool such that As(target) returns true. As will panic if// target is not a non-nil pointer to a type which implements error or is of// interface type. As returns false if error is nil.//// The As method should set the target to its value and return true if err// matches the type to which target points.func As(err error, target interface{}) bool { if target == nil { panic(\"errors: target cannot be nil\") } val := reflectlite.ValueOf(target) typ := val.Type() if typ.Kind() != reflectlite.Ptr || val.IsNil() { panic(\"errors: target must be a non-nil pointer\") } if e := typ.Elem(); e.Kind() != reflectlite.Interface &amp;&amp; !e.Implements(errorType) { panic(\"errors: *target must be interface or implement error\") } targetType := typ.Elem() for err != nil { if reflectlite.TypeOf(err).AssignableTo(targetType) { val.Elem().Set(reflectlite.ValueOf(err)) return true } if x, ok := err.(interface{ As(interface{}) bool }); ok &amp;&amp; x.As(target) { return true } err = Unwrap(err) } return false}var errorType = reflectlite.TypeOf((*error)(nil)).Elem()","link":"/2019/11/19/Go/Golang%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/Go%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90(2)-errors/"},{"title":"Go源码分析(1) - net.http","text":"Golang 中 net/http 包下是非常关键的源码,gin 中的框架也是实现了 Golang 中的handler接口的SeverHttp方法才能够适配,可以见的该包是网络编程的核心,我针对于其中一部分源码进行了分析,希望能够帮助大家更好的理解 Golang 网络编程。 一、分析过程通过自顶向下的分析方式来分析整个源码,不关心其他实现,只关心整个调用的核心过程。 二、编写一个正常运行的例子随便写一个例子,查看其调用链 ,http.NewServeMux()返回一个多路复用的服务,其结构如下: 123456789101112131415package mainimport \"net/http\"func main() { mux := http.NewServeMux() mux.HandleFunc(\"/a\", func(writer http.ResponseWriter, request *http.Request) { writer.Write([]byte(\"aaaaaa\")) }) mux.HandleFunc(\"/b\", func(writer http.ResponseWriter, request *http.Request) { writer.Write([]byte(\"bbbbbb\")) }) http.ListenAndServe(\":3000\",mux)} m map[string]muxEntry包含了请求路径对应的映射方法, 内部过程是并发的,需要加锁。 123456type ServeMux struct { mu sync.RWMutex m map[string]muxEntry es []muxEntry // slice of entries sorted from longest to shortest. hosts bool // whether any patterns contain hostnames} 看一下mux.HandleFunc这个方法,将路径与处理该路径的方法对应其内部调用了mux.Handle(pattern, HandlerFunc(handler)),其作用也不言而喻,将路由器表以及对应的处理方法注册到多路服务中。 1234567// HandleFunc registers the handler function for the given pattern.func (mux *ServeMux) HandleFunc(pattern string, handler func(ResponseWriter, *Request)) { if handler == nil { panic(\"http: nil handler\") } mux.Handle(pattern, HandlerFunc(handler))} http.ListenAndServe(&quot;:3000&quot;,mux)监听了3000端口,传入创建好的多路复用服务,其内部又包装了一个Server,然后通过server.ListenAndServe()开启内部调用过程。 1234567891011// ListenAndServe listens on the TCP network address addr and then calls// Serve with handler to handle requests on incoming connections.// Accepted connections are configured to enable TCP keep-alives.//// The handler is typically nil, in which case the DefaultServeMux is used.//// ListenAndServe always returns a non-nil error.func ListenAndServe(addr string, handler Handler) error { server := &amp;Server{Addr: addr, Handler: handler} return server.ListenAndServe()} 三、内部调用过程ListenAndServe()方法中使用ln, err := net.Listen(&quot;tcp&quot;, addr)打开了tcp连接（这个过程在后序的文章会进行分析）,最后调用了srv.Serve(tcpKeepAliveListener{ln.(*net.TCPListener)})处理。 1234567891011121314func (srv *Server) ListenAndServe() error { if srv.shuttingDown() { return ErrServerClosed } addr := srv.Addr if addr == \"\" { addr = \":http\" } ln, err := net.Listen(\"tcp\", addr) if err != nil { return err } return srv.Serve(tcpKeepAliveListener{ln.(*net.TCPListener)})} Serve(l net.Listener) error方法是一个监听端口消息的处理器。其过程可以简化描述为首先监听请求,如果当前有错误信息,直接关闭服务,如果没有错误信息,创建新的连接去处理这个请求。 接受Listener l上的传入连接,创建一个每个新服务goroutine。服务goroutines读取请求和调用srv.Handler来回复他们的请求。整个过程最重要的就是整个for循环,他做了什么呢？ rw, e := l.Accept() Accept等待并返回与侦听器的下一个连接 &lt;-srv.getDoneChan()如果收到结束的通知,就停止监听 if ne, ok := e.(net.Error); ok &amp;&amp; ne.Temporary()如果发生错误就进行重试 tempDelay = 5 * time.Millisecond重试时间最初设置为5毫秒 tempDelay *= 2每次重试时间为2的指数级 max := 1 * time.Second ；tempDelay = max重试时间最大为1秒钟 time.Sleep(tempDelay)执行休眠的过程（非阻塞） c := srv.newConn(rw)建立连接 c.setState(c.rwc, StateNew) // before Serve can return设置连接状态为StateNew go c.serve(ctx)创建一个协程去处理 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859// Serve accepts incoming connections on the Listener l, creating a// new service goroutine for each. The service goroutines read requests and// then call srv.Handler to reply to them.//// HTTP/2 support is only enabled if the Listener returns *tls.Conn// connections and they were configured with \"h2\" in the TLS// Config.NextProtos.//// Serve always returns a non-nil error and closes l.// After Shutdown or Close, the returned error is ErrServerClosed.func (srv *Server) Serve(l net.Listener) error { if fn := testHookServerServe; fn != nil { fn(srv, l) // call hook with unwrapped listener } l = &amp;onceCloseListener{Listener: l} defer l.Close() if err := srv.setupHTTP2_Serve(); err != nil { return err } if !srv.trackListener(&amp;l, true) { return ErrServerClosed } defer srv.trackListener(&amp;l, false) var tempDelay time.Duration // how long to sleep on accept failure baseCtx := context.Background() // base is always background, per Issue 16220 ctx := context.WithValue(baseCtx, ServerContextKey, srv) for { rw, e := l.Accept() if e != nil { select { case &lt;-srv.getDoneChan(): return ErrServerClosed default: } if ne, ok := e.(net.Error); ok &amp;&amp; ne.Temporary() { if tempDelay == 0 { tempDelay = 5 * time.Millisecond } else { tempDelay *= 2 } if max := 1 * time.Second; tempDelay &gt; max { tempDelay = max } srv.logf(\"http: Accept error: %v; retrying in %v\", e, tempDelay) time.Sleep(tempDelay) continue } return e } tempDelay = 0 c := srv.newConn(rw) c.setState(c.rwc, StateNew) // before Serve can return go c.serve(ctx) }} 传入是一个tcpKeepAliveListener,所以会设置keepAlive,其默认设置为设置为3分钟保持活动之间的时间间隔,保持tcp连接不会马上中断。 123456789func (ln tcpKeepAliveListener) Accept() (net.Conn, error) { tc, err := ln.AcceptTCP() if err != nil { return nil, err } tc.SetKeepAlive(true) tc.SetKeepAlivePeriod(3 * time.Minute) return tc, nil} 处理整个过程的关键又到了c.serve(ctx)这个方法,核心就是将c.server的参数传给一个实现了Handler接口的类去处理这件事情。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149// Serve a new connection.func (c *conn) serve(ctx context.Context) { c.remoteAddr = c.rwc.RemoteAddr().String() ctx = context.WithValue(ctx, LocalAddrContextKey, c.rwc.LocalAddr()) defer func() { if err := recover(); err != nil &amp;&amp; err != ErrAbortHandler { const size = 64 &lt;&lt; 10 buf := make([]byte, size) buf = buf[:runtime.Stack(buf, false)] c.server.logf(\"http: panic serving %v: %v\\n%s\", c.remoteAddr, err, buf) } if !c.hijacked() { c.close() c.setState(c.rwc, StateClosed) } }() if tlsConn, ok := c.rwc.(*tls.Conn); ok { if d := c.server.ReadTimeout; d != 0 { c.rwc.SetReadDeadline(time.Now().Add(d)) } if d := c.server.WriteTimeout; d != 0 { c.rwc.SetWriteDeadline(time.Now().Add(d)) } if err := tlsConn.Handshake(); err != nil { // If the handshake failed due to the client not speaking // TLS, assume they're speaking plaintext HTTP and write a // 400 response on the TLS conn's underlying net.Conn. if re, ok := err.(tls.RecordHeaderError); ok &amp;&amp; re.Conn != nil &amp;&amp; tlsRecordHeaderLooksLikeHTTP(re.RecordHeader) { io.WriteString(re.Conn, \"HTTP/1.0 400 Bad Request\\r\\n\\r\\nClient sent an HTTP request to an HTTPS server.\\n\") re.Conn.Close() return } c.server.logf(\"http: TLS handshake error from %s: %v\", c.rwc.RemoteAddr(), err) return } c.tlsState = new(tls.ConnectionState) *c.tlsState = tlsConn.ConnectionState() if proto := c.tlsState.NegotiatedProtocol; validNPN(proto) { if fn := c.server.TLSNextProto[proto]; fn != nil { h := initNPNRequest{tlsConn, serverHandler{c.server}} fn(c.server, tlsConn, h) } return } } // HTTP/1.x from here on. ctx, cancelCtx := context.WithCancel(ctx) c.cancelCtx = cancelCtx defer cancelCtx() c.r = &amp;connReader{conn: c} c.bufr = newBufioReader(c.r) c.bufw = newBufioWriterSize(checkConnErrorWriter{c}, 4&lt;&lt;10) for { w, err := c.readRequest(ctx) if c.r.remain != c.server.initialReadLimitSize() { // If we read any bytes off the wire, we're active. c.setState(c.rwc, StateActive) } if err != nil { const errorHeaders = \"\\r\\nContent-Type: text/plain; charset=utf-8\\r\\nConnection: close\\r\\n\\r\\n\" if err == errTooLarge { // Their HTTP client may or may not be // able to read this if we're // responding to them and hanging up // while they're still writing their // request. Undefined behavior. const publicErr = \"431 Request Header Fields Too Large\" fmt.Fprintf(c.rwc, \"HTTP/1.1 \"+publicErr+errorHeaders+publicErr) c.closeWriteAndWait() return } if isCommonNetReadError(err) { return // don't reply } publicErr := \"400 Bad Request\" if v, ok := err.(badRequestError); ok { publicErr = publicErr + \": \" + string(v) } fmt.Fprintf(c.rwc, \"HTTP/1.1 \"+publicErr+errorHeaders+publicErr) return } // Expect 100 Continue support req := w.req if req.expectsContinue() { if req.ProtoAtLeast(1, 1) &amp;&amp; req.ContentLength != 0 { // Wrap the Body reader with one that replies on the connection req.Body = &amp;expectContinueReader{readCloser: req.Body, resp: w} } } else if req.Header.get(\"Expect\") != \"\" { w.sendExpectationFailed() return } c.curReq.Store(w) if requestBodyRemains(req.Body) { registerOnHitEOF(req.Body, w.conn.r.startBackgroundRead) } else { w.conn.r.startBackgroundRead() } // HTTP cannot have multiple simultaneous active requests.[*] // Until the server replies to this request, it can't read another, // so we might as well run the handler in this goroutine. // [*] Not strictly true: HTTP pipelining. We could let them all process // in parallel even if their responses need to be serialized. // But we're not going to implement HTTP pipelining because it // was never deployed in the wild and the answer is HTTP/2. serverHandler{c.server}.ServeHTTP(w, w.req) w.cancelCtx() if c.hijacked() { return } w.finishRequest() if !w.shouldReuseConnection() { if w.requestBodyLimitHit || w.closedRequestBodyEarly() { c.closeWriteAndWait() } return } c.setState(c.rwc, StateIdle) c.curReq.Store((*response)(nil)) if !w.conn.server.doKeepAlives() { // We're in shutdown mode. We might've replied // to the user without \"Connection: close\" and // they might think they can send another // request, but such is life with HTTP/1.1. return } if d := c.server.idleTimeout(); d != 0 { c.rwc.SetReadDeadline(time.Now().Add(d)) if _, err := c.bufr.Peek(4); err != nil { return } } c.rwc.SetReadDeadline(time.Time{}) }} serverHandler{c.server}.ServeHTTP(w, w.req) 调用ServeHTTP方法. 123type serverHandler struct { srv *Server} 这个结构体,实现了Handler接口的ServeHTTP(ResponseWriter, *Request)方法 12345678910func (sh serverHandler) ServeHTTP(rw ResponseWriter, req *Request) { handler := sh.srv.Handler if handler == nil { handler = DefaultServeMux } if req.RequestURI == \"*\" &amp;&amp; req.Method == \"OPTIONS\" { handler = globalOptionsHandler{} } handler.ServeHTTP(rw, req)} 然后就将c.server传入的参数sh.srv.Handler直接调用handler.ServeHTTP(rw, req)。 12345678910111213// ServeHTTP dispatches the request to the handler whose// pattern most closely matches the request URL.func (mux *ServeMux) ServeHTTP(w ResponseWriter, r *Request) { if r.RequestURI == \"*\" { if r.ProtoAtLeast(1, 1) { w.Header().Set(\"Connection\", \"close\") } w.WriteHeader(StatusBadRequest) return } h, _ := mux.Handler(r) h.ServeHTTP(w, r)} 首先会调用h, _ := mux.Handler(r)方法,对请求对数据进行查找路径,重定向,加工之类对操作,调用mux.handler(host, r.URL.Path)在路由表里查找路径对应对方法,返回的一个对应该请求的处理handler。handler再调用ServeHTTP方法进行处理。 12345678910111213141516171819202122232425262728293031323334func (mux *ServeMux) Handler(r *Request) (h Handler, pattern string) { // CONNECT requests are not canonicalized. if r.Method == \"CONNECT\" { // If r.URL.Path is /tree and its handler is not registered, // the /tree -&gt; /tree/ redirect applies to CONNECT requests // but the path canonicalization does not. if u, ok := mux.redirectToPathSlash(r.URL.Host, r.URL.Path, r.URL); ok { return RedirectHandler(u.String(), StatusMovedPermanently), u.Path } return mux.handler(r.Host, r.URL.Path) } // All other requests have any port stripped and path cleaned // before passing to mux.handler. host := stripHostPort(r.Host) path := cleanPath(r.URL.Path) // If the given path is /tree and its handler is not registered, // redirect for /tree/. if u, ok := mux.redirectToPathSlash(host, path, r.URL); ok { return RedirectHandler(u.String(), StatusMovedPermanently), u.Path } if path != r.URL.Path { _, pattern = mux.handler(host, path) url := *r.URL url.Path = path return RedirectHandler(url.String(), StatusMovedPermanently), pattern } return mux.handler(host, r.URL.Path)} 最终处理流程还是交给了HandlerFunc去处理了这些请求。 1234// ServeHTTP calls f(w, r).func (f HandlerFunc) ServeHTTP(w ResponseWriter, r *Request) { f(w, r)} 四、总结整个过程我们在总结一下,我用一个流程符号来表示一下整个调用过程吧 http.ListenAndServe(&quot;:3000&quot;,mux) -&gt; server.ListenAndServe() -&gt; srv.Serve(tcpKeepAliveListener{ln.(*net.TCPListener)}) -&gt; c.serve(ctx) -&gt; serverHandler{c.server}.ServeHTTP(w, w.req) -&gt; h, _ := mux.Handler(r) -&gt; h.ServeHTTP(w, r) 对于调用过程,我的理解是一共分成了三层,第一层为server这一层对请求进行处理,处理错误请求,是否需要创建连接。第二层 为connect创建http请求,处理安全认证.第三层为serverHandler,进行路由,查找对应的方法,调用最终的处理。每一层的职责进行处理,分工明确,采用委托的方式来实现自定义的处理。如果文中有错误或者可以补充的,不吝指教。","link":"/2019/09/03/Go/Golang%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/Go%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90(1)-net.http/"},{"title":"Go源码分析(3) - io","text":"io包下分为io和iotuil,提供了缓冲io和非缓冲io,拷贝文件等常见操作。 io.go提供了四种基本通用api 123456789101112131415type Reader interface { Read(p []byte) (n int, err error)}type Writer interface { Write(p []byte) (n int, err error)}type Closer interface { Close() error}type Seeker interface { Seek(offset int64, whence int) (int64, error)} Reader接口提供了读操作接口 Writer接口提供了写操作接口 Closer接口关闭当前io操作以及资源释放 Seeker接口将当前读取或者移动指针移动到特定到位置 12345678910111213141516171819202122232425262728293031323334353637383940414243// ReadWriter is the interface that groups the basic Read and Write methods.type ReadWriter interface { Reader Writer}// ReadCloser is the interface that groups the basic Read and Close methods.type ReadCloser interface { Reader Closer}// WriteCloser is the interface that groups the basic Write and Close methods.type WriteCloser interface { Writer Closer}// ReadWriteCloser is the interface that groups the basic Read, Write and Close methods.type ReadWriteCloser interface { Reader Writer Closer}// ReadSeeker is the interface that groups the basic Read and Seek methods.type ReadSeeker interface { Reader Seeker}// WriteSeeker is the interface that groups the basic Write and Seek methods.type WriteSeeker interface { Writer Seeker}// ReadWriteSeeker is the interface that groups the basic Read, Write and Seek methods.type ReadWriteSeeker interface { Reader Writer Seeker} 以上几个接口都是对几种基本接口的组合 123456789101112131415161718192021// ReaderFrom is the interface that wraps the ReadFrom method.//// ReadFrom reads data from r until EOF or error.// The return value n is the number of bytes read.// Any error except io.EOF encountered during the read is also returned.//// The Copy function uses ReaderFrom if available.type ReaderFrom interface { ReadFrom(r Reader) (n int64, err error)}// WriterTo is the interface that wraps the WriteTo method.//// WriteTo writes data to w until there's no more data to write or// when an error occurs. The return value n is the number of bytes// written. Any error encountered during the write is also returned.//// The Copy function uses WriterTo if available.type WriterTo interface { WriteTo(w Writer) (n int64, err error)} ReaderFrom从一个reader读取内容 WriterTo将当前当前writer的内容读取到另一个w中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748// ReaderAt is the interface that wraps the basic ReadAt method.//// ReadAt reads len(p) bytes into p starting at offset off in the// underlying input source. It returns the number of bytes// read (0 &lt;= n &lt;= len(p)) and any error encountered.//// When ReadAt returns n &lt; len(p), it returns a non-nil error// explaining why more bytes were not returned. In this respect,// ReadAt is stricter than Read.//// Even if ReadAt returns n &lt; len(p), it may use all of p as scratch// space during the call. If some data is available but not len(p) bytes,// ReadAt blocks until either all the data is available or an error occurs.// In this respect ReadAt is different from Read.//// If the n = len(p) bytes returned by ReadAt are at the end of the// input source, ReadAt may return either err == EOF or err == nil.//// If ReadAt is reading from an input source with a seek offset,// ReadAt should not affect nor be affected by the underlying// seek offset.//// Clients of ReadAt can execute parallel ReadAt calls on the// same input source.//// Implementations must not retain p.type ReaderAt interface { ReadAt(p []byte, off int64) (n int, err error)}// WriterAt is the interface that wraps the basic WriteAt method.//// WriteAt writes len(p) bytes from p to the underlying data stream// at offset off. It returns the number of bytes written from p (0 &lt;= n &lt;= len(p))// and any error encountered that caused the write to stop early.// WriteAt must return a non-nil error if it returns n &lt; len(p).//// If WriteAt is writing to a destination with a seek offset,// WriteAt should not affect nor be affected by the underlying// seek offset.//// Clients of WriteAt can execute parallel WriteAt calls on the same// destination if the ranges do not overlap.//// Implementations must not retain p.type WriterAt interface { WriteAt(p []byte, off int64) (n int, err error)} 从指定偏移量开始读取或者写 1234567891011121314// StringWriter is the interface that wraps the WriteString method.type StringWriter interface { WriteString(s string) (n int, err error)}// WriteString writes the contents of the string s to w, which accepts a slice of bytes.// If w implements StringWriter, its WriteString method is invoked directly.// Otherwise, w.Write is called exactly once.func WriteString(w Writer, s string) (n int, err error) { if sw, ok := w.(StringWriter); ok { return sw.WriteString(s) } return w.Write([]byte(s))} WriteString可以将字符串写入Writer中,如果该Writer是WriteString类型,则会调用该对象自己的WriteString方法 12345678910111213141516func ReadAtLeast(r Reader, buf []byte, min int) (n int, err error) { if len(buf) &lt; min { return 0, ErrShortBuffer } for n &lt; min &amp;&amp; err == nil { var nn int nn, err = r.Read(buf[n:]) n += nn } if n &gt;= min { err = nil } else if n &gt; 0 &amp;&amp; err == EOF { err = ErrUnexpectedEOF } return} 如果当前buf长度小于最少读取的字节,返回太短的buffer错误 循环读取当前reader中的内容到buffer,比较是已经读取到min长度 如果当前读取的长度小于min并且错误等于EOF,代表reader里面没有足够对长度,抛出EOF错误 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970func CopyN(dst Writer, src Reader, n int64) (written int64, err error) { written, err = Copy(dst, LimitReader(src, n)) if written == n { return n, nil } if written &lt; n &amp;&amp; err == nil { // src stopped early; must have been EOF. err = EOF } return}func Copy(dst Writer, src Reader) (written int64, err error) { return copyBuffer(dst, src, nil)}func CopyBuffer(dst Writer, src Reader, buf []byte) (written int64, err error) { if buf != nil &amp;&amp; len(buf) == 0 { panic(\"empty buffer in io.CopyBuffer\") } return copyBuffer(dst, src, buf)}func copyBuffer(dst Writer, src Reader, buf []byte) (written int64, err error) { // If the reader has a WriteTo method, use it to do the copy. // Avoids an allocation and a copy. if wt, ok := src.(WriterTo); ok { return wt.WriteTo(dst) } // Similarly, if the writer has a ReadFrom method, use it to do the copy. if rt, ok := dst.(ReaderFrom); ok { return rt.ReadFrom(src) } if buf == nil { size := 32 * 1024 if l, ok := src.(*LimitedReader); ok &amp;&amp; int64(size) &gt; l.N { if l.N &lt; 1 { size = 1 } else { size = int(l.N) } } buf = make([]byte, size) } for { nr, er := src.Read(buf) if nr &gt; 0 { nw, ew := dst.Write(buf[0:nr]) if nw &gt; 0 { written += int64(nw) } if ew != nil { err = ew break } if nr != nw { err = ErrShortWrite break } } if er != nil { if er != EOF { err = er } break } } return written, err} CopyN(dst Writer, src Reader, n int64) (written int64, err error)调用Copy方法并包装当前reader为LimitReader Copy(dst Writer, src Reader) (written int64, err error)调用copyBuffer(dst, src, nil)方法传入buf为nil,不是用缓冲区 copyBuffer(dst Writer, src Reader, buf []byte) (written int64, err error)是这些方法中最关键的一个方法 如果当前reader方法实现WriterTo方法,则直接调用 如果当前writer方法实现ReadFrom方法,则直接调用 如果buf为空,处理直接为Copy或者CopyN的情况 首先如果强转为LimitedReader方法,如果可以则直接将buf的大小设置为LimitedReader.N的大小 buf大小为32*1024,既为32mb大小 循环从read中读取到buf,然后从buf中写入到writer中,reader中的数据被读取完毕,或者出现读写大小不一样的错误 12345678910111213141516171819202122232425// LimitReader returns a Reader that reads from r// but stops with EOF after n bytes.// The underlying implementation is a *LimitedReader.func LimitReader(r Reader, n int64) Reader { return &amp;LimitedReader{r, n} }// A LimitedReader reads from R but limits the amount of// data returned to just N bytes. Each call to Read// updates N to reflect the new amount remaining.// Read returns EOF when N &lt;= 0 or when the underlying R returns EOF.type LimitedReader struct { R Reader // underlying reader N int64 // max bytes remaining}func (l *LimitedReader) Read(p []byte) (n int, err error) { if l.N &lt;= 0 { return 0, EOF } if int64(len(p)) &gt; l.N { p = p[0:l.N] } n, err = l.R.Read(p) l.N -= int64(n) return} 限制被读取的大小,通过切片的方式来限制buf的大小 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566// NewSectionReader returns a SectionReader that reads from r// starting at offset off and stops with EOF after n bytes.func NewSectionReader(r ReaderAt, off int64, n int64) *SectionReader { return &amp;SectionReader{r, off, off, off + n}}// SectionReader implements Read, Seek, and ReadAt on a section// of an underlying ReaderAt.type SectionReader struct { r ReaderAt base int64 off int64 limit int64}func (s *SectionReader) Read(p []byte) (n int, err error) { if s.off &gt;= s.limit { return 0, EOF } if max := s.limit - s.off; int64(len(p)) &gt; max { p = p[0:max] } n, err = s.r.ReadAt(p, s.off) s.off += int64(n) return}var errWhence = errors.New(\"Seek: invalid whence\")var errOffset = errors.New(\"Seek: invalid offset\")func (s *SectionReader) Seek(offset int64, whence int) (int64, error) { switch whence { default: return 0, errWhence case SeekStart: offset += s.base case SeekCurrent: offset += s.off case SeekEnd: offset += s.limit } if offset &lt; s.base { return 0, errOffset } s.off = offset return offset - s.base, nil}func (s *SectionReader) ReadAt(p []byte, off int64) (n int, err error) { if off &lt; 0 || off &gt;= s.limit-s.base { return 0, EOF } off += s.base if max := s.limit - off; int64(len(p)) &gt; max { p = p[0:max] n, err = s.r.ReadAt(p, off) if err == nil { err = EOF } return n, err } return s.r.ReadAt(p, off)}// Size returns the size of the section in bytes.func (s *SectionReader) Size() int64 { return s.limit - s.base } SectionReader部分读取,base是基础的读取的位置,off为偏移量,limit限制的最大偏移量. Seek(offset int64, whence int) (int64, error)方法中whence是一个枚举类型有三个值SeekStart,SeekCurrent,SeekEnd从开头,当前位置,和结尾位置作为初始下标,返回寻找的下表位置 (s *SectionReader) ReadAt(p []byte, off int64) (n int, err error)从指定位置开始读取,如果当前偏移量超出了限制,就返回EOF,并且如果结尾的数量小于当前buf的大小,就对buf进行重新切片,再调用reader的ReadAt（）方法防止超出。 1234567891011121314151617181920212223// TeeReader returns a Reader that writes to w what it reads from r.// All reads from r performed through it are matched with// corresponding writes to w. There is no internal buffering -// the write must complete before the read completes.// Any error encountered while writing is reported as a read error.func TeeReader(r Reader, w Writer) Reader { return &amp;teeReader{r, w}}type teeReader struct { r Reader w Writer}func (t *teeReader) Read(p []byte) (n int, err error) { n, err = t.r.Read(p) if n &gt; 0 { if n, err := t.w.Write(p[:n]); err != nil { return n, err } } return} 将buffer中的所有内容全部都传输入到writer中 multi.go12345type eofReader struct{}func (eofReader) Read([]byte) (int, error) { return 0, EOF} 定义一个eofReader实现reader接口作为EOF处理 12345678910111213141516171819202122232425262728293031323334353637383940type multiReader struct { readers []Reader}func (mr *multiReader) Read(p []byte) (n int, err error) { for len(mr.readers) &gt; 0 { // Optimization to flatten nested multiReaders (Issue 13558). if len(mr.readers) == 1 { if r, ok := mr.readers[0].(*multiReader); ok { mr.readers = r.readers continue } } n, err = mr.readers[0].Read(p) if err == EOF { // Use eofReader instead of nil to avoid nil panic // after performing flatten (Issue 18232). mr.readers[0] = eofReader{} // permit earlier GC mr.readers = mr.readers[1:] } if n &gt; 0 || err != EOF { if err == EOF &amp;&amp; len(mr.readers) &gt; 0 { // Don't return EOF yet. More readers remain. err = nil } return } } return 0, EOF}// MultiReader returns a Reader that's the logical concatenation of// the provided input readers. They're read sequentially. Once all// inputs have returned EOF, Read will return EOF. If any of the readers// return a non-nil, non-EOF error, Read will return that error.func MultiReader(readers ...Reader) Reader { r := make([]Reader, len(readers)) copy(r, readers) return &amp;multiReader{r}} multiReader是一个多readers多读取的一个结构体,实现了reader接口,构造方法为传入多个reader,调用系统内置copy()方法防止该multireader对原始对reader进行修改。 Read(p []byte) (n int, err error),查看构造的reader是否有可用数量的reader,如果构造的reader本身也multiReader类型,那么将当前reader解包添加到readers中,然后调用readers[0]的Read(p)方法,返回结果之后,如果已经读取到结尾,当前reader从readers中剔除,但是这里不用nil来避免panic,而是使用一个eofReader来表示这个reader已经不可用了,同时加快GC。继续判断如果读取的字节是大于0或者错误不是是EOF就直接返回。实质上mulitReader就是一个序列化的读取reader,从readers[0]读取到readers[n]。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859type multiWriter struct { writers []Writer}func (t *multiWriter) Write(p []byte) (n int, err error) { for _, w := range t.writers { n, err = w.Write(p) if err != nil { return } if n != len(p) { err = ErrShortWrite return } } return len(p), nil}var _ StringWriter = (*multiWriter)(nil)func (t *multiWriter) WriteString(s string) (n int, err error) { var p []byte // lazily initialized if/when needed for _, w := range t.writers { if sw, ok := w.(StringWriter); ok { n, err = sw.WriteString(s) } else { if p == nil { p = []byte(s) } n, err = w.Write(p) } if err != nil { return } if n != len(s) { err = ErrShortWrite return } } return len(s), nil}// MultiWriter creates a writer that duplicates its writes to all the// provided writers, similar to the Unix tee(1) command.//// Each write is written to each listed writer, one at a time.// If a listed writer returns an error, that overall write operation// stops and returns the error; it does not continue down the list.func MultiWriter(writers ...Writer) Writer { allWriters := make([]Writer, 0, len(writers)) for _, w := range writers { if mw, ok := w.(*multiWriter); ok { allWriters = append(allWriters, mw.writers...) } else { allWriters = append(allWriters, w) } } return &amp;multiWriter{allWriters}} multiWriter和multiReader的实现过程非常相似,从writers[0]顺序写入到writers[n]中。 pipe.go1234567891011121314// atomicError is a type-safe atomic value for errors.// We use a struct{ error } to ensure consistent use of a concrete type.type atomicError struct{ v atomic.Value }func (a *atomicError) Store(err error) { a.v.Store(struct{ error }{err})}func (a *atomicError) Load() error { err, _ := a.v.Load().(struct{ error }) return err.error}// ErrClosedPipe is the error used for read or write operations on a closed pipe.var ErrClosedPipe = errors.New(\"io: read/write on closed pipe\") 该文件定一个原子错误的结构体,这个结构体是没有向外暴露的,仅内部使用。然后定一个关闭pipe的错误 1234567891011// A pipe is the shared pipe structure underlying PipeReader and PipeWriter.type pipe struct { wrMu sync.Mutex // Serializes Write operations wrCh chan []byte rdCh chan int once sync.Once // Protects closing done done chan struct{} rerr atomicError werr atomicError} wrMupiple需要保持序列化,所需要加锁 wrCh写管道 rdCh读管道,表示需要读取多少字节 once让关闭只被执行一次的操作 done监听是否关闭 rerr读错误 werr写错误 12345678910111213141516func (p *pipe) Read(b []byte) (n int, err error) { select { case &lt;-p.done: return 0, p.readCloseError() default: } select { case bw := &lt;-p.wrCh: nr := copy(b, bw) p.rdCh &lt;- nr return nr, nil case &lt;-p.done: return 0, p.readCloseError() }} 首先判断管道是否被关闭,如果关闭直接返回关闭的错误,从写管道中读取内容,然后将管道中的内容copy（）出来,防止元数据发生改变后读取后的内容也跟着改变了,然后将当前读取了多少字节给读通道,在其中要判断是否管道是否发生关闭,防止这个时候管道被关闭。 1234567func (p *pipe) readCloseError() error { rerr := p.rerr.Load() if werr := p.werr.Load(); rerr == nil &amp;&amp; werr != nil { return werr } return ErrClosedPipe} 返回读关闭错误 12345678func (p *pipe) CloseRead(err error) error { if err == nil { err = ErrClosedPipe } p.rerr.Store(err) p.once.Do(func() { close(p.done) }) return nil} 从读错误里面存储关闭管道的错误,然后调用close方法关闭p.done,来通知关闭了管道,使用once.Do()来防止被关闭多次,导致报错 123456789101112131415161718192021func (p *pipe) Write(b []byte) (n int, err error) { select { case &lt;-p.done: return 0, p.writeCloseError() default: p.wrMu.Lock() defer p.wrMu.Unlock() } for once := true; once || len(b) &gt; 0; once = false { select { case p.wrCh &lt;- b: nw := &lt;-p.rdCh b = b[nw:] n += nw case &lt;-p.done: return n, p.writeCloseError() } } return n, nil} 写方法依然后是先判断管道有没有被关闭,如果没有关闭就对整个方法加速,然后将bytes写入到写管道中,然后从读管道中得到读取数量,作为下一次buf的开始位置,直到byte长度为0,也就是写入完毕,或者管道被关闭。最后返回当前写入的数量。 12345678910111213141516func (p *pipe) writeCloseError() error { werr := p.werr.Load() if rerr := p.rerr.Load(); werr == nil &amp;&amp; rerr != nil { return rerr } return ErrClosedPipe}func (p *pipe) CloseWrite(err error) error { if err == nil { err = EOF } p.werr.Store(err) p.once.Do(func() { close(p.done) }) return nil} 上面这两个方法和读操作是类似的。 总结Go中的io操作有很多精妙的操作,比如不将数组中的对象置为nil,避免panic,使用另一个对象来代替,从而使原来数组的对象没有被引用到,使其防止到白色区域,下一次的时候就可以被GC回收掉。然后该文件定义了相当多的接口,很多都没有在这个包下实现,大多是在其他包中进行实现,该包没有承担过多的责任,使其扩展起来也可以很容易明白。定义了很多工具和通用的一些结构体,多个readers的类,管道,部分阅读器,TeeReader等类型。","link":"/2019/11/23/Go/Golang%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/Go%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90(3)-io/"},{"title":"(译) Go中的垃圾收集：第一部分 - 语义","text":"这是三部分系列中的第一篇文章,它将提供对Go中垃圾收集器背后的机制和语义的理解。这篇文章重点介绍了收集器语义的基础材料。 三部分系列的索引：1）Go中的垃圾收集：第一部分 - 语义2）Go中的垃圾收集：第二部分 - GC跟踪3）Go中的垃圾收集：第三部分 - GC步伐 介绍垃圾收集器负责跟踪堆内存分配,释放不再需要的分配,并保留仍在使用中的分配。语言决定如何实现此行为很复杂,但应该不应该让应用程序开发人员了解细节以构建软件。此外,对于语言的VM或运行时的不同版本,这些系统的实现总是在变化和发展。对于应用程序开发人员来说,重要的是保持一个良好的工作模型,了解垃圾收集器对其语言的行为以及如何在不关心实现的情况下对这种行为表示支持。 从版本1.12开始,Go编程语言使用非代数并发三色标记和扫描收集器。如果你想直观地看到标记和扫描收集器是如何工作的,Ken Fox写了这篇伟大的文章并提供动画。Go的收集器的实现随着Go的每个版本的变化而发生变化。因此,一旦发布下一版本的语言,任何谈论实现细节的帖子将不再准确。 尽管如此,我将在本文中做的建模不会关注实际的实现细节。建模将关注你将经历的行为以及你应该在未来几年看到的行为。在这篇文章中,我将与你分享收集者的行为,并解释如何对该行为表示支持,无论当前的实施情况如何或未来如何变化。这将使你成为更好的Go开发人员。 注意：这里有更多关于垃圾收集器和Go的实际收集器的解读。 堆不是容器我永远不会将堆称为可以存储或释放值的容器。重要的是要理解没有线性遏制内存来定义“堆”。认为为进程空间中的应用程序使用保留的任何内存都可用于堆内存分配。虚拟或物理存储任何给定的堆内存分配与我们的模型无关。这种理解将帮助你更好地了解垃圾收集器的工作原理。 收集器行为收集开始时,收集器将运行三个阶段的工作。其中两个阶段会产生Stop The World（STW）延迟,另一个阶段会产生延迟,从而降低应用程序的吞吐量。这三个阶段是： 标记设置 - STW 标记 - 并发 标记终止 - STW 这是每个阶段的细分。 标记设置 - STW收集器开始时,必须执行的第一个活动是打开写屏障。写屏障的目的是允许收集器在收集器期间维护堆上的数据完整性,因为收集器和应用程序Goroutine将同时运行。 为了打开写屏障,必须停止每个运行Goroutine的应用程序。此活动通常非常快,平均在10到30微秒之内。也就是说,只要应用程序Goroutines表现正常。 注意：为了更好地理解这些调度程序图,请务必阅读Go Scheduler上的这一系列帖子 图1 图1显示了在收集器开始之前运行的4个应用程序Goroutine。必须停止这4个Goroutine中的每一个。唯一的方法是让收集器观察并等待每个Goroutine进行函数调用。函数调用保证Goroutine处于安全点停止。如果其中一个Goroutine不进行函数调用而其他函数执行,会发生什么？ 图2 图2显示了一个真正的问题。在P4上运行的Goroutine停止之前,收集器无法启动,并且这种情况不会发生,因为它处于执行某些数学运算的紧密循环中。 清单1 123456701 func add(numbers []int) int {02 var v int03 for _, n := range numbers {04 v += n05 }06 return v07 } 清单1显示了在P4上运行的Goroutine正在执行的代码。根据切片的大小,Goroutine可能会运行一段不合理的时间而无法停止。这种代码可以阻止收集器启动。更糟糕的是,当收集器等待时,其他P不能为任何其他Goroutine提供服务。Goroutines在合理的时间范围内进行函数调用至关重要。 注意：这是语言团队希望通过向调度程序添加抢先技术来在1.14中进行更正的内容。 标记 - 并发一旦写屏障打开,收集器就开始标记阶段。收集器所做的第一件事就是占用自身可用CPU容量的25％。收集器使用Goroutines进行收集工作,并且需要与Goroutines使用的应用程序相同的P和M. 这意味着对于我们的4线程Go程序,一个完整的P将专门用于收集工作。 图3 图3显示了收集器在收集过程中如何为自己收集P1。现在收集器可以开始标记阶段。标记阶段包括在堆内存中标记仍在使用中的值。这项工作首先检查所有现有Goroutine的堆栈,以找到堆内存的根指针。然后收集器必须从那些根指针遍历堆内存图。当标记工作在P1上进行时,应用程序工作可以在P2,P3和P4上同时继续进行。这意味着收集器的影响已最小化到当前CPU容量的25％。 我希望这是故事的结局,但事实并非如此。如果在收集过程中确定在P1上专用于GC的Goroutine在使用中的堆内存达到极限之前无法完成标记工作,该怎么办？如果3个Goroutines中只有一个进行应用工作使收集器无法及时完成的​​原因怎么办？在这种情况下,新的分配必须放慢速度,特别是从那个Goroutine。 如果收集器确定它需要减慢分配,它将招募应用程序Goroutines以协助标记工作。这称为协助标记。任何应用程序Goroutine放置在协助标记中的时间长度与它添加到堆内存中的数据量成正比。协助标记的一个积极的副作用是它有助于更​​快地完成收集。 图4 图4显示了在P3上运行的应用程序Goroutine现在如何执行协助标记并帮助进行收集工作。希望其他应用程序Goroutines也不需要参与其中。分配重的应用程序可以看到大多数正在运行的Goroutines在收集期间执行少量协助标记。 收集器的一个目标是消除对协助标记的需求。如果任何给定的收集器最终需要大量的协助标记,则收集器可以更早地开始下一个垃圾收集。这样做是为了减少下一次收集所需的协助标记量。 标记终止 - STW标记工作完成后,下一阶段是标记终止。这是当写屏障关闭时,执行各种清理任务,并计算下一个收集目标。在标记阶段发现自己处于紧密循环中的Goroutines也可能导致标记终止, STW 延迟延长。 图5 图5显示了标记终止阶段完成后所有Goroutines是如何停止的。此活动通常平均在60到90微秒之内。这个阶段可以在没有STW的情况下完成,但是通过使用STW,代码更简单,并且增加的复杂性不值得小的增益。 收集完成后,应用程序Goroutines可以再次使用每个P,应用程序将恢复全油门。 图6 图6显示了收集完成后,所有可用的P现在如何处理应用程序的工作。应用程序恢复到收集开始之前的全油门。 清扫 - 并发完成一个名为清扫的收集器后会发生另一个活动。清除是指回收与堆内存中未标记为使用中的值相关联的内存。当应用程序Goroutines尝试在堆内存中分配新值时,会发生此活动。清扫的延迟被添加到在堆内存中执行分配的成本中,并且不依赖于与垃圾收集相关的任何延迟。 以下是我的机器上的跟踪示例,其中有12个硬件线程可用于执行Goroutines。 图7 图7显示了跟踪的部分快照。你可以在此收集器中看到如何（将你的视图保持在顶部的蓝色GC行中）,十二个P中的三个专用于GC。你可以看到Goroutine 2450,1978和2696在这段时间里正在执行协助标记的工作,而不是它的应用工作。在收集器的最后,只有一个P专用于GC并最终执行STW（标记终止）工作。 收集完成后,应用程序将恢复全油门运行。除了你看到Goroutines下面有很多玫瑰色的线条。 图8 图8显示了那些玫瑰色线条代表Goroutine执行清扫工作而非其应用工作的时刻。这些是Goroutine试图在堆内存中分配新值的时刻。 图9 图9显示了Sweep活动中其中一个Goroutines的堆栈跟踪结束。调用runtime.mallocgc是调用在堆内存中分配新值。调用runtime.(*mcache).nextFree导致Sweep活动。一旦堆内存中没有更多的分配要回收,nextFree就不会再看到调用了。 刚刚描述的收集器行为仅在收集器已启动并正在运行时发生。GC百分比配置选项在确定收集器何时开始时起着重要作用。 GC百分比运行时中有一个名为GC Percentage的配置选项,默认情况下设置为100。此值表示在下一个收集器必须启动之前可以分配多少新堆内存的比率。将GC百分比设置为100意味着,基于在收集完成后标记为活动的堆内存量,下一个收集器必须在100％以上的新分配添加到堆内存时启动。 举个例子,假设一个收集器在使用中有2MB的堆内存。 注意：使用Go时,本文中堆内存的图表不代表真实的配置文件。Go中的堆内存通常会碎片化并且混乱,并且你没有图像所代表的干净分离。这些图提供了一种以更容易理解的方式可视化堆内存的方法,该方式对于你将体验的行为是准确的。 图10 图10显示了最后一次收集完成后正在使用的2MB堆内存。由于GC百分比设置为100％,因此下一个收集器需要在添加 2MB 堆内存时或之前启动。 图11 图11显示现在正在使用2个MB的堆内存。这将触发一个收集器。查看所有这些操作的方法是为每个发生的收集器生成GC跟踪。 GC跟踪运行任何Go应用程序时,可以通过在环境变量中GODEBUG包含gctrace=1选项来生成GC跟踪。每次发生收集器时,运行时都会将GC跟踪信息写入stderr。 清单2 1234567GODEBUG=gctrace=1 ./appgc 1405 @6.068s 11%: 0.058+1.2+0.083 ms clock, 0.70+2.5/1.5/0+0.99 ms cpu, 7-&gt;11-&gt;6 MB, 10 MB goal, 12 Pgc 1406 @6.070s 11%: 0.051+1.8+0.076 ms clock, 0.61+2.0/2.5/0+0.91 ms cpu, 8-&gt;11-&gt;6 MB, 13 MB goal, 12 Pgc 1407 @6.073s 11%: 0.052+1.8+0.20 ms clock, 0.62+1.5/2.2/0+2.4 ms cpu, 8-&gt;14-&gt;8 MB, 13 MB goal, 12 P 清单2显示了如何使用该GODEBUG变量生成GC跟踪。该列表还显示了正在运行的Go应用程序生成的3条跟踪。 以下是通过查看清单中的第一个GC跟踪线来细分GC跟踪中每个值的含义。 清单3 123456789101112131415161718192021222324252627gc 1405 @6.068s 11%: 0.058+1.2+0.083 ms clock, 0.70+2.5/1.5/0+0.99 ms cpu, 7-&gt;11-&gt;6 MB, 10 MB goal, 12 P// Generalgc 1404 : The 1404 GC run since the program started@6.068s : Six seconds since the program started11% : Eleven percent of the available CPU so far has been spent in GC// Wall-Clock0.058ms : STW : Mark Start - Write Barrier on1.2ms : Concurrent : Marking0.083ms : STW : Mark Termination - Write Barrier off and clean up// CPU Time0.70ms : STW : Mark Start2.5ms : Concurrent : Mark - Assist Time (GC performed in line with allocation)1.5ms : Concurrent : Mark - Background GC time0ms : Concurrent : Mark - Idle GC time0.99ms : STW : Mark Term// Memory7MB : Heap memory in-use before the Marking started11MB : Heap memory in-use after the Marking finished6MB : Heap memory marked as live after the Marking finished10MB : Collection goal for heap memory in-use after Marking finished// Threads12P : Number of logical processors or threads used to run Goroutines 清单3显示了第一个GC跟踪线的实际数字,按行值分解。我最终将讨论大多数这些值,但现在只关注跟踪1405的GC跟踪的内存部分。 图12 清单4 12345// Memory7MB : Heap memory in-use before the Marking started11MB : Heap memory in-use after the Marking finished6MB : Heap memory marked as live after the Marking finished10MB : Collection goal for heap memory in-use after Marking finished 此GC跟踪行在清单4中告诉你的是,在标记工作开始之前,正在使用的堆内存量为7MB。标记工作完成后,正在使用的堆内存量达到11MB。这意味着在收集过程中还有4MB的分配。标记工作完成后标记为活动的堆内存量为6MB。这意味着在下一个收集器需要启动之前,应用程序可以将正在使用的堆内存量增加到12MB（实时堆大小为6MB的100％）。 你可以看到收集器错过了1MB的目标。标记工作完成后正在使用的堆内存量为11MB而不是10MB。没关系,因为目标是根据当前正在使用的堆内存量,标记为实时的堆内存量以及有关在收集器运行时将发生的其他分配的计时计算来计算的。在这种情况下,应用程序做了一些事情,需要在Marking之后使用更多堆内存而不是预期。 如果查看下一个GC跟踪线（1406）,你将看到事情在2ms内发生了变化 图13 清单51234567gc 1406 @6.070s 11%: 0.051+1.8+0.076 ms clock, 0.61+2.0/2.5/0+0.91 ms cpu, 8-&gt;11-&gt;6 MB, 13 MB goal, 12 P// Memory8MB : Heap memory in-use before the Marking started11MB : Heap memory in-use after the Marking finished6MB : Heap memory marked as live after the Marking finished13MB : Collection goal for heap memory in-use after Marking finished 清单5显示了这个收集器在上一个收集器开始后2ms（6.068s对6.070s）的启动情况,即使使用中的堆内存仅达到允许的12MB的8MB。重要的是要注意,如果收集者决定更早开始收集它会更好。在这种情况下,它可能更早开始,因为应用程序分配很多,收集器希望减少此收集器期间的协助标记延迟量。 还有两点需要注意。这次收集器保持在其目标之内。标记完成后正在使用的堆内存量为11MB而不是13MB,少了2 MB。标记完成后标记为活动的堆内存量在6MB时相同。 作为旁注。你可以通过添加gcpacertrace=1标志从GC跟踪中获取更多详细信息。这会导致收集器打印有关并发步伐器内部状态的信息。 清单612345678910$ export GODEBUG=gctrace=1,gcpacertrace=1 ./appSample output:gc 5 @0.071s 0%: 0.018+0.46+0.071 ms clock, 0.14+0/0.38/0.14+0.56 ms cpu, 29-&gt;29-&gt;29 MB, 30 MB goal, 8 Ppacer: sweep done at heap size 29MB; allocated 0MB of spans; swept 3752 pages at +6.183550e-004 pages/bytepacer: assist ratio=+1.232155e+000 (scan 1 MB in 70-&gt;71 MB) workers=2+0pacer: H_m_prev=30488736 h_t=+2.334071e-001 H_T=37605024 h_a=+1.409842e+000 H_a=73473040 h_g=+1.000000e+000 H_g=60977472 u_a=+2.500000e-001 u_g=+2.500000e-001 W_a=308200 goalΔ=+7.665929e-001 actualΔ=+1.176435e+000 u_a/u_g=+1.000000e+000运行GC跟踪可以告诉你很多关于应用程序的运行状况和收集器的速度。收集器运行的速度在收集过程中起着重要作用。 步伐收集器具有调步算法,该算法用于确定何时开始收集。该算法依赖于收集器用于收集有关正在运行的应用程序的信息以及应用程序放在堆上的压力的反馈循环。压力可以定义为应用程序在给定时间内分配堆内存的速度。正是压力决定了收集器需要的速度。 在收集器开始收集之前,它会计算它认为完成收集所需的时间。然后,一旦收集器运行,将在正在运行的应用程序上造成延迟,这将减慢应用程序的工作。每个收集器都会增加应用程序的整体延迟。 一种误解是认为减慢收集器的速度是提高性能的一种方法。这个想法是,如果你可以推迟下一个收集器的开始,那么你将延迟它将造成的延迟。支持收集器并不是要放慢步伐。 你可以决定将GC百分比值更改为大于100的值。这将增加在下一个收集器必须启动之前可以分配的堆内存量。这可能导致收集速度减慢。不要考虑这样做。 图14 图14显示了更改GC百分比如何更改在下一个收集器必须启动之前允许分配的堆内存量。你可以直观地了解收集器在等待更多堆内存使用时如何减慢速度。 试图直接影响收集的速度与收集者的支持无关。这真的是在每个收集器之间或收集器期间完成更多的工作。你可以通过减少任何工作添加到堆内存的分配数量或数量来影响它。 注意：这个想法也是为了用尽可能小的堆来实现所需的吞吐量。请记住,在云环境中运行时,最小化堆内存等资源的使用非常重要。 图15 清单15显示了将在本系列的下一部分中使用的正在运行的Go应用程序的一些统计信息。蓝色版本显示应用程序的统计信息,而不通过应用程序处理10k请求时进行任何优化。在发现4.48GB的非生产性内存分配后,绿色版本显示统计数据,并从应用程序中删除相同的10k请求。 查看两个版本的平均收集速度（2.08ms vs 1.96ms）。它们几乎相同,约为2.0毫秒。这两个版本之间的根本变化是每个收集器之间的工作量。该应用程序从每个收集器处理3.98到7.13个请求。这是以同样的速度完成工作量增加79.1％。正如你所看到的,该收集器并没有随着这些分配的减少而减慢,但保持不变。获胜来自于在每个系列之间完成更多工作。 调整收集器的速度以延迟延迟成本并不是你提高应用程序性能的方式。它是关于减少收集器运行所需的时间,这反过来将减少造成的延迟成本。已经解释了收集器造成的延迟成本,但为了清楚起见,让我再次总结一下。 收集器延迟成本每个收集器在运行的应用程序上有两种类型的延迟。 首先是窃取CPU容量。这种被盗CPU容量的影响意味着你的应用程序在收集过程中没有全速运行。应用程序Goroutines现在与收集器的Goroutines共享P或帮助收集（Mark Assist）。 图16 图16显示了应用程序如何仅将75％的CPU容量用于应用程序工作。这是因为收集器本身就有专用的P1。这将是大部分收集器。 图17 图17显示了应用程序在这个时刻（通常只有几微秒）现在只能将其CPU容量的一半用于应用程序工作。这是因为P3上的Goroutine正在执行协助标记,并且收集器为自己设置了专用P1。 注意：标记通常需要每MB实时堆4个CPU毫秒（例如,估计标记阶段将运行多少毫秒,以MB为单位取实时堆大小除以CPU *的数量）。标记实际上以大约1 MB / ms的速度运行,但只有四分之一的CPU。 造成的第二个延迟是收集期间发生的STW延迟量。STW时间是没有应用程序Goroutines执行任何应用程序工作的时间。该应用程序基本上已停止。 图18 图18显示了所有Goroutines停止的STW延迟。每次收集都会发生两次。如果你的应用程序运行正常,则收集器应该能够将大部分收集器的总STW时间保持在100微秒或以下。 你现在知道收集器的不同阶段,内存的大小,调整的工作方式以及收集器对正在运行的应用程序造成的不同延迟。有了这些知识,最终可以回答你如何与收集器支持的问题。 支持对收集器表示支持是为了减少堆内存的压力。请记住,压力可以定义为应用程序在给定时间内分配堆内存的速度。当压力减小时,收集器造成的延迟将会减少。这是GC延迟会降低你的应用程序速度。 减少GC延迟的方法是从应用程序中识别并删除不必要的分配。这样做有助于收集器的几种方式。 帮助收集器： 尽可能保持最小的堆。 找到最佳的一致步伐。 保持每个收集器的目标。 最小化每个收集器,STW和Mark Assist的持续时间。 所有这些都有助于减少收集器对正在运行的应用程序造成的延迟。这将提高应用程序的性能和吞吐量。收集的速度与它无关。这些是你可以做的其他事情,以帮助做出更好的工程决策,减少堆上的压力。 了解应用程序执行工作负载的性质了解工作负载意味着确保使用合理数量的Goroutine来完成你已完成的工作。CPU与IO绑定的工作负载不同,需要不同的工程决策。 https://www.ardanlabs.com/blog/2018/12/scheduling-in-go-part3.html 了解已定义的数据及其在应用程序中的传递方式了解数据意味着了解你要解决的问题。数据语义一致性是维护数据完整性的关键部分,并允许你在堆栈上选择堆分配时知道（通过读取代码）。 https://www.ardanlabs.com/blog/2017/06/design-philosophy-on-data-and-semantics.html 结论如果你花时间专注于减少分配,那么你就像Go开发人员一样,对垃圾收集器表示支持。你不打算编写零分配应用程序,因此重要的是要认识到有效的分配（帮助应用程序的分配）和那些没有生产力的分配（那些损害应用程序）之间的差异。然后将你的信任和信任放在垃圾收集器中,以保持堆健康并使你的应用程序始终如一地运行。 拥有垃圾收集器是一个很好的权衡。我将花费垃圾收集的成本,所以我没有内存管理的负担。Go是关于允许你作为开发人员提高工作效率,同时仍然编写足够快的应用程序。垃圾收集器是实现这一目标的重要组成部分。在下一篇文章中,我将向你展示一个示例Web应用程序以及如何使用该工具查看所有这些操作。","link":"/2019/08/07/Go/Golang%E8%AF%91%E6%96%87/Go%E4%B8%AD%E7%9A%84%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%EF%BC%9A%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86-%E8%AF%AD%E4%B9%89/"},{"title":"Go源码分析(5) - 数据结构","text":"介绍常见的数据结构,比如channel、slice、map等,通过对其底层实现原理的分析,来更好的使用这些数据结构。 一、切片Slice数据结构12345type slice struct { array unsafe.Pointer len int cap int} array指针指向底层数组 len表示切片长度 cap表示底层数组容量 slice的三种初始化方式make初始化123456789101112131415161718func makeslice(et *_type, len, cap int) slice { // NOTE: The len &gt; maxElements check here is not strictly necessary, // but it produces a 'len out of range' error instead of a 'cap out of range' error // when someone does make([]T, bignumber). 'cap out of range' is true too, // but since the cap is only being supplied implicitly, saying len is clearer. // See issue 4085. maxElements := maxSliceCap(et.size) if len &lt; 0 || uintptr(len) &gt; maxElements { panic(errorString(\"makeslice: len out of range\")) } if cap &lt; len || uintptr(cap) &gt; maxElements { panic(errorString(\"makeslice: cap out of range\")) } p := mallocgc(et.size*uintptr(cap), et, true) return slice{p, len, cap}} 使用make()方法会调用makeslice()的方法,会对 slice的 array 指针进行分配地址,创建后可直接使用。 []struct{}{}使用该方法创建后的对象可以直接使用。 new([]struct{})12345func main() { array := new([]int) (*array)[0] = 1 // nil[0] = 1 err println(array)} 使用该方式只是创建一个该数组类型的指针,调用runtime.newobject方法 ,new是返回 slice 的地址。指针类型初始化后,值为nil,如果对该类型进行赋值会发生空指针异常,创建后不可直接使用。 slice的扩容机制使用append()方法的扩容:使用append()向Slice添加一个元素的实现步骤如下: 假如Slice容量够用,则将新元素追加进去,Slice.len++,返回原Slice 原Slice容量不够,则将Slice先扩容,扩容后得到新Slice 将新元素追加进新Slice,Slice.len++,返回新的Slice。 1234567891011121314151617181920212223242526func growslice(et *_type, old slice, cap int) slice { // 省略一些判断... newcap := old.cap doublecap := newcap + newcap if cap &gt; doublecap { newcap = cap } else { if old.len &lt; 1024 { newcap = doublecap } else { // Check 0 &lt; newcap to detect overflow // and prevent an infinite loop. for 0 &lt; newcap &amp;&amp; newcap &lt; cap { newcap += newcap / 4 } // Set newcap to the requested cap when // the newcap calculation overflowed. if newcap &lt;= 0 { newcap = cap } } } // 省略一些后续...} 如果原Slice容量小于1024,则新Slice容量将扩大为原来的2倍; 如果原Slice容量大于等于1024,则新Slice容量将扩大为原来的1.25倍; slice的复制使用copy()进行复制12345678910111213141516171819202122232425262728293031323334func slicecopy(to, fm slice, width uintptr) int { if fm.len == 0 || to.len == 0 { return 0 } n := fm.len if to.len &lt; n { n = to.len } if width == 0 { return n } if raceenabled { callerpc := getcallerpc() pc := funcPC(slicecopy) racewriterangepc(to.array, uintptr(n*int(width)), callerpc, pc) racereadrangepc(fm.array, uintptr(n*int(width)), callerpc, pc) } if msanenabled { msanwrite(to.array, uintptr(n*int(width))) msanread(fm.array, uintptr(n*int(width))) } size := uintptr(n) * width if size == 1 { // common case worth about 2x to do here // TODO: is this still worth it with new memmove impl? *(*byte)(to.array) = *(*byte)(fm.array) // known to be a byte pointer } else { memmove(to.array, fm.array, size) } return n} 使用copy()内置函数拷贝两个切片时,memmove()方法同时将被拷贝切片的array的切片的值逐一拷贝到新到切片,拷贝数量取两个切片长度的最小值。 使用slice[start:end]方法进行复制使用该方法,同时将被拷贝切片的array的切片的指针拷贝到新到切片的指针上,同时len变为end-start,cap则和原slice一样。 二、channelchan数据结构12345678910111213type hchan struct { qcount uint // total data in the queue dataqsiz uint // size of the circular queue buf unsafe.Pointer // points to an array of dataqsiz elements elemsize uint16 closed uint32 elemtype *_type // element type sendx uint // send index recvx uint // receive index recvq waitq // list of recv waiters sendq waitq // list of send waiters lock mutex} qcount 当前队列中剩余元素个数 dataqsiz 环形队列长度,即可以存放的元素个数 buf 环形队列指针 elemsize 每个元素的大小 closed 标识关闭状态 elemtype 元素类型 sendx 队列下标,指示元素写入时存放到队列中的位置 recvx 队列下标,指示元素从队列的该位置读出 recvq 等待读消息的goroutine队列 sendq 等待写消息的goroutine队列 lock 互斥锁,chan不允许并发读写 hchan 实际上就是一个环形队列,buf指向环形队列,dataqsiz、qcount 分别指定了队列的容量和当前使用量,其中recvq队列和sendq队列是一个链表的结构,包含该goroutine和该groutine的数据,然后再来看一下waitq这个数据结构。 1234type waitq struct { first *sudog last *sudog} waitq是链表的定义,包含一个头结点和一个尾结点。我们可能对节点中存放对内容感到疑惑,再来看一下sudog这个数据结构。 123456789101112131415161718192021222324252627type sudog struct { // The following fields are protected by the hchan.lock of the // channel this sudog is blocking on. shrinkstack depends on // this for sudogs involved in channel ops. g *g // isSelect indicates g is participating in a select, so // g.selectDone must be CAS'd to win the wake-up race. isSelect bool next *sudog prev *sudog elem unsafe.Pointer // data element (may point to stack) // The following fields are never accessed concurrently. // For channels, waitlink is only accessed by g. // For semaphores, all fields (including the ones above) // are only accessed when holding a semaRoot lock. acquiretime int64 releasetime int64 ticket uint32 parent *sudog // semaRoot binary tree waitlink *sudog // g.waiting list or semaRoot waittail *sudog // semaRoot c *hchan // channel} sudog结构可以实际上是一个对应goroutine上保存着其对应的data数据,类似于java中的ThreadLocal。其中： g 代表着 G-M-P模型中的 G,sudog 是对g的封装便于在 csp 模型中 g 可以同时阻塞在不同的 channel 上 elem 用于存储 goroutine 的数据;读通道时,数据会从 hchan 的队列中拷贝到 sudog 的 elem 域;写通道时,数据则是由 sudog 的elem 域拷贝到 hchan 的队列中。 下面给出他们的结构图: 创建channel12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849func makechan(t *chantype, size int64) *hchan { elem := t.elem // compiler checks this but be safe. // 异常判断 元素类型大小限制 if elem.size &gt;= 1&lt;&lt;16 { throw(\"makechan: invalid channel element type\") } // 异常判断 对齐限制 if hchanSize%maxAlign != 0 || elem.align &gt; maxAlign { throw(\"makechan: bad alignment\") } // maxAlloc 是 Arena 区域的最大值,缓冲元素的大小与hchan相加不能超过 缓冲槽大小 if size &lt; 0 || int64(uintptr(size)) != size || (elem.size &gt; 0 &amp;&amp; uintptr(size) &gt; (_MaxMem-hchanSize)/elem.size) { panic(plainError(\"makechan: size out of range\")) } var c *hchan // 不是指针类型 if elem.kind&amp;kindNoPointers != 0 || size == 0 { // 在一个调用中分配内存。 // 在这种情况下,Hchan不包含GC感兴趣的指针： // buf指向相同的分配,elemtype是持久的。 // SudoG从它们自己的线程中引用,因此无法将其收集。 // TODO（dvyukov,rlh）：重新考虑何时收集器可以移动分配的对象。 c = (*hchan)(mallocgc(hchanSize+uintptr(size)*elem.size, nil, true)) if size &gt; 0 &amp;&amp; elem.size != 0 { c.buf = add(unsafe.Pointer(c), hchanSize) } else { // 竞争检测器使用此位置进行同步 // 还可以防止我们超出分配范围（请参见问题9401）。 c.buf = unsafe.Pointer(c) } } else { // 是指针类型 分配hchan结构体 buf单独分配 c = new(hchan) c.buf = newarray(elem, int(size)) } // 初始化元素类型的大小 c.elemsize = uint16(elem.size) // 初始化元素的类型 c.elemtype = elem // 初始化 channel 的容量 c.dataqsiz = uint(size) if debugChan { print(\"makechan: chan=\", c, \"; elemsize=\", elem.size, \"; elemalg=\", elem.alg, \"; dataqsiz=\", size, \"\\n\") } return c} 创建channel的过程实际上是初始化hchan结构。其中类型信息和缓冲区长度由make语句传入,buf的大小则与元素大小和缓冲区长度共同决定。 向channel写数据123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101// entry point for c &lt;- x from compiled code//go:nosplitfunc chansend1(c *hchan, elem unsafe.Pointer) { chansend(c, elem, true, getcallerpc(unsafe.Pointer(&amp;c)))}func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool { if c == nil { if !block { return false } gopark(nil, nil, \"chan send (nil chan)\", traceEvGoStop, 2) throw(\"unreachable\") } ... if !block &amp;&amp; c.closed == 0 &amp;&amp; ((c.dataqsiz == 0 &amp;&amp; c.recvq.first == nil) || (c.dataqsiz &gt; 0 &amp;&amp; c.qcount == c.dataqsiz)) { return false } var t0 int64 if blockprofilerate &gt; 0 { t0 = cputicks() } lock(&amp;c.lock) if c.closed != 0 { unlock(&amp;c.lock) panic(plainError(\"send on closed channel\")) } // 1 if sg := c.recvq.dequeue(); sg != nil { // Found a waiting receiver. We pass the value we want to send // directly to the receiver, bypassing the channel buffer (if any). send(c, sg, ep, func() { unlock(&amp;c.lock) }, 3) return true } // 2 if c.qcount &lt; c.dataqsiz { // Space is available in the channel buffer. Enqueue the element to send. qp := chanbuf(c, c.sendx) if raceenabled { raceacquire(qp) racerelease(qp) } typedmemmove(c.elemtype, qp, ep) c.sendx++ if c.sendx == c.dataqsiz { c.sendx = 0 } c.qcount++ unlock(&amp;c.lock) return true } if !block { unlock(&amp;c.lock) return false } // Block on the channel. Some receiver will complete our operation for us. gp := getg() mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil mysg.g = gp mysg.selectdone = nil mysg.c = c gp.waiting = mysg gp.param = nil c.sendq.enqueue(mysg) goparkunlock(&amp;c.lock, \"chan send\", traceEvGoBlockSend, 3) // someone woke us up. if mysg != gp.waiting { throw(\"G waiting list is corrupted\") } gp.waiting = nil if gp.param == nil { if c.closed == 0 { throw(\"chansend: spurious wakeup\") } panic(plainError(\"send on closed channel\")) } gp.param = nil if mysg.releasetime &gt; 0 { blockevent(mysg.releasetime-t0, 2) } mysg.c = nil releaseSudog(mysg) return true} if c == nil判断 channel 为空 向其中发送数据将会永久阻塞 if !block如果非阻塞返回 false gopark(nil, nil, waitReasonChanReceiveNilChan, traceEvGoStop, 2)如果阻塞, gopark 会使当前 goroutine 挂起,通过 unlockf 唤醒;调用gopark时传入的unlockf为nil,会被一直休眠 在不获取锁定的情况下检查失败的非阻塞操作。如果检测到,将直接返回false !block &amp;&amp; c.closed == 0非阻塞并且没有关闭channel (c.dataqsiz == 0 &amp;&amp; c.recvq.first == nil)无缓冲channel并且消费者环形队列头结点为空,说明channel还没有准备好。 (c.dataqsiz &gt; 0 &amp;&amp; c.qcount == c.dataqsiz)有缓冲channel中存储的元素数量与容量相等,容量已经满了,不能够缓存更多的。 lock(&amp;c.lock)对channel进行加锁 c.closed != 0如果channel在途中关闭,unlock(&amp;c.lock)解锁并 panic sg := c.recvq.dequeue(); sg != nil当有 goroutine 在 recvq 队列上等待时,跳过缓存队列,send(c, sg, ep, func() { unlock(&amp;c.lock) }, 3)将消息直接发给 reciever goroutine;dequeue 从等待接受的 goroutine 队列链表获取一个sudog,goready()唤醒阻塞的 goroutine c.qcount &lt; c.dataqsiz缓存队列未满,将消息复制到缓存队列上并移动 sendx 下标,hchan buf 数据量增加。 typedmemmove(c.elemtype, qp, ep)数据拷贝到 buf 中 c.sendx++index 移动 c.sendx == c.dataqsiz环形队列如果已经加到最大,c.sendx = 0就置 0 c.qcount++缓冲元素数量加 1 unlock(&amp;c.lock)解锁返回 if !block阻塞 解锁直接返回 false gp := getg()返回指向当前goroutine的指针 mysg := acquireSudog()从sudogcache中获取sudog 对mysg进行一系列的赋值 c.sendq.enqueue(mysg) 加入到写阻塞的等待队列 goparkunlock(&amp;c.lock, waitReasonChanSend, traceEvGoBlockSend, 3)将当前gorountine挂起休眠 KeepAlive(ep)保证数据不被回收 mysg != gp.waiting此时被唤醒 gp.waiting不是当前的 mysg 直接 panic gp.waiting = nil说明waiting是当前waiting,将gp中的waiting置为nil gp.param == nil唤醒时传递的参数为 nil 说明出问题了直接 panic mysg.c = nilsudog 中的 hchan 置为 nil releaseSudog(mysg)释放 sudog 从上面的可以看出来channelsend()的处理逻辑为： 如果当前 Channel 的 recvq 上存在已经被阻塞的 Goroutine,那么会直接将数据发送给当前的 Goroutine 并将其设置成下一个运行的协程。 如果 Channel 存在缓冲区并且其中还有空闲的容量,我们就会直接将数据直接存储到当前缓冲 区 sendx 所在的位置上。 如果都不满足上面的两种情况,就会创建一个 sudog 结构并加入 Channel 的 sendq 队 列并更新到 Goroutine 的 waiting 字段上,同时当前的 Goroutine 就会陷入阻塞等待 其他的协程向 Channel 接收数据,一旦有其它的协程向 Channel 接收数据时就会唤醒当前的 Goroutine;发送数据的过程中包含几个会触发 Goroutine 调度的时机,首先是发送数据时发现 Channel 上存在等待接收数据的 Goroutine,这是会立刻设置处理器的 runnext 属 性,但是并不会立刻触发调度,第二个时机是发送数据时并没有找到接收方并且缓冲区已经满 了,这时就会将自己加入 Channel 的 sendq 队列并立刻调用 goparkunlock 触发 Goroutine 的调度让出处理器的使用权。 直接将消息发送给reciever是怎样的呢？ 1234567891011121314151617181920212223242526272829303132333435363738func send(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) { if raceenabled { if c.dataqsiz == 0 { racesync(c, sg) } else { // Pretend we go through the buffer, even though // we copy directly. Note that we need to increment // the head/tail locations only when raceenabled. qp := chanbuf(c, c.recvx) raceacquire(qp) racerelease(qp) raceacquireg(sg.g, qp) racereleaseg(sg.g, qp) c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } c.sendx = c.recvx // c.sendx = (c.sendx+1) % c.dataqsiz } } // 写入的数据不为空 if sg.elem != nil { // 将数据拷贝到 hchan sendDirect(c.elemtype, sg, ep) // sudog 中数据置为 nil sg.elem = nil } // 取数 goroutine gp := sg.g unlockf() // 传入 sudug 使 param 不为空 gp.param = unsafe.Pointer(sg) if sg.releasetime != 0 { sg.releasetime = cputicks() } // 唤醒 goroutine goready(gp, skip+1)} 调用sendDirect函数将发送的消息拷贝到接收方持有的目标内存地址上,取出gp := sg.g,然后将当前sg的数据赋值回去,使用goready(gp, skip+1)将接收方 Goroutine 的状态修改成 Grunnable 并更新发送方所在处理器 P 的 runnext 属性,当处理器 P 再次发生调度时就会优先执行 runnext 中的协程。 从channel读数据123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) { // raceenabled: don't need to check ep, as it is always on the stack // or is new memory allocated by reflect. if debugChan { print(\"chanrecv: chan=\", c, \"\\n\") } if c == nil { if !block { return } gopark(nil, nil, waitReasonChanReceiveNilChan, traceEvGoStop, 2) throw(\"unreachable\") } // Fast path: check for failed non-blocking operation without acquiring the lock. // // After observing that the channel is not ready for receiving, we observe that the // channel is not closed. Each of these observations is a single word-sized read // (first c.sendq.first or c.qcount, and second c.closed). // Because a channel cannot be reopened, the later observation of the channel // being not closed implies that it was also not closed at the moment of the // first observation. We behave as if we observed the channel at that moment // and report that the receive cannot proceed. // // The order of operations is important here: reversing the operations can lead to // incorrect behavior when racing with a close. if !block &amp;&amp; (c.dataqsiz == 0 &amp;&amp; c.sendq.first == nil || c.dataqsiz &gt; 0 &amp;&amp; atomic.Loaduint(&amp;c.qcount) == 0) &amp;&amp; atomic.Load(&amp;c.closed) == 0 { return } var t0 int64 if blockprofilerate &gt; 0 { t0 = cputicks() } lock(&amp;c.lock) if c.closed != 0 &amp;&amp; c.qcount == 0 { if raceenabled { raceacquire(c.raceaddr()) } unlock(&amp;c.lock) if ep != nil { typedmemclr(c.elemtype, ep) } return true, false } if sg := c.sendq.dequeue(); sg != nil { // Found a waiting sender. If buffer is size 0, receive value // directly from sender. Otherwise, receive from head of queue // and add sender's value to the tail of the queue (both map to // the same buffer slot because the queue is full). recv(c, sg, ep, func() { unlock(&amp;c.lock) }, 3) return true, true } if c.qcount &gt; 0 { // Receive directly from queue qp := chanbuf(c, c.recvx) if raceenabled { raceacquire(qp) racerelease(qp) } if ep != nil { typedmemmove(c.elemtype, ep, qp) } typedmemclr(c.elemtype, qp) c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } c.qcount-- unlock(&amp;c.lock) return true, true } if !block { unlock(&amp;c.lock) return false, false } gp := getg() mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } //在分配elem和排队mysg之间没有堆栈拆分 //在gp.waiting上copystack可以找到它的地方。 mysg.elem = ep mysg.waitlink = nil gp.waiting = mysg mysg.g = gp mysg.isSelect = false mysg.c = c gp.param = nil c.recvq.enqueue(mysg) goparkunlock(&amp;c.lock, waitReasonChanReceive, traceEvGoBlockRecv, 3) // someone woke us up if mysg != gp.waiting { throw(\"G waiting list is corrupted\") } gp.waiting = nil if mysg.releasetime &gt; 0 { blockevent(mysg.releasetime-t0, 2) } closed := gp.param == nil gp.param = nil mysg.c = nil releaseSudog(mysg) return true, !closed} 该方法与chansend()没有太大的区别,主要讲两个不同的地方。 if sg := c.sendq.dequeue(); sg != nil如果有 send 生产者阻塞在队列中,recv(c, sg, ep, func() { unlock(&amp;c.lock) }, 3)直接从 send 生产者取数据 c.recvq.enqueue(mysg)否则 goroutine 加入到读阻塞等待队列 所以大致逻辑为： 如果 Channel 上的 sendq 队列中存在挂起的 Goroutine,就会将 recvx 索引所在的数 据拷贝到接收变量所在的内存空间上并将 sendq 队列中 Goroutine 的数据拷贝到缓冲区中。 如果 Channel 的缓冲区中包含数据就会直接从 recvx 所在的索引上进行读取 在默认情况下会直接挂起当前的 Goroutine,将 sudog 结构加入 recvq 队列并更新 Goroutine 的 waiting 属性,最后陷入休眠等待调度器的唤醒;在从管道中接收数据的过 程中,其实会在两个时间点触发 Goroutine 的调度,首先空的 Channel 意味着永远接收不 到消息,那么就会直接挂起当前 Goroutine,第二个时间点是缓冲区中不存在数据,在这时也 会直接挂起当前的 Goroutine 等待发送方发送数据。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051func recv(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) { // 缓存队列不为空,直接从生产者获取数据 if c.dataqsiz == 0 { if raceenabled { racesync(c, sg) } if ep != nil { // copy data from sender recvDirect(c.elemtype, sg, ep) } } else { // Queue is full. Take the item at the // head of the queue. Make the sender enqueue // its item at the tail of the queue. Since the // queue is full, those are both the same slot. // 有 send 阻塞在这里,从 buf 中获取数据 qp := chanbuf(c, c.recvx) if raceenabled { raceacquire(qp) racerelease(qp) raceacquireg(sg.g, qp) racereleaseg(sg.g, qp) } // copy data from queue to receiver if ep != nil { // 将 buf 中未读的当前位置数据拷贝给消费者 typedmemmove(c.elemtype, ep, qp) } // 将阻塞的生产者数据拷贝此位置 typedmemmove(c.elemtype, qp, sg.elem) // 接收元素索引向后移动 c.recvx++ // 环形队列如果已经加到最大就置 0 if c.recvx == c.dataqsiz { c.recvx = 0 } // 环形队列读取的索引位置就是写入数据环形的末端 c.sendx = c.recvx // c.sendx = (c.sendx+1) % c.dataqsiz } // 数据置为 nil sg.elem = nil // 获取 SudoG 中的 goroutine 传递给 param 参数 gp := sg.g unlockf() gp.param = unsafe.Pointer(sg) if sg.releasetime != 0 { sg.releasetime = cputicks() } // 唤醒 sendq 里面 SudoG 对应的 g goready(gp, skip+1)} 关闭channel关闭通道设置chan关闭标志位,closed=1 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768func closechan(c *hchan) { if c == nil { panic(plainError(\"close of nil channel\")) } lock(&amp;c.lock) if c.closed != 0 { unlock(&amp;c.lock) panic(plainError(\"close of closed channel\")) } if raceenabled { callerpc := getcallerpc() racewritepc(c.raceaddr(), callerpc, funcPC(closechan)) racerelease(c.raceaddr()) } c.closed = 1 var glist gList // release all readers for { sg := c.recvq.dequeue() if sg == nil { break } if sg.elem != nil { typedmemclr(c.elemtype, sg.elem) sg.elem = nil } if sg.releasetime != 0 { sg.releasetime = cputicks() } gp := sg.g gp.param = nil if raceenabled { raceacquireg(gp, c.raceaddr()) } glist.push(gp) } // release all writers (they will panic) for { sg := c.sendq.dequeue() if sg == nil { break } sg.elem = nil if sg.releasetime != 0 { sg.releasetime = cputicks() } gp := sg.g gp.param = nil if raceenabled { raceacquireg(gp, c.raceaddr()) } glist.push(gp) } unlock(&amp;c.lock) // Ready all Gs now that we've dropped the channel lock. for !glist.empty() { gp := glist.pop() gp.schedlink = 0 goready(gp, 3) }} c == nil // 关闭为 nil 的 hchan 直接 panic lock(&amp;c.lock)获取同步锁 if c.closed != 0已关闭 hchan 释放锁 panic c.closed = 1将 closed 置为 1 sg := c.recvq.dequeue()释放所有的读者if sg == nil break sg := c.sendq.dequeue()释放所有的写者if sg == nil break unlock(&amp;c.lock)释放同步锁 goready(gp, 3)将接收队列和发送队列全部唤醒 三、mapGolang中map由链式哈希表实现,主要涉及创建、插入、查找、删除等基本操作,而核心涉及到Map的冲突解决、扩容机制及迁移策略,这也是Map中最难理解的部分。 map数据结构1234567891011121314// A header for a Go map.type hmap struct { // Note: the format of the hmap is also encoded in cmd/compile/internal/gc/reflect.go. // Make sure this stays in sync with the compiler's definition. count int // # live cells == size of map. Must be first (used by len() builtin) flags uint8 B uint8 // log_2 of # of buckets (can hold up to loadFactor * 2^B items) noverflow uint16 // approximate number of overflow buckets; see incrnoverflow for details hash0 uint32 // hash seed buckets unsafe.Pointer // array of 2^B Buckets. may be nil if count==0. oldbuckets unsafe.Pointer // previous bucket array of half the size, non-nil only when growing nevacuate uintptr // progress counter for evacuation (buckets less than this have been evacuated) extra *mapextra // optional fields} count表示当前哈希表中的元素数量。 B表示当前哈希表持有的 buckets 数量,B为2的对数,2^B。 hash0是哈希的种子,它能为哈希函数的结果引入随机性,这个值在创建哈希表时确定,并在 调用哈希函数时作为参数传入。 buckets2^B个Buckets的桶 oldbuckets是哈希在扩容时用于保存之前buckets的字段,它的大小是当前buckets的一半。 12345678910111213141516171819202122232425262728// mapextra holds fields that are not present on all maps.type mapextra struct { // If both key and value do not contain pointers and are inline, then we mark bucket // type as containing no pointers. This avoids scanning such maps. // However, bmap.overflow is a pointer. In order to keep overflow buckets // alive, we store pointers to all overflow buckets in hmap.extra.overflow and hmap.extra.oldoverflow. // overflow and oldoverflow are only used if key and value do not contain pointers. // overflow contains overflow buckets for hmap.buckets. // oldoverflow contains overflow buckets for hmap.oldbuckets. // The indirection allows to store a pointer to the slice in hiter. overflow *[]*bmap oldoverflow *[]*bmap // nextOverflow holds a pointer to a free overflow bucket. nextOverflow *bmap}type struct Bucket { // tophash generally contains the top byte of the hash value // for each key in this bucket. If tophash[0] &lt; minTopHash, // tophash[0] is a bucket evacuation state instead. tophash [bucketCnt]uint8 // Followed by bucketCnt keys and then bucketCnt values. // NOTE: packing all the keys together and then all the values together makes the // code a bit more complicated than alternating key/value/key/value/... but it allows // us to eliminate padding which would be needed for, e.g., map[int64]int8. // Followed by an overflow pointer.}; tophash是个长度为8的数组,哈希值相同的键(准确的说是哈希值低位相同的键)存入当前bucket时会将哈希值的高位存储在该数组中,以方便后续匹配。 overflow指针指向的是下一个bucket,据此将所有冲突的键连接起来。 data其中BUCKETSIZE是用宏定义的8,每个bucket中存放最多8个key/value对,存放顺序是key/key/key/…value/value/value,如此存放是为了节省 字节对齐带来的空间浪费。 如果多于8个,那么会申请一个新的bucket,并将它与之前的bucket链起来。 平衡因子选取扩容的填充因子是多少呢？如果grow的太频繁,会造成空间的利用率很低, 如果很久才grow,会形成很多的overflow buckets,查找的效率也会下降。 这个平衡点如何选取呢(在go中,这个平衡点是有一个宏控制的(#define LOAD 6.5), 它的意思是这样的,如果table中元素的个数大于table中能容纳的元素的个数, 那么就触发一次grow动作。那么这个6.5是怎么得到的呢？作者给出了测试的结果： 123456789101112131415 LOAD %overflow bytes/entry hitprobe missprobe 4.00 2.13 20.77 3.00 4.00 4.50 4.05 17.30 3.25 4.50 5.00 6.85 14.77 3.50 5.00 5.50 10.55 12.94 3.75 5.50 6.00 15.27 11.67 4.00 6.00 6.50 20.90 10.79 4.25 6.50 7.00 27.14 10.15 4.50 7.00 7.50 34.03 9.73 4.75 7.50 8.00 41.10 9.40 5.00 8.00%overflow = percentage of buckets which have an overflow bucketbytes/entry = overhead bytes used per key/value pairhitprobe = # of entries to check when looking up a present keymissprobe = # of entries to check when looking up an absent key 冲突解决就像我们之前所提到的,在通常情况下,哈希函数输入的范围一定会远远大于输出的范围,所以在使用哈希表时一定会遇到冲突,哪怕我们使用了完美的哈希函数,当输入的键足够多最终也会造成冲突。 map使用了拉链法在一个性能比较好的哈希表中,每一个桶中都应该有 0~1 个元素,有时会有 2~3 个,很少会超过这个数量,计算哈希、定位桶和遍历链表三个过程是哈希表读写操作的主要开销,使用拉链法实现的哈希也有装载因子这一概念：装载因子 := 元素数量 / 桶数量 map创建make([Type]Type) 当不指定map元素数量时,使用make_small函数创建hmap结构,但并不初始化桶。产生哈希种子–&gt;返回。 12345func makemap_small() *hmap { h := new(hmap) h.hash0 = fastrand() /* 创建哈希种子 */ return h} make([Type]Type, len) 指定元素数量,当元素数量小于8并且小于1&lt;&lt;B*6.5时,B = 0,此时仍然不会初始化桶指针buckets,只产生哈希种子返回,在使用的过程中初始化；其他情况设定B的值,并对桶指针buckets进行初始化。 123456789101112131415161718192021222324252627func makemap(t *maptype, hint int, h *hmap) *hmap { mem, overflow := math.MulUintptr(uintptr(hint), t.bucket.size) if overflow || mem &gt; maxAlloc { hint = 0 } if h == nil { h = new(hmap) /* 新建hmap结构 */ } h.hash0 = fastrand() /* 产生哈希种子 */ B := uint8(0) for overLoadFactor(hint, B) { /* 确定B的值 */ B++ } h.B = B if h.B != 0 { /* B != 0 时初始化桶指针buckets */ var nextOverflow *bmap h.buckets, nextOverflow = makeBucketArray(t, h.B, nil) /* 初始化桶指针 buckets并分配空间 */ if nextOverflow != nil { h.extra = new(mapextra) h.extra.nextOverflow = nextOverflow /* 设置溢出桶 */ } } return h} map查找过程mapaccess1指针返回到h[k]。 永远不会返回nil,而是会参考返回零对象的值类型,如果key是没有在map上。 注：返回的指针可以保持整个map的存活,所以不要抓住它很长时间 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657func mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { if raceenabled &amp;&amp; h != nil { callerpc := getcallerpc() pc := funcPC(mapaccess1) racereadpc(unsafe.Pointer(h), callerpc, pc) raceReadObjectPC(t.key, key, callerpc, pc) } if msanenabled &amp;&amp; h != nil { msanread(key, t.key.size) } if h == nil || h.count == 0 { /* 判断哈希表中是否含有数据 */ if t.hashMightPanic() { t.key.alg.hash(key, 0) // see issue 23734 } return unsafe.Pointer(&amp;zeroVal[0]) } if h.flags&amp;hashWriting != 0 { /* 是否并发写 */ throw(\"concurrent map read and map write\") } alg := t.key.alg hash := alg.hash(key, uintptr(h.hash0)) /* 计算键的哈希值 */ m := bucketMask(h.B) /* 1&lt;&lt;h.B -1 ,低B位掩码*/ b := (*bmap)(add(h.buckets, (hash&amp;m)*uintptr(t.bucketsize))) /* 找到相应的桶,hash&amp;m为第n个桶 */ if c := h.oldbuckets; c != nil { if !h.sameSizeGrow() { m &gt;&gt;= 1 } oldb := (*bmap)(add(c, (hash&amp;m)*uintptr(t.bucketsize))) if !evacuated(oldb) { b = oldb } } top := tophash(hash) /* 计算该键tophash的值 */bucketloop: for ; b != nil; b = b.overflow(t) { /* 依次查找桶或溢出桶的元素 */ for i := uintptr(0); i &lt; bucketCnt; i++ { /* 依次遍历桶中的每个key, bucketCnt=8 */ if b.tophash[i] != top { /* 如果找到top值,则比较第i个key */ if b.tophash[i] == emptyRest { break bucketloop } continue } k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) /* 求key地址 */ if t.indirectkey() { k = *((*unsafe.Pointer)(k)) } if alg.equal(key, k) { /* 比较键是否相等。如果相等,则找到key对应的值 */ v := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize)) if t.indirectvalue() { v = *((*unsafe.Pointer)(v)) } return v } } } return unsafe.Pointer(&amp;zeroVal[0])} 按key的类型采用相应的hash算法得到key的hash值。 将hash值的低位与hmpa.B取模确定bucket位置。 先比较hash值高位与bucket的tophash[i]是否相等,如果相等则再比较bucket的第i个的key与所给的key是否相等。 如果相等,则返回其对应的value。 反之,在overflowbuckets 中按照上述方法继续寻找。 如果当前处于搬迁过程,则优先从oldbuckets查找 map插入过程123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { if h == nil { panic(plainError(\"assignment to entry in nil map\")) } if raceenabled { callerpc := getcallerpc() pc := funcPC(mapassign) racewritepc(unsafe.Pointer(h), callerpc, pc) raceReadObjectPC(t.key, key, callerpc, pc) } if msanenabled { msanread(key, t.key.size) } if h.flags&amp;hashWriting != 0 { throw(\"concurrent map writes\") } alg := t.key.alg hash := alg.hash(key, uintptr(h.hash0)) //1 h.flags ^= hashWriting //给falgs上标记 if h.buckets == nil { h.buckets = newobject(t.bucket) // newarray(t.bucket, 1) }again: bucket := hash &amp; bucketMask(h.B) //2 if h.growing() { growWork(t, h, bucket) } b := (*bmap)(unsafe.Pointer(uintptr(h.buckets) + bucket*uintptr(t.bucketsize))) top := tophash(hash) //取tophash var inserti *uint8 var insertk unsafe.Pointer var val unsafe.Pointerbucketloop: for { for i := uintptr(0); i &lt; bucketCnt; i++ { /* 遍历桶中的8个key */ if b.tophash[i] != top { if isEmpty(b.tophash[i]) &amp;&amp; inserti == nil { //4.找到插入的位置 inserti = &amp;b.tophash[i] insertk = add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) val = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize)) } if b.tophash[i] == emptyRest { break bucketloop } continue } k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if t.indirectkey() { k = *((*unsafe.Pointer)(k)) } if !alg.equal(key, k) { continue } if t.needkeyupdate() { //3.更新 typedmemmove(t.key, k, key) } val = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize)) goto done } ovf := b.overflow(t) if ovf == nil { break } b = ovf } if !h.growing() &amp;&amp; (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) { hashGrow(t, h) goto again // Growing the table invalidates everything, so try again } if inserti == nil { newb := h.newoverflow(t, b) //5 inserti = &amp;newb.tophash[0] insertk = add(unsafe.Pointer(newb), dataOffset) val = add(insertk, bucketCnt*uintptr(t.keysize)) } if t.indirectkey() { kmem := newobject(t.key) *(*unsafe.Pointer)(insertk) = kmem insertk = kmem } if t.indirectvalue() { vmem := newobject(t.elem) *(*unsafe.Pointer)(val) = vmem } typedmemmove(t.key, insertk, key) *inserti = top h.count++done: if h.flags&amp;hashWriting == 0 { throw(\"concurrent map writes\") } h.flags &amp;^= hashWriting if t.indirectvalue() { val = *((*unsafe.Pointer)(val)) } return val} 跟据key值算出哈希值。 取哈希值低位与hmap.B取模确定bucket位置。 取哈希值高位与hmap.B查找该key是否已经存在,如果存在则直接更新值。 如果未找到且剩下的空间为empty,则将新的键存到该位置 如果未找到且遍历完buckets,查看是否有溢出桶,若有则遍历溢出桶；如果没有溢出桶,则申请一个新的溢出桶存放该元素。 map删除过程123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108func mapdelete(t *maptype, h *hmap, key unsafe.Pointer) { if raceenabled &amp;&amp; h != nil { callerpc := getcallerpc() pc := funcPC(mapdelete) racewritepc(unsafe.Pointer(h), callerpc, pc) raceReadObjectPC(t.key, key, callerpc, pc) } if msanenabled &amp;&amp; h != nil { msanread(key, t.key.size) } if h == nil || h.count == 0 { if t.hashMightPanic() { t.key.alg.hash(key, 0) // see issue 23734 } return } if h.flags&amp;hashWriting != 0 { throw(\"concurrent map writes\") } alg := t.key.alg hash := alg.hash(key, uintptr(h.hash0)) // Set hashWriting after calling alg.hash, since alg.hash may panic, // in which case we have not actually done a write (delete). h.flags ^= hashWriting bucket := hash &amp; bucketMask(h.B) if h.growing() { growWork(t, h, bucket) } b := (*bmap)(add(h.buckets, bucket*uintptr(t.bucketsize))) bOrig := b top := tophash(hash)search: for ; b != nil; b = b.overflow(t) { for i := uintptr(0); i &lt; bucketCnt; i++ { if b.tophash[i] != top { if b.tophash[i] == emptyRest { break search } continue } k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) k2 := k if t.indirectkey() { k2 = *((*unsafe.Pointer)(k2)) } if !alg.equal(key, k2) { continue } // Only clear key if there are pointers in it. if t.indirectkey() { *(*unsafe.Pointer)(k) = nil } else if t.key.kind&amp;kindNoPointers == 0 { memclrHasPointers(k, t.key.size) } v := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize)) if t.indirectvalue() { *(*unsafe.Pointer)(v) = nil } else if t.elem.kind&amp;kindNoPointers == 0 { memclrHasPointers(v, t.elem.size) } else { memclrNoHeapPointers(v, t.elem.size) } b.tophash[i] = emptyOne // If the bucket now ends in a bunch of emptyOne states, // change those to emptyRest states. // It would be nice to make this a separate function, but // for loops are not currently inlineable. if i == bucketCnt-1 { if b.overflow(t) != nil &amp;&amp; b.overflow(t).tophash[0] != emptyRest { goto notLast } } else { if b.tophash[i+1] != emptyRest { goto notLast } } for { b.tophash[i] = emptyRest if i == 0 { if b == bOrig { break // beginning of initial bucket, we're done. } // Find previous bucket, continue at its last entry. c := b for b = bOrig; b.overflow(t) != c; b = b.overflow(t) { } i = bucketCnt - 1 } else { i-- } if b.tophash[i] != emptyOne { break } } notLast: h.count-- break search } } if h.flags&amp;hashWriting == 0 { throw(\"concurrent map writes\") } h.flags &amp;^= hashWriting} 哈希表的删除逻辑与写入逻辑非常相似,只是触发哈希的删除需要使用关键字,如果在删除期间遇到了哈希表的扩容,就会对即将操作的桶进行迁移,迁移结束之后会找到桶中的目标元素完成键值对的删除工作。 map扩容原理扩容的前提条件 增量扩容:负载因子 &gt; 6.5时,也即平均每个bucket存储的键值对达到6.5个。 1234// overLoadFactor reports whether count items placed in 1&lt;&lt;B buckets is over loadFactor.func overLoadFactor(count int, B uint8) bool { return count &gt; bucketCnt &amp;&amp; uintptr(count) &gt; loadFactorNum*(bucketShift(B)/loadFactorDen)} 等量扩容:overflow数量 &gt; 2^15时,也即overflow数量超过32768时。 1234567891011121314// tooManyOverflowBuckets reports whether noverflow buckets is too many for a map with 1&lt;&lt;B buckets.// Note that most of these overflow buckets must be in sparse use;// if use was dense, then we'd have already triggered regular map growth.func tooManyOverflowBuckets(noverflow uint16, B uint8) bool { // If the threshold is too low, we do extraneous work. // If the threshold is too high, maps that grow and shrink can hold on to lots of unused memory. // \"too many\" means (approximately) as many overflow buckets as regular buckets. // See incrnoverflow for more details. if B &gt; 15 { B = 15 } // The compiler doesn't see here that B &lt; 16; mask B to generate shorter shift code. return noverflow &gt;= uint16(1)&lt;&lt;(B&amp;15)} 123456789101112131415161718192021222324252627282930313233343536373839func hashGrow(t *maptype, h *hmap) { bigger := uint8(1) if !overLoadFactor(h.count+1, h.B) { /* 判断是2倍空间扩容还是等量空间扩容 */ bigger = 0 h.flags |= sameSizeGrow /* 等量空间扩容,bigger=0 */ } oldbuckets := h.buckets newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil) /* 分配桶空间 */ flags := h.flags &amp;^ (iterator | oldIterator) /* 将buckets和oldbuckets迭代标志置0 */ if h.flags&amp;iterator != 0 { flags |= oldIterator } h.B += bigger /* 增量扩容为h.B+1,等量扩容为h.B */ h.flags = flags h.oldbuckets = oldbuckets h.buckets = newbuckets h.nevacuate = 0 /* 搬迁状态为0表示未进行迁移 */ h.noverflow = 0 /* 当key/value不是指针时,用extramap中的指针存储溢出桶,而不用bmap中的 * overflow。overflow表示hmap结构buckets中的溢出桶,oldoverflow表示hmap中 * oldbuckets中的溢出桶 ,nextoverflow预分配溢出桶空间 。 */ if h.extra != nil &amp;&amp; h.extra.overflow != nil { if h.extra.oldoverflow != nil { throw(\"oldoverflow is not nil\") } h.extra.oldoverflow = h.extra.overflow h.extra.overflow = nil } if nextOverflow != nil { if h.extra == nil { h.extra = new(mapextra) } h.extra.nextOverflow = nextOverflow }} map迁移原理 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110func evacuate(t *maptype, h *hmap, oldbucket uintptr) { b := (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize))) /* oldbucket为旧桶的索引 */ newbit := h.noldbuckets() /* 与原来旧桶分配的容量相等 */ if !evacuated(b) { var xy [2]evacDst /*xy 包含x和y的 (low and high)疏散目的地.*/ x := &amp;xy[0] /* 等量扩容或2倍扩容的前一部分（X,和原来相等） */ x.b = (*bmap)(add(h.buckets, oldbucket*uintptr(t.bucketsize))) x.k = add(unsafe.Pointer(x.b), dataOffset) /* key的地址 */ x.v = add(x.k, bucketCnt*uintptr(t.keysize)) /* value得地址 */ if !h.sameSizeGrow() { //如果不是等量扩容 y := &amp;xy[1] /* 若为2倍扩容,需要后一部分,即增长的空间 */ y.b = (*bmap)(add(h.buckets, (oldbucket+newbit)*uintptr(t.bucketsize))) /* 后一部分桶的索引 */ y.k = add(unsafe.Pointer(y.b), dataOffset) y.v = add(y.k, bucketCnt*uintptr(t.keysize)) } for ; b != nil; b = b.overflow(t) { /* 遍历最后一个bmap及溢出桶 */ k := add(unsafe.Pointer(b), dataOffset) /* key的地址 */ v := add(k, bucketCnt*uintptr(t.keysize)) /* value的地址 */ for i := 0; i &lt; bucketCnt; i, k, v = i+1, add(k, uintptr(t.keysize)), add(v, uintptr(t.valuesize)) { /* 遍历桶中的元素 */ top := b.tophash[i] /* 获取tophash的值 */ if isEmpty(top) { /* 如果tophash为空,标记为已被搬迁状态 */ b.tophash[i] = evacuatedEmpty continue } if top &lt; minTopHash { /* tophash的值为hash+minTopHash */ throw(\"bad map state\") } k2 := k if t.indirectkey() { k2 = *((*unsafe.Pointer)(k2)) } var useY uint8 /* useY用来判断是落在oldbucket还是newbit */ if !h.sameSizeGrow() { /* 如果为2倍扩容,h.B增大1,桶的位置发生变化 */ hash := t.key.alg.hash(k2, uintptr(h.hash0)) if h.flags&amp;iterator != 0 &amp;&amp; !t.reflexivekey() &amp;&amp; !t.key.alg.equal(k2,k2) { useY = top &amp; 1 top = tophash(hash) } else { if hash&amp;newbit != 0 { useY = 1 } } } /* evacuatedY = evacuatedX + 1 */ if evacuatedX+1 != evacuatedY || evacuatedX^1 != evacuatedY { throw(\"bad evacuatedN\") } b.tophash[i] = evacuatedX + useY /* 搬迁为X或者Y状态 */ dst := &amp;xy[useY] /* useY=0表示搬迁到前半部分, 否则到后半部分*/ if dst.i == bucketCnt { /* 当桶中元素数量达到最大8时,需要溢出桶 */ dst.b = h.newoverflow(t, dst.b) dst.i = 0 dst.k = add(unsafe.Pointer(dst.b), dataOffset) dst.v = add(dst.k, bucketCnt*uintptr(t.keysize)) } dst.b.tophash[dst.i&amp;(bucketCnt-1)] = top if t.indirectkey() { *(*unsafe.Pointer)(dst.k) = k2 /* key为指针时,复制指针 */ } else { typedmemmove(t.key, dst.k, k) } if t.indirectvalue() { *(*unsafe.Pointer)(dst.v) = *(*unsafe.Pointer)(v) /* value为指针时,复制指针 */ } else { typedmemmove(t.elem, dst.v, v) } /* 进行下一个元素的搬迁 */ dst.i++ dst.k = add(dst.k, uintptr(t.keysize)) dst.v = add(dst.v, uintptr(t.valuesize)) } } /* 遍历完桶后,如果没有其他goroutine使用该桶,就把该桶清空 */ if h.flags&amp;oldIterator == 0 &amp;&amp; t.bucket.kind&amp;kindNoPointers == 0 { b := add(h.oldbuckets, oldbucket*uintptr(t.bucketsize)) ptr := add(b, dataOffset) n := uintptr(t.bucketsize) - dataOffset memclrHasPointers(ptr, n) } } if oldbucket == h.nevacuate { advanceEvacuationMark(h, t, newbit) } } /* 确定桶的搬迁进度,如果搬迁完成进行后续操作 */ func advanceEvacuationMark(h *hmap, t *maptype, newbit uintptr) { h.nevacuate++ stop := h.nevacuate + 1024 if stop &gt; newbit { stop = newbit } for h.nevacuate != stop &amp;&amp; bucketEvacuated(t, h, h.nevacuate) { /*如果搬迁没有完成将搬迁进度nevacuate加1 */ h.nevacuate++ } if h.nevacuate == newbit { h.oldbuckets = nil /* 搬迁完成,将oldbuckets置nil */ if h.extra != nil { h.extra.oldoverflow = nil /* 溢出桶置为nil */ } h.flags &amp;^= sameSizeGrow /* 等量扩容位置0 */ } }","link":"/2020/02/27/Go/Golang%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/Go%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90(5)-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"title":"(译) Go 1.13中的错误处理","text":"在过去的十年中, Go的errors are values的理念在编码实践中运行得也很良好。 尽管标准库对错误处理的的支持很少（只有errors.New和fmt.Errorf函数可以用来构造仅包含字符串消息的错误）,但是内置的error接口使Go程序员可以添加所需的任何信息。它所需要的只是一个实现Error方法的类型： 123456type QueryError struct { Query string Err error}func (e *QueryError) Error() string { return e.Query + \": \" + e.Err.Error() } 像这样的错误类型无处不在,它们存储的信息变化很大,从时间戳到文件名再到服务器地址。通常,该信息包括另一个较低级别的错误以提供其他上下文信息。 在Go代码中,使用一个包含了另一个错误的错误类型的模式十分普遍,以至于经过广泛讨论后,Go 1.13为其添加了明确的支持。这篇文章描述了标准库提供的支持：errors包中的三个新功能,以及fmt.Errorf中添加的新格式化动词。 在详细描述这些变化之前,让我们先回顾一下在Go语言的早期版本中如何检查和构造错误。 一、Go 1.13版本之前的错误处理检查错误错误是值(errors are values)。程序通过几种方式基于这些值来做出决策。最常见的是通过与nil的比较来确定操作是否失败。 123if err != nil { // 出错了!} 有时我们将错误与已知的哨兵值(sentinel value)进行比较来查看是否发生了特定错误。比如： 12345var ErrNotFound = errors.New(\"not found\")if err == ErrNotFound { // something wasn't found} 错误值可以是满足语言定义的error 接口的任何类型。程序可以使用类型断言(type assertion)或类型开关(type switch)来判断错误值是否可被视为特定的错误类型。 123456789type NotFoundError struct { Name string}func (e *NotFoundError) Error() string { return e.Name + \": not found\" }if e, ok := err.(*NotFoundError); ok { // e.Name wasn't found} 添加信息函数通常在将错误向上传递给调用堆栈时添加额外错误信息,例如对错误发生时所发生情况的简短描述。一种简单的方法是构造一个新错误,并在其中包括上一个错误： 123if err != nil { return fmt.Errorf(\"decompress %v: %v\", name, err)} 使用fmt.Errorf创建的新错误将丢弃原始错误中的所有内容（文本除外）。就像我们在前面所看到的QueryError那样,有时我们可能想要定义一个包含基础错误的新错误类型,并将其保存下来以供代码检查。我们再次来看一下QueryError： 1234type QueryError struct { Query string Err error} 程序可以查看一个*QueryError值的内部以根据潜在的错误进行决策。有时您会看到称为“展开”错误的信息。 123if e, ok := err.(*QueryError); ok &amp;&amp; e.Err == ErrPermission { // query failed because of a permission problem} 标准库中的os.PathError类型就是另外一个在错误中包含另一个错误的示例。 二、Go 1.13版本的错误处理Unwrap方法Go 1.13在errors和fmt标准库包中引入了新功能以简化处理包含其他错误的错误。其中最重要的不是改变,而是一个约定：包含另一个错误的错误可以实现Unwrap方法来返回所包含的底层错误。如果e1.Unwrap()返回了e2,那么我们说e1包装了e2,您可以Unwrap e1来得到e2。 遵循此约定,我们可以为上面的QueryError类型提供一个Unwrap方法来返回其包含的错误： 1func (e *QueryError) Unwrap() error { return e.Err } Unwrap错误的结果本身(底层错误)可能也具有Unwrap方法。我们将这种通过重复unwrap而得到的错误序列为错误链。 使用Is和As检查错误Go 1.13的errors包中包括了两个用于检查错误的新函数：Is和As。 errors.Is函数将错误与值进行比较。 12345// Similar to:// if err == ErrNotFound { … }if errors.Is(err, ErrNotFound) { // something wasn't found} As函数用于测试错误是否为特定类型。 123456// Similar to:// if e, ok := err.(*QueryError); ok { … }var e *QueryErrorif errors.As(err, &amp;e) { // err is a *QueryError, and e is set to the error's value} 在最简单的情况下,errors.Is函数的行为类似于上面对哨兵错误(sentinel error))的比较,而errors.As函数的行为类似于类型断言(type assertion)。但是,在处理包装错误(包含其他错误的错误）时,这些函数会考虑错误链中的所有错误。让我们再次看一下通过展开QueryError以检查潜在错误： 123if e, ok := err.(*QueryError); ok &amp;&amp; e.Err == ErrPermission { // query failed because of a permission problem} 使用errors.Is函数,我们可以这样写： 123if errors.Is(err, ErrPermission) { // err, or some error that it wraps, is a permission problem} errors包还包括一个新Unwrap函数,该函数返回调用错误Unwrap方法的结果,或者当错误没有Unwrap方法时返回nil。通常我们最好使用errors.Is或errors.As,因为这些函数将在单个调用中检查整个错误链。 用%w包装错误如前面所述,我们通常使用fmt.Errorf函数向错误添加其他信息。 123if err != nil { return fmt.Errorf(\"decompress %v: %v\", name, err)} 在Go 1.13中,fmt.Errorf函数支持新的%w动词。当存在该动词时,所返回的错误fmt.Errorf将具有Unwrap方法,该方法返回参数%w对应的错误。%w对应的参数必须是错误(类型)。在所有其他方面,%w与%v等同。 1234if err != nil { // Return an error which unwraps to err. return fmt.Errorf(\"decompress %v: %w\", name, err)} 使用%w创建的包装错误可用于errors.Is和errors.As： 123456err := fmt.Errorf(\"access denied: %w”, ErrPermission) ...if errors.Is(err, ErrPermission){ ... } 是否包装在使用fmt.Errorf或通过实现自定义类型将其他上下文添加到错误时,您需要确定新错误是否应该包装原始错误。这个问题没有统一答案。它取决于创建新错误的上下文。包装错误将会被公开给调用者。如果要避免暴露实现细节,那么请不要包装错误。 举一个例子,假设一个Parse函数从io.Reader读取复杂的数据结构。如果发生错误,我们希望报告发生错误的行号和列号。如果从io.Reader读取时发生错误,我们将包装该错误以供检查底层问题。由于调用者为函数提供了io.Reader,因此有理由公开它产生的错误。 相反,一个对数据库进行多次调用的函数可能不应该将其中调用之一的结果解开的错误返回。如果该函数使用的数据库是实现细节,那么暴露这些错误就是对抽象的违反。例如,如果你的程序包pkg中的函数LookupUser使用了Go的database/sql程序包,则可能会遇到sql.ErrNoRows错误。如果使用fmt.Errorf(“accessing DB: %v”, err)来返回该错误,则调用者无法检视到内部的sql.ErrNoRows。但是,如果函数使用fmt.Errorf(“accessing DB: %w”, err)返回错误,则调用者可以编写下面代码： 12err := pkg.LookupUser(...)if errors.Is(err, sql.ErrNoRows) … 此时,如果您不希望对客户端源码产生影响,该函数也必须始终返回sql.ErrNoRows,即使您切换到其他数据库程序包。换句话说,包装错误会使该错误成为您API的一部分。如果您不想将来将错误作为API的一部分来支持,则不应包装该错误。 重要的是要记住,无论是否包装错误,错误文本都将相同。那些试图理解错误的人将得到相同的信息,无论采用哪种方式; 是否要包装错误的选择是关于是否要给程序提供更多信息,以便他们可以做出更明智的决策,还是保留该信息以保留抽象层。 使用Is和As方法自定义错误测试errors.Is函数检查错误链中的每个错误是否与目标值匹配。默认情况下,如果两者相等,则错误与目标匹配。另外,链中的错误可能会通过实现Is方法来声明它与目标匹配。 例如,下面的错误类型定义是受Upspin error包的启发,它将错误与模板进行了比较,并且仅考虑模板中非零的字段： 1234567891011121314151617type Error struct { Path string User string}func (e *Error) Is(target error) bool { t, ok := target.(*Error) if !ok { return false } return (e.Path == t.Path || t.Path == \"\") &amp;&amp; (e.User == t.User || t.User == \"\")}if errors.Is(err, &amp;Error{User: \"someuser\"}) { // err's User field is \"someuser\".} 同样,errors.As函数将使用链中某个错误的As方法,如果该错误实现了As方法。 错误和包API返回错误的程序包（大多数都会返回错误）应描述程序员可能依赖的那些错误的属性。一个经过精心设计的程序包也将避免返回带有不应依赖的属性的错误。 最简单的规约是用于说明操作成功或失败的属性,分别返回nil或non-nil错误值。在许多情况下,不需要进一步的信息了。 如果我们希望函数返回可识别的错误条件,例如“item not found”,则可能会返回包装哨兵的错误。 123456789101112var ErrNotFound = errors.New(\"not found\")// FetchItem returns the named item.//// If no item with the name exists, FetchItem returns an error// wrapping ErrNotFound.func FetchItem(name string) (*Item, error) { if itemNotFound(name) { return nil, fmt.Errorf(\"%q: %w\", name, ErrNotFound) } // ...} 还有其他现有的提供错误的模式,可以由调用方进行语义检查,例如直接返回哨兵值,特定类型或可以使用谓词函数检查的值。 在所有情况下,都应注意不要向用户公开内部细节。正如我们在上面的“是否要包装”中提到的那样,当您从另一个包中返回错误时,应该将错误转换为不暴露基本错误的形式,除非您愿意将来再返回该特定错误。 12345678f, err := os.Open(filename)if err != nil { // The *os.PathError returned by os.Open is an internal detail. // To avoid exposing it to the caller, repackage it as a new // error with the same text. We use the %v formatting verb, since // %w would permit the caller to unwrap the original *os.PathError. return fmt.Errorf(\"%v\", err)} 如果将函数定义为返回包装某些标记或类型的错误,请不要直接返回基础错误。 123456789101112131415161718192021var ErrPermission = errors.New(\"permission denied\")// DoSomething returns an error wrapping ErrPermission if the user// does not have permission to do something.func DoSomething() { if !userHasPermission() { // If we return ErrPermission directly, callers might come // to depend on the exact error value, writing code like this: // // if err := pkg.DoSomething(); err == pkg.ErrPermission { … } // // This will cause problems if we want to add additional // context to the error in the future. To avoid this, we // return an error wrapping the sentinel so that users must // always unwrap it: // // if err := pkg.DoSomething(); errors.Is(err, pkg.ErrPermission) { ... } return fmt.Errorf(\"%w\", ErrPermission) } // ...} 三、结论尽管我们讨论的更改仅包含三个函数和一个格式化动词(%w),但我们希望它们能大幅改善Go程序中错误处理的方式。我们希望通过包装来提供其他上下文的方式得到Gopher们地普遍使用,从而帮助程序做出更好的决策,并帮助程序员更快地发现错误。 正如Russ Cox在GopherCon 2019主题演讲中所说的那样,在Go2的道路上,我们进行了实验,简化和发布。现在,我们已经发布了这些更改,我们期待接下来的实验。","link":"/2019/11/18/Go/Golang%E8%AF%91%E6%96%87/Go1.13%E4%B8%AD%E7%9A%84%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86/"},{"title":"(译) Go中的垃圾收集：第三部分 - GC步伐","text":"这是三部分系列中的第三篇文章,它将提供对Go中垃圾收集器背后的机制和语义的理解。这篇文章重点介绍GC如何自我调整。 三部分系列的索引：1）Go中的垃圾收集：第一部分 - 语义2）Go中的垃圾收集：第二部分 - GC跟踪3）Go中的垃圾收集：第三部分 - GC步伐 介绍在第二篇文章中,我向你展示了垃圾收集器的行为以及如何使用工具查看收集器对正在运行的应用程序造成的延迟。我带你了解了一个真实的Web应用程序,并向你展示了如何生成GC跟踪和应用程序配置文件。然后,我向你展示了如何解释这些工具的输出,以便你可以找到提高应用程序性能的方法。 该帖子的最终结论与第一篇相同：如果减少堆上的压力,你将减少延迟成本,从而提高应用程序的性能。与垃圾收集器同情的最佳策略是减少每个工作的分配数量或数量。在这篇文章中,我将展示调步算法如何能够识别给定工作负载随时间的最佳速度。 并发示例代码我将使用此链接中的代码。 https://github.com/ardanlabs/gotraining/tree/master/topics/go/profiling/trace 该程序确定在RSS新闻订阅源文档集合中可以找到特定主题的频率。跟踪程序包含不同版本的查找算法,以测试不同的并发模式。我将集中在freq,freqConcurrent和freqNumCPU的算法版本。 注意：我在Macbook Pro上运行代码,使用带有12个硬件线程的Intel i9处理器,使用go1.12.7。你将在不同的体系结构,操作系统和Go版本上看到不同的结果。该职位的核心成果应保持不变。 我先从freq版本开始。它表示程序的非并发顺序版本。这将为后续的并发版本提供基线。 清单1 123456789101112131415161718192021222324252627282930313233343536373801 func freq(topic string, docs []string) int {02 var found int0304 for _, doc := range docs {05 file := fmt.Sprintf(\"%s.xml\", doc[:8])06 f, err := os.OpenFile(file, os.O_RDONLY, 0)07 if err != nil {08 log.Printf(\"Opening Document [%s] : ERROR : %v\", doc, err)09 return 010 }11 defer f.Close()1213 data, err := ioutil.ReadAll(f)14 if err != nil {15 log.Printf(\"Reading Document [%s] : ERROR : %v\", doc, err)16 return 017 }1819 var d document20 if err := xml.Unmarshal(data, &amp;d); err != nil {21 log.Printf(\"Decoding Document [%s] : ERROR : %v\", doc, err)22 return 023 }2425 for _, item := range d.Channel.Items {26 if strings.Contains(item.Title, topic) {27 found++28 continue29 }3031 if strings.Contains(item.Description, topic) {32 found++33 }34 }35 }3637 return found38 } 清单1显示了该freq函数。此顺序版本的范围超过文件名集合,并执行四个操作：打开,读取,解码和搜索。它为每个文件执行此操作,一次一个。 当我freq在我的机器上运行此版本时,我得到以下结果。 清单2 123$ time ./trace2019/07/02 13:40:49 Searching 4000 files, found president 28000 times../trace 2.54s user 0.12s system 105% cpu 2.512 total 你可以通过输出时间看到,程序需要大约2.5秒来处理4000个文件。很高兴看到在垃圾收集中花费了多少时间。你可以通过查看程序的痕迹来做到这一点。由于这是一个启动和完成的程序,因此你可以使用跟踪包生成跟踪。 清单3 1234503 import \"runtime/trace\"0405 func main() {06 trace.Start(os.Stdout)07 defer trace.Stop() 清单3显示了从程序生成跟踪所需的代码。trace从runtime标准库中的文件夹导入包后,调用trace.Start和trace.Stop。将跟踪输出os.Stdout定向为简化代码。 使用此代码,现在你可以重新生成并再次运行该程序。不要忘记重定向stdout到文件。 清单4 1234$ go build$ time ./trace &gt; t.outSearching 4000 files, found president 28000 times../trace &gt; t.out 2.67s user 0.13s system 106% cpu 2.626 total 运行时添加了100多毫秒,但这是预期的。跟踪捕获每个函数调用,进出,直到微秒。重要的是,现在有一个名为t.out包含跟踪数据的文件。 要查看跟踪,需要通过跟踪工具运行跟踪数据。 清单5 1$ go tool trace t.out 运行该命令会使用以下屏幕启动Chrome浏览器。 注意：跟踪工具使用Chrome浏览器内置的工具。此工具仅适用于Chrome。 图1 图1显示了跟踪工具启动时显示的9个链接。现在重要的链接是第一个链接View trace。选择该链接后,你将看到类似于以下内容的内容。 图2 图2显示了在我的机器上运行程序的完整跟踪窗口。对于这篇文章,我将重点介绍与垃圾收集器相关的部分。这是第二部分标记Heap,第四部分标记GC。 图3 图3更详细地展示了跟踪的前200毫秒。将注意力集中在Heap（绿色和橙色区域）和GC（底部的蓝线）上。该Heap部分向你展示了两件事。橙色区域是堆上任何给定微秒的当前正在使用的空间。绿色是堆上将触发下一个集合的正在使用的空间量。这就是为什么每当橙色区域到达绿色区域的顶部时,就会发生垃圾收集。蓝线代表垃圾收集。 在此版本的程序中,堆上使用的内存在整个程序运行时保持在~4mcg。要查看有关发生的所有单个垃圾收集的统计信息,请使用选择工具并在所有蓝线周围绘制一个框。 图4 图4显示了如何使用箭头工具在蓝线周围绘制蓝​​框。你想在每一行画出框。框内的数字表示从图表中选择的项目消耗的时间量。在这种情况下,选择接近316毫秒（ms,μs,ns）来生成此图像。选择所有蓝线后,将提供以下统计数据。 图5 图5显示图中的所有蓝线都在15.911毫秒标记到2.596秒标记之间。共有232个垃圾收集,代表64.524毫秒的时间,平均收集时间为287.121微秒。知道程序运行需要2.626秒,这意味着垃圾收集只占总运行时间的2％。基本上垃圾收集器是运行该程序的一个微不足道的成本。 有了可以使用的基线,可以使用并发算法执行相同的工作,以期加快程序的速度。 清单6 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505101 func freqConcurrent(topic string, docs []string) int {02 var found int320304 g := len(docs)05 var wg sync.WaitGroup06 wg.Add(g)0708 for _, doc := range docs {09 go func(doc string) {10 var lFound int3211 defer func() {12 atomic.AddInt32(&amp;found, lFound)13 wg.Done()14 }()1516 file := fmt.Sprintf(\"%s.xml\", doc[:8])17 f, err := os.OpenFile(file, os.O_RDONLY, 0)18 if err != nil {19 log.Printf(\"Opening Document [%s] : ERROR : %v\", doc, err)20 return21 }22 defer f.Close()2324 data, err := ioutil.ReadAll(f)25 if err != nil {26 log.Printf(\"Reading Document [%s] : ERROR : %v\", doc, err)27 return28 }2930 var d document31 if err := xml.Unmarshal(data, &amp;d); err != nil {32 log.Printf(\"Decoding Document [%s] : ERROR : %v\", doc, err)33 return34 }3536 for _, item := range d.Channel.Items {37 if strings.Contains(item.Title, topic) {38 lFound++39 continue40 }4142 if strings.Contains(item.Description, topic) {43 lFound++44 }45 }46 }(doc)47 }4849 wg.Wait()50 return int(found)51 } 清单6显示了一个可能的并发版本freq。此版本的核心设计模式是使用扇出模式。对于docs集合中列出的每个文件,都会创建一个Goroutine来处理该文件。如果要处理4000个文档,则使用4000个Goroutine。这种算法的优点是它是利用并发性的最简单方法。每个Goroutine处理1个且只有1个文件。等待处理每个文档的编排可以使用a来执行WaitGroup,并且原子指令可以使计数器保持同步。 该算法的缺点在于它不能很好地适应文档或核心的数量。所有的Goroutine都会有时间在程序开始时很早就运行,这意味着很快就会消耗大量的内存。found在第12行添加变量也存在缓存一致性问题。由于每个核心共享该变量的相同缓存行,这将导致内存抖动。随着文件或核心数量的增加,这会变得更糟。 使用此代码,现在你可以重新生成并再次运行该程序。 清单7 1234$ go build$ time ./trace &gt; t.outSearching 4000 files, found president 28000 times../trace &gt; t.out 6.49s user 2.46s system 941% cpu 0.951 total 你可以通过清单7中的输出看到,程序现在需要951毫秒来处理相同的4000个文件。这是性能提升约64％。看看跟踪。 图6 图6显示了此版本程序正在使用的计算机上的CPU容量。图表的开头有很多密度。这是因为当所有Goroutine都被创建时,它们会运行并开始尝试在堆中分配内存。一旦分配了前4兆内存,这很快就会启动GC。在此GC期间,每个Goroutine都有时间运行,并且当它们在堆上请求内存时,大多数都会进入等待状态。到GC完成时,至少有9个Goroutine继续运行并将堆增加到~26 meg。 图7 图7显示了第一个GC的大部分时间内大量的Goroutine处于Runnable和Running状态以及如何快速重新启动。请注意,堆配置文件看起来不规则,并且集合不像以前那样处于任何常规节奏上。如果仔细观察,第二个GC几乎会在第一个GC后立即开始。 如果你选择此图表中的所有集合,你将看到以下内容。 图8 图8显示图中的所有蓝线都在4.828毫秒标记到906.939毫秒标记之间。共有23个垃圾收集,代表284.447毫秒的时间,平均收集时间为12.367毫秒。知道该程序运行需要951毫秒,这意味着垃圾收集占总运行时间的约34％。 这与顺序版本在性能和GC时间方面存在显着差异。但是,按照它的方式并行运行更多的Goroutine,可以让工作完成~64％的速度。成本需要更多的资源在机器上。不幸的是,在堆上一次正在使用大约200兆的内存。 使用并发基线,下一个并发算法会尝试使用资源更高效。 清单8 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606101 func freqNumCPU(topic string, docs []string) int {02 var found int320304 g := runtime.NumCPU()05 var wg sync.WaitGroup06 wg.Add(g)0708 ch := make(chan string, g)0910 for i := 0; i &lt; g; i++ {11 go func() {12 var lFound int3213 defer func() {14 atomic.AddInt32(&amp;found, lFound)15 wg.Done()16 }()1718 for doc := range ch {19 file := fmt.Sprintf(\"%s.xml\", doc[:8])20 f, err := os.OpenFile(file, os.O_RDONLY, 0)21 if err != nil {22 log.Printf(\"Opening Document [%s] : ERROR : %v\", doc, err)23 return24 }2526 data, err := ioutil.ReadAll(f)27 if err != nil {28 f.Close()29 log.Printf(\"Reading Document [%s] : ERROR : %v\", doc, err)23 return24 }25 f.Close()2627 var d document28 if err := xml.Unmarshal(data, &amp;d); err != nil {29 log.Printf(\"Decoding Document [%s] : ERROR : %v\", doc, err)30 return31 }3233 for _, item := range d.Channel.Items {34 if strings.Contains(item.Title, topic) {35 lFound++36 continue37 }3839 if strings.Contains(item.Description, topic) {40 lFound++41 }42 }43 }44 }()45 }4647 for _, doc := range docs {48 ch &lt;- doc49 }50 close(ch)5152 wg.Wait()53 return int(found)54 } 清单8显示了freqNumCPU该程序的版本。此版本的核心设计模式是使用池模式。基于处理所有文件的逻辑处理器数量的Goroutine池。如果有12个逻辑处理器可供使用,则使用12个Goroutine。该算法的优点在于它始终保持程序的资源使用一致。由于使用了固定数量的Goroutine,因此只需要在任何给定时间需要12个Goroutine的存储器。这也解决了缓存一致性问题与内存抖动。这是因为对第14行的原子指令的调用只需要发生很小的固定次数。 该算法的缺点是更复杂。它增加了一个通道的使用来为Goroutines池提供所有工作。在使用任何时间池时,识别池的“正确”数量的Goroutine是复杂的。作为一般规则,我为每个逻辑处理器启用池1一个Goroutine。然后执行负载测试或使用生产指标,可以计算池的最终值。 使用此代码,现在你可以重新生成并再次运行该程序。 清单9 1234$ go build$ time ./trace &gt; t.outSearching 4000 files, found president 28000 times../trace &gt; t.out 6.22s user 0.64s system 909% cpu 0.754 total 你可以通过清单9中的输出看到,该程序现在需要754毫秒来处理相同的4000个文件。该程序的速度提高约200毫秒,这对于这个小负载来说非常重要。看看跟踪。 图9 图9显示了此版本程序如何使用我机器上的所有CPU容量。如果你密切关注,那么该计划将再次具有一致的干扰。与顺序版非常相似。 图10 图10显示了如何仔细查看程序前20毫秒的核心指标。这些集合肯定比顺序版本更长,但有12个Goroutines正在运行。堆上使用的内存在整个程序运行时保持在~4mcg。同样,与程序的顺序版本相同。 如果你选择此图表中的所有集合,你将看到以下内容。 图11 图11显示图中的所有蓝线都在3.055毫秒标记到719.928毫秒标记之间。共有467个垃圾收集,代表177.709毫秒的时间,平均收集时间为380.535微秒。知道该程序运行需要754毫秒,这意味着垃圾收集占总运行时间的约25％。比其他并发版本提高9％。 此版本的并发算法似乎可以使用更多文件和内核进行更好的扩展。我认为复杂性成本是值得的。可以通过将列表切换成每个Goroutine的工作桶来替换该通道。这肯定会增加更多的复杂性,尽管它可以减少通道产生的一些延迟成本。在更多文件和核心上,这可能是重要的,但需要测量复杂性成本。这是你可以自己尝试的东西。 结论我喜欢比较算法的三个版本是GC如何处理每种情况。处理文件所需的内存总量不会随任何版本而变化。程序如何分配有什么变化。 当只有一个Goroutine时,只需要一个4兆的基础堆。当程序立即将所有工作都放在运行时时,GC采用了让堆增长的方法,减少了集合的数量,但运行了更长的集合。当程序控制在任何给定时间处理的文件数时,GC采取了再次保持堆小的方法,增加了集合的数量但运行较小的集合。GC采用的每种方法基本上允许程序运行,GC可能对程序产生最小的影响。 12345| Algorithm | Program | GC Time | % Of GC | # of GC’s | Avg GC | Max Heap ||------------|---------|----------|---------|-----------|----------|----------|| freq | 2626 ms | 64.5 ms | ~2% | 232 | 278 μs | 4 meg || concurrent | 951 ms | 284.4 ms | ~34% | 23 | 12.3 ms | 200 meg || numCPU | 754 ms | 177.7 ms | ~25% | 467 | 380.5 μs | 4 meg | 该freqNumCPU版本还有其他功能,比如更好地处理缓存一致性,这是有帮助的。但是,每个程序的GC时间总量的差异非常接近,约为284.4毫秒vs 177.7毫秒。有些日子在我的机器上运行这个程序,这些数字更接近。使用版本1.13.beta1运行一些实验,我看到两个算法在相同的时间运行。潜在地暗示它们可能会有一些改进,使GC能够更好地预测如何运行。 所有这些让我有信心在运行时抛出大量工作。这是一个使用50k Goroutines的Web服务,它本质上是一个类似于第一个并发算法的扇出模式。GC将研究工作量并找到服务的最佳速度以避开它。至少对我来说,不必考虑任何这个是值得入场的代价。","link":"/2019/08/08/Go/Golang%E8%AF%91%E6%96%87/Go%E4%B8%AD%E7%9A%84%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%EF%BC%9A%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86-GC%E6%AD%A5%E4%BC%90/"},{"title":"Go源码分析(4) - expvar","text":"今天是要分析的是一个封装好的关于 int,string,float, map 等基本类型原子操作包,还有一些公共发布变量。 Int1234567891011121314151617181920// Int is a 64-bit integer variable that satisfies the Var interface.type Int struct { i int64}func (v *Int) Value() int64 { return atomic.LoadInt64(&amp;v.i)}func (v *Int) String() string { return strconv.FormatInt(atomic.LoadInt64(&amp;v.i), 10)}func (v *Int) Add(delta int64) { atomic.AddInt64(&amp;v.i, delta)}func (v *Int) Set(value int64) { atomic.StoreInt64(&amp;v.i, value)} 以int64作为基本类型,然后使用atomic包下等原子操作。 Float12345678910111213141516171819202122232425262728293031// Float is a 64-bit float variable that satisfies the Var interface.type Float struct { f uint64}func (v *Float) Value() float64 { return math.Float64frombits(atomic.LoadUint64(&amp;v.f))}func (v *Float) String() string { return strconv.FormatFloat( math.Float64frombits(atomic.LoadUint64(&amp;v.f)), 'g', -1, 64)}// Add adds delta to v.func (v *Float) Add(delta float64) { for { cur := atomic.LoadUint64(&amp;v.f) curVal := math.Float64frombits(cur) nxtVal := curVal + delta nxt := math.Float64bits(nxtVal) if atomic.CompareAndSwapUint64(&amp;v.f, cur, nxt) { return } }}// Set sets v to value.func (v *Float) Set(value float64) { atomic.StoreUint64(&amp;v.f, math.Float64bits(value))} 以uint64作为基本类型,来实现float类型等原子操作。 Add(delta float64)使用cas算法不断拿到最新值,重复进行cas设置,直到成功为止。 12345678910// Float64bits returns the IEEE 754 binary representation of f,// with the sign bit of f and the result in the same bit position,// and Float64bits(Float64frombits(x)) == x.func Float64bits(f float64) uint64 { return *(*uint64)(unsafe.Pointer(&amp;f)) }// Float64frombits returns the floating-point number corresponding// to the IEEE 754 binary representation b, with the sign bit of b// and the result in the same bit position.// Float64frombits(Float64bits(x)) == x.func Float64frombits(b uint64) float64 { return *(*float64)(unsafe.Pointer(&amp;b)) } 在其中使用到了func Float64bits(f float64) uint64将float类型转换为uint64类型进行存储,使用Float64frombits(b uint64) float64将uint64类型转换为float类型。 12345// LoadUint64 atomically loads *addr.func LoadUint64(addr *uint64) (val uint64)// StoreUint64 atomically stores val into *addr.func StoreUint64(addr *uint64, val uint64) 转换为uint64类型,使用atomic包下到存储和去出uint64类型。 Map1234567891011121314// Var is an abstract type for all exported variables.type Var interface { // String returns a valid JSON value for the variable. // Types with String methods that do not return valid JSON // (such as time.Time) must not be used as a Var. String() string}// Map is a string-to-Var map variable that satisfies the Var interface.type Map struct { m sync.Map // map[string]Var keysMu sync.RWMutex keys []string // sorted} 从定义上很清楚的知道Var是一个抽象接口,String()方法返回的是一个json字符串Map类型是一个string类型作为key, 实现了Var接口类型的值作为value的键值对,结构体如下： 12345// KeyValue represents a single entry in a Map.type KeyValue struct { Key string Value Var} Map本身也是一个实现了Var接口对类型,其,String()方法会返回Map内的全部键值对作为json字符串 1234567891011121314func (v *Map) String() string { var b strings.Builder fmt.Fprintf(&amp;b, \"{\") first := true v.Do(func(kv KeyValue) { if !first { fmt.Fprintf(&amp;b, \", \") } fmt.Fprintf(&amp;b, \"%q: %v\", kv.Key, kv.Value) first = false }) fmt.Fprintf(&amp;b, \"}\") return b.String()} 可以看到其中调用Map本身的Do()方法,首先要对整个方法加读锁,这个Do()方法里面有一个循环遍历map的所有的键,然后通过key取出value,包装成KeyValue结构体,然后被传入f func(KeyValue)调用。 1234567891011// Do calls f for each entry in the map.// The map is locked during the iteration,// but existing entries may be concurrently updated.func (v *Map) Do(f func(KeyValue)) { v.keysMu.RLock() defer v.keysMu.RUnlock() for _, k := range v.keys { i, _ := v.m.Load(k) f(KeyValue{k, i.(Var)}) }} 接下来我看看添加key的方法 12345678910111213// addKey updates the sorted list of keys in v.keys.func (v *Map) addKey(key string) { v.keysMu.Lock() defer v.keysMu.Unlock() // Using insertion sort to place key into the already-sorted v.keys. if i := sort.SearchStrings(v.keys, key); i &gt;= len(v.keys) { v.keys = append(v.keys, key) } else if v.keys[i] != key { v.keys = append(v.keys, \"\") copy(v.keys[i+1:], v.keys[i:]) v.keys[i] = key }} 首先加了一个读锁,使用插入排序将键放入已排序的v.keys中。通过key在keys中找到要插入的合适的位置,然后将keys的长度加1,将i - n-1位置的值移动到i+1 - n上,然后将keys[i]设置为key。 12345678910111213141516171819func (v *Map) Get(key string) Var { i, _ := v.m.Load(key) av, _ := i.(Var) return av}func (v *Map) Set(key string, av Var) { // Before we store the value, check to see whether the key is new. Try a Load // before LoadOrStore: LoadOrStore causes the key interface to escape even on // the Load path. if _, ok := v.m.Load(key); !ok { if _, dup := v.m.LoadOrStore(key, av); !dup { v.addKey(key) return } } v.m.Store(key, av)} 这两个方法很简单,一个是取值,通过sync.map的Load方法,一个是设置值,但是这里除了用sync.map的LoadOrStore方法,还需要将key加入到keys中。 12345678910111213141516171819202122232425262728293031323334// Add adds delta to the *Int value stored under the given map key.func (v *Map) Add(key string, delta int64) { i, ok := v.m.Load(key) if !ok { var dup bool i, dup = v.m.LoadOrStore(key, new(Int)) if !dup { v.addKey(key) } } // Add to Int; ignore otherwise. if iv, ok := i.(*Int); ok { iv.Add(delta) }}// AddFloat adds delta to the *Float value stored under the given map key.func (v *Map) AddFloat(key string, delta float64) { i, ok := v.m.Load(key) if !ok { var dup bool i, dup = v.m.LoadOrStore(key, new(Float)) if !dup { v.addKey(key) } } // Add to Float; ignore otherwise. if iv, ok := i.(*Float); ok { iv.Add(delta) }} 两个都是添加的方法,一个是value为Int的方法,一个是value为Float的方法,先找到这个是否有这个key,如果没有就创建这个key,设置value为一个默认值,然后将累加值再后面进行相加（如果没有这个值的话,默认值就是0）。 12345678910// Deletes the given key from the map.func (v *Map) Delete(key string) { v.keysMu.Lock() defer v.keysMu.Unlock() i := sort.SearchStrings(v.keys, key) if i &lt; len(v.keys) &amp;&amp; key == v.keys[i] { v.keys = append(v.keys[:i], v.keys[i+1:]...) v.m.Delete(key) }} 删除这个key,首先也是用过插入排序的方法吗,该值在目标索引的位置,然后通过切片的方法,重新拼装一个keys,然后再从sync.map中删除这个keyvalue String123456789101112131415161718192021// String is a string variable, and satisfies the Var interface.type String struct { s atomic.Value // string}func (v *String) Value() string { p, _ := v.s.Load().(string) return p}// String implements the Var interface. To get the unquoted string// use Value.func (v *String) String() string { s := v.Value() b, _ := json.Marshal(s) return string(b)}func (v *String) Set(value string) { v.s.Store(value)} 这个String结构体也很简单,同样也是实现了Var接口,每一个操作都是原子操作 Func123456789101112// Func implements Var by calling the function// and formatting the returned value using JSON.type Func func() interface{}func (f Func) Value() interface{} { return f()}func (f Func) String() string { v, _ := json.Marshal(f()) return string(v)} Func通过调用函数并使用JSON格式化返回值来实现Var。类型Func Func（）接口{} 使用方法如下: 12345678910111213141516func TestFunc(t *testing.T) { RemoveAll() var x interface{} = []string{\"a\", \"b\"} f := Func(func() interface{} { return x }) if s, exp := f.String(),`[\"a\",\"b\"]`; s != exp { t.Errorf(`f.String() = %q, want %q`, s, exp) } if v := f.Value(); !reflect.DeepEqual(v, x) { t.Errorf(`f.Value() = %q, want %q`, v, x) } x = 17 if s, exp := f.String(),`17`; s != exp { t.Errorf(`f.String() = %q, want %q`, s, exp) }} All published variables下面是所有所有已发布的变量。 123456789101112131415161718192021222324252627// All published variables.var ( vars sync.Map // map[string]Var varKeysMu sync.RWMutex varKeys []string // sorted)// Publish declares a named exported variable. This should be called from a// package's init function when it creates its Vars. If the name is already// registered then this will log.Panic.func Publish(name string, v Var) { if _, dup := vars.LoadOrStore(name, v); dup { log.Panicln(\"Reuse of exported var name:\", name) } varKeysMu.Lock() defer varKeysMu.Unlock() varKeys = append(varKeys, name) sort.Strings(varKeys)}// Get retrieves a named exported variable. It returns nil if the name has// not been registered.func Get(name string) Var { i, _ := vars.Load(name) v, _ := i.(Var) return v} 这一部分代码的作用就是一些公共遍历被存储的地方,vars是一个存储keyvalue的map,varKeysMu则是一个读写锁,varKeys则是一个keys的集合,这个和Map的数据类型很像。 Publish(name string, v Var) Publish声明一个命名的导出变量。当包创建变量时,应该从包的init函数调用它。如果名称已经注册,则这将导致log.Panic。 Get(name string) VarGet检索命名的导出变量。如果名称尚未注册,则返回nil。 下面是创建新导出变量的工具函数。 12345678910111213141516171819202122232425// Convenience functions for creating new exported variables.func NewInt(name string) *Int { v := new(Int) Publish(name, v) return v}func NewFloat(name string) *Float { v := new(Float) Publish(name, v) return v}func NewMap(name string) *Map { v := new(Map).Init() Publish(name, v) return v}func NewString(name string) *String { v := new(String) Publish(name, v) return v} Do(f func(KeyValue))方法为每个导出的变量调用f。全局变量映射在迭代期间被锁定,但是现有的条目可以同时更新。 1234567891011// Do calls f for each exported variable.// The global variable map is locked during the iteration,// but existing entries may be concurrently updated.func Do(f func(KeyValue)) { varKeysMu.RLock() defer varKeysMu.RUnlock() for _, k := range varKeys { val, _ := vars.Load(k) f(KeyValue{k, val.(Var)}) }} expvarHandler(w http.ResponseWriter, r *http.Request),通过http服务器,查看当前所有的公共发布变量,同样保存了机器的命令行启动参数以及内存状态 123456789101112131415161718192021222324252627282930313233343536func expvarHandler(w http.ResponseWriter, r *http.Request) { w.Header().Set(\"Content-Type\", \"application/json; charset=utf-8\") fmt.Fprintf(w, \"{\\n\") first := true Do(func(kv KeyValue) { if !first { fmt.Fprintf(w, \",\\n\") } first = false fmt.Fprintf(w, \"%q: %s\", kv.Key, kv.Value) }) fmt.Fprintf(w, \"\\n}\\n\")}// Handler returns the expvar HTTP Handler.//// This is only needed to install the handler in a non-standard location.func Handler() http.Handler { return http.HandlerFunc(expvarHandler)}func cmdline() interface{} { return os.Args}func memstats() interface{} { stats := new(runtime.MemStats) runtime.ReadMemStats(stats) return *stats}func init() { http.HandleFunc(\"/debug/vars\", expvarHandler) Publish(\"cmdline\", Func(cmdline)) Publish(\"memstats\", Func(memstats))} init()会初始化的将公共变量发布到http服务器,如果服务器开启的话就可以访问到这些信息 。 总结个人认为expvar是一个很有用的工具包,可以替代繁琐的atomic包下的内容,同时map也是,并且String（）方法返回的json字符串也是很有用的。","link":"/2019/11/26/Go/Golang%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/Go%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90(4)-expvar/"},{"title":"(译) Go中的调度：第III部分 - 并发","text":"这是三部分系列中的第三篇文章,它将提供对Go中调度程序背后的机制和语义的理解。这篇文章重点关注并发性。 Go中的调度：第I部分 - OS调度程序 Go中的调度：第II部分 - Go Scheduler Go中的调度：第III部分 - 并发 介绍当我解决问题时,特别是如果这是一个新问题,我最初并不会考虑并发是否适合。我首先寻找顺序解决方案并确保它正常工作。然后在可读性和技术评论之后,我将开始提出并发性是否合理和实用的问题。有时很明显,并发性是一个很好的选择,有时则不太清楚。 在本系列的第一部分中,我解释了操作系统调度程序的机制和语义,如果你计划编写多线程代码,我认为这很重要。在第二部分中,我解释了Go调度程序的语义,我认为这对于理解如何在Go中编写并发代码非常重要。在这篇文章中,我将开始将操作系统和Go调度程序的机制和语义结合在一起,以便更深入地了解并发性和不兼容性。 这篇文章的目标是： 提供有关必须考虑的语义的指导,以确定工作负载是否适合使用并发。 向你展示不同类型的工作负载如何改变语义,从而改变你想要做出的工程决策。 什么是并发并发意味着“乱序”执行。获取一组指令,否则这些指令将按顺序执行,并找到一种无序执行它们的方法,并仍然产生相同的结果。对于你面前的问题,必须明显的是,乱序执行会增加价值。当我说价值时,我的意思是为复杂性成本增加足够的性能增益。根据你的问题,可能无法执行乱序执行甚至有意义。 图1：并发与并行 在图1中,你可以看到两个逻辑处理器（P）的图表,每个处理器的独立OS线程（M）连接到计算机上的独立硬件线程（Core）。你可以看到两个Goroutines（G1和G2）并行执行,同时在各自的操作系统上执行它们的指令。在每个逻辑处理器中,三个Goroutines轮流共享各自的OS线程。所有这些Goroutines同时运行,没有特定顺序执行他们的指令并在OS线程上共享时间。 这就是摩擦,有时利用没有并行性的并发性实际上可以减慢吞吐量。有趣的是,有时利用并发性和并行性并不会给你带来比你认为可以实现的更大的性能提升。 工作负载你怎么知道什么时候可能无序执行或有意义？了解问题所处理的工作负载类型是一个很好的起点。在考虑并发时,有两种类型的工作负载是很重要的。 CPU绑定：这是一个永远不会产生Goroutines自然进出等待状态的工作负载。这是不断进行计算的工作。计算Pi到第N位的线程将是CPU绑定的。 IO绑定：这是一个导致Goroutines自然进入等待状态的工作负载。这项工作包括请求通过网络访问资源,或将系统调用进入操作系统,或等待事件发生。需要读取文件的Goroutine将是IO绑定。我会包含同步事件（互斥,原子）,导致Goroutine等待此类别的一部分。 使用CPU绑定工作负载,你需要并行来利用并发性。处理多个Goroutines的单个操作系统效率不高,因为Goroutines作为其工作负载的一部分不会进入和退出等待状态。拥有更多的Goroutines而不是操作系统/硬件线程可以减慢工作负载执行速度,因为在操作系统线程上移动和关闭Goroutines的延迟成本（花费的时间）。上下文切换正在为你的工作负载创建“Stop The World”事件,因为在切换期间你的工作负载都没有被执行。 使用IO绑定工作负载,你不需要并行来使用并发。单个操作系统线程可以高效地处理多个Goroutines,因为Goroutines作为其工作负载的一部分自然地进出等待状态。拥有比操作系统/硬件线程更多的Goroutines可以加快工作负载执行速度,因为在操作系统线程上移动和移除Goroutines的延迟成本并不会产生“停止世界”事件。你的工作负载自然停止,这允许不同的Goroutine有效地利用相同的操作系统线程,而不是让操作系统线程闲置。 你如何知道每个线程有多少Goroutines提供最佳吞吐量？很少有Goroutines,你有更多的空闲时间。Goroutines太多,你有更多的上下文切换延迟时间。这是你要考虑的事情,但超出了这个特定职位的范围。 现在,重要的是要检查一些代码以巩固你识别工作负载何时可以利用并发性的能力,何时不能并且是否需要并行性。 添加数字我们不需要复杂的代码来可视化和理解这些语义。查看以下命名的函数,该函数add汇总整数集合。 清单1https://play.golang.org/p/r9LdqUsEzEz 123456736 func add(numbers []int) int {37 var v int38 for _, n := range numbers {39 v += n40 }41 return v42 } 在第36行的清单1中,add声明了一个名为的函数,它接受一个整数集合并返回集合的总和。它从第37行开始,v变量声明包含总和。然后在第38行,函数线性地遍历集合,并且每个数字被添加到第39行的当前总和。最后在第41行,函数将最终的总和返回给调用者。 问题：该add功能是一个适合乱序执行的工作负载吗？我相信答案是肯定的。整数集合可以分解为较小的列表,并且可以同时处理这些列表。一旦将所有较小的列表相加,就可以将这组和被加在一起以产生与顺序版本相同的答案。 但是,还有另一个问题浮现在脑海中。应该独立创建和处理多少个较小的列表以获得最佳吞吐量？要回答此问题,你必须知道add正在执行的工作负载类型。该add函数正在执行CPU绑定工作负载,因为该算法正在执行纯数学,并且它不会导致goroutine进入自然等待状态。这意味着每个操作系统线程使用一个Goroutine就可以获得良好的吞吐量。 下面的清单2是我的并发版本add。 注意：编写并发版本的add时,可以采用多种方法和选项。暂时不要挂断我的特定实现。如果你有一个更易读的版本,表现相同或更好,我希望你能分享它。 清单2https://play.golang.org/p/r9LdqUsEzEz 1234567891011121314151617181920212223242526272829303144 func addConcurrent(goroutines int, numbers []int) int {45 var v int6446 totalNumbers := len(numbers)47 lastGoroutine := goroutines - 148 stride := totalNumbers / goroutines4950 var wg sync.WaitGroup51 wg.Add(goroutines)5253 for g := 0; g &lt; goroutines; g++ {54 go func(g int) {55 start := g * stride56 end := start + stride57 if g == lastGoroutine {58 end = totalNumbers59 }6061 var lv int62 for _, n := range numbers[start:end] {63 lv += n64 }6566 atomic.AddInt64(&amp;v, int64(lv))67 wg.Done()68 }(g)69 }7071 wg.Wait()7273 return int(v)74 } 在清单2中,显示了addConcurrent函数,它是函数的并发版本add。并发版本使用26行代码而不是非并发版本的5行代码。有很多代码,所以我只强调要理解的重要内容。 第48行：每个Goroutine都会得到他们自己独特但更小的数字列表。列表的大小是通过获取集合的大小并将其除以Goroutines的数量来计算的。 第53行：创建Goroutines池以执行添加工作。 第57-59行：最后一个Goroutine将添加剩余的数字列表,这些数字可能比其他Goroutines更大。 第66行：将较小的列表的总和加在一起作为最终总和。 并发版本肯定比顺序版本更复杂但复杂性值得吗？回答这个问题的最好方法是创建一个基准。对于这些基准测试,我使用了1000万个数字的集合,关闭了垃圾收集器。有一个使用该add函数的顺序版本和使用该函数的并发版本addConcurrent。 清单3 1234567891011func BenchmarkSequential(b *testing.B) { for i := 0; i &lt; b.N; i++ { add(numbers) }}func BenchmarkConcurrent(b *testing.B) { for i := 0; i &lt; b.N; i++ { addConcurrent(runtime.NumCPU(), numbers) }} 清单3显示了基准函数。以下是所有Goroutines只有一个操作系统线程可用的结果。顺序版本使用1个Goroutine,并发版本runtime.NumCPU在我的机器上使用或8个Goroutines。在这种情况下,并发版本正在利用没有并行性的并发性。 清单4 12345678910111210 Million Numbers using 8 goroutines with 1 core2.9 GHz Intel 4 Core i7Concurrency WITHOUT Parallelism-----------------------------------------------------------------------------$ GOGC=off go test -cpu 1 -run none -bench . -benchtime 3sgoos: darwingoarch: amd64pkg: github.com/ardanlabs/gotraining/topics/go/testing/benchmarks/cpu-boundBenchmarkSequential 1000 5720764 ns/op : ~10% FasterBenchmarkConcurrent 1000 6387344 ns/opBenchmarkSequentialAgain 1000 5614666 ns/op : ~13% FasterBenchmarkConcurrentAgain 1000 6482612 ns/op 注意：在本地计算机上运行基准测试很复杂。有许多因素可能导致你的基准测试不准确。确保你的机器尽可能空闲并运行基准测试几次。你希望确保在结果中看到一致性。通过测试工具运行两次基准测试,可以为此基准测试提供最一致的结果。 清单4中的基准测试表明,当只有一个操作系统线程可供所有Goroutines使用时,Sequential版本比Concurrent快约10％到13％。这是我所期望的,因为并发版本具有单个操作系统线程上的上下文切换和Goroutines管理的开销。 以下是每个Goroutine可用的单独操作系统线程的结果。顺序版本使用1个Goroutine,并发版本runtime.NumCPU在我的机器上使用或8个Goroutines。在这种情况下,并发版本正在利用并行性和并发性。 清单5 12345678910111210 Million Numbers using 8 goroutines with 8 cores2.9 GHz Intel 4 Core i7Concurrency WITH Parallelism-----------------------------------------------------------------------------$ GOGC=off go test -cpu 8 -run none -bench . -benchtime 3sgoos: darwingoarch: amd64pkg: github.com/ardanlabs/gotraining/topics/go/testing/benchmarks/cpu-boundBenchmarkSequential-8 1000 5910799 ns/opBenchmarkConcurrent-8 2000 3362643 ns/op : ~43% FasterBenchmarkSequentialAgain-8 1000 5933444 ns/opBenchmarkConcurrentAgain-8 2000 3477253 ns/op : ~41% Faster 清单5中的基准测试表明,当每个Goroutine可以使用单独的操作系统线程时,并发版本比顺序版本快大约41％到43％。这是我所期望的,因为所有Goroutines现在并行运行,八个Goroutines同时执行他们的同时工作。 排序重要的是要了解并非所有CPU绑定工作负载都适合并发。当破坏工作和/或组合所有结果非常昂贵时,这是主要的。使用名为冒号排序的排序算法可以看到这方面的一个例子。查看以下在Go中实现冒泡排序的代码。 清单6https://play.golang.org/p/S0Us1wYBqG6 1234567891011121314151617181920212223242526272829303132333435363738394001 package main0203 import \"fmt\"0405 func bubbleSort(numbers []int) {06 n := len(numbers)07 for i := 0; i &lt; n; i++ {08 if !sweep(numbers, i) {09 return10 }11 }12 }1314 func sweep(numbers []int, currentPass int) bool {15 var idx int16 idxNext := idx + 117 n := len(numbers)18 var swap bool1920 for idxNext &lt; (n - currentPass) {21 a := numbers[idx]22 b := numbers[idxNext]23 if a &gt; b {24 numbers[idx] = b25 numbers[idxNext] = a26 swap = true27 }28 idx++29 idxNext = idx + 130 }31 return swap32 }3334 func main() {35 org := []int{1, 3, 2, 4, 8, 6, 7, 2, 3, 0}36 fmt.Println(org)3738 bubbleSort(org)39 fmt.Println(org)40 } 在清单6中,有一个用Go编写的冒泡排序的例子。这种排序算法会扫描每次传递时交换值的整数集合。根据列表的顺序,在对所有内容进行排序之前,可能需要多次遍历集合。 问题：该bubbleSort功能是一个适合乱序执行的工作负载吗？我相信答案是否定的。整数集合可以分解为较小的列表,并且可以同时对这些列表进行排序。但是,在完成所有并发工作之后,没有有效的方法将较小的列表排序在一起。以下是冒泡排序的并发版本的示例。 清单8 123456789101112131415161718192021222324252601 func bubbleSortConcurrent(goroutines int, numbers []int) {02 totalNumbers := len(numbers)03 lastGoroutine := goroutines - 104 stride := totalNumbers / goroutines0506 var wg sync.WaitGroup07 wg.Add(goroutines)0809 for g := 0; g &lt; goroutines; g++ {10 go func(g int) {11 start := g * stride12 end := start + stride13 if g == lastGoroutine {14 end = totalNumbers15 }1617 bubbleSort(numbers[start:end])18 wg.Done()19 }(g)20 }2122 wg.Wait()2324 // Ugh, we have to sort the entire list again.25 bubbleSort(numbers)26 } 在清单8中,显示了bubbleSortConcurrent函数,它是函数的并发版本冒泡排序。它使用多个Goroutines同时对列表的某些部分进行排序。但是,你剩下的是以块为单位的已排序值列表。给定一个包含12个数字的36个数字的列表,如果整个列表在第25行没有再次排序,这将是结果列表。 清单9 123456789Before: 25 51 15 57 87 10 10 85 90 32 98 53 91 82 84 97 67 37 71 94 26 2 81 79 66 70 93 86 19 81 52 75 85 10 87 49After: 10 10 15 25 32 51 53 57 85 87 90 98 2 26 37 67 71 79 81 82 84 91 94 97 10 19 49 52 66 70 75 81 85 86 87 93 由于冒泡排序的本质是扫描列表,因此bubbleSort对第25行的调用将抵消使用并发性带来的任何潜在收益。使用冒泡排序,使用并发性没有性能提升。 阅读文件已经介绍了两个CPU绑定工作负载,但是IO绑定工作负载呢？当Goroutines自然地进出等待状态时,语义是否不同？查看读取文件并执行文本搜索的IO绑定工作负载。 第一个版本是一个名为的函数的顺序版本find。 清单10https://play.golang.org/p/8gFe5F8zweN 12345678910111213141542 func find(topic string, docs []string) int {43 var found int44 for _, doc := range docs {45 items, err := read(doc)46 if err != nil {47 continue48 }49 for _, item := range items {50 if strings.Contains(item.Description, topic) {51 found++52 }53 }54 }55 return found56 } 在清单10中,你可以看到该find函数的顺序版本。在第43行,found声明一个名为变量的变量,以维持topic在给定文档中找到指定的次数。然后在第44行,迭代文档并使用该read函数在第45行读取每个文档。最后在第49-53行,包中的Contains函数strings用于检查是否可以在从文档中读取的项集合中找到主题。如果找到主题,则found变量加1。 这是read被调用的函数的实现find。 清单11https://play.golang.org/p/8gFe5F8zweN 1234567833 func read(doc string) ([]item, error) {34 time.Sleep(time.Millisecond) // Simulate blocking disk read.35 var d document36 if err := xml.Unmarshal([]byte(file), &amp;d); err != nil {37 return nil, err38 }39 return d.Channel.Items, nil40 } read清单11中的函数time.Sleep以一毫秒的调用开始。此调用用于模拟在我们执行实际系统调用以从磁盘读取文档时可能产生的延迟。此延迟的一致性对于准确测量find针对并发版本的顺序版本的性能非常重要。然后在第35-39行,将存储在全局变量中的模拟xml文档file解组为struct值以进行处理。最后,在第39行将一组项目返回给调用者。 有了顺序版本,这里是并发版本。 注意：编写并发版本的find时,可以采用多种方法和选项。暂时不要挂断我的特定实现。如果你有一个更易读的版本,表现相同或更好,我希望你能分享它。 清单12https://play.golang.org/p/8gFe5F8zweN 123456789101112131415161718192021222324252627282930313233343558 func findConcurrent(goroutines int, topic string, docs []string) int {59 var found int646061 ch := make(chan string, len(docs))62 for _, doc := range docs {63 ch &lt;- doc64 }65 close(ch)6667 var wg sync.WaitGroup68 wg.Add(goroutines)6970 for g := 0; g &lt; goroutines; g++ {71 go func() {72 var lFound int6473 for doc := range ch {74 items, err := read(doc)75 if err != nil {76 continue77 }78 for _, item := range items {79 if strings.Contains(item.Description, topic) {80 lFound++81 }82 }83 }84 atomic.AddInt64(&amp;found, lFound)85 wg.Done()86 }()87 }8889 wg.Wait()9091 return int(found)92 } 在清单12中,显示了findConcurrent函数,它是函数的并发版本find。并发版本使用30行代码而不是非并发版本的13行代码。我实现并发版本的目标是控制用于处理未知数量文档的Goroutine的数量。我选择使用通道用于给予Goroutines池的池模式。 有很多代码,所以我只强调要理解的重要内容。 第61-64行：创建一个通道并填充要处理的所有文档。 第65行：通道关闭,因此当处理完所有文件后,Goroutines池自然终止。 第70行：创建了Goroutines游泳池。 第73-83行：池中的每个Goroutine从通道接收文档,将文档读入内存并检查主题的内容。当匹配时,本地找到的变量递增。 第84行：将各个Goroutine计数的总和加在一起作为最终计数。 并发版本肯定比顺序版本更复杂但复杂性值得吗？再次回答这个问题的最好方法是创建一个基准。对于这些基准测试,我使用了一千个文件的集合,关闭了垃圾收集器。有一个使用该find函数的顺序版本和使用该函数的并发版本findConcurrent。 清单13 1234567891011func BenchmarkSequential(b *testing.B) { for i := 0; i &lt; b.N; i++ { find(\"test\", docs) }}func BenchmarkConcurrent(b *testing.B) { for i := 0; i &lt; b.N; i++ { findConcurrent(runtime.NumCPU(), \"test\", docs) }} 清单13显示了基准函数。以下是所有Goroutines只有一个操作系统线程可用的结果。顺序使用1个Goroutine,并发版本runtime.NumCPU在我的机器上使用或8个Goroutines。在这种情况下,并发版本正在利用没有并行性的并发性。 清单14 12345678910111210 Thousand Documents using 8 goroutines with 1 core2.9 GHz Intel 4 Core i7Concurrency WITHOUT Parallelism-----------------------------------------------------------------------------$ GOGC=off go test -cpu 1 -run none -bench . -benchtime 3sgoos: darwingoarch: amd64pkg: github.com/ardanlabs/gotraining/topics/go/testing/benchmarks/io-boundBenchmarkSequential 3 1483458120 ns/opBenchmarkConcurrent 20 188941855 ns/op : ~87% FasterBenchmarkSequentialAgain 2 1502682536 ns/opBenchmarkConcurrentAgain 20 184037843 ns/op : ~88% Faster 清单14中的基准测试显示,当只有一个操作系统线程可用于所有Goroutines时,并发版本比顺序版本快大约87％到88％。这是我所期望的,因为所有Goroutines都有效地共享单个操作系统线程。read调用时每个Goroutine发生的自然上下文切换允许在单个操作系统线程上进行更多工作。 以下是并行使用并发时的基准。 清单15 12345678910111210 Thousand Documents using 8 goroutines with 1 core2.9 GHz Intel 4 Core i7Concurrency WITH Parallelism-----------------------------------------------------------------------------$ GOGC=off go test -run none -bench . -benchtime 3sgoos: darwingoarch: amd64pkg: github.com/ardanlabs/gotraining/topics/go/testing/benchmarks/io-boundBenchmarkSequential-8 3 1490947198 ns/opBenchmarkConcurrent-8 20 187382200 ns/op : ~88% FasterBenchmarkSequentialAgain-8 3 1416126029 ns/opBenchmarkConcurrentAgain-8 20 185965460 ns/op : ~87% Faster 清单15中的基准测试表明,引入额外的操作系统线程不能提供更好的性能。 结论这篇文章的目的是提供有关必须考虑的语义的指导,以确定工作负载是否适合使用并发。我尝试提供不同类型的算法和工作负载的示例,以便你可以看到语义上的差异以及需要考虑的不同工程决策。 你可以清楚地看到,使用IO绑定工作负载并不需要并行性来获得性能上的大幅提升。这与你在CPU绑定工作中看到的相反。当涉及像冒泡排序这样的算法时,并发性的使用会增加复杂性,而不会带来任何实际的性能优势。确定你的工作负载是否适合并发,然后确定必须使用正确语义的工作负载类型非常重要。 原文: 1) Scheduling In Go : Part I - OS Scheduler2) Scheduling In Go : Part II - Go Scheduler3) Scheduling In Go : Part III - Concurrency","link":"/2019/08/07/Go/Golang%E8%AF%91%E6%96%87/Go%E4%B8%AD%E7%9A%84%E8%B0%83%E5%BA%A6%EF%BC%9A%E7%AC%ACIII%E9%83%A8%E5%88%86-%E5%B9%B6%E5%8F%91/"},{"title":"(译) Go实时GC——三色算法理论与实践","text":"Go语言能够支持实时的,高并发的消息系统,在高达百万级别的消息系统中能够将延迟降低到100ms以下,着一切很大一部分需要归功于Go的高效的垃圾回收系统。 对于实时系统而言,垃圾回收系统可能是一个极大的隐患,因为在垃圾回收的时候需要将整个程序暂停。所以在我们设计消息总线系统的时候,需要小心地选择我们的语言。Go一直在强调它的低延迟,但是它真的做到了吗？如果是的,它是怎么做到的呢？ 在这篇文章当中,我们将会看到Go语言的GC是如何实现的（tricolor algorithm,三色算法）,以及为什么这种方法能够达到如此之低的GC暂停,以及最重要的是,它是否真的有效（对这些GC暂停进行benchmar测试,以及同其它类型的语言进行比较）。 From Haskell To Go我们用pub/sub消息总线系统为例说明问题,这些系统在发布消息的时候都是在内存存储的。在早期,我们用Haskell实现了第一版的消息系统,但是后面发现GHC的垃圾回收期存在一些基础延迟的问题,我们放弃了这个系统转而用Go进行了实现。 这是我们有关Haskell消息系统的一些实现细节,在GHC中最重要的一点是它GC暂停时间同当前的工作集的大小成比例关系（也就是说,GC时间和内存中存储对象的数目有关）。在我们的例子中,内存中存储对象的数目往往都非常巨大,这就导致gc时间常常高达数百毫秒。这就会导致在GC的时候整个系统是阻塞的。 而在Go语言中,不同于GHC的全局暂停(stop-the-world)收集器,Go的垃圾收集器是和主程序并行的。这就可以避免程序的长时间暂停。我们则更加关注于Go所承诺的低延迟以及其在每个新版本中所提及的延迟提升是否真的向他们所说的那样。 并行垃圾回收是如何工作的?Go的GC是如何实现并行的呢？其中的关键在于三色标记清除算法。该算法能够让系统的gc暂停时间成为能够预测的问题。调度器能够在很短的时间内实现GC调度,并且对源程序的影响极小。下面我们看看三色标记清除算法是如何工作的： 假设我们有这样的一段链表操作的代码： 123456789var A LinkedListNode;var B LinkedListNode;// ...B.next = &amp;LinkedListNode{next: nil};// ...A.next = &amp;LinkedListNode{next: nil};*(B.next).next = &amp;LinkedListNode{next: nil};B.next = *(B.next).next;B.next = nil; 第一步1234567var A LinkedListNode;var B LinkedListNode;// ...B.next = &amp;LinkedListNode{next: nil}; 刚开始我们假设有三个节点A、B和C,作为根节点,红色的节点A和B始终都能够被访问到,然后进行一次赋值B.next = &amp;C。初始的时候垃圾收集器有三个集合,分别为黑色,灰色和白色。现在,因为垃圾收集器还没有运行起来,所以三个节点都在白色集合中。 第二步我们新建一个节点D,并将其赋值给A.next。即： 123456789var A LinkedListNode;var B LinkedListNode;// ...B.next = &amp;LinkedListNode{next: nil};// ...A.next = &amp;LinkedListNode{next: nil}; 需要注意的是,作为一个新的内存对象,需要将其放置在灰色区域中。为什么要将其放在灰色区域中呢？这里有一个规则,如果一个指针域发生了变化,则被指向的对象需要变色。因为所有的新建内存对象都需要将其地址赋值给一个引用,所以他们将会立即变为灰色。（这就需要问了,为什么C不是灰色？） 第三步在开始GC的时候,根节点将会被移入灰色区域。此时A、B、D三个节点都在灰色区域中。由于所有的程序子过程(process,因为不能说是进程,应该算是线程,但是在go中又不完全是线程)要么事程序正常逻辑,要么是GC的过程,而且GC和程序逻辑是并行的,所以程序逻辑和GC过程应该是交替占用CPU资源的。 第四步 扫描内存对象在扫描内存对象的时候,GC收集器将会把该内存对象标记为黑色,然后将其子内存对象标记为灰色。在任一阶段,我们都能够计算当前GC收集器需要进行的移动步数：2*|white| + |grey|,在每一次扫描GC收集器都至少进行一次移动,直到达到当前灰色区域内存对象数目为0。 第五步程序此时的逻辑为,新赋值一个内存对象E给C.next,代码如下： 1234567891011var A LinkedListNode;var B LinkedListNode;// ...B.next = &amp;LinkedListNode{next: nil};// ...A.next = &amp;LinkedListNode{next: nil};//新赋值 C.next = &amp;E*(B.next).next = &amp;LinkedListNode{next: nil}; 按照我们之前的规则,新建的内存对象需要放置在灰色区域,如图所示： 这样做,收集器需要做更多的事情,但是这样做当在新建很多内存对象的时候,可以将最终的清除操作延迟。值得一提的是,这样处理白色区域的体积将会减小,直到收集器真正清理堆空间时再重新填入移入新的内存对象。 第六步 指针重新赋值程序逻辑此时将 B.next.next赋值给了B.next,也就是将E赋值给了B.next。代码如下： 123456789var A LinkedListNode;var B LinkedListNode;// ...B.next = &amp;LinkedListNode{next: nil};// ...A.next = &amp;LinkedListNode{next: nil};*(B.next).next = &amp;LinkedListNode{next: nil};// 指针重新赋值:B.next = *(B.next).next; 这样做之后,如图所示,C将不可达。 这就意味着,收集器需要将C从白色区域移除,然后在GC循环中将其占用的内存空间回收。 第七步将灰色区域中没有引用依赖的内存对象移动到黑色区域中,此时D在灰色区域中没有其它依赖,并依赖于它的内存对象A已经在黑色区域了,将其移动到黑色区域中。 第八步在程序逻辑中,将B.next赋值为了nil,此时E将变为不可达。但此时E在灰色区域,将不会被回收,那么这样会导致内存泄漏吗？其实不会,E将在下一个GC循环中被回收,三色算法能够保证这点：如果一个内存对象在一次GC循环开始的时候无法被访问,则将会被冻结,并在GC的最后将其回收。 第九步在进行第二次GC循环的时候,将E移入到黑色区域,但是C并不会移动,因为是C引用了E,而不是E引用C。 第十步收集器再扫描最后一个灰色区域中的内存对象B,并将其移动到黑色区域中。 第十一步 回收白色区域现在灰色区域已经没有内存对象了,这个时候就将白色区域中的内存对象回收。在这个阶段,收集器已经知道白色区域的内存对象已经没有任何引用且不可访问了,就将其当做垃圾进行回收。而在这个阶段,E不会被回收,因为这个循环中,E才刚刚变为不可达,它将在下个循环中被回收。 第十二步 区域变色这一步是最有趣的,在进行下次GC循环的时候,完全不需要将所有的内存对象移动回白色区域,只需要将黑色区域和白色区域的颜色换一下就好了,简单而且高效。 GC三色算法小结上面就是三色标记清除算法的一些细节,在当前算法下仍旧有两个阶段需要 stop-the-world：一是进行root内存对象的栈扫描；二是标记阶段的终止暂停。令人激动的是,标记阶段的终止暂停将被去除。在实践中我们发现,用这种算法实现的GC暂停时间能够在超大堆空间回收的情况下达到&lt;1ms的表现。 延迟 VS 吞吐如果一个并行GC收集器在处理超大内存堆时能够达到极低的延迟,那么为什么还有人在用stop-the-world的GC收集器呢？难道Go的GC收集器还不够优秀吗？ 这不是绝对的,因为低延迟是有开销的。最主要的开销就是,低延迟削减了吞吐量。并发需要额外的同步和赋值操作,而这些操作将会占用程序的处理逻辑的时间。而Haskell的GHC则针对吞吐量进行了优化,Go则专注于延迟,我们在考虑采用哪种语言的时候需要针对我们自己的需求进行选择,对于推送系统这种实时性要求比较高的系统,选择Go语言则是权衡之下得到的选择。 实际表现目前而言,Go好像已经能够满足低延迟系统的要求了,但是在实际中的表现又怎么样呢？利用相同的benchmark测试逻辑实现进行比较：该基准测试将不断地向一个限定缓冲区大小的buffer中推送消息,旧的消息将会不断地过期并成为垃圾需要进行回收,这要求内存堆需要一直保持较大的状态,这很重要,因为在回收的阶段整个内存堆都需要进行扫描以确定是否有内存引用。这也是为什么GC的运行时间和存活的内存对象和指针数目成正比例关系的原因。 这是Go语言版本的基准测试代码,这里的buffer用数组实现: 1234567891011121314151617181920212223242526272829303132333435363738394041424344package mainimport ( \"fmt\" \"time\")const ( windowSize = 200000 msgCount = 1000000)type ( message []byte buffer [windowSize]message)var worst time.Durationfunc mkMessage(n int) message { m := make(message, 1024) for i := range m { m[i] = byte(n) } return m}func pushMsg(b *buffer, highID int) { start := time.Now() m := mkMessage(highID) (*b)[highID%windowSize] = m elapsed := time.Since(start) if elapsed &gt; worst { worst = elapsed }}func main() { var b buffer for i := 0; i &lt; msgCount; i++ { pushMsg(&amp;b, i) } fmt.Println(\"Worst push time: \", worst)} 相同的逻辑,不同语言实现(Haskell/Ocaml/Racke、Java),在同等测试条件下进行的测试结果如下： 12345678910111213Benchmark Longest pause (ms)OCaml 4.03.0 (map based) (manual timing) 2.21Haskell/GHC 8.0.1 (map based) (rts timing) 67.00Haskell/GHC 8.0.1 (array based) (rts timing) 58.60Racket 6.6 experimental incremental GC (map based) (tuned) (rts timing) 144.21Racket 6.6 experimental incremental GC (map based) (untuned) (rts timing) 124.14Racket 6.6 (map based) (tuned) (rts timing) 113.52Racket 6.6 (map based) (untuned) (rts timing) 136.76Go 1.7.3 (array based) (manual timing) 7.01Go 1.7.3 (map based) (manual timing) 37.67Go HEAD (map based) (manual timing) 7.81Java 1.8.0_102 (map based) (rts timing) 161.55Java 1.8.0_102 G1 GC (map based) (rts timing) 153.89 令人惊讶的是Java,表现得非常一般,而OCaml则非常之好,OCaml语言能够达到约3ms的GC暂停时间,这是因为OCaml采用的GC算法是incremental GC algorithm(而在实时系统中不采用OCaml的原因是该语言对多核的支持不好)。 正如表中显示的,Go的GC暂停时间大约在7ms左右,表现也好,已经完全能够满足我们的要求。 一些注意事项 进行基准测试往往需要多加小心,因为不同的运行时针对不同的测试用例都有不同程度的优化,所以表现往往也有差异。而我们需要针对自己的需求来编写测试用例,对于基准测试应该能够满足我们自己的产品需求。在上面的例子中可以看到,Go已经完全能够满足我们的产品需求。 Map Vs. Array： 最初我们的基准测试是在map中进行插入和删除操作的,但是Go在对大型的map进行GC的时候存在Bug。因此在设计Go的基准测试的时候用可修改的Array作为Map的替代。Go map的Bug已经在1.8版本中得到了修复,但是并不是所有的基准测试都得到了修正,这也是我们需要正视的一些问题。但是不管怎么说,没有理由说GC时间将会因为使用map导致大幅度增长（除去bug和糟糕的实现之外）。 manual timing Vs. rst timing :作为另一个注意事项,有些基准测试则在不同的计时系统下将会有所差异,因为有些语言不支持运行时时间统计,例如Go,而有些语言则支持。因此,我们应该在测试时候都把计时方式设置为manual timing。 最后一个需要注意的事项是测试用例的实现将会极大地影响基准测试的结果,如果map的插入删除实现方式比较糟糕,则将会对测试结果造成不利影响,这也是用array的另一个原因。 为什么Go的结果不能再好点？尽管我们采用的map bugfixed版本或者是array版本的go实现能够达到~7ms的GC暂停表现,这已经很好了,但是根据Go官方发布的“1.5 Garbage Benchmark Latency”](https://talks.golang.org/2015/go-gc.pdf) , 在200MB的堆内存前提下,能够达到~1ms的GC暂停延时(经管GC暂停时间应该和指针引用数目有关而和堆所占用的容量无关但我们无法得到确切数据)。而Twitch团队也发布文章称在Go1.7中能够达到约1ms的GC延迟。 在联系go-nuts mail list之后得到的答案是,这些暂停实验可能是因为一些未修复的bug导致的。空闲的标记worker可能会对程序逻辑造成阻塞,为了确定这个问题,我采用了go tool trace,一个可视化工具对go的运行时行为进行了跟踪。 正如图所示,这里有近12ms的后台mark worker运行在所有的processor（CPU核?）中。这让我更加确信是上述的bug导致的该问题。 总结这次调查的重点在于GC要么关注于低延迟,要么关注于高吞吐。当然这些也都取决于我们的程序是如何使用堆空间的(我们是否有很多内存对象？每个对象的生命周期是长还是短？) 理解底层的GC算法对该系统是否适用于你的测试用例是非常重要的。当然GC系统的实际实现也至关重要。你的基准测试程序的内存占用应该同你将要实现的真正程序类似,这样才能够在实践中检验GC系统对于你的程序而言是否高效。正如前文所说的,Go的GC系统并不完美,但是对于我们的系统而言是可以接受的。 尽管存在一些问题,但是Go的GC表现已经优于大部分同样拥有GC系统的语言了,Go的开发团队针对GC延迟进行了优化,并且还在继续。Go的GC确实是有可圈可点之处,无论是理论上还是实践中。 原文 Golang’s Real-time GC in Theory and Practice","link":"/2019/08/06/Go/Golang%E8%AF%91%E6%96%87/Go%E5%AE%9E%E6%97%B6GC%E2%80%94%E2%80%94%E4%B8%89%E8%89%B2%E7%AE%97%E6%B3%95%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5%20/"},{"title":"(译) Go中的调度：第II部分 - Go Scheduler","text":"这是三部分系列中的第二篇文章,它将提供对Go中调度程序背后的机制和语义的理解。本文重点介绍Go调度程序。 三部分系列的索引： Go中的调度：第I部分 - 操作系统调度程序 Go中的调度：第II部分 - Go Scheduler Go中的调度：第III部分 - 并发 介绍在本调度系列的第一部分中,我解释了操作系统调度程序的各个方面,我认为这些方面对于理解和理解Go调度程序的语义非常重要。在这篇文章中,我将在语义层面解释Go调度程序的工作原理并关注高级行为。Go调度程序是一个复杂的系统,小的机器上的细节并不重要。重要的是拥有良好的工作和行为方式。这将使你能够做出更好的工程决策。 你的计划开始当你的Go程序启动时,它会为主机上标识的每个虚拟核心提供一个逻辑处理器（P）。如果你的处理器每个物理核心具有多个硬件线程（超线程）,则每个硬件线程将作为虚拟核心呈现给你的Go程序。为了更好地理解这一点,请查看我的MacBook Pro的系统报告。 图1 你可以看到我有一个带有4个物理内核的处理器。本报告未公开的是每个物理核心的硬件线程数。英特尔酷睿i7处理器具有超线程功能,这意味着每个物理内核有2个硬件线程。这将向Go程序报告,8个虚拟核可用于并行执行操作系统线程。 要测试这一点,请考虑以下程序： 清单1 12345678910111213package mainimport ( \"fmt\" \"runtime\")func main() { // NumCPU returns the number of logical // CPUs usable by the current process. fmt.Println(runtime.NumCPU())} 当我在本地机器上运行该程序时,NumCPU（）函数调用的结果将是值8.我在我的机器上运行的任何Go程序将被赋予8P。 每个P被分配一个操作系统线程（“M”）。’M’代表机器。该线程仍由操作系统管理,操作系统仍负责将线程放在核心上执行,如上一篇文章所述。这意味着当我在我的机器上运行Go程序时,我有8个线程可用于执行我的工作,每个线程都单独连接到P. 每个Go程序也都有一个初始的Goroutine（“G”）,这是Go程序的执行路径。Goroutine本质上是一个Coroutine,但这是Go,所以我们用“G”代替字母“C”,我们得到了Goroutine这个词。你可以将Goroutines视为应用程序级线程,它们在很多方面类似于操作系统线程。正如操作系统线程在核心上下载上下文一样,Goroutines在上下文中打开和关闭。 最后一个难题是运行队列。Go调度程序中有两个不同的运行队列：全局运行队列（GRQ）和本地运行队列（LRQ）。每个P都有一个LRQ,用于管理指定在P的上下文中执行的Goroutines。这些Goroutines轮流在上下文中切换到分配给P的M。GRQ用于尚未分配给的Goroutines。还没有。有一个过程将Goroutines从GRQ转移到LRQ,我们将在后面讨论。 图2提供了所有这些组件的图像。 图2 协作调度程序正如我们在第一篇文章中讨论的那样,操作系统调度程序是一个抢占式调度程序。从本质上讲,这意味着你无法预测调度程序在任何给定时间将要执行的操作。内核正在做出决策,一切都是非确定性的。运行在操作系统之上的应用程序无法控制内核中发生的事情,除非它们利用原子指令和互斥调用等同步原语。 Go调度程序是Go运行时的一部分,Go运行时内置在应用程序中。这意味着Go调度程序在内核之上的用户空间中运行。Go调度程序的当前实现不是抢占式调度程序,而是协作调度程序。作为协作调度程序意味着调度程序需要在代码中的安全点处发生的明确定义的用户空间事件以做出调度决策。 Go合作调度程序的优点在于它的表现和感觉先发制人。你无法预测Go调度程序将要执行的操作。这是因为这个合作调度程序的决策不是由开发人员掌握,而是在Go运行时。将Go调度程序视为抢占式调度程序非常重要,并且由于调度程序是非确定性的,因此这并不是一件容易的事。 Goroutine并发就像线程一样,Goroutines拥有相同的三个高级状态。这些决定了Go调度程序在任何给定的Goroutine中所起的作用。Goroutine可以处于以下三种状态之一：Waiting,Runnable或Executing。 等待：这意味着Goroutine已停止并等待某些事情继续进行。这可能是出于等待操作系统（系统调用）或同步调用（原子操作和互斥操作）等原因。这些类型的延迟是性能不佳的根本原因。 可运行：这意味着Goroutine需要时间在M上,因此它可以执行其指定的指令。如果你有很多想要时间的Goroutines,那么Goroutines必须等待更长时间才能得到时间。此外,随着更多Goroutines争夺时间,任何给定的Goroutine获得的个人时间缩短了。这种类型的调度延迟也可能是性能不佳的原因。 执行：这意味着Goroutine已被置于M并正在执行其指令。与应用程序相关的工作即将完成。这是每个人都想要的。 上下文切换Go调度程序需要明确定义的用户空间事件,这些事件发生在代码中的安全点以进行上下文切换。这些事件和安全点在函数调用中表现出来。函数调用对Go调度程序的运行状况至关重要。今天（使用Go 1.11或更低版本）,如果运行任何未进行函数调用的紧密循环,则会导致调度程序和垃圾回收中的延迟。函数调用在合理的时间范围内发生是至关重要的。 注意：有一个1.12 的提议被接受在Go调度程序中应用非协作抢占技术,以允许抢占紧密循环。 Go程序中发生了四类事件,允许调度程序做出调度决策。这并不意味着它总是会发生在其中一个事件上。这意味着调度程序获得了机会。 使用关键字 go 垃圾收集 系统调用 同步和编排 使用关键字 go关键字go是你创建Goroutines的方式。一旦创建了新的Goroutine,它就为调度程序提供了做出调度决策的机会。 垃圾收集由于GC使用自己的Goroutines运行,因此那些Goroutines需要时间在M上运行。这会导致GC产生大量的调度混乱。但是,调度程序非常聪明地了解Goroutine正在做什么,它将利用这些智能做出明智的决策。一个聪明的决定是上下文切换一个Goroutine,它想要在GC期间接触那些没有接触堆的堆。当GC运行时,正在做出许多调度决策。 系统调用如果Goroutine进行系统调用会导致Goroutine阻塞M,有时调度程序能够将Goroutine从M上下文切换并将新的Goroutine上下文切换到相同的M.但是,有时新的M是需要继续执行在P中排队的Goroutines。如何工作将在下一节中更详细地解释。 同步和编排当你运行的操作系统具有异步处理系统调用的能力时,可以使用称为网络轮询器的内容来更有效地处理系统调用。这是通过在这些相应的操作系统中使用kqueue（Mac操作系统）,epoll（Linux）或iocp（Windows）来实现的。 基于网络的系统调用可以由我们今天使用的许多操作系统异步处理。这是网络轮询器获得其名称的地方,因为它的主要用途是处理网络操作。通过使用网络轮询器进行网络系统调用,调度程序可以防止Goroutines在进行系统调用时阻止M. 这有助于保持M可用于在P的LRQ中执行其他Goroutines而无需创建新的Ms.这有助于减少操作系统上的调度负载。 查看其工作原理的最佳方法是运行示例。 图3 图3显示了我们的基本调度图。Goroutine-1正在M上执行,并且还有3个Goroutines等待LRQ在M上等待。网络轮询器无所事事。 图4 在图4中,Goroutine-1想要进行网络系统调用,因此Goroutine-1被移动到网络轮询器并处理异步网络系统调用。一旦Goroutine-1移动到网络轮询器,M现在可以从LRQ执行不同的Goroutine。在这种情况下,Goroutine-2在M.上下文切换。 图5 在图5中,异步网络系统调用由网络轮询器完成,Goroutine-1被移回到L的LRQ中。一旦Goroutine-1可以在M上进行上下文切换,Go负责的Go相关代码可以再次执行。这里的最大优势是,要执行网络系统调用,不需要额外的Ms。网络轮询器具有操作系统线程,它正在处理有效的事件循环。 同步系统调用当Goroutine想要进行无法异步完成的系统调用时会发生什么？在这种情况下,网络轮询器不能被使用,并且进行系统调用的Goroutine将阻止M.这是不幸的,但是没有办法防止这种情况发生。不能异步进行的系统调用的一个示例是基于文件的系统调用。如果你正在使用CGO,则可能还有其他情况,调用C函数也会阻止M. 注意：Windows操作系统确实能够异步进行基于文件的系统调用。从技术上讲,在Windows上运行时,可以使用网络轮询器。 让我们来看看同步系统调用（如文件I / O）会导致M阻塞的情况。 图6 图6再次显示了我们的基本调度图,但这次Goroutine-1将进行同步系统调用以阻止M1。 图7 在图7中,调度程序能够识别Goroutine-1已导致M阻塞。此时,调度程序将M1与P分离,同时仍然附加阻塞Goroutine-1。然后调度器引入新的M2来为P服务。此时,可以从LRQ中选择Goroutine-2并且在M2上进行上下文切换。如果由于之前的交换而已经存在M,则此切换比必须创建新M更快。 图8 在图8中,由Goroutine-1完成的阻塞系统调用完成。此时,Goroutine-1可以移回LRQ并再次由P服务。如果需要再次发生这种情况,则将M1放在侧面以备将来使用。 工作窃取调度程序的另一个方面是它是一个工作窃取调度程序。这有助于在一些领域保持有效的调度。首先,你想要的最后一件事就是M进入等待状态,因为一旦发生这种情况,操作系统就会将M从核心上下文切换。这意味着即使有一个Goroutine处于可运行状态,P也无法完成任何工作,直到M在核心上进行上下文切换。窃取工作也有助于平衡所有P的Goroutines,从而更好地分配工作并更有效地完成工作。 让我们来看一个例子。 图9 在图9中,我们有一个多线程Go程序,其中两个P服务四个Goroutines,每个服务GRQ中有一个Goroutine。如果P的所有Goroutines中的一个服务很快就会发生什么？ 图10 在图10中,P1没有更多的Goroutines来执行。但是Goroutines处于可运行状态,无论是在LRQ中还是在GRQ中。这是P1需要偷工作的时刻。窃取工作的规则如下。 清单2 12345678runtime.schedule() { //只有1/61的时间,检查G的全局可运行队列 //如果找不到,请检查本地队列。 //如果没找到, //试图从其他Ps窃取 //如果没有,请检查全局可运行队列。 //如果找不到,轮询网络。} 因此,基于清单2中的这些规则,P1需要在其LRQ中检查P2 for Goroutines并获取其发现的一半。 图11 在图11中,Goroutines的一半来自P2,现在P1可以执行那些Goroutines。 如果P2完成为其所有Goroutines提供服务并且P1的LRQ中没有任何东西会发生什么？ 图12 在图12中,P2完成了所有工作,现在需要窃取一些。首先,它将查看P1的LRQ,但它不会找到任何Goroutines。接下来,它将查看GRQ。那里会发现Goroutine-9。 图13 在图13中,P2从GRQ窃取了Goroutine-9并开始执行工作。所有这些偷窃工作的好处在于它允许女士保持忙碌而不会闲着。这项工作窃取在内部被视为旋转M.这种旋转具有JBD在她的工作窃取博客文章中解释得很好的其他好处。 实际例子有了相应的机制和语义,我想向你展示如何将所有这些结合在一起,以便Go调度程序随着时间的推移执行更多工作。想象一下用C编写的多线程应用程序,其中程序管理两个操作系统线程,它们相互传递消息。 图14 在图14中,有2个线程来回传递消息。线程1在Core 1上进行上下文切换,现在正在执行,这允许线程1将其消息发送到线程2。 注意：消息的传递方式并不重要。当业务流程继续进行时,重要的是线程的状态。 图15 在图15中,一旦线程1完成发送消息,它现在需要等待响应。这将导致线程1从Core 1上下文关闭并进入等待状态。一旦线程2收到有关该消息的通知,它就会进入可运行状态。现在操作系统可以执行上下文切换并在Core上执行线程2,它恰好是Core 2.接下来,线程2处理消息并将新消息发送回线程1。 图16 在图16中,线程上下文切换再次由线程2接收线程2的消息。现在线程2上下文 - 从执行状态切换到等待状态和线程1上下文 - 从等待状态切换到可运行状态最后回到执行状态,允许它处理并发回新消息。 所有这些上下文切换和状态更改都需要时间来执行,这限制了工作的完成速度。由于每个上下文切换可能会产生约1000纳秒的延迟,并且希望硬件每纳秒执行12条指令,因此你可以查看12k指令,或多或少,在这些上下文切换期间不执行。由于这些线程也在不同的核心之间弹跳,因高速缓存行未命中而导致额外延迟的可能性也很高。 让我们采用相同的例子,但使用Goroutines和Go调度程序。 图17 在图17中,有两个Goroutine正在编排,彼此之间来回传递消息。G1在M1上进行上下文切换,这恰好在Core 1上运行,这允许G1执行其工作。G1的工作是将其消息发送给G2。 图18 在图18中,一旦G1完成发送消息,它现在需要等待响应。这将导致G1上下文关闭M1并进入等待状态。一旦G2收到有关该消息的通知,它就会进入可运行状态。现在,Go调度程序可以执行上下文切换并在M1上执行G2,M1仍然在Core 1上运行。接下来,G2处理消息并将新消息发送回G1。 图19 在图19中,当G2接收到由G2发送的消息时,事物再次上下文切换。现在G2上下文 - 从执行状态切换到等待状态,G1上下文 - 从等待状态切换到可运行状态,最后返回到执行状态,这允许它处理并发回新消息。 表面上的事情似乎没有任何不同。无论你使用线程还是Goroutines,都会发生所有相同的上下文切换和状态更改。但是,使用线程和Goroutines之间存在一个主要区别,乍一看可能并不明显。 在使用Goroutines的情况下,相同的操作系统线程和核心用于所有处理。这意味着,从操作系统的角度来看,操作系统线程永远不会进入等待状态; 不止一次。因此,在使用Goroutines时,使用Threads时我们丢失到上下文切换的所有指令都不会丢失。 从本质上讲,Go已将IO / Blocking工作转变为操作系统级别的CPU限制工作。由于所有上下文切换都是在应用程序级别进行的,因此在使用Threads时,每个上下文切换都不会丢失相同的~12k指令（平均）。在Go中,那些相同的上下文切换花费大约200纳秒或~2.4k指令。调度程序还有助于提高缓存线效率和NUMA。这就是为什么我们不需要比虚拟核心更多的线程。在Go中,随着时间的推移,可以完成更多的工作,因为Go调度程序尝试使用更少的线程并在每个线程上执行更多操作,这有助于减少操作系统和硬件的负载。 结论Go调度程序在设计如何考虑操作系统和硬件如何工作的复杂性方面确实令人惊讶。在操作系统级别将IO /阻塞工作转换为CPU限制工作的能力是我们在利用更多CPU容量的过程中获得巨大成功的地方。这就是为什么你不需要比虚拟核心更多的操作系统线程。你可以合理地期望每个虚拟核心只需一个操作系统线程即可完成所有工作（CPU和阻塞IO绑定）。对于不需要阻止操作系统线程的系统调用的网络应用程序和其他应用程序,可以这样做。 作为开发人员,你仍然需要了解你的应用在你正在处理的工作类型方面正在做什么。你无法创建无限数量的Goroutines并期望惊人的性能。少总是更多,但是通过理解这些Go-scheduler语义,你可以做出更好的工程决策。在下一篇文章中,我将探讨以保守方式利用并发性以获得更好性能的想法,同时仍然平衡可能需要添加到代码中的复杂性。 原文: 1) Scheduling In Go : Part I - 操作系统 Scheduler2) Scheduling In Go : Part II - Go Scheduler3) Scheduling In Go : Part III - Concurrency","link":"/2019/08/07/Go/Golang%E8%AF%91%E6%96%87/Go%E4%B8%AD%E7%9A%84%E8%B0%83%E5%BA%A6%EF%BC%9A%E7%AC%ACII%E9%83%A8%E5%88%86-Go%20Scheduler/"},{"title":"(译) Go的工具概述","text":"有时我会被问到“你为什么喜欢使用Go？” 我经常提到的一件事是作为go命令的一部分与语言一起存在的周到工具。我每天都会使用一些工具（例如go fmt和）go build，而其他类似工具go tool pprof仅用于帮助解决特定问题。但是在所有情况下，我都很欣赏它们使我的项目管理和维护更加容易的事实。 在这篇文章中，我希望提供一些有关我发现最有用的工具的背景知识和背景知识，并且重要的是，说明它们如何适合典型项目的工作流程。如果你是Go的新手，希望它能给你一个良好的开端。 或者，如果你使用Go已有一段时间，并且该内容不适用于你，则希望你仍会发现以前不知道的命令或标志：） 这篇文章中的信息是为Go 1.12编写的，并假定你正在一个启用了模块的项目中。 安装工具 查看环境信息 发展历程 运行代码 获取依赖项 重构代码 查看Go文档 测试中 运行测试 分析测试覆盖率 压力测试 测试所有依赖项 提交前检查 格式化代码 执行静态分析 整理代码 整理和验证依赖项 构建和部署 建立可执行文件 交叉编译 使用编译器和链接器标志 诊断问题并进行优化 运行和比较基准 分析和跟踪 检查比赛条件 管理依赖关系 升级到新的Go版本 报告错误 备忘单 安装工具在这篇文章中，我将主要关注作为go命令一部分的工具。但是我将要提到的一些内容不是标准Go 1.12版本的一部分。 要在使用Go 1.12时安装这些程序，首先需要确保你_不在_模块启用的目录中（我通常只是更改为/tmp）。然后，你可以使用GO111MODULE=on go get命令安装该工具。例如： 12$ cd /tmp$ GO111MODULE=on go get golang.org/x/tools/cmd/stress 这将下载相关的软件包和依赖项，生成可执行文件并将其添加到你的GOBIN目录中。如果你尚未明确设置GOBIN目录，则可执行文件将添加到你的GOPATH/bin文件夹中。无论哪种方式，都应确保系统路径上有适当的目录。 注意：此过程有点笨拙，并有望在以后的Go版本中改进。问题30515正在跟踪有关此问题的讨论。 查看环境信息你可以使用该go env工具显示有关当前Go操作环境的信息。如果你在不熟悉的计算机上工作，这可能特别有用。 123456789101112131415161718192021222324252627$ go envGOARCH=\"amd64\"GOBIN=\"\"GOCACHE=\"/home/alex/.cache/go-build\"GOEXE=\"\"GOFLAGS=\"\"GOHOSTARCH=\"amd64\"GOHOSTOS=\"linux\"GOOS=\"linux\"GOPATH=\"/home/alex/go\"GOPROXY=\"\"GORACE=\"\"GOROOT=\"/usr/local/go\"GOTMPDIR=\"\"GOTOOLDIR=\"/usr/local/go/pkg/tool/linux_amd64\"GCCGO=\"gccgo\"CC=\"gcc\"CXX=\"g++\"CGO_ENABLED=\"1\"GOMOD=\"\"CGO_CFLAGS=\"-g -O2\"CGO_CPPFLAGS=\"\"CGO_CXXFLAGS=\"-g -O2\"CGO_FFLAGS=\"-g -O2\"CGO_LDFLAGS=\"-g -O2\"PKG_CONFIG=\"pkg-config\"GOGCCFLAGS=\"-fPIC -m64 -pthread -fmessage-length=0 -fdebug-prefix-map=/tmp/go-build245740092=/tmp/go-build -gno-record-gcc-switches\" 如果你需要特定的值，可以将它们作为参数传递给go env。例如： 1234$ go env GOPATH GOOS GOARCH/home/alex/golinuxamd64 要显示所有go env变量和值的文档，可以运行： 1$ go help environment 发展历程运行代码在开发过程中，该go run工具是试用代码的便捷方式。从本质上讲，它是一种编译代码，在/tmp目录中创建可执行二进制文件然后一步运行此二进制文件的快捷方式。 12$ go run . # Run the package in the current directory$ go run ./cmd/foo # Run the package in the ./cmd/foo directory 注意：从Go 1.11开始，你可以像上面一样将包的路径传递到go run。这意味着你不再需要使用go run *.go通配符扩展之类的变通办法来运行多个文件。我非常喜欢这种改进！ 获取依赖项假设你有启用的模块，当你使用go run（或go test或go build与此有关的）任何外部的依赖关系会自动（和递归）下载到符合import你的代码语句。默认情况下，将下载依赖项的最新标记版本，或者如果没有可用的标记版本，则在最新提交时依赖项。 如果你事先知道需要特定版本的依赖项（而不是Go默认会获取的go get版本），则可以使用相关的版本号或提交哈希。例如： 12$ go get github.com/foo/bar@v1.2.3$ go get github.com/foo/bar@8e1b8d3 如果相关性被提取有go.mod文件，那么它的依赖不会列出_你的_ go.mod文件。相反，如果要下载的依赖项没有go.mod文件，则该依赖项_将_在go.mod文件中列出，并在其// indirect旁边带有注释。 因此，这意味着你的go.mod文件不一定会在一处显示项目的所有依赖关系。相反，你可以使用以下go list工具查看所有内容： 1$ go list -m all 有时你可能会问，为什么是一个依赖？你可以使用go mod why命令回答此问题，该命令将显示从主模块中的软件包到给定依赖项的最短路径。例如： 12345$ go mod why -m golang.org/x/sys# golang.org/x/sysgithub.com/alexedwards/argon2idgolang.org/x/crypto/argon2golang.org/x/sys/cpu 注意：该go mod why命令将为大多数（但不是全部）依赖项返回答案。问题27900正在对此进行跟踪。 如果你有兴趣分析或可视化应用程序的依赖关系，那么你可能还需要签出该go mod graph工具。还有用于生成可视化一个伟大的教程和示例代码在这里。 最后，下载的依赖项存储在位于的模块缓存中GOPATH/pkg/mod。如果你需要清除模块缓存，则可以使用该go clean工具。但是请注意：这将删除计算机上所有项目的下载依赖关系。 1$ go clean -modcache 重构代码你可能对使用该gofmt工具自动设置代码格式很熟悉。但它也支持重写规则，可用于帮助重构代码。我会示范。 假设你具有以下代码，并且想要将foo变量更改为Foo以便将其导出。 123456var foo intfunc bar() { foo = 1 fmt.Println(\"foo\")} 为此，你可以gofmt 与-r标志一起使用以实现重写规则，-d标志可以显示更改的差异，-w标志可以在适当的位置进行更改，如下所示： 123456789$ gofmt -d -w -r 'foo -&gt; Foo' .-var foo int+var Foo int func bar() {- foo = 1+ Foo = 1 fmt.Println(\"foo\") } 注意，这比查找和替换聪明吗？该foo变量已发生变化，但&quot;foo&quot;在串fmt.Println()语句已保持不变。需要注意的另一件事是该gofmt命令是递归工作的，因此上述命令将*.go在当前目录和子目录中的所有文件上运行。 如果要使用此功能，我建议运行重写规则，而不该-w标志第一次，第一次检查diff来确保该修改的代码是你期望的。 让我们看一个稍微复杂的例子。假设你要更新代码以使用新的Go 1.12 strings.ReplaceAll（）函数而不是strings.Replace（）。要进行此更改，你可以运行： 1$ gofmt -w -r 'strings.Replace(a, b, c, -1) -&gt; strings.ReplaceAll(a, b, c)' . 在重写规则中，单个小写字符充当与任意表达式匹配的通配符，并且这些表达式将在替换中被替换。 查看Go文档你可以使用go doc工具通过终端查看标准库软件包的文档。在开发过程中，我经常使用它来快速检查某些内容，例如特定功能的名称或签名。我发现它比浏览基于Web的文档更快，并且它始终也可以脱机使用。 12345$ go doc strings # View simplified documentation for the strings package$ go doc -all strings # View full documentation for the strings package$ go doc strings.Replace # View documentation for the strings.Replace function$ go doc sql.DB # View documentation for the database/sql.DB type$ go doc sql.DB.Query # View documentation for the database/sql.DB.Query method 你还可以包括该-src标志以显示相关的Go源代码。例如： 1$ go doc -src strings.Replace # View the source code for the strings.Replace function 测试中运行测试你可以使用该go test工具在项目中运行测试，如下所示： 123$ go test . # Run all tests in the current directory$ go test ./... # Run all tests in the current directory and sub-directories$ go test ./foo/bar # Run all tests in the ./foo/bar directory 通常，我会在启用Go的竞争检测器的情况下运行测试，这可以帮助拾取现实使用中可能发生的_一些_数据竞争。像这样： 1go test -race ./... 重要的是要注意，启用竞赛检测器会增加测试的总体运行时间。因此，如果你经常在TDD工作流程中运行测试，则可能更愿意将其保存为仅用于预提交测试运行。 从1.10开始，Go 在程序包级别缓存测试结果。如果程序包在两次测试运行之间没有变化（并且你使用的是可go test缓存的相同标志），则将显示缓存的测试结果并在其&quot;(cached)&quot;旁边显示。这对于加快大型代码库的测试运行时间非常有帮助。如果要强制测试完全运行（并避免缓存），则可以使用该-count=1标志，也可以使用该go clean工具清除所有缓存的测试结果。 12$ go test -count=1 ./... # Bypass the test cache when running tests$ go clean -testcache # Delete all cached test results 注意：缓存的测试结果与缓存的构建结果一起存储在你的GOCACHE目录中。检查go env GOCACHE你不确定机器上的位置。 你可以go test通过使用-run 标志来限制运行特定的测试（和子测试）。这将接受一个正则表达式，并且仅运行名称与该正则表达式匹配的测试。我喜欢将其与-v标志结合使用以启用详细模式，因此将显示正在运行的测试和子测试的名称。这是一种有用的方法，可以确保我没有搞砸正则表达式，并且确实可以运行我期望的测试！ 123 $ go test -v -run=^TestFooBar$ . # Run the test with the exact name TestFooBar$ go test -v -run=^TestFoo . # Run tests whose names start with TestFoo$ go test -v -run=^TestFooBar$/^Baz$ . # Run the Baz subtest of the TestFooBar test only 最好注意几个标记-short（可以用来跳过长时间运行的测试）和-failfast（在第一次失败后将停止运行进一步的测试）。请注意，这-failfast将防止缓存测试结果。 12$ go test -short ./... # Skip long running tests$ go test -failfast ./... # Don't run further tests after a failure. 分析测试覆盖率你可以使用该-cover标志在运行测试时启用覆盖率分析。这将显示每个包的输出中测试覆盖的代码百分比，类似于以下内容： 12$ go test -cover ./...ok github.com/alexedwards/argon2id 0.467s coverage: 78.6% of statements 你还可以使用标志生成coverage配置文件，-coverprofile并使用以下go tool cover -html命令在Web浏览器中查看它： 12$ go test -coverprofile=/tmp/profile.out ./...$ go tool cover -html=/tmp/profile.out` 这将为你提供所有测试文件的可导航列表，测试覆盖的代码以绿色显示，未覆盖的代码以红色显示。 如果需要，可以更进一步，设置-covermode=count标志以使coverage配置文件记录测试期间每个语句执行的确切_次数_。 12$ go test -covermode=count -coverprofile=/tmp/profile.out ./...$ go tool cover -html=/tmp/profile.out 在浏览器中查看时，执行频率更高的语句以更加饱和的绿色阴影显示，类似于： 注意：如果t.Parallel()在任何测试中都使用该命令，则应使用该标志-covermode=atomic代替，-covermode=count以确保计数准确。 最后，如果你没有可用于查看覆盖范围配置文件的网络浏览器，则可以使用以下命令在终端中按功能/方法查看测试覆盖率的细分： 1234$ go tool cover -func=/tmp/profile.outgithub.com/alexedwards/argon2id/argon2id.go:77: CreateHash 87.5%github.com/alexedwards/argon2id/argon2id.go:96: ComparePasswordAndHash 85.7%... 压力测试你可以使用该go test -count命令连续运行测试多次，如果你要检查偶发性或间歇性故障，这将很有用。例如： 1go test -run=^TestFooBar$ -count=500 . 在此示例中，TestFooBar测试将连续重复500次。但重要的是要注意，测试将连续串行进行 -即使它包含t.Parallel()指令。因此，如果你的测试运行相对较慢，例如往返数据库，硬盘或Internet，则运行大量测试可能会花费很长时间。 在这种情况下，你可能希望使用该stress工具并行并行重复多次相同的测试。你可以这样安装它： 12$ cd /tmp$ GO111MODULE=on go get golang.org/x/tools/cmd/stress 要使用该stress工具，你首先需要为要_测试的特定程序包编译一个测试二进制文件_。你可以使用go test -c命令来完成。例如，要在当前目录中为程序包创建一个测试二进制文件： 1go test -c -o=/tmp/foo.test . 在此示例中，测试二进制文件将输出到/tmp/foo.test。然后，你可以使用该stress工具在测试二进制文件中执行特定的测试，如下所示： 1234$ stress -p=4 /tmp/foo.test -test.run=^TestFooBar$60 runs so far, 0 failures120 runs so far, 0 failures... 注意：在上面的示例中，我使用了-p标志将所使用的并行进程数限制stress为4。没有该标志，该工具将默认使用等于的进程数runtime.NumCPU()。 测试所有依赖项在构建用于发布或部署的可执行文件或公开分发代码之前，可能需要运行以下go test all命令： 1$ go test all 这将对模块中的所有软件包以及所有依赖项（包括测试测试依赖项和必要的标准库软件包）运行测试，并且可以帮助验证所使用的依赖项的确切版本是否相互兼容。这可能需要很长时间才能运行，但是结果缓存良好，因此以后的任何后续测试都应该更快。如果需要，还可以使用go test -short all跳过任何长时间运行的测试。 提交前检查格式化代码Go提供了两种工具，可以根据Go约定自动设置代码格式：gofmt和go fmt。使用这些有助于使代码在文件和项目之间保持一致，并且-如果在提交代码之前使用它们-有助于减少检查文件版本之间的差异时的噪音。 我喜欢将gofmt工具与以下标志一起使用： 12$ gofmt -w -s -d foo.go # Format the foo.go file$ gofmt -w -s -d . # Recursively format all files in the current directory and sub-directories 在这些命令中，该-w标志指示该工具在适当的位置重写文件，-s指示该工具在可能的情况下对代码进行简化，该-d标志指示该工具输出更改的差异（因为我很想知道是什么）更改）。如果你只想显示已更改文件的名称，而不是差异，则可以将其交换为-l标志。 注意：该gofmt命令以递归方式工作。如果你将目录传递给，则它会格式化.或./cmd/foo格式化.go该目录下的所有文件。 另一个格式化工具- go fmt工具是包装器，本质上调用gofmt -l -w指定的文件或目录。你可以像这样使用它： 1$ go fmt ./... 执行静态分析该go vet工具_会对你的代码进行静态分析，并警告你某些可能_与你的代码有误，但编译器不会处理的问题。诸如无法访问的代码，不必要的分配和格式错误的构建标签之类的问题。你可以这样使用它： 1234$ go vet foo.go # Vet the foo.go file$ go vet . # Vet all files in the current directory$ go vet ./... # Vet all files in the current directory and sub-directories$ go vet ./foo/bar # Vet all files in the ./foo/bar directory 在幕后，go vet运行一堆不同的分析仪，这些分析仪在此处列出，你可以根据情况禁用特定的分析仪。例如，要禁用composite分析仪，可以使用： 1$ go vet -composites=false ./... 有一对夫妇的实验分析仪golang.org/x/tools，你可能会想尝试：nilness（这对于冗余或不可能为零比较检查）和阴影（其检查的变数可能出现的意外阴影）。如果要使用它们，则需要单独安装和运行它们。例如，要安装，nilness请运行： 12$ cd /tmp$ GO111MODULE=on go get golang.org/x/tools/go/analysis/passes/nilness/cmd/nilness 然后你可以像这样使用它： 1$ go vet -vettool=$(which nilness) ./... 注意：使用该-vettool 标志时，它将_仅_运行指定的分析器-其他所有go vet分析器将不会运行。 附带一提，自Go 1.10起，该go test工具会go vet在运行任何测试之前自动执行小的，高可信度的部分检查。你可以在运行如下测试时关闭此行为： 1$ go test -vet=off ./... 整理代码你可以使用该golint工具来识别代码中的样式错误。与go vet有所不同，这与代码的正确性无关，但是可以帮助你使代码与Effective Go和Go CodeReviewComments中的样式约定对齐。 它不是标准库的一部分，因此你需要像这样安装它： 12$ cd /tmp$ GO111MODULE=on go get golang.org/x/lint/golint 然后可以按以下方式运行它：1234$ golint foo.go # Lint the foo.go file$ golint . # Lint all files in the current directory$ golint ./... # Lint all files in the current directory and sub-directories$ golint ./foo/bar # Lint all files in the ./foo/bar directory 整理和验证依赖项在提交对代码的任何更改之前，我建议运行以下两个命令来整理和验证依赖关系： 12$ go mod tidy$ go mod verify 该go mod tidy命令将修剪任何未使用的依赖从你go.mod和go.sum文件，并更新文件，包括所有可能的构建标签/ OS /建筑组合的依赖关系（注：go run，go test，go build等都是“懒惰”，将只取所需当前构建标签包/ OS /体系结构）。在每次提交之前运行此命令，可以更轻松地确定在查看版本控制历史记录时哪些代码更改负责添加或删除哪些依赖项。 我还建议你使用go mod verify命令检查自下载后对计算机的依赖项是否有意外（或有意）更改，并且它们与go.sum文件中的加密哈希值匹配。运行此命令有助于确保所使用的依赖项与你期望的依赖项完全相同，并且该提交的任何构建都可以在以后重现。 构建和部署建立可执行文件要编译main软件包并创建可执行二进制文件，可以使用该go build工具。通常，我将其与-o标志结合使用，让你显式设置输出目录和二进制文件名称，如下所示： 12$ go build -o=/tmp/foo . # Compile the package in the current directory$ go build -o=/tmp/foo ./cmd/foo # Compile the package in the ./cmd/foo directory 在这些示例中，go build将_编译指定的程序包（和所有相关程序包），然后调用链接器_以生成可执行二进制文件，并将其输出到/tmp/foo。 重要的是要注意，从Go 1.10开始，该go build工具将构建输出缓存在_构建缓存中_。此缓存的输出将在以后的适当版本中再次重用，这可以显着缩短总体生成时间。这种新的缓存行为方式的古训的“宁可go install要go build以提高缓存”不再适用。 如果不确定构建缓存在哪里，可以通过运行以下go env GOCACHE命令进行检查： 12$ go env GOCACHE/home/alex/.cache/go-build 使用构建缓存有一个重要的警告 -它不会检测到使用导入的C库的更改cgo。因此，如果你的代码通过导入了C库，cgo并且自上次构建以来已对其进行了更改，则需要使用-a标志来强制重新构建所有软件包。另外，你可以使用go clean清除缓存： 12$ go build -a -o=/tmp/foo . # Force all packages to be rebuilt$ go clean -cache # Remove everything from the build cache 注意：运行go clean -cache也会删除缓存的测试结果。 如果你对go build幕后操作感兴趣，则可以使用以下命令： 12$ go list -deps . | sort -u # List all packages that are used to build the executable$ go build -a -x -o=/tmp/foo . # Rebuild everything and show the commands that are run 最后，如果你go build在非main软件包上运行，它将在一个临时位置进行编译，然后再次将结果存储在构建缓存中。没有可执行文件。 交叉编译这是我最喜欢的Go功能之一。 默认情况下，go build将输出适合在你当前的操作系统和体系结构上使用的二进制文件。但是它也支持交叉编译，因此你可以生成适合在另一台计算机上使用的二进制文件。如果你要在一个操作系统上进行开发，而在另一个操作系统上进行部署，这将特别有用。 你可以通过分别设置GOOS和GOARCH环境变量来指定要为其创建二进制文件的操作系统和体系结构。例如： 12$ GOOS=linux GOARCH=amd64 go build -o=/tmp/linux_amd64/foo .$ GOOS=windows GOARCH=amd64 go build -o=/tmp/windows_amd64/foo.exe . 要查看所有受支持的操作系统/体系结构组合的列表，可以运行go tool dist list： 123456789$ go tool dist listaix/ppc64android/386android/amd64android/armandroid/arm64darwin/386darwin/amd64... 提示：你可以使用Go的交叉编译来创建WebAssembly二进制文件。 有关交叉编译的更深入的信息，我建议阅读这篇出色的文章。 使用编译器和链接器标志在生成可执行文件时，你可以使用该-gcflags标志来更改编译器的行为，并查看有关其工作方式的更多信息。你可以通过运行以下命令查看可用编译器标志的完整列表： 1$ go tool compile -help 你可能会发现一个有趣的标志-m，它会触发打印有关在编译过程中做出的优化决策的信息。你可以像这样使用它： 1$ go build -gcflags=\"-m -m\" -o=/tmp/foo . # Print information about optimization decisions 在上面的示例中，我-m两次使用该标志来指示我想将决策信息打印为两层。你只需使用一个就可以得到更简单的输出。 另外，从Go 1.10开始，编译器标志仅适用于传递给的特定程序包go build-在上例中，该程序包是当前目录中的程序包（由表示.）。如果要打印所有程序包（包括依赖项）的优化决策，可以改用以下命令： 1$ go build -gcflags=\"all=-m\" -o=/tmp/foo . 从Go 1.11开始，你应该发现调试优化的二进制文件比以前更容易。但是，如果需要，你仍然可以使用这些标志-N来禁用优化和-l禁用内联。例如： 1$ go build -gcflags=\"all=-N -l\" -o=/tmp/foo . # Disable optimizations and inlining 你可以通过运行以下命令查看可用的链接器标志列表： 1$ go tool link -help 其中最著名的可能是-X标志，它允许你将（字符串）值“烧入”应用程序中的特定变量。通常用于添加版本号或提交哈希。例如： 1$ go build -ldflags=\"-X main.version=1.2.3\" -o=/tmp/foo . 有关该-X标志的更多信息和一些示例代码，请参见此StackOverflow问题以及本帖子和本帖子。 你可能还对使用-s和-w标志从二进制文件中删除调试信息感兴趣。这通常会将最终尺寸减少约25％。例如： 1$ go build -ldflags=\"-s -w\" -o=/tmp/foo . # Strip debug information from the binary 注意：如果你需要优化二进制大小，则可能需要使用upx对其进行压缩。有关更多信息，请参见此帖子。 诊断问题并进行优化运行和比较基准Go的一个不错的功能是，它使基准测试变得容易。如果你不熟悉编写基准测试的一般过程，这里和这里都有很好的指南。 要运行基准测试，你将需要使用该go test工具，并将-bench标志设置为与要执行的基准匹配的正则表达式。例如： 123$ go test -bench=. ./... # Run all benchmarks and tests$ go test -run=^$ -bench=. ./... # Run all benchmarks (and no tests)$ go test -run=^$ -bench=^BenchmarkFoo$ ./... # Run only the BenchmarkFoo benchmark (and no tests) 我几乎总是使用该-benchmem标志运行基准测试，该标志会强制将内存分配统计信息包含在输出中。 1$ go test -bench=. -benchmem ./... 默认情况下，每一个基准测试将为运行_最少_ 1次，只有一次的。你可以使用-benchtime和-count标志进行更改： 123$ go test -bench=. -benchtime=5s ./... # Run each benchmark test for at least 5 seconds$ go test -bench=. -benchtime=500x ./... # Run each benchmark test for exactly 500 iterations$ go test -bench=. -count=3 ./... # Repeat each benchmark test 3 times over 如果基准测试的代码使用并发性，则可以使用该-cpu标志来查看更改GOMAXPROCS值（实际上是可以同时执行G​​o代码的OS线程数）对性能的影响。例如，运行GOMAXPROCS设置为1、4和8的基准测试： 1$ go test -bench=. -cpu=1,4,8 ./... 要比较基准之间的更改，你可能需要使用Benchcmp工具。这不是标准go命令的一部分，因此你需要像这样安装它： 12$ cd /tmp$ GO111MODULE=on go get golang.org/x/tools/cmd/benchcmp 然后可以像这样使用它： 123456789101112$ go test -run=^$ -bench=. -benchmem ./... &gt; /tmp/old.txt# make changes$ go test -run=^$ -bench=. -benchmem ./... &gt; /tmp/new.txt$ benchcmp /tmp/old.txt /tmp/new.txtbenchmark old ns/op new ns/op deltaBenchmarkExample-8 21234 5510 -74.05%benchmark old allocs new allocs deltaBenchmarkExample-8 17 11 -35.29%benchmark old bytes new bytes deltaBenchmarkExample-8 8240 3808 -53.79% 分析和跟踪Go使创建用于CPU使用，内存使用，goroutine阻止和互斥锁争用的诊断配置文件成为可能。你可以使用它们进行更深入的了解，并确切地了解你的应用程序如何使用（或等待）资源。 有三种方法可以生成配置文件： 如果你有Web应用程序，则可以导入net/http/pprof软件包。这将向中注册一些处理程序，http.DefaultServeMux然后你可以使用这些处理程序为正在运行的应用程序生成和下载配置文件。这篇文章提供了很好的解释和一些示例代码。 对于其他类型的应用程序，你可以使用pprof.StartCPUProfile()和pprof.WriteHeapProfile()函数来分析正在运行的应用程序。请参阅runtime/pprof文档以获取示例代码。 或者，你可以在运行基准测试或测试时通过使用各种-***profile标志来生成概要文件，如下所示： 1234$ go test -run=^$ -bench=^BenchmarkFoo$ -cpuprofile=/tmp/cpuprofile.out .$ go test -run=^$ -bench=^BenchmarkFoo$ -memprofile=/tmp/memprofile.out .$ go test -run=^$ -bench=^BenchmarkFoo$ -blockprofile=/tmp/blockprofile.out .$ go test -run=^$ -bench=^BenchmarkFoo$ -mutexprofile=/tmp/mutexprofile.out . 注意：-***profile在运行基准测试或测试时使用这些标志将导致测试二进制文件输出到你的当前目录。如果要将其输出到其他位置，则应使用如下-o标记： 1$ go test -run=^$ -bench=^BenchmarkFoo$ -o=/tmp/foo.test -cpuprofile=/tmp/cpuprofile.out . 无论选择哪种方式创建配置文件，启用概要分析后，你的Go程序都将每秒停止约100次，并在该时刻进行快照。将这些_样本收集在一起以形成一个配置文件_，你可以使用该pprof工具进行分析。 我最喜欢的检查配置文件的方法是使用go tool pprof -http命令在Web浏览器中将其打开。例如： 1$ go tool pprof -http=:5000 /tmp/cpuprofile.out 这将默认为显示一个_图形_，该_图形_显示了应用程序采样方面的执行树，这使你可以快速了解任何资源使用“热点”。在上图中，我们可以看到，就CPU使用率而言，热点是源自的两个系统调用ioutil.ReadFile()。 你还可以导航到配置文件的其他_视图_，包括按功能和源代码列出的最高使用率。 如果信息量不胜枚举，则你可能希望使用该--nodefraction标志来忽略占少于一定百分比样本的节点。例如，要忽略少于10％的样本中使用的节点，可以这样运行pprof： 1$ go tool pprof --nodefraction=0.1 -http=:5000 /tmp/cpuprofile.out 这使图形的“噪点”少了很多，如果放大此屏幕截图，现在可以更加清楚地看到并了解CPU使用率热点所在的位置。 分析和优化资源使用情况是一个很大，细微的话题，而我在这里几乎没有涉及到任何表面。如果你有兴趣了解更多信息，那么我建议你阅读以下博客文章： 分析和优化Go Web应用程序 调试Go程序中的性能问题 使用基准和性能分析进行每日代码优化 用pprof分析Go程序 可以用来帮助诊断问题的另一个工具是运行时执行跟踪程序。这使你可以了解Go如何创建和调度goroutine，以及何时运行垃圾回收器，以及有关阻止syscall / network / sync操作的信息。 同样，你可以从测试或基准测试中生成跟踪，或者用于net/http/pprof创建和下载Web应用程序的跟踪。然后，你可以使用go tool trace来在Web浏览器中查看输出，如下所示： 12$ go test -run=^$ -bench=^BenchmarkFoo$ -trace=/tmp/trace.out .$ go tool trace /tmp/trace.out 重要提示：目前仅在Chrome / Chromium中可见。 有关Go的执行跟踪器以及如何解释输出的更多信息，请参见Rhys Hiltner的dotGo 2016演讲和这篇出色的博客文章。 检查比赛条件我之前谈到过在测试过程中使用启用Go的竞态检测器go test -race。但是你也可以在构建可执行文件时启用它以运行程序，如下所示： 1$ go build -race -o=/tmp/foo . 需要特别注意的是，启用了竞争检测器的二进制文件将比-race正常情况下使用更多的CPU和内存，因此，在正常情况下为生产构建二进制文件时，不应使用该标志。 但是你可能希望在多个池中的一台服务器上部署启用了竞争检测器的二进制文件。或通过使用负载测试工具将流量并发到启用了种族检测器的二进制文件上，同时使用它来帮助查找可疑的竞争状况。 默认情况下，如果在二进制文件运行时检测到任何竞争，则会将日志写入stderr。你可以GORACE根据需要使用环境变量来更改它。例如，要运行位于的二进制文件/tmp/foo并向其输出任何种族日志，/tmp/race.&lt;pid&gt;可以使用： 1$ GORACE=\"log_path=/tmp/race\" /tmp/foo 管理依赖关系你可以使用该go list工具检查特定依赖项是否具有可用的较新版本，如下所示： 12$ go list -m -u github.com/alecthomas/chromagithub.com/alecthomas/chroma v0.6.2 [v0.6.3] 这将输出你当前正在使用的依赖项名称和版本[]，如果存在较新的版本，则会在方括号中输出最新版本。你还可以go list像这样检查所有依赖项（和子依赖项）的更新： 1$ go list -m -u all 你可以使用以下go get命令将依赖项升级（或降级）为最新版本，特定的标记发布或提交哈希： 123$ go get github.com/foo/bar@latest$ go get github.com/foo/bar@v1.2.3$ go get github.com/foo/bar@7e0369f 如果要更新的依赖项有一个go.mod文件，则根据此go.mod文件中的信息，如有必要，还将下载对任何子依赖项的更新。如果使用该go get -u标志，则go.mod文件的内容将被忽略，所有子依赖项都将升级到其最新的次要版本/修补程序版本，即使go.mod指定了其他版本也是如此。 升级或降级任何依赖项后，最好整理一下modfile。你可能还想对所有软件包运行测试以帮助检查不兼容性。像这样： 12$ go mod tidy$ go test all 有时，你可能希望使用依赖项的本地版本（例如，在补丁合并到上游之前，你需要使用本地派生）。为此，可以使用go mod edit命令将go.mod文件中的依赖项替换为本地版本。例如： 1$ go mod edit -replace=github.com/alexedwards/argon2id=/home/alex/code/argon2id 这将添加一个替换规则，以你的go.mod文件像这样，和任何未来的调用go run，go build等将使用本地版本。 档案：go.mod 1234567module alexedwards.net/examplego 1.12require github.com/alexedwards/argon2id v0.0.0-20190109181859-24206601af6creplace github.com/alexedwards/argon2id =&gt; /home/alex/Projects/playground/argon2id 一旦不再需要，你可以使用以下命令删除替换规则： 1$ go mod edit -dropreplace=github.com/alexedwards/argon2id 你可以使用相同的通用技术来导入_仅存_在于你自己的文件系统上的软件包。如果你同时在开发中处理多个模块，而其中一个依赖于另一个模块，则这很有用。 注意：如果你不想使用该go mod edit命令，则可以go.mod手动编辑文件以进行这些更改。无论哪种方式都可以。 升级到新的Go版本该go fix工具最初于2011年发布（当时仍在对Go’s API进行定期更改），以帮助用户自动更新其旧代码以与Go的最新版本兼容。从那时起，Go的兼容性承诺意味着，如果你从一个Go 1.x版本升级到一个新的1.x版本，则一切正常工作和使用go fix通常都是不必要的。 但是，它确实处理了一些非常具体的问题。你可以通过运行来查看它们的摘要go tool fix -help。如果你决定go fix升级后要运行，则应运行以下命令，然后在提交更改之前先检查一下差异。 1$ go fix ./... 报告错误如果你确信已发现Go的标准库，工具或文档中未报告的问题，则可以使用该go bug命令来创建新的Github问题。 1go bug 这将打开一个浏览器窗口，其中包含一个预填有你的系统信息和报告模板的问题。 备忘单更新2019-04-19：@FedirFR已经根据这篇文章做了一个备忘单。你可以在这里下载。 如果你喜欢这篇博客文章，请不要忘记阅读有关如何使用Go构建专​​业Web应用程序的新书！ 在Twitter @ajmedwards上关注我。 根据MIT许可证，本文中的所有代码段均可免费使用。","link":"/2020/06/18/Go/Golang%E8%AF%91%E6%96%87/Go%E7%9A%84%E5%B7%A5%E5%85%B7%E6%A6%82%E8%BF%B0/"},{"title":"(译) 如何优雅的关闭Go Channel","text":"Channel关闭原则 不要在消费端关闭channel，不要在有多个并行的生产者时对channel执行关闭操作。 也就是说应该只在[唯一的或者最后唯一剩下]的生产者协程中关闭channel，来通知消费者已经没有值可以继续读了。只要坚持这个原则，就可以确保向一个已经关闭的channel发送数据的情况不可能发生。 暴力关闭channel的正确方法如果想要在消费端关闭channel，或者在多个生产者端关闭channel，可以使用recover机制来上个保险，避免程序因为panic而崩溃。 1234567891011func SafeClose(ch chan T) (justClosed bool) { defer func() { if recover() != nil { justClosed = false } }() // assume ch != nil here. close(ch) // panic if ch is closed return true // &lt;=&gt; justClosed = true; return} 使用这种方法明显违背了上面的channel关闭原则，然后性能还可以，毕竟在每个协程只会调用一次SafeClose，性能损失很小。 同样也可以在生产消息的时候使用recover方法。 123456789101112func SafeSend(ch chan T, value T) (closed bool) { defer func() { if recover() != nil { // The return result can be altered // in a defer function call. closed = true } }() ch &lt;- value // panic if ch is closed return false // &lt;=&gt; closed = false; return} 礼貌地关闭channel方法还有不少人经常使用用sync.Once来关闭channel，这样可以确保只会关闭一次 1234567891011121314type MyChannel struct { C chan T once sync.Once}func NewMyChannel() *MyChannel { return &amp;MyChannel{C: make(chan T)}}func (mc *MyChannel) SafeClose() { mc.once.Do(func() { close(mc.C) })} 同样我们也可以使用sync.Mutex达到同样的目的。 123456789101112131415161718192021222324type MyChannel struct { C chan T closed bool mutex sync.Mutex}func NewMyChannel() *MyChannel { return &amp;MyChannel{C: make(chan T)}}func (mc *MyChannel) SafeClose() { mc.mutex.Lock() if !mc.closed { close(mc.C) mc.closed = true } mc.mutex.Unlock()}func (mc *MyChannel) IsClosed() bool { mc.mutex.Lock() defer mc.mutex.Unlock() return mc.closed} 要知道golang的设计者不提供SafeClose或者SafeSend方法是有原因的，他们本来就不推荐在消费端或者在并发的多个生产端关闭channel，比如关闭只读channel在语法上就彻底被禁止使用了。 优雅地关闭channel的方法上文的SafeSend方法一个很大的劣势在于它不能用在select块的case语句中。而另一个很重要的劣势在于像我这样对代码有洁癖的人来说，使用panic/recover和sync/mutex来搞定不是那么的优雅。下面我们引入在不同的场景下可以使用的纯粹的优雅的解决方法。 多个消费者，单个生产者。这种情况最简单，直接让生产者关闭channel好了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package mainimport ( \"time\" \"math/rand\" \"sync\" \"log\")func main() { rand.Seed(time.Now().UnixNano()) log.SetFlags(0) // ... const MaxRandomNumber = 100000 const NumReceivers = 100 wgReceivers := sync.WaitGroup{} wgReceivers.Add(NumReceivers) // ... dataCh := make(chan int, 100) // the sender go func() { for { if value := rand.Intn(MaxRandomNumber); value == 0 { // The only sender can close the channel safely. close(dataCh) return } else { dataCh &lt;- value } } }() // receivers for i := 0; i &lt; NumReceivers; i++ { go func() { defer wgReceivers.Done() // Receive values until dataCh is closed and // the value buffer queue of dataCh is empty. for value := range dataCh { log.Println(value) } }() } wgReceivers.Wait()} 多个生产者，单个消费者。这种情况要比上面的复杂一点。我们不能在消费端关闭channel，因为这违背了channel关闭原则。但是我们可以让消费端关闭一个附加的信号来通知发送端停止生产数据。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374package mainimport ( \"time\" \"math/rand\" \"sync\" \"log\")func main() { rand.Seed(time.Now().UnixNano()) log.SetFlags(0) // ... const MaxRandomNumber = 100000 const NumSenders = 1000 wgReceivers := sync.WaitGroup{} wgReceivers.Add(1) // ... dataCh := make(chan int, 100) stopCh := make(chan struct{}) // stopCh is an additional signal channel. // Its sender is the receiver of channel dataCh. // Its reveivers are the senders of channel dataCh. // senders for i := 0; i &lt; NumSenders; i++ { go func() { for { // The first select here is to try to exit the goroutine // as early as possible. In fact, it is not essential // for this example, so it can be omitted. select { case &lt;- stopCh: return default: } // Even if stopCh is closed, the first branch in the // second select may be still not selected for some // loops if the send to dataCh is also unblocked. // But this is acceptable, so the first select // can be omitted. select { case &lt;- stopCh: return case dataCh &lt;- rand.Intn(MaxRandomNumber): } } }() } // the receiver go func() { defer wgReceivers.Done() for value := range dataCh { if value == MaxRandomNumber-1 { // The receiver of the dataCh channel is // also the sender of the stopCh cahnnel. // It is safe to close the stop channel here. close(stopCh) return } log.Println(value) } }() // ... wgReceivers.Wait()} 就上面这个例子，生产者同时也是退出信号channel的接受者，退出信号channel仍然是由它的生产端关闭的，所以这仍然没有违背channel关闭原则。值得注意的是，这个例子中生产端和接受端都没有关闭消息数据的channel，channel在没有任何goroutine引用的时候会自行关闭，而不需要显示进行关闭。 多个生产者，多个消费者这是最复杂的一种情况，我们既不能让接受端也不能让发送端关闭channel。我们甚至都不能让接受者关闭一个退出信号来通知生产者停止生产。因为我们不能违反channel关闭原则。但是我们可以引入一个额外的协调者来关闭附加的退出信号channel。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126package mainimport ( \"time\" \"math/rand\" \"sync\" \"log\" \"strconv\")func main() { rand.Seed(time.Now().UnixNano()) log.SetFlags(0) // ... const MaxRandomNumber = 100000 const NumReceivers = 10 const NumSenders = 1000 wgReceivers := sync.WaitGroup{} wgReceivers.Add(NumReceivers) // ... dataCh := make(chan int, 100) stopCh := make(chan struct{}) // stopCh is an additional signal channel. // Its sender is the moderator goroutine shown below. // Its reveivers are all senders and receivers of dataCh. toStop := make(chan string, 1) // The channel toStop is used to notify the moderator // to close the additional signal channel (stopCh). // Its senders are any senders and receivers of dataCh. // Its reveiver is the moderator goroutine shown below. var stoppedBy string // moderator go func() { stoppedBy = &lt;- toStop close(stopCh) }() // senders for i := 0; i &lt; NumSenders; i++ { go func(id string) { for { value := rand.Intn(MaxRandomNumber) if value == 0 { // Here, a trick is used to notify the moderator // to close the additional signal channel. select { case toStop &lt;- \"sender#\" + id: default: } return } // The first select here is to try to exit the goroutine // as early as possible. This select blocks with one // receive operation case and one default branches will // be optimized as a try-receive operation by the // official Go compiler. select { case &lt;- stopCh: return default: } // Even if stopCh is closed, the first branch in the // second select may be still not selected for some // loops (and for ever in theory) if the send to // dataCh is also unblocked. // This is why the first select block is needed. select { case &lt;- stopCh: return case dataCh &lt;- value: } } }(strconv.Itoa(i)) } // receivers for i := 0; i &lt; NumReceivers; i++ { go func(id string) { defer wgReceivers.Done() for { // Same as the sender goroutine, the first select here // is to try to exit the goroutine as early as possible. select { case &lt;- stopCh: return default: } // Even if stopCh is closed, the first branch in the // second select may be still not selected for some // loops (and for ever in theory) if the receive from // dataCh is also unblocked. // This is why the first select block is needed. select { case &lt;- stopCh: return case value := &lt;-dataCh: if value == MaxRandomNumber-1 { // The same trick is used to notify // the moderator to close the // additional signal channel. select { case toStop &lt;- \"receiver#\" + id: default: } return } log.Println(value) } } }(strconv.Itoa(i)) } // ... wgReceivers.Wait() log.Println(\"stopped by\", stoppedBy)} 以上三种场景不能涵盖全部，但是它们是最常见最通用的三种场景，基本上所有的场景都可以划分为以上三类。 总结首先从三种场景中我们可以得到的结论是永远都是从生产者那边驱动关闭channel，即使不在生产者那边去关闭，也是生产者发送一个关闭的驱动的信息，然后消费者在那边根据回应的消息做出是否要关闭channel，这样才可以channel是被正常关闭。 在多对多的模式中，也是通过生产者驱动channel关闭，但是中间多了一个协调者。为什么要多一个协调者？ 因为我们要保证channel仅只被关闭一次，如果是多个生产者的话，谁来做这个关闭操作呢？因此只能是由一个第三方中间人去做这个事情。 情况一：生产者根据条件主动发送事件channel123456789if value == 0 { // Here, a trick is used to notify the moderator // to close the additional signal channel. select { case toStop &lt;- \"sender#\" + id: default: } return} 情况二：消费者根据生产者的数据条件被动发送事件关闭channel不过是那边驱动消息发送过来，我认为关闭的条件仍然是由生产者决定，因为多对多的情况下，消费者依然要根据生产者的数据来做出判断，所以决定channel是否关闭，仍然取决于生产者来控制。 1234567891011case value := &lt;-dataCh: if value == MaxRandomNumber-1 { // The same trick is used to notify // the moderator to close the // additional signal channel. select { case toStop &lt;- \"receiver#\" + id: default: } return } 再来看看channel的关闭原则不要在消费端关闭channel，不要在有多个并行的生产者时对channel执行关闭操作，似乎是印证了我的想法。","link":"/2020/07/14/Go/Golang%E8%AF%91%E6%96%87/%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E5%85%B3%E9%97%ADGo-Channel/"},{"title":"(译) 我是如何在大型代码库上使用 pprof 调查 Go 中的内存泄漏","text":"在今年的大部分时间里,我一直在 Orbs 团队用 Go 语言做可扩展的区块链的基础设施开发,这是令人兴奋的一年。在 2018 年的时候,我们研究我们的区块链该选择哪种语言实现。因为我们知道 Go 拥有一个良好的社区和一个非常棒的工具集,所以我们选择了 Go。 最近几周,我们进入了系统整合的最后阶段。与任何大型系统一样,可能会在后期阶段出现一些问题,包括性能问题,内存泄漏等。当整合系统时,我们找到了一个不错的方法。在本文中,我将介绍如何调查 Go 中的内存泄漏,详细说明寻找,理解和解决它的步骤。 Golang 提供的工具集非常出色但也有其局限性。首先来看看这个问题,最大的一个问题是查询完整的 core dumps 能力有限。完整的 core dumps 是程序运行时的进程占用内存（或用户内存）的镜像。 我们可以把内存映射想象成一棵树,遍历那棵树我们会得到不同的对象分配和关系。这意味着无论如何根会持有内存而不被 GCing（垃圾回收）内存的原因。因为在 Go 中没有简单的方法来分析完整的 core dump,所以很难找到一个没有被 GC 过的对象的根。 在撰写本文时,我们无法在网上找到任何可以帮助我们的工具。由于存在 core dump 格式以及从 debug 包中导出该文件的简单方法,这可能是 Google 使用过的一种方法。网上搜索它看起来像是在 Golang pipeline 中创建了这样的 core dump 查看器,但看起来并不像有人在使用它。话虽如此,即使没有这样的解决方案,使用现有工具我们通常也可以找到根本原因。 内存泄漏内存泄漏或内存压力可以以多种形式出现在整个系统中。通常我们将它们视为 bug,但有时它们的根本原因可能是因为设计的问题。 当我们在新的设计原则下构建我们的系统时,这些考虑并不重要。更重要的是以避免过早优化的方式构建系统,并使你能够在代码成熟后再优化它们,而不是从一开始就过度设计它。然而,一些常见内存压力的问题是： 内存分配太多,数据表示不正确 大量使用反射或字符串 使用全局变量 孤儿,没有结束的 goroutines 在 Go 中,创建内存泄漏的最简单方法是定义全局变量,数组,然后将该数据添加到数组。这篇博客文章以一种不错的方式描述了这个例子。 我为什么要写这篇文章呢？当我研究这个例子时,我发现了很多关于内存泄漏的方法。但是,相比较这个例子,我们的真实系统有超过 50 行代码和单个结构。在这种情况下,找到内存问题的来源比该示例描述的要复杂得多。 Golang 为我们提供了一个神奇的工具叫pprof。掌握此工具后,可以帮助调查并发现最有可能的内存问题。它的另一个用途是查找 CPU 问题,但我不会在这篇文章中介绍任何与 CPU 有关的内容。 go tool pprof把这个工具的方方面面讲清楚需要不止一篇博客文章。我将花一点时间找出怎么使用这个工具去获取有用的东西。在这篇文章里,将集中在它的内存相关功能上。 pprof包创建一个 heap dump 文件,你可以在随后进行分析/可视化以下两种内存映射： 当前的内存分配 总（累积）内存分配 该工具可以比较快照。例如,可以让你比较显示现在和 30 秒前的差异。对于压力场景,这可以帮助你定位到代码中有问题的区域。 pprof 画像pprof 的工作方式是使用画像。 画像是一组显示导致特定事件实例的调用顺序堆栈的追踪,例如内存分配。 文件runtime/pprof/pprof.go包含画像的详细信息和实现。 Go 有几个内置的画像供我们在常见情况下使用： goroutine - 所有当前 goroutines 的堆栈跟踪 heap - 活动对象的内存分配的样本 allocs - 过去所有内存分配的样本 threadcreate - 导致创建新 OS 线程的堆栈跟踪 block - 导致阻塞同步原语的堆栈跟踪 mutex - 争用互斥锁持有者的堆栈跟踪 在查看内存问题时,我们将专注于堆画像。 allocs 画像和它在关于数据收集方面是相同的。两者之间的区别在于 pprof 工具在启动时读取的方式不一样。 allocs 画像将以显示自程序启动以来分配的总字节数（包括垃圾收集的字节）的模式启动 pprof。在尝试提高代码效率时,我们通常会使用该模式。 堆简而言之,这是 OS（操作系统）存储我们代码中对象占用内存的地方。这块内存随后会被“垃圾回收”,或者在非垃圾回收语言中手动释放。 堆不是唯一发生内存分配的地方,一些内存也在栈中分配。栈主要是短周期的内存。在 Go 中,栈通常用于在函数闭包内发生的赋值。 Go 使用栈的另一个地方是编译器“知道”在运行时需要多少内存（例如固定大小的数组）。有一种方法可以使 Go 编译器将栈“转义”到堆中输出分析,但我不会在这篇文章中谈到它。 堆数据需要“释放”和垃圾回收,而栈数据则不需要。这意味着使用栈效率更高。 这是分配不同位置的内存的简要说明。还有更多内容,但这不在本文的讨论范围之内。 使用 pprof 获取堆数据获取数据主要有两种方式。第一种通常是把代码加入到测试或分支中,包括导入runtime/pprof,然后调用pprof.WriteHeapProfile(some_file)来写入堆信息。 请注意,WriteHeapProfile是用于运行的语法糖： 12// lookup takes a profile namepprof.Lookup(\"heap\").WriteTo(some_file, 0) 根据文档,WriteHeapProfile可以向后兼容。其余类型的画像没有这样的便捷方式,必须使用Lookup()函数来获取其画像数据。 第二个更有意思,是通过 HTTP（基于 Web 的 endpoints）来启用。这允许你从正在运行的 e2e/test 环境中的容器中去提取数据,甚至从“生产”环境中提取数据。这是 Go 运行时和工具集所擅长的部分。整个包文档可以在这里找到,太长不看版,只需要你将它添加到代码中： 123456789import ( \"net/http\" _ \"net/http/pprof\")...func main() { ... http.ListenAndServe(\"localhost:8080\", nil)} 导入net/http/pprof的“副作用”是在/debug/pprof的 web 服务器根目录下会注册 pprof endpoint。现在使用 curl 我们可以获取要查看的堆信息文件： 1curl -sK -v http://localhost:8080/debug/pprof/heap &gt; heap.out 只有在你的程序之前没有 http listener 时才需要添加上面的http.ListenAndServe()。如果有的话就没有必要再监听了,它会自动处理。还可以使用ServeMux.HandleFunc()来设置它,这对于更复杂的 http 程序有意义。 使用 pprof所以我们收集了这些数据,现在该干什么呢？如上所述,pprof 有两种主要的内存分析策略。一个是查看当前的内存分配（字节或对象计数）,称为inuse。另一个是查看整个程序运行时的所有分配的字节或对象计数,称为alloc。这意味着无论它是否被垃圾回收,都会是所有样本的总和。 在这里我们需要重申一下堆画像文件是内存分配的样例。幕后的pprof使用runtime.MemProfile函数,该函数默认按分配字节每 512KB 收集分配信息。可以修改 MemProfile 以收集所有对象的信息。需要注意的是,这很可能会降低应用程序的运行速度。 这意味着默认情况下,对于在 pprof 监控下抖动的小对象,可能会出现问题。对于大型代码库/长期运行的程序,这不是问题。 一旦收集好画像文件后,就可以将其加载到 pprof 的交互式命令行中了,通过运行： 1&gt; go tool pprof heap.out 我们可以观察到显示的信息 1234Type: inuse_spaceTime: Jan 22, 2019 at 1:08pm (IST)Entering interactive mode (type \"help\" for commands, \"o\" for options)(pprof) 这里要注意的事项是Type：inuse_space。这意味着我们正在查看特定时刻的内存分配数据（当我们捕获该配置文件时）。type 是sample_index的配置值,可能的值为： inuse_space - 已分配但尚未释放的内存数量 inuse_objects - 已分配但尚未释放的对象数量 alloc_space - 已分配的内存总量（不管是否已释放） alloc_objects - 已分配的对象总量（不管是否已释放） 现在在交互命令行中输入top,将输出顶级内存消费者 123456789101112131415(pprof) topShowing nodes accounting for 330.04MB, 93.73% of 352.11MB totalDropped 19 nodes (cum &lt;= 1.76MB)Showing top 10 nodes out of 56 flat flat% sum% cum cum% 142.02MB 40.33% 40.33% 142.02MB 40.33% github.com/orbs-network/orbs-network-go/vendor/github.com/orbs-network/membuffers/go.(*InternalMessage).lazyCalcOffsets 28MB 7.95% 48.29% 28MB 7.95% github.com/orbs-network/orbs-network-go/vendor/github.com/orbs-network/orbs-spec/types/go/protocol.TransactionsBlockProofReader (inline) 26.51MB 7.53% 55.81% 39.01MB 11.08% github.com/orbs-network/orbs-network-go/vendor/github.com/orbs-network/orbs-spec/types/go/protocol.(*ResultsBlockHeaderBuilder).Build 25.51MB 7.24% 63.06% 32.51MB 9.23% github.com/orbs-network/orbs-network-go/vendor/github.com/orbs-network/orbs-spec/types/go/protocol.(*ResultsBlockProofBuilder).Build 23MB 6.53% 69.59% 23MB 6.53% github.com/orbs-network/orbs-network-go/vendor/github.com/orbs-network/orbs-spec/types/go/protocol.ResultsBlockHeaderReader (inline) 20.50MB 5.82% 75.41% 20.50MB 5.82% github.com/orbs-network/orbs-network-go/vendor/github.com/orbs-network/orbs-spec/types/go/protocol.TransactionsBlockMetadataReader (inline) 20MB 5.68% 81.09% 20MB 5.68% github.com/orbs-network/orbs-network-go/vendor/github.com/orbs-network/orbs-spec/types/go/protocol.TransactionsBlockHeaderReader (inline) 16MB 4.54% 85.64% 24MB 6.82% github.com/orbs-network/orbs-network-go/vendor/github.com/orbs-network/orbs-spec/types/go/protocol.(*TransactionsBlockHeaderBuilder).Build 14.50MB 4.12% 89.76% 122.51MB 34.79% github.com/orbs-network/orbs-network-go/services/gossip/codec.DecodeBlockPairs 14MB 3.98% 93.73% 14MB 3.98% github.com/orbs-network/orbs-network-go/vendor/github.com/orbs-network/orbs-spec/types/go/protocol.ResultsBlockProofReader (inline) 我们可以看到关于Dropped Nodes的一系列数据,这意味着它们被过滤掉了。一个节点或树中的一个“节点”就是一整个对象。丢弃节点有利于我们更快的找到问题,但有时它可能会隐藏内存问题产生的根本原因。我们继续看一个例子。 如果要该画像文件的所有数据,请在运行 pprof 时添加-nodefraction=0选项,或在交互命令行中键入nodefraction=0。 在输出列表中,我们可以看到两个值,flat和cum。 flat表示堆栈中当前层函数的内存 cum表示堆栈中直到当前层函数所累积的内存 仅仅这个信息有时可以帮助我们了解是否存在问题。例如,一个函数负责分配了大量内存但没有保留内存的情况。这意味着某些其他对象指向该内存并维护其分配,这说明我们可能存在系统设计的问题或 bug。 top实际上运行了top10。top 命令支持topN格式,其中N是你想要查看的条目数。在上面的情况,如果键入top70将输出所有节点。 可视化虽然topN提供了一个文本列表,但 pprof 附带了几个非常有用的可视化选项。可以输入png或gif等等（请参阅go tool pprof -help获取完整信息）。 在我们的系统上,默认的可视化输出类似于： 这看起来可能有点吓人,但它是程序中内存分配流程（根据堆栈跟踪）的可视化。阅读图表并不像看起来那么复杂。带有数字的白色方块显示已分配的空间（在图形边缘上是它占用内存的数量）,每个更宽的矩形显示调用的函数。 需要注意的是,在上图中,我从执行模式inuse_space中取出了一个 png。很多时候你也应该看看inuse_objects,因为它可以帮助你找到内存分配问题。 深入挖掘,寻找根本原因到目前为止,我们能够理解应用程序在运行期间内存怎么分配的。这有助于我们了解我们程序的行为（或不好的行为）。 在我们的例子中,我们可以看到内存由membuffers持有,这是我们的数据序列化库。这并不意味着我们在该代码段有内存泄漏,这意味着该函数持有了内存。了解如何阅读图表以及 pprof 输出非常重要。在这个例子中,当我们序列化数据时,意味着我们将内存分配给结构和原始对象（int,string）,它不会被释放。 跳到结论部分,我们可以假设序列化路径上的一个节点负责持有内存,例如： 我们可以看到日志库中链中的某个地方,控制着&gt;50MB 的已分配内存。这是由我们的日志记录器调用函数分配的内存。经过思考,这实际上是预料之中的。日志记录器会分配内存,是因为它需要序列化数据以将其输出到日志,因此它会造成进程中的内存分配。 我们还可以看到,在分配路径下,内存仅由序列化持有,而不是任何其他内容。此外,日志记录器保留的内存量约为总量的 30％。综上告诉我们,最有可能的问题不在于日志记录器。如果它是 100％,或接近它,那么我们应该一直找下去 - 但事实并非如此。这可能意味着它记录了一些不应该记录的东西,但不是日志记录器的内存泄漏。 是时候介绍另一个名为list的pprof命令。它接受一个正则表达式,该表达式是内容的过滤器。 “list”实际上是与分配相关的带注释的源代码。在我们可以看到在日志记录器的上下文中将执行list RequestNew,因为我们希望看到对日志记录器的调用。这些调用来自恰好以相同前缀开头的两个函数。 12345678910111213141516171819202122232425262728293031323334353637383940(pprof) list RequestNewTotal: 352.11MBROUTINE ======================== github.com/orbs-network/orbs-network-go/services/consensuscontext.(*service).RequestNewResultsBlock in /Users/levison/work/go/src/github.com/orbs-network/orbs-network-go/services/consensuscontext/service.go 0 77.51MB (flat, cum) 22.01% of Total . . 82:} . . 83: . . 84:func (s *service) RequestNewResultsBlock(ctx context.Context, input *services.RequestNewResultsBlockInput) (*services.RequestNewResultsBlockOutput, error) { . . 85: logger := s.logger.WithTags(trace.LogFieldFrom(ctx)) . . 86: . 47.01MB 87: rxBlock, err := s.createResultsBlock(ctx, input) . . 88: if err != nil { . . 89: return nil, err . . 90: } . . 91: . 30.51MB 92: logger.Info(&quot;created Results block&quot;, log.Stringable(&quot;results-block&quot;, rxBlock)) . . 93: . . 94: return &amp;services.RequestNewResultsBlockOutput{ . . 95: ResultsBlock: rxBlock, . . 96: }, nil . . 97:}ROUTINE ======================== github.com/orbs-network/orbs-network-go/services/consensuscontext.(*service).RequestNewTransactionsBlock in /Users/levison/work/go/src/github.com/orbs-network/orbs-network-go/services/consensuscontext/service.go 0 64.01MB (flat, cum) 18.18% of Total . . 58:} . . 59: . . 60:func (s *service) RequestNewTransactionsBlock(ctx context.Context, input *services.RequestNewTransactionsBlockInput) (*services.RequestNewTransactionsBlockOutput, error) { . . 61: logger := s.logger.WithTags(trace.LogFieldFrom(ctx)) . . 62: logger.Info(&quot;starting to create transactions block&quot;, log.BlockHeight(input.CurrentBlockHeight)) . 42.50MB 63: txBlock, err := s.createTransactionsBlock(ctx, input) . . 64: if err != nil { . . 65: logger.Info(&quot;failed to create transactions block&quot;, log.Error(err)) . . 66: return nil, err . . 67: } . . 68: . . 69: s.metrics.transactionsRate.Measure(int64(len(txBlock.SignedTransactions))) . 21.50MB 70: logger.Info(&quot;created transactions block&quot;, log.Int(&quot;num-transactions&quot;, len(txBlock.SignedTransactions)), log.Stringable(&quot;transactions-block&quot;, txBlock)) . . 71: s.printTxHash(logger, txBlock) . . 72: return &amp;services.RequestNewTransactionsBlockOutput{ . . 73: TransactionsBlock: txBlock, . . 74: }, nil . . 75:} 我们可以看到所做的内存分配位于cum列中,这意味着分配的内存保留在调用栈中。这与图表显示的内容相关。此时很容易看出日志记录器分配内存是因为我们发送了整个“block”对象造成的。这个对象需要序列化它的某些部分（我们的对象是 membuffer 对象,它实现了一些String()函数）。它是一个有用的日志,还是一个好的做法？可能不是,但它不是日志记录器端或调用日志记录器的代码产生了内存泄漏, list在GOPATH路径下搜索可以找到源代码。如果它搜索的根不匹配（取决于你电脑的项目构建）,则可以使用-trim_path选项。这将有助于修复它并让你看到带注释的源代码。当正在捕获堆配置文件时要将 git 设置为可以正确提交。 内存泄漏原因之所以调查是因为怀疑有内存泄漏的问题。我们发现内存消耗高于系统预期的需要。最重要的是,我们看到它不断增加,这是“这里有问题”的另一个强有力的指标。 此时,在 Java 或.Net 的情况下,我们将打开一些’gc roots’分析或分析器,并获取引用该数据并造成泄漏的实际对象。正如所解释的那样,对于 Go 来说这是不可能的,因为工具问题也是由于 Go 低等级的内存表示。 没有详细说明,我们不知道 Go 把哪个对象存储在哪个地址（指针除外）。这意味着实际上,了解哪个内存地址表示对象（结构）的哪个成员将需要把某种映射输出到堆画像文件。这可能意味着在进行完整的 core dump 之前,还应该采用堆画像文件,以便将地址映射到分配的行和文件,从而映射到内存中表示的对象。 此时,因为我们熟悉我们的系统,所以很容易理解这不再是一个 bug。它（几乎）是设计的。但是让我们继续探索如何从工具（pprof）中获取信息以找到根本原因。 设置nodefraction=0时,我们将看到已分配对象的整个图,包括较小的对象。我们来看看输出： 我们有两个新的子树。再次提醒,pprof 堆画像文件是内存分配的采样。对于我们的系统而言 - 我们不会遗漏任何重要信息。这个较长的绿色新子树的部分是与系统的其余部分完全断开的测试运行器,在本篇文章中我没有兴趣考虑它。 较短的蓝色子树,有一条边连接到整个系统是inMemoryBlockPersistance。这个名字也解释了我们想象的’泄漏’。这是数据后端,它将所有数据存储在内存中而不是持久化到磁盘。值得注意的是,我们可以看到它持有两个大的对象。为什么是两个？因为我们可以看到对象大小为 1.28MB,函数占用大小为 2.57MB。 这个问题很好理解。我们可以使用 delve（调试器）（译者注：deleve）来查看调试我们代码中的内存情况。 如何修复这是一个糟糕的人为错误。虽然这个过程是有教育意义的,我们能不能做得更好呢？ 我们仍然能“嗅探到”这个堆信息。反序列化的数据占用了太多的内存,为什么 142MB 的内存需要大幅减少呢？.. pprof 可以回答这个问题 - 实际上,它确实可以回答这些问题。 要查看函数的带注释的源代码,我们可以运行list lazy。我们使用lazy,因为我们正在寻找的函数名是lazyCalcOffsets(),而且我们的代码中也没有以 lazy 开头的其他函数。当然输入list lazyCalcOffsets也可以。 123456789101112131415161718192021222324(pprof) list lazyTotal: 352.11MBROUTINE ======================== github.com/orbs-network/orbs-network-go/vendor/github.com/orbs-network/membuffers/go.(*InternalMessage).lazyCalcOffsets in /Users/levison/work/go/src/github.com/orbs-network/orbs-network-go/vendor/github.com/orbs-network/membuffers/go/message.go 142.02MB 142.02MB (flat, cum) 40.33% of Total . . 29: . . 30:func (m *InternalMessage) lazyCalcOffsets() bool { . . 31: if m.offsets != nil { . . 32: return true . . 33: } 36MB 36MB 34: res := make(map[int]Offset) . . 35: var off Offset = 0 . . 36: var unionNum = 0 . . 37: for fieldNum, fieldType := range m.scheme { . . 38: // write the current offset . . 39: off = alignOffsetToType(off, fieldType) . . 40: if off &gt;= m.size { . . 41: return false . . 42: } 106.02MB 106.02MB 43: res[fieldNum] = off . . 44: . . 45: // skip over the content to the next field . . 46: if fieldType == TypeUnion { . . 47: if off + FieldSizes[TypeUnion] &gt; m.size { . . 48: return false 我们可以看到两个有趣的信息。同样,请记住 pprof 堆画像文件会对有关分配的信息进行采样。我们可以看到flat和cum数字是相同的。这表明分配的内存也在这些分配点被保留。 接下来,我们可以看到make()占用了一些内存。这是很正常的,它是指向数据结构的指针。然而,我们也看到第 43 行的赋值占用了内存,这意味着它分配了内存。 这让我们学习了映射 map,其中 map 的赋值不是简单的变量赋值。本文详细介绍了 map 的工作原理。简而言之,map 与切片相比,map 开销更大,“成本”更大,元素更多。 接下来应该保持警惕：如果内存消费是一个相关的考虑因素的话,当数据不稀疏或者可以转换为顺序索引时,使用map[int]T也没问题,但是通常应该使用切片实现。然而,当扩容一个大的切片时,切片可能会使操作变慢,在 map 中这种变慢可以忽略不计。优化没有万能的方法。 在上面的代码中,在检查了我们如何使用该 map 之后,我们意识到虽然我们想象它是一个稀疏数组,但它并不是那么稀疏。这与上面描述的情况匹配,我们能马上想到一个将 map 改为切片的小型重构实际上是可行的,并且可能使该代码内存效率更好。所以我们将其改为： 1234567891011121314func (m *InternalMessage) lazyCalcOffsets() bool { if m.offsets != nil { return true } res := make([]Offset, len(m.scheme)) var off Offset = 0 var unionNum = 0 for fieldNum, fieldType := range m.scheme { // write the current offset off = alignOffsetToType(off, fieldType) if off &gt;= m.size { return false } res[fieldNum] = off 就这么简单,我们现在使用切片替代了 map。由于我们接收数据的方式是懒加载进去的,并且我们随后如何访问这些数据,除了这两行和保存该数据的结构之外,不需要修改其他代码。这些修改对内存消耗有什么影响？ 让我们来看看benchcmp的几次测试 1234567891011121314151617benchmark old ns/op new ns/op deltaBenchmarkUint32Read-4 2047 1381 -32.54%BenchmarkUint64Read-4 507 321 -36.69%BenchmarkSingleUint64Read-4 251 164 -34.66%BenchmarkStringRead-4 1572 1126 -28.37%benchmark old allocs new allocs deltaBenchmarkUint32Read-4 14 7 -50.00%BenchmarkUint64Read-4 4 2 -50.00%BenchmarkSingleUint64Read-4 2 1 -50.00%BenchmarkStringRead-4 12 6 -50.00%benchmark old bytes new bytes deltaBenchmarkUint32Read-4 1120 80 -92.86%BenchmarkUint64Read-4 320 16 -95.00%BenchmarkSingleUint64Read-4 160 8 -95.00%BenchmarkStringRead-4 960 32 -96.67% 读取测试的初始化创建分配的数据结构。我们可以看到运行时间提高了约 30％,内存分配下降了 50％,内存消耗提高了&gt; 90％（！） 由于切片（之前是 map）从未添加过很多数据,因此这些数字几乎显示了我们将在生产中看到的内容。它取决于数据熵,但可能在内存分配和内存消耗还有提升的空间。 从同一测试中获取堆画像文件来看一下pprof,我们将看到现在内存消耗实际上下降了约 90％。 需要注意的是,对于较小的数据集,在切片满足的情况就不要使用 map,因为 map 的开销很大。 完整的 core dump如上所述,这就是我们现在看到工具受限制的地方。当我们调查这个问题时,我们相信自己能够找到根对象,但没有取得多大成功。随着时间的推移,Go 会以很快的速度发展,但在完全转储或内存表示的情况下,这种演变会带来代价。完整的堆转储格式在修改时不向后兼容。这里描述的最新版本和写入完整堆转储,可以使用debug.WriteHeapDump()。 虽然现在我们没有“陷入困境”,因为没有很好的解决方案来探索完全转储（full down）。 目前为止,pprof回答了我们所有的问题。 请注意,互联网会记住许多不再相关的信息。如果你打算尝试自己打开一个完整的转储,那么你应该忽略一些事情,从 go1.11 开始： 没有办法在 MacOS 上打开和调试完整的 core dump,只有 Linux 可以。 https://github.com/randall77/hprof上的工具适用于 Go1.3,它存在 1.7+的分支,但它也不能正常工作（不完整）。 在https://github.com/golang/debug/tree/master/cmd/viewcore上查看并不真正编译。它很容易修复（内部的包指向 golang.org 而不是 github.com）,但是,在 MacOS 或者 Linux 上可能都不起作用。 此外,https://github.com/randall77/corelib在 MacOS 也会失败 pprof UI关于 pprof,要注意的一个细节是它的 UI 功能。在开始调查与使用 pprof 画像文件相关的问题时可以节省大量时间。（译者注：需要安装 graphviz） 1go tool pprof -http=:8080 heap.out 此时它应该打开 Web 浏览器。如果没有,则浏览你设置的端口。它使你能够比命令行更快地更改选项并获得视觉反馈。消费信息的一种非常有用的方法。 UI 确实让我熟悉了火焰图,它可以非常快速地暴露代码的罪魁祸首。 结论Go 是一种令人兴奋的语言,拥有非常丰富的工具集,你可以用 pprof 做更多的事情。例如,这篇文章没有涉及到的 CPU 分析。 其他一些好的文章： https://rakyll.org/archive/ - 我相信这是围绕性能监控的主要贡献者之一,她的博客上有很多好帖子 https://github.com/google/gops - 由JBD（运行 rakyll.org）编写,此工具保证是自己的博客文章。 https://medium.com/@cep21/using-go-1-10-new-trace-features-to-debug-an-integration-test-1dc39e4e812d - go tool trace是用来做 CPU 分析的,这是一个关于该分析功能的不错的帖子。 原文地址：How I investigated memory leaks in Go using pprof on a large codebase","link":"/2020/04/23/Go/Golang%E8%AF%91%E6%96%87/%E6%88%91%E6%98%AF%E5%A6%82%E4%BD%95%E5%9C%A8%E5%A4%A7%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%BA%93%E4%B8%8A%E4%BD%BF%E7%94%A8pprof%E8%B0%83%E6%9F%A5Go%E4%B8%AD%E7%9A%84%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F/"},{"title":"(译) Go中的调度：第I部分 - OS调度程序","text":"这是三部分系列中的第一篇文章,它将提供对Go中调度程序背后的机制和语义的理解。本文重点介绍操作系统调度程序。 三部分系列的索引： Go中的调度：第I部分 - OS调度程序 Go中的调度：第II部分 - Go Scheduler Go中的调度：第III部分 - 并发 介绍Go调度程序的设计和行为使你的多线程Go程序更高效,更高效。这要归功于Go调度程序对操作系统（OS）调度程序的机械支持。但是,如果多线程Go软件的设计和行为与调度程序的工作方式没有机械上的支持,那么这一切都不重要。了解OS和Go调度程序如何正确设计多线程软件非常重要。 这篇由多部分组成的文章将重点介绍调度程序的更高级别的机制和语义。我将提供足够的详细信息,以便你可以看到工作原理,以便你做出更好的工程决策。尽管你需要为多线程应用程序做出很多工程决策,但是机制和语义构成了你所需的基础知识的关键部分。 OS Scheduler操作系统调度程序是复杂的软件。他们必须考虑他们运行的硬件的布局和设置。这包括但不限于存在多个处理器和内核,CPU缓存和NUMA。没有这些知识,调度程序就不能尽可能高效。最棒的是,你仍然可以开发一个关于操作系统调度程序如何工作的良好心理模型,而无需深入研究这些主题。 你的程序只是一系列需要依次执行的机器指令。为了实现这一点,操作系统使用处理的概念。线程的工作是考虑并顺序执行它分配的指令集。执行继续,直到没有更多的线程执行指令。这就是我称之为“执行之路”的线程的原因。 你运行的每个程序都会创建一个处理器,并为每个处理器提供一个初始线程。线程可以创建更多的线程。所有这些不同的线程彼此独立地运行,并且调度决策在线程级别进行,而不是在进程级别。线程可以同时运行（每个线程在单个核心上转向）,也可以并行运行（每个线程在不同的核心上同时运行）。线程还保持自己的状态,以允许安全,本地和独立执行其指令。 如果存在可以执行的线程,则OS调度程序负责确保核心不空闲。它还必须创建一个错觉,即可以执行的所有线程同时执行。在创建这种错觉的过程中,调度程序需要运行优先级高于低优先级线程的线程。但是,具有较低优先级的线程不能缺乏执行时间。调度程序还需要通过快速而明智的决策尽可能地最小化调度延迟。 为实现这一目标,很多算法都要考虑到这一点,但幸运的是,该行业能够利用数十年的工作和经验。为了更好地理解所有这些,最好描述和定义一些重要的概念。 执行指令该程序计数器（PC）,有时被称为指令指针（IP）,就是允许的线程来跟踪下一个执行指令的。在大多数处理器中,PC指向下一条指令而不是当前指令。 如果你曾经看过Go程序的堆栈跟踪,你可能已经注意到每行末尾的这些小十六进制数字。寻找+0x39和+0x72清单1所示。 12345goroutine 1 [running]: main.example(0xc000042748, 0x2, 0x4, 0x106abae, 0x5, 0xa) stack_trace/example1/example1.go:13 +0x39 &lt;- LOOK HERE main.main() stack_trace/example1/example1.go:8 +0x72 &lt;- LOOK HERE 这些数字表示从相应功能的顶部偏移的PC值。该+0x39PC的偏移量代表的下一个指令线程将内部已经执行example的功能,如果该方法没有panic。在0+x72PC偏移值是内部的下一个指令main功能,如果控制正巧回到那个功能。更重要的是,该指针之前的指令会告诉你正在执行的指令。 查看清单2中的程序,该程序导致清单1中的堆栈跟踪。 清单2 123456789https://github.com/ardanlabs/gotraining/blob/master/topics/go/profiling/stack_trace/example1/example1.go07 func main() {08 example(make([]string, 2, 4), \"hello\", 10)09 }12 func example(slice []string, str string, i int) {13 panic(\"Want stack trace\")14 } 十六进制数+0x39表示example函数内部指令的PC偏移量,该指令比函数的起始指令低57（基数10）字节。在下面的清单3中,你可以看到一个objdump对的example从二元函数。找到第12条指令,它在底部列出。注意该指令上面的代码行是对它的调用panic。 12345678910111213141516$ go tool objdump -S -s \"main.example\" ./example1TEXT main.example(SB) stack_trace/example1/example1.gofunc example(slice []string, str string, i int) { 0x104dfa0 65488b0c2530000000 MOVQ GS:0x30, CX 0x104dfa9 483b6110 CMPQ 0x10(CX), SP 0x104dfad 762c JBE 0x104dfdb 0x104dfaf 4883ec18 SUBQ $0x18, SP 0x104dfb3 48896c2410 MOVQ BP, 0x10(SP) 0x104dfb8 488d6c2410 LEAQ 0x10(SP), BP panic(\"Want stack trace\") 0x104dfbd 488d059ca20000 LEAQ runtime.types+41504(SB), AX 0x104dfc4 48890424 MOVQ AX, 0(SP) 0x104dfc8 488d05a1870200 LEAQ main.statictmp_0(SB), AX 0x104dfcf 4889442408 MOVQ AX, 0x8(SP) 0x104dfd4 e8c735fdff CALL runtime.gopanic(SB) 0x104dfd9 0f0b UD2 &lt;--- LOOK HERE PC(+0x39) 请记住：PC是下一条指令,而不是当前指令。清单3是基于amd64的指令的一个很好的例子,该Go程序的Thread负责顺序执行。 线程状态另一个重要的概念是线程状态,它规定了调度程序对线程所采用的角色。线程可以处于以下三种状态之一：等待,可运行,执行。 等待：这意味着线程停止并等待某些东西才能继续。这可能是因为等待硬件（磁盘,网络）,操作系统（系统调用）或同步调用（原子,互斥）等原因。这些类型的延迟是性能不佳的根本原因。 可运行：这意味着线程需要时间在核心上,以便它可以执行其分配的机器指令。如果你有很多需要时间的线程,那么线程必须等待更长时间才能获得时间。此外,随着更多线程争用时间,缩短了任何给定线程获得的单独时间量。这种类型的调度延迟也可能是性能不佳的原因。 执行：这意味着线程已被放置在核心上并正在执行其机器指令。与应用程序相关的工作即将完成。这是每个人都想要的。 工作类型线程可以执行两种类型的工作。第一个称为CPU绑定,第二个称为IO绑定。 CPU绑定：这是永远不会创建线程可能处于等待状态的情况的工作。这是不断进行计算的工作。计算Pi到第N位的线程将是CPU绑定的。 IO绑定：这是导致线程进入等待状态的工作。这项工作包括请求通过网络访问资源或将系统调用进入操作系统。需要访问数据库的线程将是IO绑定。我将包括同步事件（互斥,原子）,导致线程等待此类别的一部分。 上下文切换如果你在Linux,Mac或Windows上运行,则运行在具有抢占式调度程序的操作系统上。这意味着一些重要的事情。首先,它意味着调度程序在任何给定时间选择运行什么线程时都是不可预测的。线程优先级与事件一起（如在网络上接收数据）使得无法确定调度程序将选择执行什么操作以及何时执行操作。 其次,这意味着你必须永远不要根据你有幸经历的一些感知行为编写代码,但不能保证每次都能发生。很容易让自己思考,因为我已经看到过这种情况发生了1000次,这是有保障的行为。如果在应用程序中需要确定性,则必须控制线程的同步和编排。 在核心上交换线程的物理行为称为上下文切换。当调度程序从核心拉出执行中的线程并用可运行的线程替换它时,就会发生上下文切换。从运行队列中选择的线程进入执行状态。被拉出的线程可以移回可运行状态（如果它仍然具有运行能力）,或者进入等待状态（如果由于IO绑定类型的请求而被替换）。 上下文切换被认为是昂贵的,因为在核心上交换线程需要花费很多时间。在上下文切换期间存在的等待时间量取决于不同的因素,但是它在~1000和~1500纳秒之间花费是不合理的。考虑到硬件应该能够合理地执行（平均）每个核心每纳秒12条指令,上下文切换可能需要大约12k到18k的延迟指令。实质上,你的程序在上下文切换期间失去了执行大量指令的能力。 如果你有一个专注于IO绑定工作的程序,那么上下文切换将是一个优势。一旦线程进入等待中状态,另一个处于可运行状态的线程就可以取代它。这使得核心始终可以正常工作。这是调度的最重要方面之一。如果有工作（处于可运行状态的线程）,则不允许内核空闲。 如果你的程序专注于CPU绑定工作,那么上下文切换将成为性能的噩梦。由于Thead总是有工作要做,因此上下文切换正在停止这项工作的进展。这种情况与IO绑定工作负载的情况形成鲜明对比 少即是多在处理器只有一个核心的早期阶段,调度并不过分复杂。因为你有一个单核处理器,所以在任何给定时间只能执行一个线程。我们的想法是定义一个调度程序周期并尝试在该段时间内执行所有Runnable线程。没问题：采用调度周期并除以需要执行的线程数。 例如,如果你将调度程序周期定义为10毫秒（毫秒）并且你有2个线程,则每个线程各获得5毫秒。如果你有5个线程,每个线程各获得2ms。但是,当你有100个线程时会发生什么？为每个线程提供10μs（微秒）的时间片不起作用,因为你将在上下文切换中花费大量时间。 你需要的是限制切片的短时间。在最后一种情况下,如果最小时间片是2ms并且你有100个线程,则调度程序周期需要增加到2000ms或2s（秒）。如果有1000个线程,现在你正在查看20秒的调度期间。如果每个线程使用其全时间片,则在此简单示例中所有线程运行一次需要20秒。 请注意,这是一个非常简单的世界观。在制定调度决策时,调度程序需要考虑和处理更多事情。您可以控制在应用程序中使用的线程数。当需要考虑更多的线程,并且发生IO-Bound工作时,会出现更多混乱和不确定行为。事情需要更长的时间来安排和执行。 这就是为什么游戏规则是“少即是多”。可运行状态中较少的线程意味着较少的调度开销和每个线程随时间推移的更多时间。处于可运行状态的更多线程意味着每个线程随时间变化的时间更短。这意味着你的工作也会随着时间的推移完成。 找到平衡点你需要在你拥有的核心数量和获得应用程序最佳吞吐量所需的线程数之间找到平衡点。在管理这种平衡时,线程池是一个很好的答案。我将在第二部分告诉你,Go不再需要这个。我认为这是Go为使多线程应用程序开发更容易做的好事之一。 在Go编码之前,我用C ++编写代码,用NT编写C＃。在该操作系统上,使用IOCP（IO完成端口）线程池对于编写多线程软件至关重要。作为工程师,你需要确定所需的线程池数量和任何给定池的最大线程数,以最大化你给定的核心数量的吞吐量。 在编写与数据库通信的Web服务时,每个核心3个线程的神奇数量似乎始终在NT上提供最佳吞吐量。换句话说,每个内核3个线程最小化了上下文切换的延迟成本,同时最大化了内核上的执行时间。在创建IOCP线程池时,我知道在主机上识别出的每个核心都至少有1个线程和最多3个线程。 如果我每个核心使用2个线程,则需要更长时间才能完成所有工作,因为我有空闲时间可以完成工作。如果我每个核心使用4个线程,它也需要更长的时间,因为我在上下文切换中有更多的延迟。无论出于何种原因,每个核心3个线程的平衡似乎总是在NT上的神奇数字。 如果你的服务正在进行许多不同类型的工作,该怎么办？这可能会产生不同且不一致的延迟。也许它还会创建许多需要处理的不同系统级事件。可能无法找到一直适用于所有不同工作负载的幻数。当使用线程池来调整服务的性能时,找到正确的一致配置会变得非常复杂。 缓存行从主存储器访问数据具有如此高的延迟成本（约100至约300个时钟周期）,处理器和内核具有本地高速缓存以使数据保持接近需要它的硬件线程。从高速缓存访​​问数据的成本要低得多（约3到约40个时钟周期）,具体取决于所访问的高速缓存。今天,性能的一个方面是关于如何有效地将数据导入处理器以减少这些数据访问延迟。编写改变状态的多线程应用程序需要考虑缓存系统的机制。 使用高速缓存行在处理器和主存储器之间交换数据。高速缓存行是在主存储器和高速缓存系统之间交换的64字节内存块。每个核心都有自己需要的任何缓存行的副本,这意味着硬件使用值语义。这就是为什么多线程应用程序中的内存突变会造成性能噩梦的原因。 当并行运行的多个线程访问相同的数据值或甚至是彼此接近的数据值时,它们将访问同一缓存线上的数据。在任何核心上运行的任何线程都将获得其自己的同一缓存行的副本。 如果给定核心上的一个线程对其高速缓存行的副本进行了更改,那么通过硬件的能力,同一高速缓存行的所有其他副本都必须标记为脏状态。当线程尝试对脏缓存行进行读或写访问时,需要主存储器访问（约100到约300个时钟周期）来获取缓存行的新副本。 也许在2核处理器上这不是什么大问题,但是并行运行32个线程的32核处理器在同一个缓存线上访问和改变数据呢？具有两个物理处理器的系统如何,每个处理器有16个核心？由于处理器到处理器通信的延迟增加,情况会更糟。该应用程序将通过内存进行颠簸,性能将变得非常糟糕,而且很可能,你将无法理解为什么。 这称为缓存一致性问题,并且还引入了诸如错误共享之类的问题。在编写将改变共享状态的多线程应用程序时,必须考虑缓存系统。 调度决策场景想象一下,我已经要求你根据我给你的高级信息编写OS调度程序。想想你必须考虑的这种情况。请记住,这是调度程序在做出调度决策时必须考虑的许多有趣的事情之一。 启动应用程序并创建主线程并在核心1上执行。当线程开始执行其指令时,正在检索缓存行,因为需要数据。Thread现在决定为某些并发处理创建一个新的Thread。这是个问题。 一旦创建了Thread并准备好了,调度程序应该是： 上下文切换核心1的主线程？这样做有助于提高性能,因为这个新线程需要相同的数据已经被缓存的可能性非常大。但主线程没有得到它的全部时间片。 是否等待核心1在主线程的时间片完成之前可用？线程未运行,但一旦启动,将取消获取数据的延迟。 让线程等待下一个可用的核心？这将意味着将刷新,检索和复制所选核心的高速缓存行,从而导致延迟。但是线程会更快地启动,主线程可以完成其时间片。 玩得开心吗？这些是OS调度程序在做出调度决策时需要考虑的有趣问题。对每个人来说幸运的是,我不是那个制作它们的人。我可以告诉你的是,如果有空闲核心,它将会被使用。你希望线程在运行时运行。 结论这篇文章的第一部分提供了在编写多线程应用程序时对线程和OS调度程序必须考虑的内容的见解。这些是Go调度程序也考虑到的事情。在下一篇文章中,我将描述Go调度程序的语义以及它们如何与此信息相关。最后,你将通过运行几个程序来看到所有这些。 原文: 1) Scheduling In Go : Part I - OS Scheduler2) Scheduling In Go : Part II - Go Scheduler3) Scheduling In Go : Part III - Concurrency","link":"/2019/08/06/Go/Golang%E8%AF%91%E6%96%87/Go%E4%B8%AD%E7%9A%84%E8%B0%83%E5%BA%A6%EF%BC%9A%E7%AC%ACI%E9%83%A8%E5%88%86-OS%E8%B0%83%E5%BA%A6%E7%A8%8B%E5%BA%8F/"},{"title":"(译)自定义Go Json的序列化方法","text":"翻译自 Custom JSON Marshalling in Go。 Go的 encoding/json序列化strcut到JSON数据: 12345678910111213141516package mainimport ( \"encoding/json\" \"os\" \"time\")type MyUser struct { ID int64 `json:\"id\"` Name string `json:\"name\"` LastSeen time.Time `json:\"lastSeen\"`}func main() { _ = json.NewEncoder(os.Stdout).Encode( &amp;MyUser{1, \"Ken\", time.Now()}, )} 序列化的结果: 1{\"id\":1,\"name\":\"Ken\",\"lastSeen\":\"2009-11-10T23:00:00Z\"} 但是如果我们想改变一个字段的显示结果我们要怎么做呢？例如，我们想把LastSeen显示为unix时间戳。 最简单的方式是引入另外一个辅助struct,在MarshalJSON中使用它进行正确的格式化： 1234567891011func (u *MyUser) MarshalJSON() ([]byte, error) { return json.Marshal(&amp;struct { ID int64 `json:\"id\"` Name string `json:\"name\"` LastSeen int64 `json:\"lastSeen\"` }{ ID: u.ID, Name: u.Name, LastSeen: u.LastSeen.Unix(), })} 这样做当然没有问题，但是如果有很多字段的话就会很麻烦，如果我们能把原始struct嵌入到新的struct中，并让它继承所有不需要改变的字段就太好了: 123456789func (u *MyUser) MarshalJSON() ([]byte, error) { return json.Marshal(&amp;struct { LastSeen int64 `json:\"lastSeen\"` *MyUser }{ LastSeen: u.LastSeen.Unix(), MyUser: u, })} 但是等等，问题是这个辅助struct也会继承原始struct的MarshalJSON方法，这会导致这个方法进入无限循环中，最后堆栈溢出。 解决办法就是为原始类型起一个别名，别名会有原始struct所有的字段，但是不会继承它的方法： 12345678910func (u *MyUser) MarshalJSON() ([]byte, error) { type Alias MyUser return json.Marshal(&amp;struct { LastSeen int64 `json:\"lastSeen\"` *Alias }{ LastSeen: u.LastSeen.Unix(), Alias: (*Alias)(u), })} 同样的技术也可以应用于UnmarshalJSON方法: 1234567891011121314func (u *MyUser) UnmarshalJSON(data []byte) error { type Alias MyUser aux := &amp;struct { LastSeen int64 `json:\"lastSeen\"` *Alias }{ Alias: (*Alias)(u), } if err := json.Unmarshal(data, &amp;aux); err != nil { return err } u.LastSeen = time.Unix(aux.LastSeen, 0) return nil}","link":"/2020/06/12/Go/Golang%E8%AF%91%E6%96%87/%E8%87%AA%E5%AE%9A%E4%B9%89Go-Json%E7%9A%84%E5%BA%8F%E5%88%97%E5%8C%96%E6%96%B9%E6%B3%95/"},{"title":"(译) Uber Go 风格指南","text":"Uber 是一家美国硅谷的科技公司,也是 Go 语言的早期 adopter。其开源了很多 golang 项目,诸如被 Gopher 圈熟知的 zap、jaeger 等。2018 年年末 Uber 将内部的 Go 风格规范 开源到 GitHub,经过一年的积累和更新,该规范已经初具规模,并受到广大 Gopher 的关注。本文是该规范的中文版本。本版本会根据原版实时更新。 版本 当前更新版本：2020-02-25 版本地址：commit:#86 如果您发现任何更新、问题或改进,请随时 fork 和 PR Please feel free to fork and PR if you find any updates, issues or improvement. 目录 介绍 指导原则 指向 interface 的指针 Interface 合理性验证 接收器 (receiver) 与接口 零值 Mutex 是有效的 在边界处拷贝 Slices 和 Maps 使用 defer 释放资源 Channel 的 size 要么是 1,要么是无缓冲的 枚举从 1 开始 使用&quot;time&quot;处理时间 错误类型 错误包装 (Error Wrapping) 处理类型断言失败 不要 panic 使用 go.uber.org/atomic 避免可变全局变量 避免在公共结构中嵌入类型 性能 优先使用 strconv 而不是 fmt 避免字符串到字节的转换 尽量初始化时指定 Map 容量 规范 一致性 相似的声明放在一组 import 分组 包名 函数名 导入别名 函数分组与顺序 减少嵌套 不必要的 else 顶层变量声明 对于未导出的顶层常量和变量,使用_作为前缀 结构体中的嵌入 使用字段名初始化结构体 本地变量声明 nil 是一个有效的 slice 小变量作用域 避免参数语义不明确（Avoid Naked Parameters） 使用原始字符串字面值,避免转义 初始化 Struct 引用 初始化 Maps 字符串 string format 命名 Printf 样式的函数 编程模式 表驱动测试 功能选项 介绍样式 (style) 是支配我们代码的惯例。术语样式有点用词不当,因为这些约定涵盖的范围不限于由 gofmt 替我们处理的源文件格式。 本指南的目的是通过详细描述在 Uber 编写 Go 代码的注意事项来管理这种复杂性。这些规则的存在是为了使代码库易于管理,同时仍然允许工程师更有效地使用 Go 语言功能。 该指南最初由 Prashant Varanasi 和 Simon Newton 编写,目的是使一些同事能快速使用 Go。多年来,该指南已根据其他人的反馈进行了修改。 本文档记录了我们在 Uber 遵循的 Go 代码中的惯用约定。其中许多是 Go 的通用准则,而其他扩展准则依赖于下面外部的指南： Effective Go The Go common mistakes guide 所有代码都应该通过golint和go vet的检查并无错误。我们建议您将编辑器设置为： 保存时运行goimports 运行golint和go vet检查错误 您可以在以下 Go 编辑器工具支持页面中找到更为详细的信息：https://github.com/golang/go/wiki/IDEsAndTextEditorPlugins 指导原则指向 interface 的指针您几乎不需要指向接口类型的指针。您应该将接口作为值进行传递,在这样的传递过程中,实质上传递的底层数据仍然可以是指针。 接口实质上在底层用两个字段表示： 一个指向某些特定类型信息的指针。您可以将其视为”type”。 数据指针。如果存储的数据是指针,则直接存储。如果存储的数据是一个值,则存储指向该值的指针。 如果希望接口方法修改基础数据,则必须使用指针传递。 Interface 合理性验证在编译时验证接口的符合性。这包括： 将实现特定接口所需的导出类型作为其 API 的一部分 导出或未导出的类型是实现同一接口的类型集合的一部分 其他违反接口的情况会破坏用户。 Bad vs Good 123456789type Handler struct { // ...}func (h *Handler) ServeHTTP( w http.ResponseWriter, r *http.Request,) { ...} 12345678910type Handler struct { // ...}var _ http.Handler = (*Handler)(nil)func (h *Handler) ServeHTTP( w http.ResponseWriter, r *http.Request,) { // ...} 如果*Handler永远不会与http.Handler接口匹配,那么语句var _ http.Handler = (*Handler)(nil)将无法编译 赋值的右边应该是断言类型的零值。对于指针类型（如*Handler）、切片和映射,这是nil；对于结构类型,这是空结构。 1234567891011type LogHandler struct { h http.Handler log *zap.Logger}var _ http.Handler = LogHandler{}func (h LogHandler) ServeHTTP( w http.ResponseWriter, r *http.Request,) { // ...} 接收器 (receiver) 与接口使用值接收器的方法既可以通过值调用,也可以通过指针调用。 例如, 12345678910111213141516171819202122232425type S struct { data string}func (s S) Read() string { return s.data}func (s *S) Write(str string) { s.data = str}sVals := map[int]S{1: {\"A\"}}// 你只能通过值调用 ReadsVals[1].Read()// 这不能编译通过：// sVals[1].Write(\"test\")sPtrs := map[int]*S{1: {\"A\"}}// 通过指针既可以调用 Read,也可以调用 Write 方法sPtrs[1].Read()sPtrs[1].Write(\"test\") 同样,即使该方法具有值接收器,也可以通过指针来满足接口。 123456789101112131415161718192021222324type F interface { f()}type S1 struct{}func (s S1) f() {}type S2 struct{}func (s *S2) f() {}s1Val := S1{}s1Ptr := &amp;S1{}s2Val := S2{}s2Ptr := &amp;S2{}var i Fi = s1Vali = s1Ptri = s2Ptr// 下面代码无法通过编译。因为 s2Val 是一个值,而 S2 的 f 方法中没有使用值接收器// i = s2Val Effective Go 中有一段关于 pointers vs. values 的精彩讲解。 零值 Mutex 是有效的零值sync.Mutex和sync.RWMutex是有效的。所以指向 mutex 的指针基本是不必要的。 Bad vs Good 12mu := new(sync.Mutex)mu.Lock() 12var mu sync.Mutexmu.Lock() 如果你使用结构体指针,mutex 可以非指针形式作为结构体的组成字段,或者更好的方式是直接嵌入到结构体中。如果是私有结构体类型或是要实现 Mutex 接口的类型,我们可以使用嵌入 mutex 的方法： 123456789101112131415161718type smap struct { sync.Mutex // only for unexported types（仅适用于非导出类型） data map[string]string}func newSMap() *smap { return &amp;smap{ data: make(map[string]string), }}func (m *smap) Get(k string) string { m.Lock() defer m.Unlock() return m.data[k]} 123456789101112131415161718type SMap struct { mu sync.Mutex // 对于导出类型,请使用私有锁 data map[string]string}func NewSMap() *SMap { return &amp;SMap{ data: make(map[string]string), }}func (m *SMap) Get(k string) string { m.mu.Lock() defer m.mu.Unlock() return m.data[k]} 为私有类型或需要实现互斥接口的类型嵌入。对于导出的类型,请使用专用字段。 在边界处拷贝 Slices 和 Mapsslices 和 maps 包含了指向底层数据的指针,因此在需要复制它们时要特别注意。 接收 Slices 和 Maps请记住,当 map 或 slice 作为函数参数传入时,如果您存储了对它们的引用,则用户可以对其进行修改。 Bad vs Good 123456789func (d *Driver) SetTrips(trips []Trip) { d.trips = trips}trips := ...d1.SetTrips(trips)// 你是要修改 d1.trips 吗？trips[0] = ... 12345678910func (d *Driver) SetTrips(trips []Trip) { d.trips = make([]Trip, len(trips)) copy(d.trips, trips)}trips := ...d1.SetTrips(trips)// 这里我们修改 trips[0],但不会影响到 d1.tripstrips[0] = ... 返回 slices 或 maps同样,请注意用户对暴露内部状态的 map 或 slice 的修改。 Bad vs Good 123456789101112131415161718type Stats struct { mu sync.Mutex counters map[string]int}// Snapshot 返回当前状态。func (s *Stats) Snapshot() map[string]int { s.mu.Lock() defer s.mu.Unlock() return s.counters}// snapshot 不再受互斥锁保护// 因此对 snapshot 的任何访问都将受到数据竞争的影响// 影响 stats.counterssnapshot := stats.Snapshot() 12345678910111213141516171819type Stats struct { mu sync.Mutex counters map[string]int}func (s *Stats) Snapshot() map[string]int { s.mu.Lock() defer s.mu.Unlock() result := make(map[string]int, len(s.counters)) for k, v := range s.counters { result[k] = v } return result}// snapshot 现在是一个拷贝snapshot := stats.Snapshot() 使用 defer 释放资源使用 defer 释放资源,诸如文件和锁。 Bad vs Good 12345678910111213p.Lock()if p.count &lt; 10 { p.Unlock() return p.count}p.count++newCount := p.countp.Unlock()return newCount// 当有多个 return 分支时,很容易遗忘 unlock 1234567891011p.Lock()defer p.Unlock()if p.count &lt; 10 { return p.count}p.count++return p.count// 更可读 Defer 的开销非常小,只有在您可以证明函数执行时间处于纳秒级的程度时,才应避免这样做。使用 defer 提升可读性是值得的,因为使用它们的成本微不足道。尤其适用于那些不仅仅是简单内存访问的较大的方法,在这些方法中其他计算的资源消耗远超过defer。 Channel 的 size 要么是 1,要么是无缓冲的channel 通常 size 应为 1 或是无缓冲的。默认情况下,channel 是无缓冲的,其 size 为零。任何其他尺寸都必须经过严格的审查。我们需要考虑如何确定大小,考虑是什么阻止了 channel 在高负载下和阻塞写时的写入,以及当这种情况发生时系统逻辑有哪些变化。(翻译解释：按照原文意思是需要界定通道边界,竞态条件,以及逻辑上下文梳理) Bad vs Good 12// 应该足以满足任何情况！c := make(chan int, 64) 1234// 大小：1c := make(chan int, 1) // 或者// 无缓冲 channel,大小为 0c := make(chan int) 枚举从 1 开始在 Go 中引入枚举的标准方法是声明一个自定义类型和一个使用了 iota 的 const 组。由于变量的默认值为 0,因此通常应以非零值开头枚举。 Bad vs Good 123456789type Operation intconst ( Add Operation = iota Subtract Multiply)// Add=0, Subtract=1, Multiply=2 123456789type Operation intconst ( Add Operation = iota + 1 Subtract Multiply)// Add=1, Subtract=2, Multiply=3 在某些情况下,使用零值是有意义的（枚举从零开始）,例如,当零值是理想的默认行为时。 123456789type LogOutput intconst ( LogToStdout LogOutput = iota LogToFile LogToRemote)// LogToStdout=0, LogToFile=1, LogToRemote=2 使用 time 处理时间时间处理很复杂。关于时间的错误假设通常包括以下几点。 一天有 24 小时 一小时有 60 分钟 一周有七天 一年 365 天 还有更多 例如,1 表示在一个时间点上加上 24 小时并不总是产生一个新的日历日。 因此,在处理时间时始终使用 &quot;time&quot; 包,因为它有助于以更安全、更准确的方式处理这些不正确的假设。 使用time.Time表达瞬时时间在处理时间的瞬间时使用 time.time,在比较、添加或减去时间时使用time.Time中的方法。 Bad vs Good 123func isActive(now, start, stop int) bool { return start &lt;= now &amp;&amp; now &lt; stop} 123func isActive(now, start, stop time.Time) bool { return (start.Before(now) || start.Equal(now)) &amp;&amp; now.Before(stop)} 使用time.Duration表达时间段在处理时间段时使用 time.Duration . Bad vs Good 1234567func poll(delay int) { for { // ... time.Sleep(time.Duration(delay) * time.Millisecond) }}poll(10) // 是几秒钟还是几毫秒? 1234567func poll(delay time.Duration) { for { // ... time.Sleep(delay) }}poll(10*time.Second) 回到第一个例子,在一个时间瞬间加上 24 小时,我们用于添加时间的方法取决于意图。如果我们想要下一个日历日(当前天的下一天)的同一个时间点,我们应该使用 Time.AddDate。但是,如果我们想保证某一时刻比前一时刻晚 24 小时,我们应该使用 Time.Add。 12newDay := t.AddDate(0 /* years */, 0, /* months */, 1 /* days */)maybeNewDay := t.Add(24 * time.Hour) 对外部系统使用time.Time和time.Duration尽可能在与外部系统的交互中使用time.Duration和time.Time例如 : Command-line 标志: flag 通过 time.ParseDuration 支持time.Duration JSON: encoding/json 通过其 UnmarshalJSONmethod 方法支持将time.Time编码为 RFC 3339 字符串 SQL: database/sql 支持将DATETIME或TIMESTAMP列转换为time.Time,如果底层驱动程序支持则返回 YAML: gopkg.in/yaml.v2 支持将time.Time作为 RFC 3339 字符串,并通过 time.ParseDuration 支持time.Duration。 当不能在这些交互中使用time.Duration时,请使用int或float64,并在字段名称中包含单位。 例如,由于encoding/json不支持time.Duration,因此该单位包含在字段的名称中。 Bad vs Good 1234// {\"interval\": 2}type Config struct { Interval int`json:\"interval\"`} 1234// {\"intervalMillis\": 2000}type Config struct { IntervalMillis int`json:\"intervalMillis\"`} 当在这些交互中不能使用time.Time时,除非达成一致,否则使用string和 RFC 3339 中定义的格式时间戳。默认情况下,Time.UnmarshalText 使用此格式,并可通过 time.RFC3339 在Time.Format和time.Parse中使用。 尽管这在实践中并不成问题,但请记住,&quot;time&quot;包不支持解析闰秒时间戳（8728）,也不在计算中考虑闰秒（15190）。如果您比较两个时间瞬间,则差异将不包括这两个瞬间之间可能发生的闰秒。 错误类型Go 中有多种声明错误（Error) 的选项： errors.New 对于简单静态字符串的错误 fmt.Errorf 用于格式化的错误字符串 实现Error()方法的自定义类型 用 &quot;pkg/errors&quot;.Wrap 的 Wrapped errors 返回错误时,请考虑以下因素以确定最佳选择： 这是一个不需要额外信息的简单错误吗？如果是这样,errors.New 足够了。 客户需要检测并处理此错误吗？如果是这样,则应使用自定义类型并实现该Error()方法。 您是否正在传播下游函数返回的错误？如果是这样,请查看本文后面有关错误包装 section on error wrapping) 部分的内容。 否则 fmt.Errorf 就可以了。 如果客户端需要检测错误,并且您已使用创建了一个简单的错误 errors.New,请使用一个错误变量。 Bad vs Good 1234567891011121314151617// package foofunc Open() error { return errors.New(\"could not open\")}// package barfunc use() { if err := foo.Open(); err != nil { if err.Error() == \"could not open\" { // handle } else { panic(\"unknown error\") } }} 1234567891011121314151617// package foovar ErrCouldNotOpen = errors.New(\"could not open\")func Open() error { return ErrCouldNotOpen}// package barif err := foo.Open(); err != nil { if err == foo.ErrCouldNotOpen { // handle } else { panic(\"unknown error\") }} 如果您有可能需要客户端检测的错误,并且想向其中添加更多信息（例如,它不是静态字符串）,则应使用自定义类型。 Bad vs Good 12345678910111213func open(file string) error { return fmt.Errorf(\"file %q not found\", file)}func use() { if err := open(\"testfile.txt\"); err != nil { if strings.Contains(err.Error(), \"not found\") { // handle } else { panic(\"unknown error\") } }} 123456789101112131415161718192021type errNotFound struct { file string}func (e errNotFound) Error() string { return fmt.Sprintf(\"file %q not found\", e.file)}func open(file string) error { return errNotFound{file: file}}func use() { if err := open(\"testfile.txt\"); err != nil { if _, ok := err.(errNotFound); ok { // handle } else { panic(\"unknown error\") } }} 直接导出自定义错误类型时要小心,因为它们已成为程序包公共 API 的一部分。最好公开匹配器功能以检查错误。 12345678910111213141516171819202122232425262728// package footype errNotFound struct { file string}func (e errNotFound) Error() string { return fmt.Sprintf(\"file %q not found\", e.file)}func IsNotFoundError(err error) bool { _, ok := err.(errNotFound) return ok}func Open(file string) error { return errNotFound{file: file}}// package barif err := foo.Open(\"foo\"); err != nil { if foo.IsNotFoundError(err) { // handle } else { panic(\"unknown error\") }} 错误包装 (Error Wrapping)一个（函数/方法）调用失败时,有三种主要的错误传播方式： 如果没有要添加的其他上下文,并且您想要维护原始错误类型,则返回原始错误。 添加上下文,使用 &quot;pkg/errors&quot;.Wrap 以便错误消息提供更多上下文 ,&quot;pkg/errors&quot;.Cause 可用于提取原始错误。Use fmt.Errorf if the callers do not need to detect or handle that specific error case. 如果调用者不需要检测或处理的特定错误情况,使用 fmt.Errorf。 建议在可能的地方添加上下文,以使您获得诸如“调用服务 foo：连接被拒绝”之类的更有用的错误,而不是诸如“连接被拒绝”之类的模糊错误。 在将上下文添加到返回的错误时,请避免使用“failed to”之类的短语来保持上下文简洁,这些短语会陈述明显的内容,并随着错误在堆栈中的渗透而逐渐堆积： Bad vs Good 12345s, err := store.New()if err != nil { return fmt.Errorf( \"failed to create new store: %s\", err)} 12345s, err := store.New()if err != nil { return fmt.Errorf( \"new store: %s\", err)} 1failed to x: failed to y: failed to create new store: the error 1x: y: new store: the error 但是,一旦将错误发送到另一个系统,就应该明确消息是错误消息（例如使用err标记,或在日志中以”Failed”为前缀）。 另请参见 Don’t just check errors, handle them gracefully. 不要只是检查错误,要优雅地处理错误 处理类型断言失败type assertion 的单个返回值形式针对不正确的类型将产生 panic。因此,请始终使用“comma ok”的惯用法。 Bad vs Good 1t := i.(string) 1234t, ok := i.(string)if !ok { // 优雅地处理错误} 不要 panic在生产环境中运行的代码必须避免出现 panic。panic 是 cascading failures 级联失败的主要根源 。如果发生错误,该函数必须返回错误,并允许调用方决定如何处理它。 Bad vs Good 1234567891011121314func foo(bar string) { if len(bar) == 0 { panic(\"bar must not be empty\") } // ...}func main() { if len(os.Args) != 2 { fmt.Println(\"USAGE: foo &lt;bar&gt;\") os.Exit(1) } foo(os.Args[1])} 1234567891011121314151617func foo(bar string) error { if len(bar) == 0 { return errors.New(\"bar must not be empty\") } // ... return nil}func main() { if len(os.Args) != 2 { fmt.Println(\"USAGE: foo &lt;bar&gt;\") os.Exit(1) } if err := foo(os.Args[1]); err != nil { panic(err) }} panic/recover 不是错误处理策略。仅当发生不可恢复的事情（例如：nil 引用）时,程序才必须 panic。程序初始化是一个例外：程序启动时应使程序中止的不良情况可能会引起 panic。 1var _statusTemplate = template.Must(template.New(\"name\").Parse(\"_statusHTML\")) 即使在测试代码中,也优先使用t.Fatal或者t.FailNow而不是 panic 来确保失败被标记。 Bad vs Good 123456// func TestFoo(t *testing.T)f, err := ioutil.TempFile(\"\", \"test\")if err != nil { panic(\"failed to set up test\")} 123456// func TestFoo(t *testing.T)f, err := ioutil.TempFile(\"\", \"test\")if err != nil { t.Fatal(\"failed to set up test\")} 使用 go.uber.org/atomic使用 sync/atomic 包的原子操作对原始类型 (int32,int64等）进行操作,因为很容易忘记使用原子操作来读取或修改变量。 go.uber.org/atomic 通过隐藏基础类型为这些操作增加了类型安全性。此外,它包括一个方便的atomic.Bool类型。 Bad vs Good 123456789101112131415type foo struct { running int32 // atomic}func (f* foo) start() { if atomic.SwapInt32(&amp;f.running, 1) == 1 { // already running… return } // start the Foo}func (f *foo) isRunning() bool { return f.running == 1 // race!} 123456789101112131415type foo struct { running atomic.Bool}func (f *foo) start() { if f.running.Swap(true) { // already running… return } // start the Foo}func (f *foo) isRunning() bool { return f.running.Load()} 避免可变全局变量使用选择依赖注入方式避免改变全局变量。既适用于函数指针又适用于其他值类型 Bad vs Good 123456// sign.govar _timeNow = time.Nowfunc sign(msg string) string { now := _timeNow() return signWithTime(msg, now)} 12345678910111213// sign.gotype signer struct { now func() time.Time}func newSigner() *signer { return &amp;signer{ now: time.Now, }}func (s *signer) Sign(msg string) string { now := s.now() return signWithTime(msg, now)} 123456789// sign_test.gofunc TestSign(t *testing.T) { oldTimeNow := _timeNow _timeNow = func() time.Time { return someFixedTime } defer func() { _timeNow = oldTimeNow }() assert.Equal(t, want, sign(give))} 12345678// sign_test.gofunc TestSigner(t *testing.T) { s := newSigner() s.now = func() time.Time { return someFixedTime } assert.Equal(t, want, s.Sign(give))} 避免在公共结构中嵌入类型这些嵌入的类型泄漏实现细节、禁止类型演化和模糊的文档。 假设您使用共享的AbstractList实现了多种列表类型,请避免在具体的列表实现中嵌入AbstractList。相反,只需手动将方法写入具体的列表,该列表将委托给抽象列表。 123456789type AbstractList struct {}// 添加将实体添加到列表中。func (l *AbstractList) Add(e Entity) { // ...}// 移除从列表中移除实体。func (l *AbstractList) Remove(e Entity) { // ...} Bad vs Good 1234// ConcreteList 是一个实体列表。type ConcreteList struct { *AbstractList} 123456789101112// ConcreteList 是一个实体列表。type ConcreteList struct { list *AbstractList}// 添加将实体添加到列表中。func (l *ConcreteList) Add(e Entity) { return l.list.Add(e)}// 移除从列表中移除实体。func (l *ConcreteList) Remove(e Entity) { return l.list.Remove(e)} Go 允许 类型嵌入 作为继承和组合之间的折衷。外部类型获取嵌入类型的方法的隐式副本。默认情况下,这些方法委托给嵌入实例的同一方法。 结构还获得与类型同名的字段。所以,如果嵌入的类型是 public,那么字段是 public。为了保持向后兼容性,外部类型的每个未来版本都必须保留嵌入类型。 很少需要嵌入类型。这是一种方便,可以帮助您避免编写冗长的委托方法。 即使嵌入兼容的抽象列表 interface,而不是结构体,这将为开发人员提供更大的灵活性来改变未来,但仍然泄露了具体列表使用抽象实现的细节。 Bad vs Good 123456789// AbstractList 是各种实体列表的通用实现。type AbstractList interface { Add(Entity) Remove(Entity)}// ConcreteList 是一个实体列表。type ConcreteList struct { AbstractList} 123456789101112// ConcreteList 是一个实体列表。type ConcreteList struct { list *AbstractList}// 添加将实体添加到列表中。func (l *ConcreteList) Add(e Entity) { return l.list.Add(e)}// 移除从列表中移除实体。func (l *ConcreteList) Remove(e Entity) { return l.list.Remove(e)} 无论是使用嵌入式结构还是使用嵌入式接口,嵌入式类型都会限制类型的演化. 向嵌入式接口添加方法是一个破坏性的改变。 删除嵌入类型是一个破坏性的改变。 即使使用满足相同接口的替代方法替换嵌入类型,也是一个破坏性的改变。 尽管编写这些委托方法是乏味的,但是额外的工作隐藏了实现细节,留下了更多的更改机会,还消除了在文档中发现完整列表接口的间接性操作。 性能性能方面的特定准则只适用于高频场景。 优先使用 strconv 而不是 fmt将原语转换为字符串或从字符串转换时,strconv速度比fmt快。 Bad vs Good 123for i := 0; i &lt; b.N; i++ { s := fmt.Sprint(rand.Int())} 123for i := 0; i &lt; b.N; i++ { s := strconv.Itoa(rand.Int())} 1BenchmarkFmtSprint-4 143 ns/op 2 allocs/op 1BenchmarkStrconv-4 64.2 ns/op 1 allocs/op 避免字符串到字节的转换不要反复从固定字符串创建字节 slice。相反,请执行一次转换并捕获结果。 Bad vs Good 123for i := 0; i &lt; b.N; i++ { w.Write([]byte(\"Hello world\"))} 1234data := []byte(\"Hello world\")for i := 0; i &lt; b.N; i++ { w.Write(data)} 1BenchmarkBad-4 50000000 22.2 ns/op 1BenchmarkGood-4 500000000 3.25 ns/op 尽量初始化时指定 Map 容量在尽可能的情况下,在使用make()初始化的时候提供容量信息 1make(map[T1]T2, hint) 为make()提供容量信息（hint）尝试在初始化时调整 map 大小,这减少了在将元素添加到 map 时增长和分配的开销。注意,map 不能保证分配 hint 个容量。因此,即使提供了容量,添加元素仍然可以进行分配。 Bad vs Good 123456m := make(map[string]os.FileInfo)files, _ := ioutil.ReadDir(\"./files\")for _, f := range files { m[f.Name()] = f} 123456files, _ := ioutil.ReadDir(\"./files\")m := make(map[string]os.FileInfo, len(files))for _, f := range files { m[f.Name()] = f} m是在没有大小提示的情况下创建的； 在运行时可能会有更多分配。 m是有大小提示创建的；在运行时可能会有更少的分配。 规范一致性本文中概述的一些标准都是客观性的评估,是根据场景、上下文、或者主观性的判断； 但是最重要的是,保持一致. 一致性的代码更容易维护、是更合理的、需要更少的学习成本、并且随着新的约定出现或者出现错误后更容易迁移、更新、修复 bug 相反,一个单一的代码库会导致维护成本开销、不确定性和认知偏差。所有这些都会直接导致速度降低、代码审查痛苦、而且增加 bug 数量 将这些标准应用于代码库时,建议在 package（或更大）级别进行更改,子包级别的应用程序通过将多个样式引入到同一代码中,违反了上述关注点。 相似的声明放在一组Go 语言支持将相似的声明放在一个组内。 Bad vs Good 12import \"a\"import \"b\" 1234import ( \"a\" \"b\") 这同样适用于常量、变量和类型声明： Bad vs Good 12345678const a = 1const b = 2var a = 1var b = 2type Area float64type Volume float64 1234567891011121314const ( a = 1 b = 2)var ( a = 1 b = 2)type ( Area float64 Volume float64) 仅将相关的声明放在一组。不要将不相关的声明放在一组。 Bad vs Good 12345678type Operation intconst ( Add Operation = iota + 1 Subtract Multiply ENV_VAR = \"MY_ENV\") 123456789type Operation intconst ( Add Operation = iota + 1 Subtract Multiply)const ENV_VAR = \"MY_ENV\" 分组使用的位置没有限制,例如：你可以在函数内部使用它们： Bad vs Good 1234567func f() string { var red = color.New(0xff0000) var green = color.New(0x00ff00) var blue = color.New(0x0000ff) ...} 123456789func f() string { var ( red = color.New(0xff0000) green = color.New(0x00ff00) blue = color.New(0x0000ff) ) ...} import 分组导入应该分为两组： 标准库 其他库 默认情况下,这是 goimports 应用的分组。 Bad vs Good 123456import ( \"fmt\" \"os\" \"go.uber.org/atomic\" \"golang.org/x/sync/errgroup\") 1234567import ( \"fmt\" \"os\" \"go.uber.org/atomic\" \"golang.org/x/sync/errgroup\") 包名当命名包时,请按下面规则选择一个名称： 全部小写。没有大写或下划线。 大多数使用命名导入的情况下,不需要重命名。 简短而简洁。请记住,在每个使用的地方都完整标识了该名称。 不用复数。例如net/url,而不是net/urls。 不要用“common”,“util”,“shared”或“lib”。这些是不好的,信息量不足的名称。 另请参阅 Package Names 和 Go 包样式指南. 函数名我们遵循 Go 社区关于使用 MixedCaps 作为函数名 的约定。有一个例外,为了对相关的测试用例进行分组,函数名可能包含下划线,如：TestMyFunction_WhatIsBeingTested. 导入别名如果程序包名称与导入路径的最后一个元素不匹配,则必须使用导入别名。 123456import ( \"net/http\" client \"example.com/client-go\" trace \"example.com/trace/v2\") 在所有其他情况下,除非导入之间有直接冲突,否则应避免导入别名。 Bad vs Good 123456import ( \"fmt\" \"os\" nettrace \"golang.net/x/trace\") 1234567import ( \"fmt\" \"os\" \"runtime/trace\" nettrace \"golang.net/x/trace\") 函数分组与顺序 函数应按粗略的调用顺序排序。 同一文件中的函数应按接收者分组。 因此,导出的函数应先出现在文件中,放在struct,const,var定义的后面。 在定义类型之后,但在接收者的其余方法之前,可能会出现一个newXYZ()/NewXYZ() 由于函数是按接收者分组的,因此普通工具函数应在文件末尾出现。 Bad vs Good 12345678910111213func (s *something) Cost() { return calcCost(s.weights)}type something struct{ ... }func calcCost(n []int) int {...}func (s *something) Stop() {...}func newSomething() *something { return &amp;something{}} 12345678910111213type something struct{ ... }func newSomething() *something { return &amp;something{}}func (s *something) Cost() { return calcCost(s.weights)}func (s *something) Stop() {...}func calcCost(n []int) int {...} 减少嵌套代码应通过尽可能先处理错误情况/特殊情况并尽早返回或继续循环来减少嵌套。减少嵌套多个级别的代码的代码量。 Bad vs Good 123456789101112for _, v := range data { if v.F1 == 1 { v = process(v) if err := v.Call(); err == nil { v.Send() } else { return err } } else { log.Printf(\"Invalid v: %v\", v) }} 123456789101112for _, v := range data { if v.F1 != 1 { log.Printf(\"Invalid v: %v\", v) continue } v = process(v) if err := v.Call(); err != nil { return err } v.Send()} 不必要的 else如果在 if 的两个分支中都设置了变量,则可以将其替换为单个 if。 Bad vs Good 123456var a intif b { a = 100} else { a = 10} 1234a := 10if b { a = 100} 顶层变量声明在顶层,使用标准var关键字。请勿指定类型,除非它与表达式的类型不同。 Bad vs Good 123var _s string = F()func F() string { return \"A\" } 12345var _s = F()// 由于 F 已经明确了返回一个字符串类型,因此我们没有必要显式指定_s 的类型// 还是那种类型func F() string { return \"A\" } 如果表达式的类型与所需的类型不完全匹配,请指定类型。 12345678type myError struct{}func (myError) Error() string { return \"error\" }func F() myError { return myError{} }var _e error = F()// F 返回一个 myError 类型的实例,但是我们要 error 类型 对于未导出的顶层常量和变量,使用_作为前缀在未导出的顶级vars和consts, 前面加上前缀_,以使它们在使用时明确表示它们是全局符号。 例外：未导出的错误值,应以err开头。 基本依据：顶级变量和常量具有包范围作用域。使用通用名称可能很容易在其他文件中意外使用错误的值。 Bad vs Good 1234567891011121314151617// foo.goconst ( defaultPort = 8080 defaultUser = \"user\")// bar.gofunc Bar() { defaultPort := 9090 ... fmt.Println(\"Default port\", defaultPort) // We will not see a compile error if the first line of // Bar() is deleted.} 123456// foo.goconst ( _defaultPort = 8080 _defaultUser = \"user\") 结构体中的嵌入嵌入式类型（例如 mutex）应位于结构体内的字段列表的顶部,并且必须有一个空行将嵌入式字段与常规字段分隔开。 Bad vs Good 1234type Client struct { version int http.Client} 12345type Client struct { http.Client version int} 使用字段名初始化结构体初始化结构体时,几乎始终应该指定字段名称。现在由 go vet 强制执行。 Bad vs Good 1k := User{\"John\", \"Doe\", true} 12345k := User{ FirstName: \"John\", LastName: \"Doe\", Admin: true,} 例外：如果有 3 个或更少的字段,则可以在测试表中省略字段名称。 1234567tests := []struct{ op Operation want string}{ {Add, \"add\"}, {Subtract, \"subtract\"},} 本地变量声明如果将变量明确设置为某个值,则应使用短变量声明形式 (:=)。 Bad vs Good 1var s = \"foo\" 1s := \"foo\" 但是,在某些情况下,var使用关键字时默认值会更清晰。例如,声明空切片。 Bad vs Good 12345678func f(list []int) { filtered := []int{} for _, v := range list { if v &gt; 10 { filtered = append(filtered, v) } }} 12345678func f(list []int) { var filtered []int for _, v := range list { if v &gt; 10 { filtered = append(filtered, v) } }} nil 是一个有效的 slicenil是一个有效的长度为 0 的 slice,这意味着, 您不应明确返回长度为零的切片。应该返回nil来代替。 Bad vs Good 123if x == \"\" { return []int{}} 123if x == \"\" { return nil} 要检查切片是否为空,请始终使用len(s) == 0。而非nil。 Bad vs Good 123func isEmpty(s []string) bool { return s == nil} 123func isEmpty(s []string) bool { return len(s) == 0} 零值切片（用var声明的切片）可立即使用,无需调用make()创建。 Bad vs Good 12345678910nums := []int{}// or, nums := make([]int)if add1 { nums = append(nums, 1)}if add2 { nums = append(nums, 2)} 123456789var nums []intif add1 { nums = append(nums, 1)}if add2 { nums = append(nums, 2)} 小变量作用域如果有可能,尽量缩小变量作用范围。除非它与 减少嵌套的规则冲突。 Bad vs Good 1234err := ioutil.WriteFile(name, data, 0644)if err != nil { return err} 123if err := ioutil.WriteFile(name, data, 0644); err != nil { return err} 如果需要在 if 之外使用函数调用的结果,则不应尝试缩小范围。 Bad vs Good 1234567891011if data, err := ioutil.ReadFile(name); err == nil { err = cfg.Decode(data) if err != nil { return err } fmt.Println(cfg) return nil} else { return err} 1234567891011data, err := ioutil.ReadFile(name)if err != nil { return err}if err := cfg.Decode(data); err != nil { return err}fmt.Println(cfg)return nil 避免参数语义不明确(Avoid Naked Parameters)函数调用中的意义不明确的参数可能会损害可读性。当参数名称的含义不明显时,请为参数添加 C 样式注释 (/* ... */) Bad vs Good 123// func printInfo(name string, isLocal, done bool)printInfo(\"foo\", true, true) 123// func printInfo(name string, isLocal, done bool)printInfo(\"foo\", true /* isLocal */, true /* done */) 对于上面的示例代码,还有一种更好的处理方式是将上面的bool类型换成自定义类型。将来,该参数可以支持不仅仅局限于两个状态（true/false）。 12345678910111213141516type Region intconst ( UnknownRegion Region = iota Local)type Status intconst ( StatusReady = iota + 1 StatusDone // Maybe we will have a StatusInProgress in the future.)func printInfo(name string, region Region, status Status) 使用原始字符串字面值,避免转义Go 支持使用 原始字符串字面值,也就是 “`” 来表示原生字符串,在需要转义的场景下,我们应该尽量使用这种方案来替换。 可以跨越多行并包含引号。使用这些字符串可以避免更难阅读的手工转义的字符串。 Bad vs Good 1wantError := \"unknown name:\\\"test\\\"\" 1wantError :=`unknown error:\"test\"` 初始化 Struct 引用在初始化结构引用时,请使用&amp;T{}代替new(T),以使其与结构体初始化一致。 Bad vs Good 12345sval := T{Name: \"foo\"}// inconsistentsptr := new(T)sptr.Name = \"bar\" 123sval := T{Name: \"foo\"}sptr := &amp;T{Name: \"bar\"} 初始化 Maps对于空 map 请使用make(..)初始化, 并且 map 是通过编程方式填充的。这使得 map 初始化在表现上不同于声明,并且它还可以方便地在 make 后添加大小提示。 Bad vs Good 123456var ( // m1 读写安全; // m2 在写入时会 panic m1 = map[T1]T2{} m2 map[T1]T2) 123456var ( // m1 读写安全; // m2 在写入时会 panic m1 = make(map[T1]T2) m2 map[T1]T2) 声明和初始化看起来非常相似的。 声明和初始化看起来差别非常大。 在尽可能的情况下,请在初始化时提供 map 容量大小,详细请看 尽量初始化时指定 Map 容量。 另外,如果 map 包含固定的元素列表,则使用 map literals(map 初始化列表) 初始化映射。 Bad vs Good 1234m := make(map[T1]T2, 3)m[k1] = v1m[k2] = v2m[k3] = v3 12345m := map[T1]T2{ k1: v1, k2: v2, k3: v3,} 基本准则是：在初始化时使用 map 初始化列表 来添加一组固定的元素。否则使用make(如果可以,请尽量指定 map 容量)。 字符串 string format如果你在函数外声明Printf-style 函数的格式字符串,请将其设置为const常量。 这有助于go vet对格式字符串执行静态分析。 Bad vs Good 12msg := \"unexpected values %v, %v\\n\"fmt.Printf(msg, 1, 2) 12const msg = \"unexpected values %v, %v\\n\"fmt.Printf(msg, 1, 2) 命名 Printf 样式的函数声明Printf-style 函数时,请确保go vet可以检测到它并检查格式字符串。 这意味着您应尽可能使用预定义的Printf-style 函数名称。go vet将默认检查这些。有关更多信息,请参见 Printf 系列。 如果不能使用预定义的名称,请以 f 结束选择的名称：Wrapf,而不是Wrap。go vet可以要求检查特定的 Printf 样式名称,但名称必须以f结尾。 1$ go vet -printfuncs=wrapf,statusf 另请参阅 go vet: Printf family check. 编程模式表驱动测试当测试逻辑是重复的时候,通过 subtests 使用 table 驱动的方式编写 case 代码看上去会更简洁。 Bad vs Good 123456789101112131415161718192021// func TestSplitHostPort(t *testing.T)host, port, err := net.SplitHostPort(\"192.0.2.0:8000\")require.NoError(t, err)assert.Equal(t, \"192.0.2.0\", host)assert.Equal(t, \"8000\", port)host, port, err = net.SplitHostPort(\"192.0.2.0:http\")require.NoError(t, err)assert.Equal(t, \"192.0.2.0\", host)assert.Equal(t, \"http\", port)host, port, err = net.SplitHostPort(\":8000\")require.NoError(t, err)assert.Equal(t, \"\", host)assert.Equal(t, \"8000\", port)host, port, err = net.SplitHostPort(\"1:8\")require.NoError(t, err)assert.Equal(t, \"1\", host)assert.Equal(t, \"8\", port) 12345678910111213141516171819202122232425262728293031323334353637// func TestSplitHostPort(t *testing.T)tests := []struct{ give string wantHost string wantPort string}{ { give: \"192.0.2.0:8000\", wantHost: \"192.0.2.0\", wantPort: \"8000\", }, { give: \"192.0.2.0:http\", wantHost: \"192.0.2.0\", wantPort: \"http\", }, { give: \":8000\", wantHost: \"\", wantPort: \"8000\", }, { give: \"1:8\", wantHost: \"1\", wantPort: \"8\", },}for _, tt := range tests { t.Run(tt.give, func(t *testing.T) { host, port, err := net.SplitHostPort(tt.give) require.NoError(t, err) assert.Equal(t, tt.wantHost, host) assert.Equal(t, tt.wantPort, port) })} 很明显,使用 test table 的方式在代码逻辑扩展的时候,比如新增 test case,都会显得更加的清晰。 我们遵循这样的约定：将结构体切片称为tests。 每个测试用例称为tt。此外,我们鼓励使用give和want前缀说明每个测试用例的输入和输出值。 1234567891011tests := []struct{ give string wantHost string wantPort string}{ // ...}for _, tt := range tests { // ...} 功能选项功能选项是一种模式,您可以在其中声明一个不透明 Option 类型,该类型在某些内部结构中记录信息。您接受这些选项的可变编号,并根据内部结构上的选项记录的全部信息采取行动。 将此模式用于您需要扩展的构造函数和其他公共 API 中的可选参数,尤其是在这些功能上已经具有三个或更多参数的情况下。 Bad vs Good 123456789// package dbfunc Open( addr string, cache bool, logger *zap.Logger) (*Connection, error) { // ...} 123456789101112131415161718192021// package dbtype Option interface { // ...}func WithCache(c bool) Option { // ...}func WithLogger(log *zap.Logger) Option { // ...}// Open creates a connection.func Open( addr string, opts ...Option,) (*Connection, error) { // ...} 必须始终提供缓存和记录器参数,即使用户希望使用默认值。 1234db.Open(addr, db.DefaultCache, zap.NewNop())db.Open(addr, db.DefaultCache, log)db.Open(addr, false /* cache */, zap.NewNop())db.Open(addr, false /* cache */, log) 只有在需要时才提供选项。 12345678db.Open(addr)db.Open(addr, db.WithLogger(log))db.Open(addr, db.WithCache(false))db.Open( addr, db.WithCache(false), db.WithLogger(log),) 我们建议实现此模式的方法是使用一个Option接口,该接口保存一个未导出的方法,在一个未导出的options结构上记录选项。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647type options struct { cache bool logger *zap.Logger}type Option interface { apply(*options)}type cacheOption boolfunc (c cacheOption) apply(opts *options) { opts.cache = bool(c)}func WithCache(c bool) Option { return cacheOption(c)}type loggerOption struct { Log *zap.Logger}func (l loggerOption) apply(opts *options) { opts.logger = l.Log}func WithLogger(log *zap.Logger) Option { return loggerOption{Log: log}}// Open creates a connection.func Open( addr string, opts ...Option,) (*Connection, error) { options := options{ cache: defaultCache, logger: zap.NewNop(), } for _, o := range opts { o.apply(&amp;options) } // ...} 注意: 还有一种使用闭包实现这个模式的方法,但是我们相信上面的模式为作者提供了更多的灵活性,并且更容易对用户进行调试和测试。特别是,在不可能进行比较的情况下它允许在测试和模拟中对选项进行比较。此外,它还允许选项实现其他接口,包括fmt.Stringer,允许用户读取选项的字符串表示形式。 还可以参考下面资料： Self-referential functions and the design of options Functional options for friendly APIs Stargazers over time uber-go/guide 的中文翻译","link":"/2020/04/05/Go/Golang%E8%AF%91%E6%96%87/Uber-Go-%E9%A3%8E%E6%A0%BC%E6%8C%87%E5%8D%97/"},{"title":"(译) Go中的垃圾收集：第二部分 - GC痕迹","text":"这是三部分系列中的第二篇文章,它将提供对Go中垃圾收集器背后的机制和语义的理解。本文重点介绍如何生成GC跟踪并解释它们。 三部分系列的索引：1）Go中的垃圾收集：第一部分 - 语义2）Go中的垃圾收集：第二部分 - GC跟踪3）Go中的垃圾收集：第三部分 - GC步伐 介绍在第一篇文章中,我花时间描述了垃圾收集器的行为,并显示了收集器对正在运行的应用程序造成的延迟。我分享了如何生成和解释GC跟踪,显示堆上的内存如何变化,并解释了GC的不同阶段以及它们如何影响延迟成本。 该帖子的最终结论是,如果减少堆上的压力,你将减少延迟成本,从而提高应用程序的性能。我还指出,通过寻找增加任何两个系列之间的时间来减少收集开始的步伐并不是一个好的策略。一致的速度,即使它很快,也会更好地保持应用程序以最佳性能运行。 在这篇文章中,我将引导你完成运行真实Web应用程序并向你展示如何生成GC跟踪和应用程序配置文件。然后,我将向你展示如何解释这些工具的输出,以便你可以找到提高应用程序性能的方法。 运行应用程序看看我在Go学习中使用的这个Web应用程序。 图1https://github.com/ardanlabs/gotraining/tree/master/topics/go/profiling/project 图1显示了应用程序的外观。此应用程序从不同的新闻提供商下载三组RSS订阅源,并允许用户执行搜索。构建Web应用程序后,将启动该应用程序。 清单1 12$ go build$ GOGC=off ./project &gt; /dev/null 清单1显示了如何使用GOGC变量设置启动应用程序为off,从而关闭垃圾回收。日志将重定向到/dev/null设备。在应用程序运行时,可以将请求发布到服务器中。 清单2 1$ hey -m POST -c 100 -n 10000 \"http://localhost:5000/search?term=topic&amp;cnn=on&amp;bbc=on&amp;nyt=on\" 清单2显示了如何使用该hey工具在服务器上运行使用100个连接的10k请求。一旦通过服务器发送了所有请求,就会产生以下结果。 图2 图2显示了关闭垃圾收集器处理10k请求的直观表示。处理10k请求需要4,188ms,这导致服务器每秒处理~2,387个请求。 打开垃圾收集为此应用程序启用垃圾收集时会发生什么？ 清单3 1$ GODEBUG=gctrace=1 ./project &gt; /dev/null 清单3显示了如何启动应用程序以查看GC跟踪GOGC变量被删除并替换为GODEBUG变量。将GODEBUG被设定在运行时会生成一个GC跟踪每一个集合发生时。现在可以再次通过服务器运行相同的10k请求。通过服务器发送所有请求后hey,可以分析工具提供的GC跟踪和信息。 清单4 123456$ GODEBUG=gctrace=1 ./project &gt; /dev/nullgc 3 @3.182s 0%: 0.015+0.59+0.096 ms clock, 0.19+0.10/1.3/3.0+1.1 ms cpu, 4-&gt;4-&gt;2 MB, 5 MB goal, 12 P...gc 2553 @8.452s 14%: 0.004+0.33+0.051 ms clock, 0.056+0.12/0.56/0.94+0.61 ms cpu, 4-&gt;4-&gt;2 MB, 5 MB goal, 12 P 清单4显示了运行中第三个和最后一个集合的GC跟踪。自从在收集发生之后通过服务器发送加载以来,我没有显示前两个集合。最后一个集合显示它处理了10k个请求,需要2551个集合（减去前两个集合,因为它们不计算）。 以下是跟踪中每个部分的细分。 清单5 12345678910111213141516171819202122232425gc 2553 @8.452s 14%: 0.004+0.33+0.051 ms clock, 0.056+0.12/0.56/0.94+0.61 ms cpu, 4-&gt;4-&gt;2 MB, 5 MB goal, 12 Pgc 2553 : The 2553 GC runs since the program started@8.452s : Eight seconds since the program started14% : Fourteen percent of the available CPU so far has been spent in GC// wall-clock0.004ms : STW : Write-Barrier - Wait for all Ps to reach a GC safe-point.0.33ms : Concurrent : Marking0.051ms : STW : Mark Term - Write Barrier off and clean up.// CPU time0.056ms : STW : Write-Barrier0.12ms : Concurrent : Mark - Assist Time (GC performed in line with allocation)0.56ms : Concurrent : Mark - Background GC time0.94ms : Concurrent : Mark - Idle GC time0.61ms : STW : Mark Term4MB : Heap memory in-use before the Marking started4MB : Heap memory in-use after the Marking finished2MB : Heap memory marked as live after the Marking finished5MB : Collection goal for heap memory in-use after Marking finished// Threads12P : Number of logical processors or threads used to run Goroutines. 清单5显示了最后一个集合的实际数字。多亏了hey,这些是运行的性能结果。 清单6 12345678910Requests : 10,000------------------------------------------------------Requests/sec : 1,882 r/s - HeyTotal Duration : 5,311ms - HeyPercent Time in GC : 14% - GC TraceTotal Collections : 2,551 - GC Trace------------------------------------------------------Total GC Duration : 744.54ms - (5,311ms * .14)Average Pace of GC : ~2.08ms - (5,311ms / 2,551)Requests/Collection : ~3.98 r/gc - (10,000 / 2,511) 清单6显示了结果。以下内容提供了更多关于所发生事件的视觉效果。 图3 图3显示了视觉上发生的事情。当收集器打开时,它必须运行〜2.5k次以处理相同的10k请求。每个集合平均以~2.0ms的速度开始,并且运行所有这些集合增加了额外的~1.1秒的延迟。 图4 图4显示了到目前为止应用程序的两次运行的比较。 减少分配获取堆的配置文件并查看是否有任何可以删除的不必要的产生对象将会很棒。 清单7 1go tool pprof http://localhost:5000/debug/pprof/allocs 清单7显示了使用该pprof工具调用/debug/pprof/allocs端点从正在运行的应用程序中提取内存配置文件。由于以下代码,该端点存在。 清单8 12345import _ \"net/http/pprof\"go func() { http.ListenAndServe(\"localhost:5000\", http.DefaultServeMux)}() 清单8显示了如何将/debug/pprof/allocs端点绑定到任何应用程序。添加导入以net/http/pprof将端点绑定到默认服务器mux。然后,使用http.ListenAndServer与http.DefaultServerMux恒使端点可用。 一旦分析器启动,该top命令可用于查看分配最多的前6个功能。 清单9 1234567891011(pprof) top 6 -cumShowing nodes accounting for 0.56GB, 5.84% of 9.56GB totalDropped 80 nodes (cum &lt;= 0.05GB)Showing top 6 nodes out of 51 flat flat% sum% cum cum% 0 0% 0% 4.96GB 51.90% net/http.(*conn).serve 0.49GB 5.11% 5.11% 4.93GB 51.55% project/service.handler 0 0% 5.11% 4.93GB 51.55% net/http.(*ServeMux).ServeHTTP 0 0% 5.11% 4.93GB 51.55% net/http.HandlerFunc.ServeHTTP 0 0% 5.11% 4.93GB 51.55% net/http.serverHandler.ServeHTTP 0.07GB 0.73% 5.84% 4.55GB 47.63% project/search.rssSearch 清单9显示了如何在列表底部rssSearch显示该函数。此功能迄今为止分配了4.56GB的5.96GB。接下来,是时候rssSearch使用该list命令检查功能的细节。 清单10 123456789101112131415(pprof) list rssSearchTotal: 9.56GBROUTINE ======================== project/search.rssSearch in project/search/rss.go 71.53MB 4.55GB (flat, cum) 47.63% of Total . . 117: // Capture the data we need for our results if we find ... . . 118: for _, item := range d.Channel.Items { . 4.48GB 119: if strings.Contains(strings.ToLower(item.Description), strings.ToLower(term)) { 48.53MB 48.53MB 120: results = append(results, Result{ . . 121: Engine: engine, . . 122: Title: item.Title, . . 123: Link: item.Link, . . 124: Content: item.Description, . . 125: }) 清单11显示了有问题的代码行。仅该行占据了迄今为止已分配的4.55GB内存的4.48GB。接下来,是时候查看这行代码,看看有什么可以做的。 清单12 1234567891011117 // Capture the data we need for our results if we find the search term.118 for _, item := range d.Channel.Items {119 if strings.Contains(strings.ToLower(item.Description), strings.ToLower(term)) {120 results = append(results, Result{121 Engine: engine,122 Title: item.Title,123 Link: item.Link,124 Content: item.Description,125 })126 }127 } 清单12显示了该代码行如何处于紧密循环中。调用strings.ToLower是创建分配,因为它们创建了需要在堆上分配的新字符串。这些调用strings.ToLower是不必要的,因为这些调用可以在循环外完成。 可以更改第119行以删除所有这些分配。 清单13 12345// Before the code change.if strings.Contains(strings.ToLower(item.Description), strings.ToLower(term)) {// After the code change.if strings.Contains(item.Description, term) { 注意：你没有看到的其他代码更改是在将Feed放入缓存之前调用较低的描述。新闻源每15分钟缓存一次。term降低调用是在循环外部完成的。 清单13显示了如何strings.ToLower删除被调用者。通过这些新的代码更改再次构建项目,并再次通过服务器运行10k请求。 清单14 1234567$ go build$ GODEBUG=gctrace=1 ./project &gt; /dev/nullgc 3 @6.156s 0%: 0.011+0.72+0.068 ms clock, 0.13+0.21/1.5/3.2+0.82 ms cpu, 4-&gt;4-&gt;2 MB, 5 MB goal, 12 P...gc 1404 @8.808s 7%: 0.005+0.54+0.059 ms clock, 0.060+0.47/0.79/0.25+0.71 ms cpu, 4-&gt;5-&gt;2 MB, 5 MB goal, 12 P 清单14显示了在代码更改后,现在如何处理1402个集合来处理相同的10k请求。这些是两次运行的完整结果。 清单15 123456789101112With Extra Allocations Without Extra Allocations======================================================================Requests : 10,000 Requests : 10,000----------------------------------------------------------------------Requests/sec : 1,882 r/s Requests/sec : 3,631 r/sTotal Duration : 5,311ms Total Duration : 2,753 msPercent Time in GC : 14% Percent Time in GC : 7%Total Collections : 2,551 Total Collections : 1,402----------------------------------------------------------------------Total GC Duration : 744.54ms Total GC Duration : 192.71 msAverage Pace of GC : ~2.08ms Average Pace of GC : ~1.96msRequests/Collection : ~3.98 r/gc Requests/Collection : 7.13 r/gc 清单15显示了与上一结果相比的结果。以下内容提供了更多关于所发生事件的视觉效果。 图5 图5显示了视觉上发生的事情。这次收集器运行1149次（1,402对2,551）来处理相同的10k请求。这导致GC总时间的百分比从14％降低到7％。这使得应用程序运行速度提高了48％,收集时间减少了74％。 图6 图6显示了应用程序的所有不同运行的比较。我包含了一系列运行优化的代码而没有完成垃圾收集器。 我们学到了什么正如我在上一篇文章中所说,支持收集器是为了减少堆上的压力。请记住,压力可以定义为应用程序在给定时间内分配堆上所有可用内存的速度。当压力减小时,收集器造成的延迟将会减少。这种延迟会降低你的应用程序速度。 这不是要放慢收集的速度。这真的是在每个集合之间或集合期间完成更多的工作。你可以通过减少任何工作添加到堆中的分配数量或数量来影响它。 清单16 123456789101112With Extra Allocations Without Extra Allocations======================================================================Requests : 10,000 Requests : 10,000----------------------------------------------------------------------Requests/sec : 1,882 r/s Requests/sec : 3,631 r/sTotal Duration : 5,311ms Total Duration : 2,753 msPercent Time in GC : 14% Percent Time in GC : 7%Total Collections : 2,551 Total Collections : 1,402----------------------------------------------------------------------Total GC Duration : 744.54ms Total GC Duration : 192.71 msAverage Pace of GC : ~2.08ms Average Pace of GC : ~1.96msRequests/Collection : ~3.98 r/gc Requests/Collection : 7.13 r/gc 清单16显示了带有垃圾收集的两个版本应用程序的结果。很明显,删除4.48GB的分配使应用程序运行得更快。有趣的是,每个系列（两个版本）的平均速度几乎相同,约为2.0毫秒。这两个版本之间的根本变化是每个集合之间的工作量。应用范围从3.98 r / gc到7.13 r / gc。这是完成工作量增加79.1％。 在任何两个集合的开始之间完成更多的工作有助于将所需的集合数量从2,551减少到1,402,减少了45％。该应用程序的总GC时间从745毫秒减少到193毫秒,从收集的每个相应版本的总时间的14％变为7％。当你在没有垃圾收集的情况下运行应用程序的优化版本时,性能差异仅为13％,应用程序将2,753ms降至2,398ms。 结论如果你花时间专注于减少分配,那么你就像Go开发人员一样,对垃圾收集器表示支持。你不打算编写零分配应用程序,因此重要的是要认识到有效的分配（帮助应用程序的分配）和那些没有生产力的分配（那些损害应用程序）之间的差异。然后将你的信任和信任放在垃圾收集器中,以保持堆健康并使你的应用程序始终如一地运行。 拥有垃圾收集器是一个很好的权衡。我将花费垃圾收集的成本,所以我没有内存管理的负担。Go是关于允许你作为开发人员提高工作效率,同时仍然编写足够快的应用程序。垃圾收集器是实现这一目标的重要组成部分。在下一篇文章中,我将分享另一个程序,该程序显示收集器如何分析你的Go应用程序并找到最佳的收集方法。","link":"/2019/08/08/Go/Golang%E8%AF%91%E6%96%87/Go%E4%B8%AD%E7%9A%84%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%EF%BC%9A%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86-GC%E7%97%95%E8%BF%B9/"},{"title":"Happen-before原则","text":"JVM定义的Happens-Before原则是一组偏序关系：对于两个操作A和B,这两个操作可以在不同的线程中执行。如果A Happens-Before B,那么可以保证,当A操作执行完后,A操作的执行结果对B操作是可见的。 happen-before八大原则 单线程happen-before原则：在同一个线程中,书写在前面的操作happen-before后面的操作。 锁的happen-before原则：同一个锁的unlock操作happen-before此锁的lock操作。 volatile的happen-before原则：对一个volatile变量的写操作happen-before对此变量的读操作。 happen-before的传递性原则：如果A操作 happen-before B操作,B操作happen-before C操作,那么A操作happen-before C操作。 线程启动的happen-before原则：同一个线程的start方法happen-before此线程的其它方法。 线程中断的happen-before原则：对线程interrupt方法的调用happen-before被中断线程的检测到中断发送的代码。 线程终结的happen-before原则：线程中的所有操作都happen-before线程的终止检测。 对象创建的happen-before原则：一个对象的初始化完成先于他的finalize方法调用。 程序次序规则一段代码在单线程中执行的结果是有序的。注意是执行结果,因为虚拟机、处理器会对指令进行重排序（重排序后面会详细介绍）。虽然重排序了,但是并不会影响程序的执行结果,所以程序最终执行的结果与顺序执行的结果是一致的。故而这个规则只对单线程有效,在多线程环境下无法保证正确性。 锁定规则这个规则比较好理解,无论是在单线程环境还是多线程环境,一个锁处于被锁定状态,那么必须先执行unlock操作后面才能进行lock操作。 volatile变量规则这是一条比较重要的规则,它标志着volatile保证了线程可见性。通俗点讲就是如果一个线程先去写一个volatile变量,然后一个线程去读这个变量,那么这个写操作一定是happens-before读操作的。 传递规则提现了happens-before原则具有传递性,即A happens-before B , B happens-before C,那么A happens-before C 线程启动规则假定线程A在执行过程中,通过执行ThreadB.start()来启动线程B,那么线程A对共享变量的修改在接下来线程B开始执行后确保对线程B可见。 线程终结规则假定线程A在执行的过程中,通过制定ThreadB.join()等待线程B终止,那么线程B在终止之前对共享变量的修改在线程A等待返回后可见。 上面八条是原生Java满足Happens-before关系的规则,但是我们可以对他们进行推导出其他满足happens-before的规则： 将一个元素放入一个线程安全的队列的操作Happens-Before从队列中取出这个元素的操作 将一个元素放入一个线程安全容器的操作Happens-Before从容器中取出这个元素的操作 在CountDownLatch上的倒数操作Happens-Before CountDownLatch#await()操作 释放Semaphore许可的操作Happens-Before获得许可操作 Future表示的任务的所有操作Happens-Before Future#get()操作 向Executor提交一个Runnable或Callable的操作Happens-Before任务开始执行操作 两个操作不存在上述（前面8条 + 后面6条）任一一个happens-before规则 那么这两个操作就没有顺序的保障,JVM可以对这两个操作进行重排序。如果操作A happens-before操作B,那么操作A在内存上所做的操作对操作B都是可见的。 参考资料周志明：《深入理解Java虚拟机》 方腾飞：《Java并发编程的艺术》","link":"/2018/08/23/Jvm/Java/Happen-before%E5%8E%9F%E5%88%99/"},{"title":"JVM参数设置、分析","text":"不管是YGC还是Full GC,GC过程中都会对导致程序运行中中断,正确的选择不同的GC策略,调整JVM、GC的参数,可以极大的减少由于GC工作,而导致的程序运行中断方面的问题,进而适当的提高Java程序的工作效率。但是调整GC是以个极为复杂的过程,由于各个程序具备不同的特点,如：web和GUI程序就有很大区别（Web可以适当的停顿,但GUI停顿是客户无法接受的）,而且由于跑在各个机器上的配置不同（主要cup个数,内存不同）,所以使用的GC种类也会不同(如何选择见GC种类及如何选择)。本文将注重介绍JVM、GC的一些重要参数的设置来提高系统的性能。 设置堆大小 -Xms 初始堆大小 物理内存的1/64(&lt;1GB) -Xmx 最大堆大小 物理内存的1/4(&lt;1GB) 设置年轻代大小 -Xmn 年轻代大小(1.4or lator) -XX:NewSize 设置年轻代大小(for 1.3/1.4) -XX:MaxNewSize 年轻代最大值(for 1.3/1.4) 设置持久代大小 -XX:PermSize 设置持久代(perm gen)初始值 物理内存的1/64 -XX:MaxPermSize 设置持久代最大值 物理内存的1/4 设置虚拟机栈大小 -Xss:每个线程的堆栈大小 -XX:ThreadStack Size Thread Stack Size 设置空间比例 -XX:NewRatio 年轻代(包括Eden和两个Survivor区)与年老代的比值(除去持久代) -XX:SurvivorRatio Eden区与Survivor区的大小比值 其他 -XX:LargePageSizeInBytes 内存页的大小不可设置过大, 会影响Perm的大小 -XX:+UseFastAccessorMethods 原始类型的快速优化 -XX:+DisableExplicitGC 关闭System.gc() -XX:MaxTenuringThreshold 垃圾最大年龄 -XX:+AggressiveOpts 加快编译 -XX:+UseBiasedLocking 锁机制的性能改善 -Xnoclassgc 禁用class回收 -XX:SoftRefLRUPolicyMSPerMB 每兆堆空闲空间中SoftReference的存活时间 -XX:PretenureSizeThreshold 对象超过多大是直接在旧生代分配 -XX:TLABWasteTargetPercent TLAB占eden区的百分比 -XX:+CollectGen0First FullGC时是否先YGC 并行收集器相关参数 -XX:+UseParallelGC Full GC采用parallel MSC(此项待验证) -XX:+UseParNewGC 设置年轻代为并行收集 -XX:ParallelGCThreads 并行收集器的线程数 -XX:+UseParallelOldGC 年老代垃圾收集方式为并行收集(Parallel Compacting) -XX:MaxGCPauseMillis 每次年轻代垃圾回收的最长时间(最大暂停时间) -XX:+UseAdaptiveSizePolicy 自动选择年轻代区大小和相应的Survivor区比例 -XX:GCTimeRatio 设置垃圾回收时间占程序运行时间的百分比 -XX:+ScavengeBeforeFullGC Full GC前调用YGC CMS 相关参数 -XX:+UseConcMarkSweepGC 使用CMS内存收集 -XX:+AggressiveHeap 试图使用大量的物理内存 -XX:CMSFullGCsBeforeCompaction 多少次后进行内存压缩 -XX:+CMSParallelRemarkEnabled 降低标记停顿 -XX+UseCMSCompactAtFullCollection 在FULL GC的时候, 对年老代的压缩 -XX:+UseCMSInitiatingOccupancyOnly 使用手动定义初始化定义开始CMS收集 -XX:CMSInitiatingOccupancyFraction=70 使用cms作为垃圾回收使用70％后开始CMS收集 -XX:CMSInitiatingPermOccupancyFraction 设置Perm Gen使用到达多少比率时触发 -XX:+CMSIncrementalMode 设置为增量模式 -XX:+CMSClassUnloadingEnabled CMS收集器默认不会对永久代进行垃圾回收。如果希望对永久代进行垃圾回收 辅助信息 -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGC:PrintGCTimeStamps 可与-XX:+PrintGC -XX:+PrintGCDetails混用 -XX:+PrintGCApplicationStoppedTime 打印垃圾回收期间程序暂停的时间.可与上面混合使用 -XX:+PrintGCApplicationConcurrentTime 打印每次垃圾回收前,程序未中断的执行时间.可与上面混合使用 -XX:+PrintHeapAtGC打印GC前后的详细堆栈信息 -Xloggc:filename 把相关日志信息记录到文件以便分析.与上面几个配合使用 -XX:+PrintClassHistogram garbage collects before printing the histogram. -XX:+PrintTLAB 查看TLAB空间的使用情况 -XX:+PrintTenuringDistribution 查看每次minor GC后新的存活周期的阈值","link":"/2018/08/20/Jvm/Java/JVM%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE%E3%80%81%E5%88%86%E6%9E%90/"},{"title":"Java性能调优","text":"公司做拼团活动时候,服务器挂掉了,需要对服务器的性能进行排查,压力测试使用阿里云的PTS和本地的Jmemter配合使用模拟用户真实登录的情况,以下是我在工作中得到一些经验. 保持调优的环境是良好的 redis,mysql是否与服务器在同一网段 检查各个连接池的配置是否合理配置连接池让资源能够可以重复使用,避免多次创建对象而消耗过多的时间和不必要的操作 服务器端redis连接池数量是否配置 服务器端mysql连接池数量是否配置 httpclient(restTemplate)连接池数量是否配置 检查数据库字段是否有索引不加索引可能导致全表扫描,进而发生read timeout 减少远程调用的次数减少远程调用,优先存本地JVM 本地JVM -&gt; Redis -&gt; Mysql 配置合理的超时时间配置合理的超时时间可以快速的让系统响应恢复,避免慢动作而卡死系统 需要配置的超时时间如下: socketTimeout connectTimeout 页面redis缓存将静态页面,将首页的页面数据可以直接缓存到本地,然后定时刷新页面 优化tomcat参数server.xml: 12345&lt;Connector port=\"8080\" protocol=\"org.apache.coyote.http11.Http11NioProtocol\" connectionTimeout=\"5000\" redirectPort=\"8443\" keepAliveTimeout=\"5000\" maxKeepAliveRequests=\"300\" minSpareThreads=\"100\" enableLookups=\"false\" maxThreads=\"1000\" acceptCount=\"1000\" URIEncoding=\"UTF-8\"/&gt; catalina.sh: 12345CATALINA_OPTS=\"${CATALINA_OPTS} -d64 -Xms4096m -Xmx4096m -Xmn1536m -XX:MetaspaceSize=512m -XX:MaxMetaspaceSize=512m -XX:ReservedCodeCacheSize=1024m\"JAVA_OPTS=\"${JAVA_OPTS} -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:CMSInitiatingOccupancyFraction=70 -XX:SurvivorRatio=8 -XX:+DisableExplicitGC -XX:+ScavengeBeforeFullGC -XX:+CMSScavengeBeforeRemark\"JAVA_OPTS=\"${JAVA_OPTS} -verbose:gc -Xloggc:/usr/local/tomcat7/logs/gc.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps\"JAVA_OPTS=\"${JAVA_OPTS} -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/opt/tomcat/logs/heapdump.hprof\"JAVA_OPTS=\"${JAVA_OPTS} -Dfile.encoding=UTF-8\" 性能调优排查策略 保持环境在高负载的情况下,去后台查看线程情况和GC情况 ping redis,mysql的环境是否保持在一个网段 2毫秒以上可能就是在不同网段 使用jstat --gc 10 1000查看gc情况以及各个区间的情况 如果有过多的 full gc 可能需要调大 JVM 堆区的大小 使用jstack &lt;pid&gt;命令查看线程情况 看线程中是否有业务代码,如果有业务代码需要查看sql语句执行是否缓慢 远程调用是否花费过多时间 参考文档Java性能权威指南 奥克斯 (Scott Oaks) 人民邮电出版社","link":"/2019/01/01/Jvm/Java/Java%E8%B0%83%E4%BC%98/"},{"title":"(译) PECS 原理","text":"PECS来自集合的观点。如果你只是从通用集合中得到对象,那么它是生产者, 你应该使用extends; 如果你只是添加对象,它是一个消费者,你应该使用super。 如果同时使用相同的集合,则不应使用extends或super。 假设你有一个方法,它将事物的集合作为参数,但你希望它比仅接受一个更灵活Collection。 案例1：你希望浏览集合并对每个项目执行操作。 然后列表是生产者,所以你应该使用Collection&lt;? extends Thing&gt;。 原因是Collection&lt;? extends Thing&gt;可以保存任何子类型Thing,每个Thing类型的对象在执行操作时都这样。（你实际上无法向a添加任何内容Collection&lt;? extends Thing&gt;,因为你无法在运行时知道该集合的哪个特定子类型Thing。） 案例2：你想要向集合中添加内容。 然后列表是消费者,所以你应该使用Collection&lt;? super Thing&gt;。 这里的推理是不同的Collection&lt;? extends Thing&gt;,无论实际的参数化类型是什么,Collection&lt;? super Thing&gt;都可以随时保持Thing。在这里你不关心列表中已有的内容,只要它允许Thing添加; 这是什么? super Thing保证。 在一门程序设计语言的类型系统中,一个类型规则或者类型构造器是： 协变（covariant）,如果它保持了子类型序关系≦。该序关系是：子类型≦基类型。 逆变（contravariant）,如果它逆转了子类型序关系。 不变（invariant）,如果上述两种均不适用。 Animal[]并不是总能当作Cat[],因为当一个客户读取数组并期望得到一个Cat,但Animal[]中包含的可能是个Dog。所以逆变规则是不安全,所以如果get一个被斜变修饰的类型返回的是object类型 返回值的协变在允许协变返回值的语言中, 子类可以重写 getAnimalForAdoption 方法来返回一个更窄的类型： 12345class CatShelter extends AnimalShelter { Cat getAnimalForAdoption() { return new Cat(); }} 方法参数的逆变类似地,子类重写的方法接受更宽的类型也是类型安全（type safe）的： 12345class CatShelter extends AnimalShelter { void putAnimal(Object animal) { ... }} 协变的方法参数类型在主流的语言中,Eiffel 允许一个重写的方法参数比起父类中的那一个有更加具体的类型,即参数类型协变。因此,Eiffel 版本的 putAnimal 会如下所示： 12345class CatShelter extends AnimalShelter { void putAnimal(Cat animal) { ... }} 去除对参数类型协变的依赖其它语言特性可能用来弥补缺乏参数类型协变的缺乏。 在有泛型（即参数化多态及受限量词）的语言中,前面的例子可用更类型安全的方式重写[5] ：不定义 AnimalShelter,改为定义一个参数化的类 Shelter。（这种方法的缺点之一是基类实现者需要预料到哪些类型要在子类中特化） 1234567891011121314151617181920class Shelter&lt;T extends Animal&gt; { T getAnimalForAdoption() { ... } void putAnimal(T animal) { ... }}class CatShelter extends Shelter&lt;Cat&gt; { Cat getAnimalForAdoption() { ... } void putAnimal(Cat animal) { ... }} 参考文档What is PECS (Producer Extends Consumer Super)? 维基百科-逆变与协变","link":"/2018/12/29/Jvm/Java/PECS%E5%8E%9F%E7%90%86/"},{"title":"Java基础梳理及关键原理","text":"一、数据类型 包装类型 缓存池 二、String 概览 不可变的好处 String, StringBuffer and StringBuilder String.intern() 三、运算 参数传递 float 与 double 隐式类型转换 switch 四、继承 访问权限 抽象类与接口 super 重写与重载 五、Object 通用方法 概览 equals() hashCode() toString() clone() 六、关键字 final static 七、反射 八、异常 九、泛型 十、注解 十一、特性 Java 各版本的新特性 Java 与 C++ 的区别 JRE or JDK 参考资料 一、数据类型包装类型八个基本类型： boolean/1 byte/8 char/16 short/16 int/32 float/32 long/64 double/64 基本类型都有对应的包装类型,基本类型与其对应的包装类型之间的赋值使用自动装箱与拆箱完成。 12Integer x = 2; // 装箱int y = x; // 拆箱 缓存池new Integer(123) 与 Integer.valueOf(123) 的区别在于： new Integer(123) 每次都会新建一个对象 Integer.valueOf(123) 会使用缓存池中的对象,多次调用会取得同一个对象的引用。 123456Integer x = new Integer(123);Integer y = new Integer(123);System.out.println(x == y); // falseInteger z = Integer.valueOf(123);Integer k = Integer.valueOf(123);System.out.println(z == k); // true valueOf() 方法的实现比较简单,就是先判断值是否在缓存池中,如果在的话就直接返回缓存池的内容。 12345public static Integer valueOf(int i) { if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i);} 在 Java 8 中,Integer 缓存池的大小默认为 -128~127。 1234567891011121314151617181920212223242526272829static final int low = -128;static final int high;static final Integer cache[];static { // high value may be configured by property int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty(\"java.lang.Integer.IntegerCache.high\"); if (integerCacheHighPropValue != null) { try { int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(i, Integer.MAX_VALUE - (-low) -1); } catch( NumberFormatException nfe) { // If the property cannot be parsed into an int, ignore it. } } high = h; cache = new Integer[(high - low) + 1]; int j = low; for(int k = 0; k &lt; cache.length; k++) cache[k] = new Integer(j++); // range [-128, 127] must be interned (JLS7 5.1.7) assert IntegerCache.high &gt;= 127;} 编译器会在自动装箱过程调用 valueOf() 方法,因此多个 Integer 实例使用自动装箱来创建并且值相同,那么就会引用相同的对象。 123Integer m = 123;Integer n = 123;System.out.println(m == n); // true 基本类型对应的缓冲池如下： boolean values true and false all byte values short values between -128 and 127 int values between -128 and 127 char in the range \\u0000 to \\u007F 在使用这些基本类型对应的包装类型时,就可以直接使用缓冲池中的对象。 StackOverflow : Differences between new Integer(123), Integer.valueOf(123) and just 123 二、String1.概览String 被声明为 final,因此它不可被继承。 内部使用 char 数组存储数据,该数组被声明为 final,这意味着 value 数组初始化之后就不能再引用其它数组。并且 String 内部没有改变 value 数组的方法,因此可以保证 String 不可变。 1234public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence { /** The value is used for character storage. */ private final char value[]; 2.不可变的好处可以缓存 hash 值因为 String 的 hash 值经常被使用,例如 String 用做 HashMap 的 key。不可变的特性可以使得 hash 值也不可变,因此只需要进行一次计算。 String Pool 的需要如果一个 String 对象已经被创建过了,那么就会从 String Pool 中取得引用。只有 String 是不可变的,才可能使用 String Pool。 安全性String 经常作为参数,String 不可变性可以保证参数不可变。例如在作为网络连接参数的情况下如果 String 是可变的,那么在网络连接过程中,String 被改变,改变 String 对象的那一方以为现在连接的是其它主机,而实际情况却不一定是。 线程安全String 不可变性天生具备线程安全,可以在多个线程中安全地使用。 Program Creek : Why String is immutable in Java? 3.String, StringBuffer and StringBuilder可变性 String 不可变 StringBuffer 和 StringBuilder 可变 线程安全 String 不可变,因此是线程安全的 StringBuilder 不是线程安全的 StringBuffer 是线程安全的,内部使用 synchronized 进行同步 StackOverflow : String, StringBuffer, and StringBuilder 4.String.intern()使用 String.intern() 可以保证相同内容的字符串变量引用同一的内存对象。 下面示例中,s1 和 s2 采用 new String() 的方式新建了两个不同对象,而 s3 是通过 s1.intern() 方法取得一个对象引用。intern() 首先把 s1 引用的对象放到 String Pool（字符串常量池）中,然后返回这个对象引用。因此 s3 和 s1 引用的是同一个字符串常量池的对象。 12345String s1 = new String(\"aaa\");String s2 = new String(\"aaa\");System.out.println(s1 == s2); // falseString s3 = s1.intern();System.out.println(s1.intern() == s3); // true 如果是采用 “bbb” 这种使用双引号的形式创建字符串实例,会自动地将新建的对象放入 String Pool 中。 123String s4 = \"bbb\";String s5 = \"bbb\";System.out.println(s4 == s5); // true 在 Java 7 之前,字符串常量池被放在运行时常量池中,它属于永久代。而在 Java 7,字符串常量池被移到 Native Method 中。这是因为永久代的空间有限,在大量使用字符串的场景下会导致 OutOfMemoryError 错误。 StackOverflow : What is String interning? 深入解析 String#intern 三、运算参数传递Java 的参数是以值传递的形式传入方法中,而不是引用传递。 以下代码中 Dog dog 的 dog 是一个指针,存储的是对象的地址。在将一个参数传入一个方法时,本质上是将对象的地址以值的方式传递到形参中。因此在方法中改变指针引用的对象,那么这两个指针此时指向的是完全不同的对象,一方改变其所指向对象的内容对另一方没有影响。 12345678910111213141516171819public class Dog { String name; Dog(String name) { this.name = name; } String getName() { return this.name; } void setName(String name) { this.name = name; } String getObjectAddress() { return super.toString(); }} 12345678910111213141516public class PassByValueExample { public static void main(String[] args) { Dog dog = new Dog(\"A\"); System.out.println(dog.getObjectAddress()); // Dog@4554617c func(dog); System.out.println(dog.getObjectAddress()); // Dog@4554617c System.out.println(dog.getName()); // A } private static void func(Dog dog) { System.out.println(dog.getObjectAddress()); // Dog@4554617c dog = new Dog(\"B\"); System.out.println(dog.getObjectAddress()); // Dog@74a14482 System.out.println(dog.getName()); // B }} 但是如果在方法中改变对象的字段值会改变原对象该字段值,因为改变的是同一个地址指向的内容。 1234567891011class PassByValueExample { public static void main(String[] args) { Dog dog = new Dog(\"A\"); func(dog); System.out.println(dog.getName()); // B } private static void func(Dog dog) { dog.setName(\"B\"); }} StackOverflow: Is Java “pass-by-reference” or “pass-by-value”? float 与 double1.1 字面量属于 double 类型,不能直接将 1.1 直接赋值给 float 变量,因为这是向下转型。Java 不能隐式执行向下转型,因为这会使得精度降低。 1// float f = 1.1; 1.1f 字面量才是 float 类型。 1float f = 1.1f; 隐式类型转换因为字面量 1 是 int 类型,它比 short 类型精度要高,因此不能隐式地将 int 类型下转型为 short 类型。 12short s1 = 1;// s1 = s1 + 1; 但是使用 += 运算符可以执行隐式类型转换。 1s1 += 1; 上面的语句相当于将 s1 + 1 的计算结果进行了向下转型： 1s1 = (short) (s1 + 1); StackOverflow : Why don’t Java’s +=, -=, *=, /= compound assignment operators require casting? switch从 Java 7 开始,可以在 switch 条件判断语句中使用 String 对象。 123456789String s = \"a\";switch (s) { case \"a\": System.out.println(\"aaa\"); break; case \"b\": System.out.println(\"bbb\"); break;} switch 不支持 long,是因为 switch 的设计初衷是对那些只有少数的几个值进行等值判断,如果值过于复杂,那么还是用 if 比较合适。 123456789// long x = 111;// switch (x) { // Incompatible types. Found: 'long', required: 'char, byte, short, int, Character, Byte, Short, Integer, String, or an enum'// case 111:// System.out.println(111);// break;// case 222:// System.out.println(222);// break;// } StackOverflow : Why can’t your switch statement data type be long, Java? 四、继承访问权限Java 中有三个访问权限修饰符：private、protected 以及 public,如果不加访问修饰符,表示包级可见。 可以对类或类中的成员（字段以及方法）加上访问修饰符。 类可见表示其它类可以用这个类创建实例对象。 成员可见表示其它类可以用这个类的实例对象访问到该成员； protected 用于修饰成员,表示在继承体系中成员对于子类可见,但是这个访问修饰符对于类没有意义。 设计良好的模块会隐藏所有的实现细节,把它的 API 与它的实现清晰地隔离开来。模块之间只通过它们的 API 进行通信,一个模块不需要知道其他模块的内部工作情况,这个概念被称为信息隐藏或封装。因此访问权限应当尽可能地使每个类或者成员不被外界访问。 如果子类的方法重写了父类的方法,那么子类中该方法的访问级别不允许低于父类的访问级别。这是为了确保可以使用父类实例的地方都可以使用子类实例,也就是确保满足里氏替换原则。 字段决不能是公有的,因为这么做的话就失去了对这个字段修改行为的控制,客户端可以对其随意修改。例如下面的例子中,AccessExample 拥有 id 共有字段,如果在某个时刻,我们想要使用 int 去存储 id 字段,那么就需要去修改所有的客户端代码。 123public class AccessExample { public String id;} 可以使用公有的 getter 和 setter 方法来替换公有字段,这样的话就可以控制对字段的修改行为。 123456789101112public class AccessExample { private int id; public String getId() { return id + \"\"; } public void setId(String id) { this.id = Integer.valueOf(id); }} 但是也有例外,如果是包级私有的类或者私有的嵌套类,那么直接暴露成员不会有特别大的影响。 123456789101112131415public class AccessWithInnerClassExample { private class InnerClass { int x; } private InnerClass innerClass; public AccessWithInnerClassExample() { innerClass = new InnerClass(); } public int getValue() { return innerClass.x; // 直接访问 }} 抽象类与接口1. 抽象类抽象类和抽象方法都使用 abstract 关键字进行声明。抽象类一般会包含抽象方法,抽象方法一定位于抽象类中。 抽象类和普通类最大的区别是,抽象类不能被实例化,需要继承抽象类才能实例化其子类。 1234567891011public abstract class AbstractClassExample { protected int x; private int y; public abstract void func1(); public void func2() { System.out.println(\"func2\"); }} 123456public class AbstractExtendClassExample extends AbstractClassExample { @Override public void func1() { System.out.println(\"func1\"); }} 123// AbstractClassExample ac1 = new AbstractClassExample(); // 'AbstractClassExample' is abstract; cannot be instantiatedAbstractClassExample ac2 = new AbstractExtendClassExample();ac2.func1(); 2. 接口接口是抽象类的延伸,在 Java 8 之前,它可以看成是一个完全抽象的类,也就是说它不能有任何的方法实现。 从 Java 8 开始,接口也可以拥有默认的方法实现,这是因为不支持默认方法的接口的维护成本太高了。在 Java 8 之前,如果一个接口想要添加新的方法,那么要修改所有实现了该接口的类。 接口的成员（字段 + 方法）默认都是 public 的,并且不允许定义为 private 或者 protected。 接口的字段默认都是 static 和 final 的。 1234567891011121314public interface InterfaceExample { void func1(); default void func2(){ System.out.println(\"func2\"); } int x = 123; // int y; // Variable 'y' might not have been initialized public int z = 0; // Modifier 'public' is redundant for interface fields // private int k = 0; // Modifier 'private' not allowed here // protected int l = 0; // Modifier 'protected' not allowed here // private void fun3(); // Modifier 'private' not allowed here} 123456public class InterfaceImplementExample implements InterfaceExample { @Override public void func1() { System.out.println(\"func1\"); }} 1234// InterfaceExample ie1 = new InterfaceExample(); // 'InterfaceExample' is abstract; cannot be instantiatedInterfaceExample ie2 = new InterfaceImplementExample();ie2.func1();System.out.println(InterfaceExample.x); 3. 比较 从设计层面上看,抽象类提供了一种 IS-A 关系,那么就必须满足里式替换原则,即子类对象必须能够替换掉所有父类对象。而接口更像是一种 LIKE-A 关系,它只是提供一种方法实现契约,并不要求接口和实现接口的类具有 IS-A 关系。 从使用上来看,一个类可以实现多个接口,但是不能继承多个抽象类。 接口的字段只能是 static 和 final 类型的,而抽象类的字段没有这种限制。 接口的成员只能是 public 的,而抽象类的成员可以有多种访问权限。 4. 使用选择使用接口： 需要让不相关的类都实现一个方法,例如不相关的类都可以实现 Compareable 接口中的 compareTo() 方法； 需要使用多重继承。 使用抽象类： 需要在几个相关的类中共享代码。 需要能控制继承来的成员的访问权限,而不是都为 public。 需要继承非静态和非常量字段。 在很多情况下,接口优先于抽象类,因为接口没有抽象类严格的类层次结构要求,可以灵活地为一个类添加行为。并且从 Java 8 开始,接口也可以有默认的方法实现,使得修改接口的成本也变的很低。 深入理解 abstract class 和 interface When to Use Abstract Class and Interface super 访问父类的构造函数：可以使用 super() 函数访问父类的构造函数,从而委托父类完成一些初始化的工作。 访问父类的成员：如果子类重写了父类的中某个方法的实现,可以通过使用 super 关键字来引用父类的方法实现。 12345678910111213public class SuperExample { protected int x; protected int y; public SuperExample(int x, int y) { this.x = x; this.y = y; } public void func() { System.out.println(\"SuperExample.func()\"); }} 1234567891011121314public class SuperExtendExample extends SuperExample { private int z; public SuperExtendExample(int x, int y, int z) { super(x, y); this.z = z; } @Override public void func() { super.func(); System.out.println(\"SuperExtendExample.func()\"); }} 12SuperExample e = new SuperExtendExample(1, 2, 3);e.func(); 12SuperExample.func()SuperExtendExample.func() Using the Keyword super 重写与重载1. 重写（Override）存在于继承体系中,指子类实现了一个与父类在方法声明上完全相同的一个方法。 为了满足里式替换原则,重写有有以下两个限制： 子类方法的访问权限必须大于等于父类方法； 子类方法的返回类型必须是父类方法返回类型或为其子类型。 使用 @Override 注解,可以让编译器帮忙检查是否满足上面的两个限制条件。 2. 重载（Overload）存在于同一个类中,指一个方法与已经存在的方法名称上相同,但是参数类型、个数、顺序至少有一个不同。 应该注意的是,返回值不同,其它都相同不算是重载。 五、Object 通用方法概览123456789101112131415161718192021public final native Class&lt;?&gt; getClass()public native int hashCode()public boolean equals(Object obj)protected native Object clone() throws CloneNotSupportedExceptionpublic String toString()public final native void notify()public final native void notifyAll()public final native void wait(long timeout) throws InterruptedExceptionpublic final void wait(long timeout, int nanos) throws InterruptedExceptionpublic final void wait() throws InterruptedExceptionprotected void finalize() throws Throwable {} equals()1. 等价关系（一）自反性 1x.equals(x); // true （二）对称性 1x.equals(y) == y.equals(x); // true （三）传递性 12if (x.equals(y) &amp;&amp; y.equals(z)) x.equals(z); // true; （四）一致性 多次调用 equals() 方法结果不变 1x.equals(y) == x.equals(y); // true （五）与 null 的比较 对任何不是 null 的对象 x 调用 x.equals(null) 结果都为 false 1x.equals(null); // false; 2. equals() 与 == 对于基本类型,== 判断两个值是否相等,基本类型没有 equals() 方法。 对于引用类型,== 判断两个变量是否引用同一个对象,而 equals() 判断引用的对象是否等价。 1234Integer x = new Integer(1);Integer y = new Integer(1);System.out.println(x.equals(y)); // trueSystem.out.println(x == y); // false 3. 实现 检查是否为同一个对象的引用,如果是直接返回 true； 检查是否是同一个类型,如果不是,直接返回 false； 将 Object 对象进行转型； 判断每个关键域是否相等。 1234567891011121314151617181920212223public class EqualExample { private int x; private int y; private int z; public EqualExample(int x, int y, int z) { this.x = x; this.y = y; this.z = z; } @Override public boolean equals(Object o) { if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; EqualExample that = (EqualExample) o; if (x != that.x) return false; if (y != that.y) return false; return z == that.z; }} hashCode()hasCode() 返回散列值,而 equals() 是用来判断两个对象是否等价。等价的两个对象散列值一定相同,但是散列值相同的两个对象不一定等价。 在覆盖 equals() 方法时应当总是覆盖 hashCode() 方法,保证等价的两个对象散列值也相等。 下面的代码中,新建了两个等价的对象,并将它们添加到 HashSet 中。我们希望将这两个对象当成一样的,只在集合中添加一个对象,但是因为 EqualExample 没有实现 hasCode() 方法,因此这两个对象的散列值是不同的,最终导致集合添加了两个等价的对象。 1234567EqualExample e1 = new EqualExample(1, 1, 1);EqualExample e2 = new EqualExample(1, 1, 1);System.out.println(e1.equals(e2)); // trueHashSet&lt;EqualExample&gt; set = new HashSet&lt;&gt;();set.add(e1);set.add(e2);System.out.println(set.size()); // 2 理想的散列函数应当具有均匀性,即不相等的对象应当均匀分布到所有可能的散列值上。这就要求了散列函数要把所有域的值都考虑进来,可以将每个域都当成 n 进制的某一位,然后组成一个 n 进制的整数。n 一般取 31,因为它是一个奇素数,如果是偶数的话,当出现乘法溢出,信息就会丢失,因为与 2 相乘相当于向左移一位。 一个数与 31 相乘可以转换成移位和减法：31*x == (x&lt;&lt;5)-x,编译器会自动进行这个优化。 12345678@Overridepublic int hashCode() { int result = 17; result = 31 * result + x; result = 31 * result + y; result = 31 * result + z; return result;} toString()默认返回 ToStringExample@4554617c 这种形式,其中 @ 后面的数值为散列码的无符号十六进制表示。 1234567public class ToStringExample { private int number; public ToStringExample(int number) { this.number = number; }} 12ToStringExample example = new ToStringExample(123);System.out.println(example.toString()); 1ToStringExample@4554617c clone()1. cloneableclone() 是 Object 的 protected 方法,它不是 public,一个类不显式去重写 clone(),其它类就不能直接去调用该类实例的 clone() 方法。 1234public class CloneExample { private int a; private int b;} 12CloneExample e1 = new CloneExample();// CloneExample e2 = e1.clone(); // 'clone()' has protected access in 'java.lang.Object' 重写 clone() 得到以下实现： 123456789public class CloneExample { private int a; private int b; @Override protected CloneExample clone() throws CloneNotSupportedException { return (CloneExample)super.clone(); }} 123456CloneExample e1 = new CloneExample();try { CloneExample e2 = e1.clone();} catch (CloneNotSupportedException e) { e.printStackTrace();} 1java.lang.CloneNotSupportedException: CloneExample 以上抛出了 CloneNotSupportedException,这是因为 CloneExample 没有实现 Cloneable 接口。 应该注意的是,clone() 方法并不是 Cloneable 接口的方法,而是 Object 的一个 protected 方法。Cloneable 接口只是规定,如果一个类没有实现 Cloneable 接口又调用了 clone() 方法,就会抛出 CloneNotSupportedException。 123456789public class CloneExample implements Cloneable { private int a; private int b; @Override protected Object clone() throws CloneNotSupportedException { return super.clone(); }} 2. 浅拷贝拷贝对象和原始对象的引用类型引用同一个对象。 1234567891011121314151617181920212223public class ShallowCloneExample implements Cloneable { private int[] arr; public ShallowCloneExample() { arr = new int[10]; for (int i = 0; i &lt; arr.length; i++) { arr[i] = i; } } public void set(int index, int value) { arr[index] = value; } public int get(int index) { return arr[index]; } @Override protected ShallowCloneExample clone() throws CloneNotSupportedException { return (ShallowCloneExample) super.clone(); }} 123456789ShallowCloneExample e1 = new ShallowCloneExample();ShallowCloneExample e2 = null;try { e2 = e1.clone();} catch (CloneNotSupportedException e) { e.printStackTrace();}e1.set(2, 222);System.out.println(e2.get(2)); // 222 3. 深拷贝拷贝对象和原始对象的引用类型引用不同对象。 12345678910111213141516171819202122232425262728public class DeepCloneExample implements Cloneable { private int[] arr; public DeepCloneExample() { arr = new int[10]; for (int i = 0; i &lt; arr.length; i++) { arr[i] = i; } } public void set(int index, int value) { arr[index] = value; } public int get(int index) { return arr[index]; } @Override protected DeepCloneExample clone() throws CloneNotSupportedException { DeepCloneExample result = (DeepCloneExample) super.clone(); result.arr = new int[arr.length]; for (int i = 0; i &lt; arr.length; i++) { result.arr[i] = arr[i]; } return result; }} 123456789DeepCloneExample e1 = new DeepCloneExample();DeepCloneExample e2 = null;try { e2 = e1.clone();} catch (CloneNotSupportedException e) { e.printStackTrace();}e1.set(2, 222);System.out.println(e2.get(2)); // 2 4. clone() 的替代方案使用 clone() 方法来拷贝一个对象即复杂又有风险,它会抛出异常,并且还需要类型转换。Effective Java 书上讲到,最好不要去使用 clone(),可以使用拷贝构造函数或者拷贝工厂来拷贝一个对象。 12345678910111213141516171819202122232425public class CloneConstructorExample { private int[] arr; public CloneConstructorExample() { arr = new int[10]; for (int i = 0; i &lt; arr.length; i++) { arr[i] = i; } } public CloneConstructorExample(CloneConstructorExample original) { arr = new int[original.arr.length]; for (int i = 0; i &lt; original.arr.length; i++) { arr[i] = original.arr[i]; } } public void set(int index, int value) { arr[index] = value; } public int get(int index) { return arr[index]; }} 1234CloneConstructorExample e1 = new CloneConstructorExample();CloneConstructorExample e2 = new CloneConstructorExample(e1);e1.set(2, 222);System.out.println(e2.get(2)); // 2 六、关键字final1. 数据声明数据为常量,可以是编译时常量,也可以是在运行时被初始化后不能被改变的常量。 对于基本类型,final 使数值不变； 对于引用类型,final 使引用不变,也就不能引用其它对象,但是被引用的对象本身是可以修改的。 1234final int x = 1;// x = 2; // cannot assign value to final variable 'x'final A y = new A();y.a = 1; 2. 方法声明方法不能被子类重写。 private 方法隐式地被指定为 final,如果在子类中定义的方法和基类中的一个 private 方法签名相同,此时子类的方法不是重写基类方法,而是在子类中定义了一个新的方法。 3. 类声明类不允许被继承。 static1. 静态变量 静态变量：又称为类变量,也就是说这个变量属于类的,类所有的实例都共享静态变量,可以直接通过类名来访问它；静态变量在内存中只存在一份。 实例变量：每创建一个实例就会产生一个实例变量,它与该实例同生共死。 1234567891011public class A { private int x; // 实例变量 private static int y; // 静态变量 public static void main(String[] args) { // int x = A.x; // Non-static field 'x' cannot be referenced from a static context A a = new A(); int x = a.x; int y = A.y; }} 2. 静态方法静态方法在类加载的时候就存在了,它不依赖于任何实例。所以静态方法必须有实现,也就是说它不能是抽象方法（abstract）。 12345public abstract class A { public static void func1(){ } // public abstract static void func2(); // Illegal combination of modifiers: 'abstract' and 'static'} 只能访问所属类的静态字段和静态方法,方法中不能有 this 和 super 关键字。 12345678910public class A { private static int x; private int y; public static void func1(){ int a = x; // int b = y; // Non-static field 'y' cannot be referenced from a static context // int b = this.y; // 'A.this' cannot be referenced from a static context }} 3. 静态语句块静态语句块在类初始化时运行一次。 12345678910public class A { static { System.out.println(\"123\"); } public static void main(String[] args) { A a1 = new A(); A a2 = new A(); }} 1123 4. 静态内部类非静态内部类依赖于外部类的实例,而静态内部类不需要。 1234567891011121314public class OuterClass { class InnerClass { } static class StaticInnerClass { } public static void main(String[] args) { // InnerClass innerClass = new InnerClass(); // 'OuterClass.this' cannot be referenced from a static context OuterClass outerClass = new OuterClass(); InnerClass innerClass = outerClass.new InnerClass(); StaticInnerClass staticInnerClass = new StaticInnerClass(); }} 静态内部类不能访问外部类的非静态的变量和方法。 5. 静态导包在使用静态变量和方法时不用再指明 ClassName,从而简化代码,但可读性大大降低。 1import static com.xxx.ClassName.* 6. 初始化顺序静态变量和静态语句块优先于实例变量和普通语句块,静态变量和静态语句块的初始化顺序取决于它们在代码中的顺序。 1public static String staticField = \"静态变量\"; 123static { System.out.println(\"静态语句块\");} 1public String field = \"实例变量\"; 123{ System.out.println(\"普通语句块\");} 最后才是构造函数的初始化。 123public InitialOrderTest() { System.out.println(\"构造函数\");} 存在继承的情况下,初始化顺序为： 父类（静态变量、静态语句块） 子类（静态变量、静态语句块） 父类（实例变量、普通语句块） 父类（构造函数） 子类（实例变量、普通语句块） 子类（构造函数） 七、反射每个类都有一个 Class 对象,包含了与类有关的信息。当编译一个新类时,会产生一个同名的 .class 文件,该文件内容保存着 Class 对象。 类加载相当于 Class 对象的加载。类在第一次使用时才动态加载到 JVM 中,可以使用Class.forName(&quot;com.mysql.jdbc.Driver&quot;)这种方式来控制类的加载,该方法会返回一个 Class 对象。 反射可以提供运行时的类信息,并且这个类可以在运行时才加载进来,甚至在编译时期该类的 .class 不存在也可以加载进来。 Class 和 java.lang.reflect 一起对反射提供了支持,java.lang.reflect 类库主要包含了以下三个类： Field ：可以使用 get() 和 set() 方法读取和修改 Field 对象关联的字段； Method ：可以使用 invoke() 方法调用与 Method 对象关联的方法； Constructor ：可以用 Constructor 创建新的对象。 Advantages of Using Reflection: Extensibility Features : An application may make use of external, user-defined classes by creating instances of extensibility objects using their fully-qualified names. Class Browsers and Visual Development Environments : A class browser needs to be able to enumerate the members of classes. Visual development environments can benefit from making use of type information available in reflection to aid the developer in writing correct code. Debuggers and Test Tools : Debuggers need to be able to examine private members on classes. Test harnesses can make use of reflection to systematically call a discoverable set APIs defined on a class, to insure a high level of code coverage in a test suite. Drawbacks of Reflection: Reflection is powerful, but should not be used indiscriminately. If it is possible to perform an operation without using reflection, then it is preferable to avoid using it. The following concerns should be kept in mind when accessing code via reflection. Performance Overhead : Because reflection involves types that are dynamically resolved, certain Java virtual machine optimizations can not be performed. Consequently, reflective operations have slower performance than their non-reflective counterparts, and should be avoided in sections of code which are called frequently in performance-sensitive applications. Security Restrictions : Reflection requires a runtime permission which may not be present when running under a security manager. This is in an important consideration for code which has to run in a restricted security context, such as in an Applet. Exposure of Internals :Since reflection allows code to perform operations that would be illegal in non-reflective code, such as accessing private fields and methods, the use of reflection can result in unexpected side-effects, which may render code dysfunctional and may destroy portability. Reflective code breaks abstractions and therefore may change behavior with upgrades of the platform. Trail: The Reflection API 深入解析 Java 反射（1）- 基础 八、异常Throwable 可以用来表示任何可以作为异常抛出的类,分为两种： Error 和 Exception。其中 Error 用来表示 JVM 无法处理的错误,Exception 分为两种： 受检异常 ：需要用 try…catch… 语句捕获并进行处理,并且可以从异常中恢复； 非受检异常 ：是程序运行时错误,例如除 0 会引发 Arithmetic Exception,此时程序崩溃并且无法恢复。 Java 入门之异常处理 Java 异常的面试问题及答案 -Part 1 九、泛型123456public class Box&lt;T&gt; { // T stands for \"Type\" private T t; public void set(T t) { this.t = t; } public T get() { return t; }} Java 泛型详解 10 道 Java 泛型面试题 十、注解Java 注解是附加在代码中的一些元信息,用于一些工具在编译、运行时进行解析和使用,起到说明、配置的功能。注解不会也不能影响代码的实际逻辑,仅仅起到辅助性的作用。 注解 Annotation 实现原理与自定义注解例子 十一、特性Java 各版本的新特性New highlights in Java SE 8 Lambda Expressions Pipelines and Streams Date and Time API Default Methods Type Annotations Nashhorn JavaScript Engine Concurrent Accumulators Parallel operations PermGen Error Removed New highlights in Java SE 7 Strings in Switch Statement Type Inference for Generic Instance Creation Multiple Exception Handling Support for Dynamic Languages Try with Resources Java nio Package Binary Literals, Underscore in literals Diamond Syntax Difference between Java 1.8 and Java 1.7? Java 8 特性 Java 与 C++ 的区别 Java 是纯粹的面向对象语言,所有的对象都继承自 java.lang.Object,C++ 为了兼容 C 即支持面向对象也支持面向过程。 Java 通过虚拟机从而实现跨平台特性,但是 C++ 依赖于特定的平台。 Java 没有指针,它的引用可以理解为安全指针,而 C++ 具有和 C 一样的指针。 Java 支持自动垃圾回收,而 C++ 需要手动回收。 Java 不支持多重继承,只能通过实现多个接口来达到相同目的,而 C++ 支持多重继承。 Java 不支持操作符重载,虽然可以对两个 String 对象支持加法运算,但是这是语言内置支持的操作,不属于操作符重载,而 C++ 可以。 Java 的 goto 是保留字,但是不可用,C++ 可以使用 goto。 Java 不支持条件编译,C++ 通过 #ifdef #ifndef 等预处理命令从而实现条件编译。 What are the main differences between Java and C++? JRE or JDK JRE is the JVM program, Java application need to run on JRE. JDK is a superset of JRE, JRE + tools for developing java programs. e.g, it provides the compiler “javac” 参考资料 Eckel B. Java 编程思想[M]. 机械工业出版社, 2002. Bloch J. Effective java[M]. Addison-Wesley Professional, 2017.","link":"/2018/08/19/Jvm/Java/Java%E5%9F%BA%E7%A1%80%E6%A2%B3%E7%90%86%E5%8F%8A%E5%85%B3%E9%94%AE%E5%8E%9F%E7%90%86/"},{"title":"synchronized和volatile的分析和区别","text":"synchronized和volatile比较了一些其中的区别。 一、 知识普及Java内存模型[JMM]描述了Java程序中各种变量（这里的变量指的是线程共享变量）的访问规则,以及在JVM中将变量存储到内存和从内存中读取出变量这样的底层的细节。 工作内存、主内存每个程序都有一个主内存,每个线程都有自己独立的工作内存,里面保存了该线程使用到的变量的副本（主内存该变量的一份拷贝）。不能直接访问主内存。线程间变量值的传递需要通过主内存完成。 共享变量如果一个变量在多个线程的工作内存中都存在副本,那么这个变量就是这几个现成的共享变量。 as-if-serial语义as-if-serial：无论如何重排序,程序执行结果应该与代码顺序执行的结果一致（Java编译器、运行时和处理器都会保证Java在单线程下遵循as-if-serial语义）。 指令重排序代码书写的顺序与实际执行的顺序不同,指令重排序是编译器或处理器为了提高程序性能而做的优化。 编译器优化的重排序（编译器优化） 指令级并行重排序（处理器优化） 内存系统的重排序（处理器优化） 可见性一个线程对共享变量值的修改,能够及时地被其他线程看到。 二、 synchronized1.JMM关于synchronized的两条规定： 线程解锁前,必须把共享变量的最新值刷新到主内存中。 线程加锁前,将清空工作内存中共享变量的值,从而使用共享变量时需要从主内存中重新读取. 2.线程执行互斥代码的过程： 获取互斥锁 清空工作内存。 从主内存拷贝变量的最新副本到工作内存中。 执行代码 将更改后的共享变量的值刷新到主内存中。 释放互斥锁。 3.可见性分析导致共享变量在线程间不可见的原因: 线程交叉执行 重排序结合线程交叉执行 共享变量更新后的值没有在工作内存和主内存间及时更新。 synchronized的解决方案： 原子性—-锁内部的代码在一段时间内只能由一个线程执行,避免线程在锁内部交叉执行。 有序性—-避免线程在锁内部交叉执行；重排序都是在单独的线程内执行,再结合as-if-serial理解。 可见性—-这是synchronized的可见性规范。 三、volatile1.通过加入内存屏障和禁止重排序优化来实现。 对volatile变量执行写操作时,会在写操作后加入一条store屏障指令。强制更新主内存；防止处理器把volatile前面的变量重排序到volatile写变量操作之后； 对volatile变量指向读操作时,会在读操作前加入一条load屏蔽指令。同上。 2.volatile如何实现内存可见性volatile变量在每次被线程访问时,都强迫主内存中重读该变量的值,而该变量发生变化时,又会强迫线程将最新的值刷新到主内存。这样任何时刻,不同的线程总能看到该变量的最新值。 深入来说,通过加入内存屏障和禁止重排序优化来实现的 对volatile变量执行写操作时,会在写操作后加入一条store屏障指令（写后强制刷新到主内存中去） 对volatile变量执行读操作时,会在读操作前加入一条load屏障指令（强制使工作内存中的变量拷贝失效） 3.volatile不能保证volatile变量复合操作的原子性123private int num = 0;num++;//不是原子操作` num++分解成三个步骤： 读取num的值 将num的值 + 1 将最新num的值写入内存 3.1 加入synchronized代码块123synchronized(this) {num++;} 加入synchronized后变成原子操作,换句话说,num++分解出来的三个步骤只能被一个线程执行完之后才能被另外一个线程执行。 3.2 改成volatile变量无法保证原子性。 3.3 保证num自增操作的原子性 使用synchronized关键字 lock()和unlock() AtomicIntege 4.使用volatile的注意事项：要在多线程中安全地使用volatile变量,必须满足： 对volatile变量的写入操作不依赖其当前值 该变量没有包含在具有其他变量的不变式中 5.synchronized和volatile的比较： volatile本质是在告诉jvm当前变量在寄存器中的值是不确定的,需要从主存中读取,synchronized则是锁定当前变量,只有当前线程可以访问该变量,其他线程被阻塞住 volatile仅能使用在变量级别,synchronized则可以使用在变量,方法 volatile仅能实现变量的修改可见性,但不具备原子特性,而synchronized则可以保证变量的修改可见性和原子性 volatile不会造成线程的阻塞,而synchronized可能会造成线程的阻塞 volatile标记的变量不会被编译器优化,而synchronized标记的变量可以被编译器优化 所以在可以保证线程安全性的前提,尽可能使用volatile。","link":"/2018/08/23/Jvm/Java/Synchroized%E5%92%8CVolatile%E7%9A%84%E5%88%86%E6%9E%90%E5%92%8C%E5%8C%BA%E5%88%AB/"},{"title":"ReentrantLock 与 Synchronized 原理分析","text":"ReentrantLock,可重入锁,是一种递归无阻塞的同步机制。它可以等同于 synchronized 的使用,但是 ReentrantLock 提供了比 synchronized 更强大、灵活的锁机制,可以减少死锁发生的概率。 synchronized 是 Java 中的关键字,是利用锁的机制来实现同步的。 一、synchronizedsynchronized 是 Java 中的关键字,是利用锁的机制来实现同步的。锁机制有如下两种特性： 互斥性：即在同一时间只允许一个线程持有某个对象锁,通过这种特性来实现多线程中的协调机制,这样在同一时间只有一个线程对需同步的代码块(复合操作)进行访问。互斥性我们也往往称为操作的原子性。 可见性：必须确保在锁被释放之前,对共享变量所做的修改,对于随后获得该锁的另一个线程是可见的（即在获得锁时应获得最新共享变量的值）,否则另一个线程可能是在本地缓存的某个副本上继续操作从而引起不一致。 1. 实现原理 synchronized可以保证方法或者代码块在运行时,同一时刻只有一个方法可以进入到临界区,同时它还可以保证共享变量的内存可见性。 Java 中每一个对象都可以作为锁,这是 synchronized 实现同步的基础： 普通同步方法,锁是当前实例对象 静态同步方法,锁是当前类的 class 对象 同步方法块,锁是括号里面的对象 通过javap工具生成对class文件信息来分析synchronized 123monitorenter aload_imonitorexit 同步代码块是使用 monitorenter 和 monitorexit 指令实现的； 同步方法（在这看不出来需要看JVM底层实现）依靠的是方法修饰符上的ACC_SYNCHRONIZED 实现。 同步代码块：monitorenter 指令插入到同步代码块的开始位置,monitorexit 指令插入到同步代码块的结束位置,JVM 需要保证每一个 monitorenter 都有一个 monitorexit 与之相对应。任何对象都有一个 Monitor 与之相关联,当且一个 Monitor 被持有之后,他将处于锁定状态。线程执行到 monitorenter 指令时,将会尝试获取对象所对应的 Monitor 所有权,即尝试获取对象的锁。 同步方法：synchronized 方法则会被翻译成普通的方法调用和返回指令如：invokevirtual、areturn 指令,在 VM 字节码层面并没有任何特别的指令来实现被synchronized 修饰的方法,而是在 Class 文件的方法表中将该方法的 access_flags 字段中的 synchronized 标志位置设置为 1,表示该方法是同步方法,并使用调用该方法的对象或该方法所属的 Class 在 JVM 的内部对象表示 Klass 作为锁对象 ReentrantLock的底层是借助AbstractQueuedSynchronizer实现,所以其数据结构依附于AbstractQueuedSynchronizer的数据结构 2.Java 对象头、MonitorJava 对象头和 Monitor 是实现 synchronized 的基础！下面就这两个概念来做详细介绍。 2.1 Java对象头synchronized用的锁是存在Java对象头里的。那么什么是 Java 对象头呢？Hotspot 虚拟机的对象头主要包括两部分数据：Mark Word（标记字段）、Klass Pointer（类型指针）。其中： Klass Point 是是对象指向它的类元数据的指针,虚拟机通过这个指针来确定这个对象是哪个类的实例。 Mark Word 用于存储对象自身的运行时数据,它是实现轻量级锁和偏向锁的关键 Mark Word 用于存储对象自身的运行时数据,如哈希码（HashCode）、GC 分代年龄、锁状态标志、线程持有的锁、偏向线程 ID、偏向时间戳等等。Java 对象头一般占有两个机器码（在 32 位虚拟机中,1 个机器码等于 4 字节,也就是 32 bits）。但是如果对象是数组类型,则需要三个机器码,因为 JVM 虚拟机可以通过 Java 对象的元数据信息确定 Java 对象的大小,无法从数组的元数据来确认数组的大小,所以用一块来记录数组长度。 2.2 Monitor我们可以把它理解为一个同步工具,也可以描述为一种同步机制,它通常被描述为一个对象。每一个 Java 对象本身就带了一把看不见的锁,它叫做内部锁或者 Monitor 锁。 互斥： 一个 Monitor 锁在同一时刻只能被一个线程占用,其他线程无法占用。 信号机制( signal )： 占用 Monitor 锁失败的线程会暂时放弃竞争并等待某个谓词成真（条件变量）,但该条件成立后,当前线程会通过释放锁通知正在等待这个条件变量的其他线程,让其可以重新竞争锁。 Monitor Record 是线程私有的数据结构,每一个线程都有一个可用 Monitor Record 列表,同时还有一个全局的可用列表。每一个被锁住的对象都会和一个 Monitor Record 关联（对象头的 MarkWord 中的 LockWord 指向 Monitor 的起始地址）,Monitor Record 中有一个 Owner 字段,存放拥有该锁的线程的唯一标识,表示该锁被这个线程占用。其结构如下： 123456OwnerEntryQRcThisNestHashCodeCandidate Owner： 初始时为 NULL 表示当前没有任何线程拥有该 Monitor Record。 当线程成功拥有该锁后保存线程唯一标识。 当锁被释放时又设置为 NULL 。 EntryQ：关联一个系统互斥锁（ semaphore ）,阻塞所有试图锁住 Monitor Record失败的线程 。 RcThis：表示 blocked 或 waiting 在该 Monitor Record 上的所有线程的个数。 Nest：用来实现重入锁的计数。 HashCode：保存从对象头拷贝过来的 HashCode 值（可能还包含 GC age ）。 Candidate：用来避免不必要的阻塞或等待线程唤醒。因为每一次只有一个线程能够成功拥有锁,如果每次前一个释放锁的线程唤醒所有正在阻塞或等待的线程,会引起不必要的上下文切换（从阻塞到就绪然后因为竞争锁失败又被阻塞）从而导致性能严重下降。Candidate 只有两种可能的值 ：1）0 表示没有需要唤醒的线程；2）1 表示要唤醒一个继任线程来竞争锁。 3. 锁优化3.1 自旋锁由来 线程的阻塞和唤醒,需要 CPU 从用户态转为核心态。频繁的阻塞和唤醒对 CPU 来说是一件负担很重的工作,势必会给系统的并发性能带来很大的压力。同时,我们发现在许多应用上面,对象锁的锁状态只会持续很短一段时间。为了这一段很短的时间,频繁地阻塞和唤醒线程是非常不值得的。所以引入自旋锁。 定义 所谓自旋锁,就是让该线程等待一段时间,不会被立即挂起,看持有锁的线程是否会很快释放锁。 怎么等待呢？执行一段无意义的循环即可（自旋）。 3.1.1 适应自旋锁JDK 1.6 引入了更加聪明的自旋锁,即自适应自旋锁。 所谓自适应就意味着自旋的次数不再是固定的,它是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。它怎么做呢？ 线程如果自旋成功了,那么下次自旋的次数会更加多,因为虚拟机认为既然上次成功了,那么此次自旋也很有可能会再次成功,那么它就会允许自旋等待持续的次数更多。反之,如果对于某个锁,很少有自旋能够成功的,那么在以后要或者这个锁的时候自旋的次数会减少甚至省略掉自旋过程,以免浪费处理器资源。有了自适应自旋锁,随着程序运行和性能监控信息的不断完善,虚拟机对程序锁的状况预测会越来越准确,虚拟机会变得越来越聪明。 3.2 锁消除由来 为了保证数据的完整性,我们在进行操作时需要对这部分操作进行同步控制。但是,在有些情况下,JVM检测到不可能存在共享数据竞争,这是JVM会对这些同步锁进行锁消除。如果不存在竞争,为什么还需要加锁呢？所以锁消除可以节省毫无意义的请求锁的时间。 定义 锁消除的依据是逃逸分析的数据支持。变量是否逃逸,对于虚拟机来说需要使用数据流分析来确定,但是对于我们程序员来说这还不清楚么？我们会在明明知道不存在数据竞争的代码块前加上同步吗？但是有时候程序并不是我们所想的那样？我们虽然没有显示使用锁,但是我们在使用一些 JDK 的内置 API 时,如 StringBuffer、Vector、HashTable 等,这个时候会存在隐性的加锁操作。比如 StringBuffer 的append(..)方法,Vector 的add(...) 3.3 锁粗化由来 我们知道在使用同步锁的时候,需要让同步块的作用范围尽可能小：仅在共享数据的实际作用域中才进行同步。这样做的目的,是为了使需要同步的操作数量尽可能缩小,如果存在锁竞争,那么等待锁的线程也能尽快拿到锁。 在大多数的情况下,上述观点是正确的,但是如果一系列的连续加锁解锁操作,可能会导致不必要的性能损耗,所以引入锁粗话的概念。 定义 锁粗话概念比较好理解,就是将多个连续的加锁、解锁操作连接在一起,扩展成一个范围更大的锁。 如下面实例：vector 每次 add 的时候都需要加锁操作,JVM 检测到对同一个对象（vector）连续加锁、解锁操作,会合并一个更大范围的加锁、解锁操作,即加锁解锁操作会移到 for 循环之外。 1234567public void vectorTest(){ Vector&lt;String&gt; vector = new Vector&lt;String&gt;(); for (int i = 0 ; i &lt; 10 ; i++){ vector.add(i + \"\"); } System.out.println(vector);} 3.4 锁的升级 锁主要存在四种状态,依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态。它们会随着竞争的激烈而逐渐升级。注意,锁可以升级不可降级,这种策略是为了提高获得锁和释放锁的效率。 3.4.1 重量级锁重量级锁通过对象内部的监视器（Monitor）实现。 其中,Monitor 的本质是,依赖于底层操作系统的 Mutex Lock 实现。操作系统实现线程之间的切换,需要从用户态到内核态的切换,切换成本非常高。 3.4.2 轻量级锁 引入轻量级锁的主要目的,是在没有多线程竞争的前提下,减少传统的重量级锁使用操作系统互斥量产生的性能消耗。 当关闭偏向锁功能或者多个线程竞争偏向锁,导致偏向锁升级为轻量级锁,则会尝试获取轻量级锁,其步骤如下： 获取锁 判断当前对象是否处于无锁状态？ 若是,则 JVM 首先将在当前线程的栈帧中,建立一个名为锁记录（Lock Record）的空间,用于存储锁对象目前的 Mark Word的 拷贝（官方把这份拷贝加了一个 Displaced 前缀,即 Displaced Mark Word） 否则,执行步骤（3）； JVM 利用 CAS 操作尝试将对象的 Mark Word 更新为指向 Lock Record 的指正 如果成功,表示竞争到锁,则将锁标志位变成 00（表示此对象处于轻量级锁状态）,执行同步操作 如果失败,则执行步骤（3）； 判断当前对象的 Mark Word 是否指向当前线程的栈帧？ 如果是,则表示当前线程已经持有当前对象的锁,则直接执行同步代码块； 否则,只能说明该锁对象已经被其他线程抢占了,当前线程便尝试使用自旋来获取锁。若自旋后没有获得锁,此时轻量级锁会升级为重量级锁,锁标志位变成 10,当前线程会被阻塞。 释放锁 轻量级锁的释放也是通过 CAS 操作来进行的,主要步骤如下： 取出在获取轻量级锁保存在 Displaced Mark Word 中 数据。 使用 CAS 操作将取出的数据替换当前对象的 Mark Word 中。如果成功,则说明释放锁成功；否则,执行（3）。 如果 CAS 操作替换失败,说明有其他线程尝试获取该锁,则需要在释放锁的同时需要唤醒被挂起的线程。 对于轻量级锁,其性能提升的依据是：“对于绝大部分的锁,在整个生命周期内都是不会存在竞争的”。如果打破这个依据则除了互斥的开销外,还有额外的 CAS 操作,因此在有多线程竞争的情况下,轻量级锁比重量级锁更慢。 3.4.3 偏向锁 引入偏向锁主要目的是：为了在无多线程竞争的情况下,尽量减少不必要的轻量级锁执行路径。 上面提到了轻量级锁的加锁解锁操作,是需要依赖多次 CAS 原子指令的。那么偏向锁是如何来减少不必要的 CAS 操作呢？我们可以查看 Mark Word 的数据结构就明白了。 偏向锁时 Mark Word 的数据结构为：线程 ID、Epoch( 偏向锁的时间戳 )、对象分带年龄、是否是偏向锁( 1 )、锁标识位( 01 ) 只需要检查是否为偏向锁、锁标识为以及 ThreadID 即可,处理流程如下： 获取偏向锁 检测 Mark Word是 否为可偏向状态,即是否为偏向锁的标识位为 1 ,锁标识位为 01 。 若为可偏向状态,则测试线程 ID 是否为当前线程 ID ? 如果是,则执行步骤（5） 否则,执行步骤（3）。 如果线程 ID 不为当前线程 ID ,则通过 CAS 操作竞争锁。 竞争成功,则将 Mark Word 的线程 ID 替换为当前线程 ID ,则执行步骤（5） 否则,执行线程（4）。 通过 CAS 竞争锁失败,证明当前存在多线程竞争情况,当到达全局安全点,获得偏向锁的线程被挂起,偏向锁升级为轻量级锁,然后被阻塞在安全点的线程继续往下执行同步代码块。 执行同步代码块 撤销偏向锁 偏向锁的释放采用了一种只有竞争才会释放锁的机制,线程是不会主动去释放偏向锁,需要等待其他线程来竞争。 偏向锁的撤销需要等待全局安全点（这个时间点是上没有正在执行的代码）。其步骤如下： 暂停拥有偏向锁的线程,判断锁对象是否还处于被锁定状态。 撤销偏向锁,恢复到无锁状态（ 01 ）或者轻量级锁的状态。 最后唤醒暂停的线程。 关闭偏向锁 偏向锁在 JDK 1.6 以上,默认开启。开启后程序启动几秒后才会被激活,可使用 JVM 参数-XX：BiasedLockingStartupDelay = 0来关闭延迟。 如果确定锁通常处于竞争状态,则可通过JVM参数-XX:-UseBiasedLocking=false关闭偏向锁,那么默认会进入轻量级锁。 二、ReentrantLock1. 简介 一个可重入的互斥锁定 Lock,它具有与使用 synchronized 方法和语句所访问的隐式监视器锁定相同的一些基本行为和语义,但功能更强大。ReentrantLock 将由最近成功获得锁定,并且还没有释放该锁定的线程所拥有。当锁定没有被另一个线程所拥有时,调用 lock 的线程将成功获取该锁定并返回。如果当前线程已经拥有该锁定,此方法将立即返回。可以使用isHeldByCurrentThread()和getHoldCount()方法来检查此情况是否发生。 ReentrantLock 还提供了公平锁和非公平锁的选择,通过构造方法接受一个可选的 fair 参数（默认非公平锁）：当设置为 true 时,表示公平锁；否则为非公平锁。 公平锁与非公平锁的区别在于,公平锁的锁获取是有顺序的。但是公平锁的效率往往没有非公平锁的效率高,在许多线程访问的情况下,公平锁表现出较低的吞吐量。 ReentrantLock 整体结构: ReentrantLock 实现 Lock 接口,基于内部的 Sync 实现。 Sync 实现 AQS ,提供了 FairSync 和 NonFairSync 两种实现。 2. Sync 抽象类 Sync 是 ReentrantLock 的内部静态类,实现 AbstractQueuedSynchronizer 抽象类,同步器抽象类。它使用 AQS 的 state 字段,来表示当前锁的持有数量,从而实现可重入的特性。 2.1 lock12345/** * Performs {@link Lock#lock}. The main reason for subclassing * is to allow fast path for nonfair version. */abstract void lock(); 执行锁。抽象了该方法的原因是,允许子类实现快速获得非公平锁的逻辑。 2.2 nonfairTryAcquirenonfairTryAcquire(int acquires)方法,非公平锁的方式获得锁。代码如下： 123456789101112131415161718192021222324final boolean nonfairTryAcquire(int acquires) { //当前线程 final Thread current = Thread.currentThread(); //获取同步状态 int c = getState(); //state == 0,表示没有该锁处于空闲状态 if (c == 0) { //获取锁成功,设置为当前线程所有 if (compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } //线程重入 //判断锁持有的线程是否为当前线程 else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; } return false;} 该方法主要逻辑：首先判断同步状态 state == 0 ? 如果是,表示该锁还没有被线程持有,直接通过CAS获取同步状态。 如果成功,返回 true 。 否则,返回 false 。 如果不是,则判断当前线程是否为获取锁的线程？ 如果是,则获取锁,成功返回 true 。成功获取锁的线程,再次获取锁,这是增加了同步状态 state 。通过这里的实现,我们可以看到上面提到的 “它使用 AQS 的 state 字段,来表示当前锁的持有数量,从而实现可重入的特性”。 否则,返回 false 。 理论来说,这个方法应该在子类 FairSync 中实现,但是为什么会在这里呢？在下文的 ReentrantLock.tryLock() 中,详细解析。 2.3 tryReleasetryRelease(int releases)实现方法,释放锁。123456789101112131415protected final boolean tryRelease(int releases) { // 减掉releases int c = getState() - releases; // 如果释放的不是持有锁的线程,抛出异常 if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; // state == 0 表示已经释放完全了,其他线程可以获取同步状态了 if (c == 0) { free = true; setExclusiveOwnerThread(null); } setState(c); return free;} 通过判断判断是否为获得到锁的线程,保证该方法线程安全。 只有当同步状态彻底释放后,该方法才会返回 true 。当state == 0时,则将锁持有线程设置为 null ,free = true,表示释放成功。 从这些方法中,我们可以看到,ReentrantLock 是独占获取同步状态的模式。 3. Sync 实现类3.1 NonfairSync NonfairSync 是 ReentrantLock 的内部静态类,实现 Sync 抽象类,非公平锁实现类。 3.1.1 lock lock()实现方法,首先基于 AQS state 进行 CAS 操作,将 0 =&gt; 1 。 若成功,则获取锁成功。 若失败,执行 AQS 的正常的同步状态获取逻辑。 代码如下： 1234567@Overridefinal void lock() { if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1);} 3.1.2 tryAcquire tryAcquire(int acquires)实现方法,非公平的方式,获得同步状态。代码如下： protected final boolean tryAcquire(int acquires) { return nonfairTryAcquire(acquires);} 直接调用nonfairTryAcquire(int acquires)方法,非公平锁的方式获得锁。 3.2 FairSync FairSync 是 ReentrantLock 的内部静态类,实现 Sync 抽象类,公平锁实现类。 3.2.1 lock lock()实现方法,代码如下：123final void lock() { acquire(1);} 直接执行 AQS 的正常的同步状态获取逻辑。 3.2.2 tryAcquire tryAcquire(int acquires)实现方法,公平的方式,获得同步状态。代码如下： 12345678910111213141516171819protected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { if (!hasQueuedPredecessors() &amp;&amp; // &lt;1&gt; compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; } return false;} 比较非公平锁和公平锁获取同步状态的过程,会发现两者唯一的区别就在于:公平锁在获取同步状态时多了一个限制条件 处的hasQueuedPredecessors()方法,是否有前序节点,即自己不是首个等待获取同步状态的节点。 代码如下: 123456789101112// AbstractQueuedSynchronizer.javapublic final boolean hasQueuedPredecessors() { Node t = tail; //尾节点 Node h = head; //头节点 Node s; //头节点 != 尾节点 //同步队列第一个节点不为null //当前线程是同步队列第一个节点 return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread());} 该方法主要做一件事情：主要是判断当前线程是否位于 CLH 同步队列中的第一个。如果是则返回 true ,否则返回 false 。 4. Lock 接口java.util.concurrent.locks.Lock接口,定义方法如下： 123456void lock(); //获取当前锁后返回void lockInterruptibly() throws InterruptedException; //获取锁对过程中可以中断boolean tryLock(); //非阻塞对获取锁,如果能够获取就返回true,如果不能返回falseboolean tryLock(long time, TimeUnit unit) throws InterruptedException; //超时的获取锁 1.在时间内成功获取锁2.超时返回3.被中断void unlock(); //释放锁Condition newCondition(); //获取等待组件,该组件和当前的锁绑定,只有当前线程获取了锁,才能调用wait()方法,调用后当前线程的锁被释放 5. ReentrantLockjava.util.concurrent.locks.ReentrantLock,实现 Lock 接口,重入锁。 ReentrantLock 的实现方法,基本是对 Sync 的调用（通过委托的方式）。 5.1 构造方法1234567public ReentrantLock() { sync = new NonfairSync();}public ReentrantLock(boolean fair) { sync = fair ? new FairSync() : new NonfairSync();} 基于fair参数,创建 FairSync 还是 NonfairSync 对象。 5.2 lock1234@Overridepublic void lock() { sync.lock();} 5.3 lockInterruptibly1234@Overridepublic void lockInterruptibly() throws InterruptedException { sync.acquireInterruptibly(1);} 5.4 tryLock tryLock()实现方法,在实现时,希望能快速的获得是否能够获得到锁,因此即使在设置为 fair = true ( 使用公平锁 ),依然调用 Sync#nonfairTryAcquire(int acquires) 方法。 如果真的希望tryLock()还是按照是否公平锁的方式来,可以调用tryLock(0, TimeUnit)方法来实现。 5.5 tryLock(0, TimeUnit)12345@Overridepublic boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException { return sync.tryAcquireNanos(1, unit.toNanos(timeout));} 5.6 unlock12345@Overridepublic void unlock() { sync.release(1); } 5.7 newCondition1234@Overridepublic Condition newCondition() { return sync.newCondition();} 三、总结 与 synchronized 相比,ReentrantLock提供了更多,更加全面的功能,具备更强的扩展性。例如：时间锁等候,可中断锁等候,锁投票。 ReentrantLock 还提供了条件 Condition ,对线程的等待、唤醒操作更加详细和灵活,所以在多个条件变量和高度竞争锁的地方,ReentrantLock 更加适合（以后会阐述Condition）。 ReentrantLock 提供了可轮询的锁请求。它会尝试着去获取锁,如果成功则继续,否则可以等到下次运行时处理,而 synchronized 则一旦进入锁请求要么成功要么阻塞,所以相比 synchronized 而言,ReentrantLock会不容易产生死锁些。 ReentrantLock 支持更加灵活的同步代码块,但是使用 synchronized 时,只能在同一个 synchronized 块结构中获取和释放。注意,ReentrantLock 的锁释放一定要在 finally 中处理,否则可能会产生严重的后果。 ReentrantLock 支持中断处理,且性能较 synchronized 会好些。","link":"/2019/03/09/Jvm/Java/ReentrantLock%E4%B8%8ESynchronized%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/"},{"title":"使用Kubespray在国内自动化部署Kubernetes集群（1.14.1）","text":"最近刚刚学习k8s,部署k8s的操作过于麻烦,因此想要寻找到一种自动化部署方式,Kubespray是现在最好的自动化部署方式,拥有支持多平台 、相对简单 、适用于生产环境的特点。 一、准备工作每一台linux机器都需要特殊单独配置一下,才能使用于搭建k8s的环境,我使用的是centos7系统,现在开始搭建k8s准备环境的第一步 (1)更新内核驱动为了更好的使用 docker 和 k8s ,更新一下内核驱动, centos7 默认是3.3的版本12345678910111213141516171819# 导入 Keyrpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org# 安装 Yum 源rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm# 更新 kernelyum --enablerepo=elrepo-kernel install -y kernel-lt kernel-lt-devel# 配置 内核优先grub2-set-default 0 (2)关闭防火墙关闭防火墙为了防止部署时,防止各个节点因为防火墙的原因,不能通信 123#关闭防火墙。systemctl stop firewalld.servicesystemctl disable firewalld.service (3)关闭linux安全控制Security Context的目的是限制不可信容器的行为,保护系统和其他容器不受其影响。我们先关闭。 123#关闭SELinuxsed -i 's#SELINUX=enforcing#SELINUX=disabled#g' /etc/selinux/configsetenforce 0 (4)关闭交换分区从 k8s 1.8版本就要求不能开启交换分区 12swapoff -ased -i 's/.*swap.*/#&amp;/' /etc/fstab 做完上面这些操作就可以重启一下机器,准备环境的工作就已经完成了 二、准备安装k8sKubespray 是基于 ansible 上构建的一套自动化部署工具,所以我们需要先安装 ansible 123456789101112# 安装 centos 额外的yum源rpm -ivh https://dl.fedoraproject.org/pub/epel/7/x86_64/Packages/e/epel-release-7-11.noarch.rpm# make 缓存yum clean all &amp;&amp; yum makecache# ansible 必须 &gt;= 2.7# 安装 软件yum install -y python-pip python34 python-netaddr python34-pip ansible 安装好之后我们就可以先把 Kubespray 的源码从git上拉取下来 1git clone https://github.com/kubernetes-sigs/kubespray 拉去下来后还不能直接使用,为什么呢？因为谷歌嘛,大家懂的。不能直接下载,需要走代理,或者使用其他镜像,我选择将源码中所有镜像都替换一遍才可以。我使用的是七牛云,亚马逊的镜像源具体的替换过程为： quay.io替换为quay-mirror.qiniu.comgcr.io/google-containers替换为gcr.azk8s.cn/google-containers 试过中科大的镜像,但是体验不太好,老是失败。阿里云镜像则是有部分镜像没有,只有亚马逊的镜像是最全的。这个花了很长时间,因为网络原因试了很多次。 三、安装k8s首先进入 kubespray 的 git 目录下初始化 kubespray 脚本 1234pip install -r requirements.txtcp -rfp inventory/sample inventory/mycluster 编写 hosts.ini , 配置那些机器需要作为k8s的一部分12345678910111213141516171819202122232425[all]k8s ansible_host=106.14.162.10node1 ansible_host=106.14.163.10[kube-master]k8s[etcd]k8s[kube-node]k8snode1[k8s-cluster:children]kube-masterkube-node[calico-rr] 看上面编写的 host.ini 应该很容易理解： 1.[all] 下面所有的机器节点,第一个为 机器hostname,第二个为机器的ip地址。 2.[etcd] 分布式存储运行在那些机器上 3.[kube-node] k8s 的 node节点有那些,用hostname 标示 4.[k8s-cluster:children] 表示集群有哪些把 kube-master 和 kube-node 填上就可以了,代表所有的机器 你可以根据自己的配置来进行修改 然后可以启动脚本了,脚本如下： 12ansible-playbook -i inventory/mycluster/hosts.ini cluster.yml -b -v -k 启动脚本之后会让你输入ssh密码,只要输入密码就可以,中间可能出现一些问题,在访问到storage.googleapis.com这个域名的时候可能会出现下载失败,因为有的ip不能访问,多试几次就好了。 静静等待大概10分钟左右的样子应该就可以安装好了～ 上面镜像和脚本的配置我已经编写好了,大家可以参考我写的,只需要修改inventory/mycluster/hosts.ini文件就可以了 1git clone -b prod https://github.com/ulovecode/kubespray 运行脚本分别为build-step1.sh,build-step2.sh,build.sh,按照顺序运行就可以了 四、总结这次学 kubespray 搭建集群还是遇到许多问题,首先是网络问题,如果没有网络问题的原因可能只需一个小时的事情,但是因为网络原因,弄了一两天,因为每个镜像源总有或多或少的一些问题,不能够直接使用。另外搭建过程除了更换镜像原因,文章的内容还是很浅显的,但是考虑到只是搭建的步骤,应该还是能接受,后续会继续更新使用Kubespray在阿里云上自动化部署Kubernetes集群（1.14.1) 这篇文章的后续操作,有任何问题都可以在下面和我交流～","link":"/2019/05/23/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/Kubernetes/%E4%BD%BF%E7%94%A8Kubespray%E5%9C%A8%E9%98%BF%E9%87%8C%E4%BA%91%E4%B8%8A%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2Kubernetes%E9%9B%86%E7%BE%A4%EF%BC%881.14.1%EF%BC%89/"},{"title":"高性能 MySQL ｜ MySQL 逻辑架构","text":"MySQL 的逻辑架构分为三层,客户端,服务器,存储引擎。 一、逻辑架构 1.客户端第一层负责连接管理、授权认证、安全等等。每个客户端的连接都对应着服务器上的一个线程。服务器上维护了一个线程池,避免为每个连接都创建销毁一个线程。当客户端连接到MySQL服务器时,服务器对其进行认证。可以通过用户名和密码的方式进行认证,也可以通过SSL证书进行认证。登录认证通过后,服务器还会验证该客户端是否有执行某个查询的权限。 2.服务器第二层架构是MySQL比较有意思的部分。大多数MySQL的核心服务功能都在这一层,包括查询解析、分析、优化、缓存以及所有的内置函数（例如,日期、时间、数学和加密函数）,所有跨存储引擎的功能都在这一层实现：存储过程、触发器、视图等。 连接/线程处理 查询缓存 解析器 优化器 3.存储引擎第三层包含了存储引擎。存储引擎负责MySQL中数据的存储和提取。和GNU/Linux下的各种文件系统一样,每个存储引擎都有它的优势和劣势。服务器通过API与存储引擎进行通信。这些接口屏蔽了不同存储引擎之间的差异,使得这些差异对上层的查询过程透明。存储引擎API包含几十个底层函数,用于执行诸如“开始一个事务”或者“根据主键提取一行记录”等操作。但存储引擎不会去解析SQL(1),不同存储引擎之间也不会相互通信,而只是简单地响应上层服务器的请求。 执行与优化过程 解析查询 创建内部数据结构（解析树） 重写查询 决定表的读取顺序 选择合适的索引 对其进行各种优化,用户可以通过特殊的关键字提示（hint）优化器,影响它的决策过程。也可以请求优化器解释（explain）优化过程的各个因素 二、并发控制1.读写锁共享锁（shared lock）,也叫读锁（read lock）读锁是共享的,或者说是相互不阻塞的。多个客户在同一时刻可以同时读取同一个资源,而互不干扰。 写锁（write lock）,也叫排他锁（exclusive lock）写锁则是排他的,也就是说一个写锁会阻塞其他的写锁和读锁,这是出于安全策略的考虑,只有这样,才能确保在给定的时间里,只有一个用户能执行写入,并防止其他用户读取正在写入的同一资源。 2.锁粒度表锁（table lock）表锁是MySQL中最基本的锁策略,并且是开销最小的策略。表锁非常类似于前文描述的邮箱加锁机制：它会锁定整张表。一个用户在对表进行写操作（插入、删除、更新等）前,需要先获得写锁,这会阻塞其他用户对该表的所有读写操作。只有没有写锁时,其他读取的用户才能获得读锁,读锁之间是不相互阻塞的。 行级锁（row lock）行级锁可以最大程度地支持并发处理（同时也带来了最大的锁开销）。众所周知,在InnoDB和XtraDB,以及其他一些存储引擎中实现了行级锁。行级锁只在存储引擎层实现,而 MySQL 服务器层没有实现。服务器层完全不了解存储引擎中的锁实现。 三、事物1.ACID 特性原子性（atomicity）一个事务必须被视为一个不可分割的最小工作单元,整个事务中的所有操作要么全部提交成功,要么全部失败回滚,对于一个事务来说,不可能只执行其中的一部分操作,这就是事务的原子性。 一致性（consistency）数据库总是从一个一致性的状态转换到另外一个一致性的状态。在前面的例子中,一致性确保了,即使在执行第三、四条语句之间时系统崩溃,支票账户中也不会损失200美元,因为事务最终没有提交,所以事务中所做的修改也不会保存到数据库中。 隔离性（isolation）通常来说,一个事务所做的修改在最终提交以前,对其他事务是不可见的。在前面的例子中,当执行完第三条语句、第四条语句还未开始时,此时有另外一个账户汇总程序开始运行,则其看到的支票账户的余额并没有被减去200美元。后面我们讨论隔离级别（Isolation level）的时候,会发现为什么我们要说“通常来说”是不可见的。 持久性（durability）一旦事务提交,则其所做的修改就会永久保存到数据库中。此时即使系统崩溃,修改的数据也不会丢失。持久性是个有点模糊的概念,因为实际上持久性也分很多不同的级别。有些持久性策略能够提供非常强的安全保障,而有些则未必。而且不可能有能做到100％的持久性保证的策略（如果数据库本身就能做到真正的持久性,那么备份又怎么能增加持久性呢？）。在后面的一些章节中,我们会继续讨论MySQL中持久性的真正含义。 2.隔离级别READ UNCOMMITTED（未提交读）在READ UNCOMMITTED级别,事务中的修改,即使没有提交,对其他事务也都是可见的。事务可以读取未提交的数据,这也被称为脏读（Dirty Read）。这个级别会导致很多问题,从性能上来说,READ UNCOMMITTED不会比其他的级别好太多,但却缺乏其他级别的很多好处,除非真的有非常必要的理由,在实际应用中一般很少使用。 READ COMMITTED（提交读）大多数数据库系统的默认隔离级别都是READ COMMITTED（但MySQL不是）。READ COMMITTED满足前面提到的隔离性的简单定义：一个事务开始时,只能“看见”已经提交的事务所做的修改。换句话说,一个事务从开始直到提交之前,所做的任何修改对其他事务都是不可见的。这个级别有时候也叫做不可重复读（nonrepeatable read）,因为两次执行同样的查询,可能会得到不一样的结果。 REPEATABLE READ（可重复读）REPEATABLE READ解决了脏读的问题。该级别保证了在同一个事务中多次读取同样记录的结果是一致的。但是理论上,可重复读隔离级别还是无法解决另外一个幻读（Phantom Read）的问题。所谓幻读,指的是当某个事务在读取某个范围内的记录时,另外一个事务又在该范围内插入了新的记录,当之前的事务再次读取该范围的记录时,会产生幻行（Phantom Row）。InnoDB和XtraDB存储引擎通过多版本并发控制（MVCC,Multiversion Concurrency Control）解决了幻读的问题。本章稍后会做进一步的讨论。 可重复读是MySQL的默认事务隔离级别 SERIALIZABLE（可串行化）SERIALIZABLE是最高的隔离级别。它通过强制事务串行执行,避免了前面说的幻读的问题。简单来说,SERIALIZABLE会在读取的每一行数据上都加锁,所以可能导致大量的超时和锁争用的问题。实际应用中也很少用到这个隔离级别,只有在非常需要确保数据的一致性而且可以接受没有并发的情况下,才考虑采用该级别。 3.死锁死锁的产生有双重原因 有些是因为真正的数据冲突 有些则完全是由于存储引擎的实现方式导致的 系统的解决办法InnoDB目前处理死锁的方法是,将持有最少行级排他锁的事务进行回滚（这是相对比较简单的死锁回滚算法）。 超时机制 就是当查询的时间达到锁等待超时的设定后放弃锁请求,这种方式通常来说不太好。 死锁检测 比如InnoDB存储引擎,越能检测到死锁的循环依赖,并立即返回一个错误。 死锁发生以后,只有部分或者完全回滚其中一个事务,才能打破死锁。 事务日志 预写式日志（Write-Ahead Logging）,追加的方式,因此写日志的操作是磁盘上一小块区域内的顺序I/O,而不像随机I/O需要在磁盘的多个地方移动磁头,所以采用事务日志的方式相对来说要快得多。 写回磁盘 4.MySQL中的事务事务型的存储引擎 InnoDB NDB Cluster 第三方存储引擎 自动提交（AUTOCOMMIT）MySQL默认采用自动提交（AUTOCOMMIT）模式。 隐式和显式锁定隐式锁定 在事务执行过程中,随时都可以执行锁定,锁只有在执行COMMIT或者ROLLBACK的时候才会释放,并且所有的锁是在同一时刻被释放。InnoDB会根据隔离级别在需要的时候自动加锁。 显式锁定 除了事务中禁用了AUTOCOMMIT,可以使用LOCK TABLES之外,其他任何时候都不要显式地执行LOCK TABLES,不管使用的是什么存储引擎。 FOR UPDATE LOCK TABLES 四、多版本并发控制（MVCC）1.两种实现原理通过保存数据在某个时间点的快照来实现的 乐观（optimistic）并发控制 悲观（pessimistic）并发控制 2.InnoDB的MVCC的实现原理通过在每行记录后面保存两个隐藏的列来实现的 行的创建时间 行的过期时间（或删除时间） 当然存储的并不是实际的时间值,而是系统版本号（system version number）。每开始一个新的事务,系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号,用来和查询到的每行记录的版本号进行比较。 SELECT 只查找版本早于当前事务版本的数据行 行的删除版本要么未定义,要么大于当前事务版本号 INSERT为新插入的每一行保存当前系统版本号作为行版本号 DELETE为删除的每一行保存当前系统版本号作为行删除标识 UPDATE为插入一行新记录,保存当前系统版本号作为行版本号,同时保存当前系统版本号到原来的行作为行删除标识。 MVCC 只在REPEATABLE READ和READ COMMITTED两个隔离级别下工作。其他两个隔离级别都和 MVCC 不兼容,因为READ UNCOMMITTED总是读取最新的数据行,而不是符合当前事务版本的数据行。而SERIALIZABLE则会对所有读取的行都加锁。 五、存储引擎1.InnoDB存储引擎(事务型的数据库)InnoDB采用MVCC来支持高并发,并且实现了四个标准的隔离级别。其默认级别是REPEATABLE READ（可重复读）,并且通过间隙锁（next-key locking）策略防止幻读的出现。间隙锁使得InnoDB不仅仅锁定查询涉及的行,还会对索引中的间隙进行锁定,以防止幻影行的插入。 从磁盘读取数据时采用的可预测性预读 加速插入操作的插入缓冲区（insert buffer） 索引 基于聚簇索引,聚簇索引对主键查询有很高的性能。 二级索引,二级索引（secondary index,非主键索引）中必须包含主键列,所以如果主键列很大的话,其他的所有索引都会很大。因此,若表上的索引较多的话,主键应当尽可能的小。 自适应哈希索引,能够自动在内存中创建hash索引以加速读操作。 2.MyISAM存储引擎(非事务型的数据库)MyISAM提供了大量的特性,包括全文索引、压缩、空间函数（GIS）等,但MyISAM不支持事务和行级锁,而且有一个毫无疑问的缺陷就是崩溃后无法安全恢复。 3.Archive引擎(非事务型的数据库)Archive存储引擎只支持INSERT和SELECT操作,在MySQL 5.1之前也不支持索引。Archive引擎会缓存所有的写并利用zlib对插入的行进行压缩,所以比MyISAM表的磁盘I/O更少。但是每次SELECT查询都需要执行全表扫描。所以Archive表适合日志和数据采集类应用,这类应用做数据分析时往往需要全表扫描。或者在一些需要更快速的INSERT操作的场合下也可以使用。Archive引擎支持行级锁和专用的缓冲区,所以可以实现高并发的插入。在一个查询开始直到返回表中存在的所有行数之前,Archive引擎会阻止其他的SELECT执行,以实现一致性读。另外,也实现了批量插入在完成之前对读操作是不可见的。这种机制模仿了事务和MVCC的一些特性,但Archive引擎不是一个事务型的引擎,而是一个针对高速插入和压缩做了优化的简单引擎。 4.Blackhole引擎Blackhole引擎没有实现任何的存储机制,它会丢弃所有插入的数据,不做任何保存。但是服务器会记录Blackhole表的日志,所以可以用于复制数据到备库,或者只是简单地记录到日志。这种特殊的存储引擎可以在一些特殊的复制架构和日志审核时发挥作用。但这种应用方式我们碰到过很多问题,因此并不推荐。 5.CSV引擎CSV引擎可以将普通的CSV文件（逗号分割值的文件）作为MySQL的表来处理,但这种表不支持索引。CSV引擎可以在数据库运行时拷入或者拷出文件。可以将Excel等电子表格软件中的数据存储为CSV文件,然后复制到MySQL数据目录下,就能在MySQL中打开使用。同样,如果将数据写入到一个CSV引擎表,其他的外部程序也能立即从表的数据文件中读取CSV格式的数据。因此CSV引擎可以作为一种数据交换的机制,非常有用。 6.Federated引擎Federated引擎是访问其他MySQL服务器的一个代理,它会创建一个到远程MySQL服务器的客户端连接,并将查询传输到远程服务器执行,然后提取或者发送需要的数据。最初设计该存储引擎是为了和企业级数据库如Microsoft SQL Server和Oracle的类似特性竞争的,可以说更多的是一种市场行为。尽管该引擎看起来提供了一种很好的跨服务器的灵活性,但也经常带来问题,因此默认是禁用的。MariaDB使用了它的一个后续改进版本,叫做FederatedX。 7.Memory引擎应用场景 用于查找（lookup）或者映射（mapping）表 用于缓存周期性聚合数据（periodically aggregated data）的结果 用于保存数据分析中产生的中间数据 锁粒度使用表锁（table lock,表锁是MySQL中最基本的锁策略,并且是开销最小的策略。表锁非常类似于前文描述的邮箱加锁机制：它会锁定整张表。一个用户在对表进行写操作（插入、删除、更新等）前,需要先获得写锁,这会阻塞其他用户对该表的所有读写操作。只有没有写锁时,其他读取的用户才能获得读锁,读锁之间是不相互阻塞的。 缺点 并发写入的性能较低 不支持BLOB或TEXT类型的列,并且每行的长度是固定的 8.NDB集群引擎TODO 9.Merge引擎Merge表是由多个MyISAM表合并而来的虚拟表。如果将MySQL用于日志或者数据仓库类应用,该引擎可以发挥作用。但是引入分区功能后,该引擎已经被放弃 10.第三方存储引擎TODO","link":"/2020/04/28/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/%E9%AB%98%E6%80%A7%E8%83%BDmysql(1)/"},{"title":"高性能 MySQL ｜ Schema 与数据类型优化","text":"MySQL 支持的数据类型非常多,选择正确的数据类型至关重要。下面的几个简单原则有助于做出更好的选择。 一、更小的通常更好一般情况下,应该尽量使用可以正确存储数据的最小数据类型。更小的数据类型通常更快,因为他们占用更少的磁盘,内存和cpu缓存,并且处理时需要的cpu周期也更少。 二、简单就好简单的数据类型操作通常需要更少的cpu周期。例如,整型比字符操作代价更低,因为字符集和校对规则（排序规则）使字符比较比整型更加复杂。注：应使用mysql内建的类型存储时间和日期,而不是字符串。 三、Mysql很难优化包含NULL的列 可为NULL的列使得索引、索引统计和值比较都更复杂 可为NULL的列会使用更多的存储空间 当可为NULL的列被索引时,每个索引记录需要一个额外的字节 通常把可为NULL的列改为NOT NULL带来的性能提升比较小,所以（调优时）没有必要首先在现有schema中查找并修改掉这种情况,除非确定这会导致问题。但是,如果计划在列上建索引,就应该尽量避免设计成可为NULL的列。 四、选择优化的数据类型1.整数类型无符号 UNSIGNED 有符号 BIGINT INT MEDIUMINT SMALLINT TINYINT 2.实数类型FLOATDOUBLEDECIMAL因为CPU不支持对DECIMAL的直接计算,所以在MySQL 5.0以及更高版本中,MySQL服务器自身实现了DECIMAL的高精度计算。相对而言,CPU直接支持原生浮点计算,所以浮点运算明显更快。 因为需要额外的空间和计算开销,所以应该尽量只在对小数进行精确计算时才使用DECIMAL——例如存储财务数据。但在数据量比较大的时候,可以考虑使用BIGINT代替DECIMAL,将需要存储的货币单位根据小数的位数乘以相应的倍数即可。假设要存储财务数据精确到万分之一分,则可以把所有金额乘以一百万,然后将结果存储在BIGINT里,这样可以同时避免浮点存储计算不精确和DECIMAL精确计算代价高的问题。 3.字符串类型VARCHARVARCHAR类型用于存储可变长字符串,是最常见的字符串数据类型。它比定长类型更节省 需要使用1或2个额外字节记录字符串的长 如果列的最大长度小于或等于255字节,只使用1个字节表示 否则使用2个字节。 UPDATE时InnoDB可能分裂页,MyISAM会将行拆成不同的片段存储 面这些情况下使用VARCHAR是合适的 字符串列的最大长度比平均长度大很多 列的更新很少,所以碎片不是问题 在5.0或者更高版本,MySQL在存储和检索时会保留末尾空格。但在4.1或更老的版本,MySQL会剔除末尾空格。 CHAR 对于经常变更的数据,CHAR也比VARCHAR更好,因为定长的CHAR类型不容易产生碎片 CHAR适合存储很短的字符串 对于非常短的列,CHAR比VARCHAR在存储空间上也更有效率(因为VARCHAR还有一或两个记录长度的额外字节。) 使用VARCHAR（5）和VARCHAR（200）存储’hello’的空间开销是一样的。那么使用更短的列有什么优势吗？事实证明有很大的优势。更长的列会消耗更多的内存,因为MySQL通常会分配固定大小的内存块来保存内部值。尤其是使用内存临时表进行排序或操作时会特别糟糕。在利用磁盘临时表进行排序时也同样糟糕。 BLOB存储的是二进制数据 TEXT字符集和排序规则 当BLOB和TEXT值太大时,InnoDB会使用专门的“外部”存储区域来进行存储,此时每个值在行内需要1～4个字节存储一个指针,然后在外部存储区域存储实际的值。MySQL不能将BLOB和TEXT列全部长度的字符串进行索引 ENUMMySQL在内部会将每个值在列表中的位置保存为整数,并且在表的.frm文件中保存“数字-字符串”映射关系的“查找表”。 枚举字段是按照内部存储的整数而不是定义的字符串进行排序的 由于MySQL把每个枚举值保存为整数,并且必须进行查找才能转换为字符串,所以枚举列有一些开销。 4.日期和时间类型TIMESTAMP 从1970年到2038年,精度为秒 MySQL提供了FROM_UNIXTIME()函数把Unix时间戳转换为日期,并提供了UNIX_TIMESTAMP()函数把日期转换为Unix时间戳。 4个字节的存储空间 TIMESTAMP显示的值也依赖于时区。 TIMESTAMP列默认为NOT NULL,设置这个列的值为当前时间 DATETIME 从1001年到9999年,精度为秒 8个字节的存储空间 与时区无关 如果需要存储比秒更小粒度的日期和时间值怎么办？MySQL目前没有提供合适的数据类型,但是可以使用自己的存储格式：可以使用BIGINT类型存储微秒级别的时间截,或者使用DOUBLE存储秒之后的小数部分。这两种方式都可以,或者也可以使用MariaDB替代MySQL。 TIMESTAMP 与 DATETIME 选择TIMESTAMP只使用DATETIME一半的存储空间,并且会根据时区变化,具有特殊的自动更新能力。另一方面,TIMESTAMP允许的时间范围要小得多,有时候它的特殊能力会成为障碍。 5.位数据类型BITSET6.选择标识符（identifier）完全“随机”的字符串 因为插入值会随机地写到索引的不同位置,所以使得INSERT语句更慢。这会导致页分裂、磁盘随机访问,以及对于聚簇存储引擎产生聚簇索引碎片。 SELECT语句会变得更慢,因为逻辑上相邻的行会分布在磁盘和内存的不同地方 随机值导致缓存对所有类型的查询语句效果都很差,因为会使得缓存赖以工作的访问局部性原理失效。如果整个数据集都一样的“热”,那么缓存任何一部分特定数据到内存都没有好处；如果工作集比内存大,缓存将会有很多刷新和不命中。 UUID()生成的值与加密散列函数例如SHA1()生成的值有不同的特征：UUID值虽然分布也不均匀,但还是有一定顺序,如果存储UUID值,则应该移除“-”符号； 7.特殊类型数据人们经常使用VARCHAR（15）列来存储IP地址。然而,它们实际上是32位无符号整数,不是字符串。用小数点将地址分成四段的表示方法只是为了让人们阅读容易。所以应该用无符号整数存储IP地址。MySQL提供INET_ATON()和INET_NTOA()函数在这两种表示方法之间转换。 良好的schema设计原则是普遍适用的,但MySQL有它自己的实现细节要注意。概括来说,尽可能保持任何东西小而简单总是好的。MySQL喜欢简单,需要使用数据库的人应该也同样会喜欢简单的原则：尽量避免过度设计,例如会导致极其复杂查询的schema设计,或者有很多列的表设计（很多的意思是介于有点多和非常多之间）。使用小而简单的合适数据类型,除非真实数据模型中有确切的需要,否则应该尽可能地避免使用NULL值。尽量使用相同的数据类型存储相似或相关的值,尤其是要在关联条件中使用的列。注意可变长字符串,其在临时表和排序时可能导致悲观的按最大长度分配内存。尽量使用整型定义标识列。避免使用MySQL已经遗弃的特性,例如指定浮点数的精度,或者整数的显示宽度。小心使用ENUM和SET。虽然它们用起来很方便,但是不要滥用,否则有时候会变成陷阱。最好避免使用BIT。 Schema 设计中的陷阱虽然有一些普遍的好或坏的设计原则,但也有一些问题是由MySQL的实现机制导致的,这意味着有可能犯一些只在MySQL下发生的特定错误。本节我们讨论设计MySQL的schema的问题。这也许会帮助你避免这些错误,并且选择在MySQL特定实现下工作得更好的替代方案。 太多的列MySQL的存储引擎API工作时需要在服务器层和存储引擎层之间通过行缓冲格式拷贝数据,然后在服务器层将缓冲内容解码成各个列。从行缓冲中将编码过的列转换成行数据结构的操作代价是非常高的。MyISAM的定长行结构实际上与服务器层的行结构正好匹配,所以不需要转换。然而,MyISAM的变长行结构和InnoDB的行结构则总是需要转换。转换的代价依赖于列的数量。当我们研究一个CPU占用非常高的案例时,发现客户使用了非常宽的表（数千个字段）,然而只有一小部分列会实际用到,这时转换的代价就非常高。如果计划使用数千个字段,必须意识到服务器的性能运行特征会有一些不同。 太多的关联所谓的“实体-属性-值”（EAV）设计模式是一个常见的糟糕设计模式,尤其是在MySQL下不能靠谱地工作。MySQL限制了每个关联操作最多只能有61张表,但是EAV数据库需要许多自关联。我们见过不少EAV数据库最后超过了这个限制。事实上在许多关联少于61张表的情况下,解析和优化查询的代价也会成为MySQL的问题。一个粗略的经验法则,如果希望查询执行得快速且并发性好,单个查询最好在12个表以内做关联。 全能的枚举注意防止过度使用枚举（ENUM）。下面是我们见过的一个例子： 12CREATE TABLE ... ( country enum('','0','1','2',...,'31') 这种模式的schema设计非常凌乱。这么使用枚举值类型也许在任何支持枚举类型的数据库都是一个有问题的设计方案,这里应该用整数作为外键关联到字典表或者查找表来查找具体值。但是在MySQL中,当需要在枚举列表中增加一个新的国家时就要做一次ALTER TABLE操作。在MySQL 5.0以及更早的版本中ALTER TABLE是一种阻塞操作；即使在5.1和更新版本中,如果不是在列表的末尾增加值也会一样需要ALTER TABLE。 变相的枚举枚举（ENUM）列允许在列中存储一组定义值中的单个值,集合（SET）列则允许在列中存储一组定义值中的一个或多个值。有时候这可能比较容易导致混乱。这是一个例子： 12CREATE TABLE ... ( is_default set ('Y','N') NOT NULL default 'N' 非此发明（Not Invent Here）的NULL我们之前写了避免使用NULL的好处,并且建议尽可能地考虑替代方案。即使需要存储一个事实上的“空值”到表中时,也不一定非得使用NULL。也许可以使用0、某个特殊值,或者空字符串作为代替 五、范式和反范式对于任何给定的数据通常都有很多种表示方法,从完全的范式化到完全的反范式化,以及两者的折中。在范式化的数据库中,每个事实数据会出现并且只出现一次。相反,在反范式化的数据库中,信息是冗余的,可能会存储在多个地方。 1.范式的优点和缺点范式化通常能够带来好处 范式化的更新操作通常比反范式化要快。 当数据较好地范式化时,就只有很少或者没有重复数据,所以只需要修改更少的数据。 范式化的表通常更小,可以更好地放在内存里,所以执行操作会更快。 很少有多余的数据意味着检索列表数据时更少需要DISTINCT或者GROUP BY语句。还是前面的例子：在非范式化的结构中必须使用DISTINCT或者GROUP BY才能获得一份唯一的部门列表,但是如果部门（DEPARTMENT）是一张单独的表,则只需要简单的查询这张表就行了。 范式化设计的schema的缺点通常需要关联。 反范式的优点和缺点反范式化的schema因为所有数据都在一张表中,可以很好地避免关联。 如果不需要关联表,则对大部分查询最差的情况——即使表没有使用索引——是全表扫描。当数据比内存大时这可能比关联要快得多,因为这样避免了随机 I/O 。 2.混用范式化和反范式化事实是,完全的范式化和完全的反范式化schema都是实验室里才有的东西：在真实世界中很少会这么极端地使用。在实际应用中经常需要混用,可能使用部分范式化的schema、缓存表,以及其他技巧。 最常见的反范式化数据的方法是复制或者缓存,在不同的表中存储相同的特定列。在MySQL 5.0和更新版本中,可以使用触发器更新缓存值,这使得实现这样的方案变得更简单。 六、缓存表和汇总表1.物化视图TODO 2.计数器表TODO 3.加快ALTER TABLE操作的速度只修改.frm文件下面这些操作是有可能不需要重建表的 移除（不是增加）一个列的AUTO_INCREMENT属性。 增加、移除,或更改ENUM和SET常量。如果移除的是已经有行数据用到其值的常量,查询将会返回一个空字串值。 修改方法 创建一张有相同结构的空表,并进行所需要的修改（例如增加ENUM常量）。 执行FLUSH TABLES WITH READ LOCK。这将会关闭所有正在使用的表,并且禁止任何表被打开。 交换.frm文件 执行UNLOCK TABLES来释放第2步的读锁","link":"/2020/04/30/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/%E9%AB%98%E6%80%A7%E8%83%BDmysql(2)/"},{"title":"高性能  MySQL  ｜ 查询性能优化","text":"MySQL 查询性能的优化涉及多个方面,其中包括库表结构、建立合理的索引、设计合理的查询。库表结构包括如何设计表之间的关联、表字段的数据类型等。这需要依据具体的场景进行设计。如下我们从数据库的索引和查询语句的设计两个角度介绍如何提高 MySQL 查询性能。 一、为什么查询速度会慢?查询的生命周期 从客户端,到服务器 生成执行计划 执行 数据处理 包括排序 分组 返回结果给客户端 查询需要在不同的地方花费时间 网络 CPU计算 生成统计信息和执行计划 锁等待（互斥等待） 向底层存储引擎检索数据的调用操作 根据存储引擎不同,可能还会产生大量的上下文切换以及系统调用 二、慢查询基础：优化数据访问分析步骤 确认应用程序是否在检索大量超过需要的数据。这通常意味着访问了太多的行,但有时候也可能是访问了太多的列 确认 MySQL 服务器层是否在分析大量超过需要的数据行 是否向数据库请求了不需要的数据 几种示例: 查询不需要的记录 多表关联时返回全部列 总是取出全部列 重复查询相同的数据 适用范围:人们会告诉我们说这种有点浪费数据库资源的方式可以简化开发,因为能提高相同代码片段的复用性,如果清楚这样做的性能影响,那么这种做法也是值得考虑的。 MySQL 是否在扫描额外的记录 最简单的衡量查询开销的三个指标如下 响应时间 实际上可以使用快速上限估计法来估算查询的响应时间 服务时间 数据库处理这个查询真正花了多长时间 排队时间 服务器因为等待某些资源而没有真正执行查询的时间——可能是等I/O操作完成,也可能是等待行锁,等等。 扫描的行数 返回的行数 一般 MySQL 能够使用如下三种方式应用WHERE条件,从好到坏依次为 在索引中使用WHERE条件来过滤不匹配的记录。这是在存储引擎层完成的。 使用索引覆盖扫描（在Extra列中出现了Using index）来返回记录,直接从索引中过滤不需要的记录并返回命中的结果。这是在 MySQL 服务器层完成的,但无须再回表查询记录。 从数据表中返回数据,然后过滤不满足条件的记录（在Extra列中出现Using Where）。这在 MySQL 服务器层完成, MySQL 需要先从数据表读出记录然后过滤。 如果发现查询需要扫描大量的数据但只返回少数的行 重写这条 sql 使用索引覆盖扫描,把所有需要用的列都放到索引中,这样存储引擎无须回表获取对应行就可以返回结果了（在前面的章节中我们已经讨论过了）。 改变库表结构。例如使用单独的汇总表（这是我们在第4章中讨论的办法）。 三、重构查询的方式一个复杂查询还是多个简单查询将一个大查询分解为多个小查询是很有必要的,不过,在应用设计的时候,如果一个查询能够胜任时还写成多个独立查询是不明智的。 切分查询原因 如果用一个大的语句一次性完成的话,则可能需要一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询 好处 这样也可以将服务器上原本一次性的压力分散到一个很长的时间段中,就可以大大降低对服务器的影响,还可以大大减少删除时锁的持有时间 分解关联查询好处 让缓存的效率更高。许多应用程序可以方便地缓存单表查询对应的结果对象。如果关联中的某个表发生了变化,那么就无法使用查询缓存了,而拆分后,如果某个表很少改变,那么基于该表的查询就可以重复利用查询缓存结果了 例如,上面查询中的tag已经被缓存了,那么应用就可以跳过第一个查询。再例如,应用中已经缓存了ID为123、567、9098的内容,那么第三个查询的IN()中就可以少几个ID。另外,对 MySQL 的查询缓存来说(6)。 将查询分解后,执行单个查询可以减少锁的竞争。 在应用层做关联,可以更容易对数据库进行拆分,更容易做到高性能和可扩展。 查询本身效率也可能会有所提升。这个例子中,使用IN()代替关联查询,可以让 MySQL 按照ID顺序进行查询,这可能比随机的关联要更高效。我们后续将详细介绍这点。 可以减少冗余记录的查询。在应用层做关联查询,意味着对于某条记录应用只需要查询一次,而在数据库中做关联查询,则可能需要重复地访问一部分数据。从这点看,这样的重构还可能会减少网络和内存的消耗。 更进一步,这样做相当于在应用中实现了哈希关联,而不是使用 MySQL 的嵌套循环关联。某些场景哈希关联的效率要高很多（本章后续我们将讨论这点）。 四、查询执行的基础MySQL 到底做了些什么 客户端发送一条查询给服务器。 服务器先检查查询缓存,如果命中了缓存,则立刻返回存储在缓存中的结果。否则进入下一阶段。 服务器端进行SQL解析、预处理,再由优化器生成对应的执行计划。 MySQL 根据优化器生成的执行计划,调用存储引擎的API来执行查询。 将结果返回给客户端。 MySQL 客户端/服务器通信协议MySQL 客户端和服务器之间的通信协议是半双工 这意味着,在任何一个时刻,要么是由服务器向客户端发送数据,要么是由客户端向服务器发送数据,这两个动作不能同时发生。所以,我们无法也无须将一个消息切成小块独立来发送。 参数max_allowed_packet控制包长度 查询状态Sleep 线程正在等待客户端发送新的请求。 Query 线程正在执行查询或者正在将结果发送给客户端。 Locked 在 MySQL 服务器层,该线程正在等待表锁。在存储引擎级别实现的锁,例如 InnoDB 的行锁,并不会体现在线程状态中。对于 MyISAM 来说这是一个比较典型的状态,但在其他没有行锁的引擎中也经常会出现。 Analyzing and statistics 线程正在收集存储引擎的统计信息,并生成查询的执行计划。 Copying to tmp table [on disk] 线程正在执行查询,并且将其结果集都复制到一个临时表中,这种状态一般要么是在做group by操作,要么是文件排序操作,或者是UNION操作。如果这个状态后面还有on disk标记,那表示 MySQL 正在将一个内存临时表放到磁盘上。 Sorting result 线程正在对结果集进行排序。 Sending data 这表示多种情况：线程可能在多个状态之间传送数据,或者在生成结果集,或者在向客户端返回数据。 查询缓存实现原理 这个检查是通过一个对大小写敏感的哈希查找实现的 执行步骤 如果当前的查询恰好命中了查询缓存 检查一次用户权限(无须解析查询SQL语句的) 如果权限没有问题, MySQL 会跳过所有其他阶段,直接从缓存中拿到结果并返回给客户端 查询优化处理MySQL 依照这个执行计划和存储引擎进行交互的过程 解析SQL 预处理 优化SQL执行计划 语法解析器和预处理 MySQL 通过关键字将SQL语句进行解析,并生成一棵对应的解析树。 MySQL 解析器将使用 MySQL 语法规则验证和解析查询。 预处理器则根据一些 MySQL 规则进一步检查解析树是否合法 下一步预处理器会验证权限。这通常很快,除非服务器上有非常多的权限配置。 查询优化器类型 MySQL 使用基于成本的优化器 实现原理 它将尝试预测一个查询使用某种执行计划时的成本,并选择其中成本最小的一个。 成本因素 每个表或者索引的页面个数、索引的基数（索引中不同值的数量）、索引和数据行的长度、索引分布情况。优化器在评估成本的时候并不考虑任何层面的缓存,它假设读取任何数据都需要一次磁盘I/O。 最初,成本的最小单位是随机读取一个4K数据页的成本,后来（成本计算公式）变得更加复杂,并且引入了一些因子来估算某些操作的代价,如当执行一次WHERE条件比较的成本。可以通过查询当前会话的Last_query_cost的值来得知 MySQL 计算的当前查询的成本。 SHOW STATUS LIKE 'last_query_cost'; 会导致 MySQL 优化器选择错误的执行计划的原因 统计信息不准确。 MySQL 依赖存储引擎提供的统计信息来评估成本,但是有的存储引擎提供的信息是准确的,有的偏差可能非常大。例如, InnoDB 因为其MVCC的架构,并不能维护一个数据表的行数的精确统计信息。 执行计划中的成本估算不等同于实际执行的成本。所以即使统计信息精准,优化器给出的执行计划也可能不是最优的。例如有时候某个执行计划虽然需要读取更多的页面,但是它的成本却更小。因为如果这些页面都是顺序读或者这些页面都已经在内存中的话,那么它的访问成本将很小。 MySQL 层面并不知道哪些页面在内存中、哪些在磁盘上,所以查询实际执行过程中到底需要多少次物理I/O是无法得知的。 MySQL 的最优可能和你想的最优不一样。你可能希望执行时间尽可能的短,但是 MySQL 只是基于其成本模型选择最优的执行计划,而有些时候这并不是最快的执行方式。所以,这里我们看到根据执行成本来选择执行计划并不是完美的模型。 MySQL 从不考虑其他并发执行的查询,这可能会影响到当前查询的速度。 MySQL 也并不是任何时候都是基于成本的优化。有时也会基于一些固定的规则,例如,如果存在全文搜索的MATCH()子句,则在存在全文索引的时候就使用全文索引。即使有时候使用别的索引和WHERE条件可以远比这种方式要快, MySQL 也仍然会使用对应的全文索引。 MySQL 不会考虑不受其控制的操作的成本,例如执行存储过程或者用户自定义函数的成本。 后面我们还会看到,优化器有时候无法去估算所有可能的执行计划,所以它可能错过实际上最优的执行计划。 优化策略可以简单地分为两种 静态优化 例如,优化器可以通过一些简单的代数变换将WHERE条件转换成另一种等价形式。静态优化不依赖于特别的数值,如WHERE条件中带入的一些常数等。静态优化在第一次完成后就一直有效,即使使用不同的参数重复执行查询也不会发生变化。可以认为这是一种编译时优化。 可以直接对解析树进行分析,并完成优化。 动态优化 动态优化则和查询的上下文有关,也可能和很多其他因素有关,例如WHERE条件中的取值、索引中条目对应的数据行数等。这需要在每次查询的时候都重新评估,可以认为这是运行时优化。 一些 MySQL 能够处理的优化类型 重新定义关联表的顺序 数据表的关联并不总是按照在查询中指定的顺序进行。决定关联的顺序是优化器很重要的一部分功能, 将外连接转化成内连接 并不是所有的OUTER JOIN语句都必须以外连接的方式执行。诸多因素,例如WHERE条件、库表结构都可能会让外连接等价于一个内连接。 MySQL 能够识别这点并重写查询,让其可以调整关联顺序。 使用等价变换规则 MySQL 可以使用一些等价变换来简化并规范表达式。它可以合并和减少一些比较,还可以移除一些恒成立和一些恒不成立的判断。例如,（5=5 AND a&gt;5）将被改写为a&gt;5。类似的,如果有（a&lt;b AND b=c） AND a=5则会改写为b&gt;5 AND b=c AND a=5。这些规则对于我们编写条件语句很有用,我们将在本章后续继续讨论。 优化COUNT()、MIN()和MAX() 例如,要找到某一列的最小值,只需要查询对应B-Tree索引最左端的记录, MySQL 可以直接获取索引的第一行记录。在优化器生成执行计划的时候就可以利用这一点,在B-Tree索引中,优化器会将这个表达式作为一个常数对待。类似的,如果要查找一个最大值,也只需读取B-Tree索引的最后一条记录。如果 MySQL 使用了这种类型的优化,那么在 EXPLAIN 中就可以看到Select tables optimized away。从字面意思可以看出,它表示优化器已经从执行计划中移除了该表,并以一个常数取而代之。类似的,没有任何WHERE条件的COUNT（*）查询通常也可以使用存储引擎提供的一些优化（例如, MyISAM 维护了一个变量来存放数据表的行数）。 索引和列是否可为空通常可以帮助 MySQL 优化这类表达式。 预估并转化为常数表达式 例如,一个用户自定义变量在查询中没有发生变化时就可以转换为一个常数。数学表达式则是另一种典型的例子。这可以通过WHERE、USING或者ON语句来限制某列取值为常数。在上面的例子中,因为使用了USING子句,优化器知道这也限制了film_id在整个查询过程中都始终是一个常量。 当 MySQL 检测到一个表达式可以转化为常数的时候,就会一直把该表达式作为常数进行优化处理。 覆盖索引扫描 当索引中的列包含所有查询中需要使用的列的时候, MySQL 就可以使用索引返回需要的数据,而无须查询对应的数据行,在前面的章节中我们已经讨论过这点了。 子查询优化 MySQL 在某些情况下可以将子查询转换一种效率更高的形式,从而减少多个查询多次对数据进行访问。 提前终止查询 一个典型的例子就是当使用了LIMIT子句的时候。除此之外, MySQL 还有几类情况也会提前终止查询,例如发现了一个不成立的条件,这时 MySQL 可以立刻返回一个空结果。 在发现已经满足查询需求的时候, MySQL 总是能够立刻终止查询。 等值传播 如果两个列的值通过等式关联,那么 MySQL 能够把其中一个列的WHERE条件传递到另一列上。 1234SELECT film.film_id FROM sakila.film INNER JOIN sakila.film_actor USING(film_id) WHERE film.film_id &gt; 500 因为这里使用了film_id字段进行等值关联, MySQL 知道这里的WHERE子句不仅适用于flm表,而且对于flm_actor表同样适用。如果使用的是其他的数据库管理系统,可能还需要手动通过一些条件来告知优化器这个WHERE条件适用于两个表,那么写法就会如下： ... WHERE film.film_id &gt; 500 AND film_actor.film_id &gt; 500在 MySQL 中这是不必要的,这样写反而会让查询更难维护。 列表IN()的比较 在很多数据库系统中,IN()完全等同于多个OR条件的子句,因为这两者是完全等价的。在 MySQL 中这点是不成立的, MySQL 将IN()列表中的数据先进行排序,然后通过二分查找的方式来确定列表中的值是否满足条件,这是一个O（log n）复杂度的操作,等价地转换成OR查询的复杂度为O（n）,对于IN()列表中有大量取值的时候, MySQL 的处理速度将会更快。 数据和索引的统计信息 MySQL 查询优化器在生成查询的执行计划时,需要向存储引擎获取相应的统计信息。存储引擎则提供给优化器对应的统计信息,包括：每个表或者索引有多少个页面、每个表的每个索引的基数是多少、数据行和索引长度、索引的分布信息等。优化器根据这些信息来选择一个最优的执行计划。 MySQL 如何执行关联查询 在 MySQL 的概念中,每个查询都是一次关联,所以读取结果临时表也是一次关联。 什么是关联 MySQL 中关联(14)一词所包含的意义比一般意义上理解的要更广泛。总的来说, MySQL 认为任何一个查询都是一次关联——并不仅仅是一个查询需要到两个表匹配才叫关联,所以在 MySQL 中,每一个查询,每一个片段（包括子查询,甚至基于单表的SELECT）都可能是关联。 MySQL 关联执行的策略 嵌套循环关联,即 MySQL 先在一个表中循环取出单条数据,然后再嵌套循环到下一个表中寻找匹配的行,依次下去,直到找到所有表中匹配的行为止。然后根据各个表匹配的行,返回查询中需要的各个列。 MySQL 会尝试在最后一个关联表中找到所有匹配的行,如果最后一个联表无法找到更多的行以后, MySQL 返回到上一层次关联表,看是否能够找到更多的匹配记录,依此类推迭代执行。 执行计划 MySQL 的执行计划步骤 MySQL 生成查询的一棵指令树 通过存储引擎执行完成这棵指令树并返回结果 最终的执行计划包含了重构查询的全部信息 如果对某个查询执行 EXPLAIN EXTENDED后,再执行 SHOW WARNINGS,就可以看到重构出的查询 关联查询优化器 关联优化器的评判标准 关联查询优化器则通过评估不同顺序时的成本来选择一个代价最小的关联顺序 一般是根据扫描的行数来判断,因为会进行嵌套,循环,回溯的过程,如果扫描的行数越少,能够提前剔除,可以减少后面的基数 做了什么 关联优化器会尝试在所有的关联顺序中选择一个成本最小的来生成执行计划树 当搜索空间非常大的时候,优化器不可能逐一评估每一种关联顺序的成本。这时,优化器选择使用贪婪搜索的方式查找最优的关联顺序。 optimizer_search_depth参数可以根据需要指定大小 技巧 STRAIGHT_JOIN 功能同join类似,但能让左边的表来驱动右边的表,能改表优化器对于联表查询的执行顺序。 排序优化 文件排序 当不能使用索引生成排序结果的时候, MySQL 需要自己进行排序,如果数据量小则在内存中进行,如果数据量大则需要使用磁盘 如何进行文件排序 如果需要排序的数据量小于排序缓冲区, MySQL 使用内存进行快速排序操作。如果内存不够排序,那么 MySQL 会先将数据分块,对每个独立的块使用快速排序进行排序,并将各个块的排序结果存放在磁盘上,然后将各个排好序的块进行合并（merge）,最后返回排序结果。 MySQL 有如下两种排序算法 两次传输排序（旧版本使用） 读取行指针和需要排序的字段,对其进行排序,然后再根据排序结果读取所需要的数据行。这需要进行两次数据传输,即需要从数据表中读取两次数据,第二次读取数据的时候,因为是读取排序列进行排序后的所有记录,这会产生大量的随机I/O,所以两次数据传输的成本非常高。当使用的是 MyISAM 表的时候,成本可能会更高,因为 MyISAM 使用系统调用进行数据的读取（ MyISAM 非常依赖操作系统对数据的缓存）。不过这样做的优点是,在排序的时候存储尽可能少的数据,这就让排序缓冲区(21)中可能容纳尽可能多的行数进行排序。 单次传输排序（新版本使用） 先读取查询所需要的所有列,然后再根据给定列进行排序,最后直接返回排序结果。这个算法只在 MySQL 4.1和后续更新的版本才引入。因为不再需要从数据表中读取两次数据,对于I/O密集型的应用,这样做的效率高了很多。另外,相比两次传输排序,这个算法只需要一次顺序I/O读取所有的数据,而无须任何的随机I/O。缺点是,如果需要返回的列非常多、非常大,会额外占用大量的空间,而这些列对排序操作本身来说是没有任何作用的。因为单条排序记录很大,所以可能会有更多的排序块需要合并。 查询执行引擎 有什么作用 在解析和优化阶段, MySQL 将生成查询对应的执行计划, MySQL 的查询执行引擎则根据这个执行计划来完成整个查询。 执行引擎的步骤 MySQL 只是简单地根据执行计划给出的指令逐步执行。在根据执行计划逐步执行的过程中,有大量的操作需要通过调用存储引擎实现的接口来完成,这些接口也就是我们称为handler API的接口。查询中的每一个表由一个handler的实例表示。前面我们有意忽略了这点,实际上, MySQL 在优化阶段就为每个表创建了一个handler实例,优化器根据这些实例的接口可以获取表的相关信息,包括表的所有列名、索引统计信息,等等。 并不是所有的操作都由handler完成。例如,当 MySQL 需要进行表锁的时候。handler可能会实现自己的级别的、更细粒度的锁,如 InnoDB 就实现了自己的行基本锁,但这并不能代替服务器层的表锁。正如我们第1章所介绍的,如果是所有存储引擎共有的特性则由服务器层实现,比如时间和日期函数、视图、触发器等。 返回结果给客户端 执行步骤 即使查询不需要返回结果集给客户端, MySQL 仍然会返回这个查询的一些信息,如该查询影响到的行数 如果查询可以被缓存,那么 MySQL 在这个阶段也会将结果存放到查询缓存中。 MySQL 将结果集返回客户端是一个增量、逐步返回的过程。 好处 服务器端无须存储太多的结果,也就不会因为要返回太多结果而消耗太多内存 这样的处理也让 MySQL 客户端第一时间获得返回的结果 结果集中的每一行都会以一个满足 MySQL 客户端/服务器通信协议的封包发送,再通过TCP协议进行传输,在TCP传输的过程中,可能对 MySQL 的封包进行缓存然后批量传输 五、MySQL 查询优化器的局限性 MySQL 的万能嵌套循环并不是对每种查询都是最优的。不过还好, MySQL 查询优化器只对少部分查询不适用,而且我们往往可以通过改写查询让 MySQL 高效地完成工作。 关联子查询为什么要使用关联自查询 MySQL 的子查询实现得非常糟糕。最糟糕的一类查询是WHERE条件中包含IN()的子查询语句。 例如,我们希望找到Sakila数据库中,演员Penelope Guiness（他的actor_id为1）参演过的所有影片信息。很自然的,我们会按照下面的方式用子查询实现： 12345678SELECT * FROM sakila.film WHERE film_id IN( SELECT film_id FROM sakila.film_actor WHERE actor_id = 1 ) ; 因为 MySQL 对IN()列表中的选项有专门的优化策略,一般会认为 MySQL 会先执行子查询返回所有包含actor_id为1的film_id。一般来说,IN()列表查询速度很快,所以我们会认为上面的查询会这样执行： 1SELECT * FROM sakila.film 123SELECT GROUP_CONCAT(film_id) FROM sakila.film_actor WHERE actor_id = 1; Result:1,23,25,106,140,166,277,361,438, 499,506,509,605,635,749,832,939,970,980 12345SELECT * FROM sakila.film WHERE film_id IN(1,23,25,106,140,166,277,361,438,499,506,509,605,635,749,832,939,970,980); 很不幸, MySQL 不是这样做的。 MySQL 会将相关的外层表压到子查询中,它认为这样可以更高效率地查找到数据行。 改进的写法 12345SELECT * FROM sakila.film WHERE film_id IN( SELECT film_id FROM sakila.film_actor WHERE actor_id = 1); 123456SELECT * FROM sakila.film WHERE EXISTS ( SELECT * FROM sakila.film_actor WHERE actor_id = 1 WHERE film_actor.film_id = film.film_id); 1234SELECT film.* FROM sakila.film INNER JOIN sakila.film_actor USING(film_id) WHERE actor_id = 1; 如何用好关联子查询例子1 原始sql EXPLAIN SELECT film_id, language_id FROM sakila.film WHERE NOT EXISTS( WHERE * FROM sakila.film_actor WHERE film_actor.film_id = film.film_id )\\G 一般会建议使用左外连接（LEFT OUTER JOIN）重写该查询,以代替子查询。理论上,改写后 MySQL 的执行计划完全不会改变。 优化1 EXPLAIN SELECT film.film_id, film.language_id FROM sakila.film LEFT OUTER JOIN sakila.film_actor USING(film_id) WHERE film_actor.film_id IS NULL\\G 可以看到,这里的执行计划基本上一样,下面是一些微小的区别： 表flm_actor的访问类型一个是DEPENDENT SUBQUERY,而另一个是SIMPLE。这个不同是由于语句的写法不同导致的,一个是普通查询,一个是子查询。这对底层存储引擎接口来说,没有任何不同。 对film表,第二个查询的Extra中没有Using where,但这不重要,第二个查询的USING子句和第一个查询的WHERE子句实际上是完全一样的。 在第二个表film_actor的执行计划的Extra列有Not exists。这是我们前面章节中提到的提前终止算法（early-termination algorithm）, MySQL 通过使用Not exists优化来避免在表film_actor的索引中读取任何额外的行。这完全等效于直接编写NOT EXISTS子查询,这个执行计划中也是一样,一旦匹配到一行数据,就立刻停止扫描。 例子2 原始sql SELECT DISTINCT film.film_id FROM sakila.film INNER JOIN sakila.film_actor USING(film_id); 我们知道一旦使用了DISTINCT和GROUP BY,那么在查询的执行过程中,通常需要产生临时中间表。 优化1 SELECT film_id FROM sakila.film WHERE EXISTS(SELECT * FROM sakila.film_actor WHERE film.film_id = film_actor.film_id); 再一次,我们需要通过测试来对比这两种写法,哪个更快一些。测试结果参考表6-2。表6-2：EXISTS和关联性能对比查询每秒查询数结果（QPS） INNER JOIN 185 QPS EXISTS子查询 325 QPS 在这个案例中,我们看到子查询速度要比关联查询更快些。 UNION 的限制MySQL 无法将限制条件从外层下推到内层,这使得原本能够限制部分返回结果的条件无法应用到内层查询的优化上 解决办法 从临时表中取出数据的顺序并不是一定的,所以如果想获得正确的顺序,还需要加上一个全局的ORDER BY和LIMIT操作 索引合并优化我们的 where 中可能有多个条件(或者join)涉及到多个字段,它们之间进行AND或者OR,那么此时就有可能会使用到index merge技术。index merge技术如果简单的说,其实就是：对多个索引分别进行条件扫描,然后将它们各自的结果进行合并(intersect/union)。 等值传递某些时候,等值传递会带来一些意想不到的额外消耗。例如,有一个非常大的IN()列表,而 MySQL 优化器发现存在WHERE、ON或者USING的子句,将这个列表的值和另一个表的某个列相关联。那么优化器会将IN()列表都复制应用到关联的各个表中。通常,因为各个表新增了过滤条件,优化器可以更高效地从存储引擎过滤记录。但是如果这个列表非常大,则会导致优化和执行都会变慢。在本书写作的时候,除了修改 MySQL 源代码,目前还没有什么办法能够绕过该问题（不过这个问题很少会碰到）。 并行执行 MySQL 无法利用多核特性来并行执行查询。很多其他的关系型数据库能够提供这个特性,但是 MySQL 做不到。这里特别指出是想告诉读者不要花时间去尝试寻找并行执行查询的方法。 哈希关联在本书写作的时候,MySQL 并不支持哈希关联—— MySQL 的所有关联都是嵌套循环关联。不过,可以通过建立一个哈希索引来曲线地实现哈希关联。如果使用的是 Memory 存储引擎,则索引都是哈希索引,所以关联的时候也类似于哈希关联。可以参考第5章的创建自定义哈希索引部分。另外, MariaDB 已经实现了真正的哈希关联。 松散索引扫描与紧凑索引扫描松散索引扫描 松散索引扫描相当于 Oracle 中的跳跃索引扫描（skip index scan）,就是不需要连续的扫描索引中得每一个元组,扫描时仅考虑索引中得一部分。当查询中没有 where 条件的时候,松散索引扫描读取的索引元组的个数和 groups 的数量相同。如果 where 条件包含范围预测,松散索引扫描查找每个 group 中第一个满足范围条件,然后再读取最少可能数的keys。松散索引扫描只需要读取很少量的数据就可以完成group by操作,因而执行效率非常高 使用松散索引扫描需要满足以下条件 查询在单一表上。 group by指定的所有列是索引的一个最左前缀,并且没有其它的列。比如表t1（ c1,c2,c3,c4）上建立了索引（c1,c2,c3）。如果查询包含group by c1,c2,那么可以使用松散索引扫描。但是group by c2,c3(不是索引最左前缀)和group by c1,c2,c4(c4字段不在索引中)。 如果在选择列表select list中存在聚集函数,只能使用 min()和max()两个聚集函数,并且指定的是同一列（如果min()和max()同时存在）。这一列必须在索引中,且紧跟着group by指定的列。比如,select t1,t2,min(t3),max(t3) from t1 group by c1,c2。 如果查询中存在除了group by指定的列之外的其他部分,那么必须以常量的形式出现（除了min()和max()两个聚集函数）。 索引中的列必须索引整个数据列的值(full column values must be indexed),而不是一个前缀索引。比如,c1 varchar(20), INDEX (c1(10)),这个索引没发用作松散索引扫描。 紧凑索引扫描 紧凑索引扫描可能是全索引扫描或者范围索引扫描,取决于查询条件。当松散索引扫描条件没有满足的时候,group by仍然有可能避免创建临时表。如果在 where 条件有范围扫描,那么紧凑索引扫描仅读取满足这些条件的 keys（索引元组）。否则执行索引扫描。因为这种方式读取所有 where 条件定义的范围内的 keys,或者扫描整个索引当没有 where 条件,因而称作紧凑索引扫描。对于紧凑索引扫描,只有在所有满足范围条件的 keys 被找到之后才会执行分组操作。 使用紧凑索引扫描需要满足以下条件 在查询中存在常量相等 where 条件字段（索引中的字段）,且该字段在group by指定的字段的前面或者中间。来自于相等条件的常量能够填充搜索keys中的gaps,因而可能构成一个索引的完整前缀。索引前缀能够用于索引查找。如果要求对group by的结果进行排序,并且查找字段有可能组成一个索引前缀, MySQL 同样可以避免额外的排序操作,因为对有序的索引进行的查找已经按照顺序提取所有的keys。 最大值和最小值优化原始sql 123SELECT MIN(actor_id) FROM sakila.actorWHERE first_name='PENELOPE' 问题 因为在 first_name 字段上并没有索引,因此 MySQL 将会进行一次全表扫描。 解决办法 一个曲线的优化办法是移除MIN(),然后使用LIMIT来将查询重写如下： 123SELECT actor_id FROM sakila.actor USE INDEX(PRIMARY) WHERE first_name = 'PENELOPE' LIMIT 1; 在同一个表上查询和更新MySQL 不允许对同一张表同时进行查询和更新。这其实并不是优化器的限制,如果清楚 MySQL 是如何执行查询的,就可以避免这种情况。 例子 12345UPDATE tbl AS outer_tbl SET cnt = ( SELECT count(*) FROM tbl AS inner_tbl WHERE inner_tbl.type = outer_tbl.type ); 原因 实际上,这执行了两个查询：一个是子查询中的SELECT语句,另一个是多表关联UPDATE,只是关联的表是一个临时表。子查询会在UPDATE语句打开表之前就完成, 解决办法 可以通过使用生成表的形式来绕过上面的限制,因为 MySQL 只会把这个表当作一个临时表来处理。 1234567UPDATE tbl INNER JOIN( SELECT type, count(*) AS cnt FROM tbl GROUP BY type ) AS der USING(type) SET tbl.cnt = der.cnt; 六、查询优化器的提示HIGH_PRIORITY 和 LOW_PRIORITYHIGH_PRIORITY用于SELECT语句的时候, MySQL 会将此SELECT语句重新调度到所有正在等待表锁以便修改数据的语句之前。实际上 MySQL 是将其放在表的队列的最前面,而不是按照常规顺序等待。HIGH_PRIORITY还可以用于INSERT语句,其效果只是简单地抵消了全局LOW_PRIORITY设置对该语句的影响。 LOW_PRIORITY它会让该语句一直处于等待状态,只要队列中还有需要访问同一个表的语句——即使是那些比该语句还晚提交到服务器的语句。这就像一个过于礼貌的人站在餐厅门口,只要还有其他顾客在等待就一直不进去,很明显这容易把自己给饿坏。LOW_PRIORITY提示在SELECT、INSERT、UPDATE和DELETE语句中都可以使用。 总结HIGH_PRIORITY和LOW_PRIORITY经常让人感到困惑。这两个提示并不会获取更多资源让查询积极工作,也不会少获取资源让查询消极工作。它们只是简单地控制了 MySQL 访问某个数据表的队列顺序。 DELAYED这个提示对INSERT和REPLACE有效。 MySQL 会将使用该提示的语句立即返回给客户端,并将插入的行数据放入到缓冲区,然后在表空闲时批量将数据写入。日志系统使用这样的提示非常有效,或者是其他需要写入大量数据但是客户端却不需要等待单条语句完成I/O的应用。这个用法有一些限制：并不是所有的存储引擎都支持这样的做法；并且该提示会导致函数LAST_INSERT_ID()无法正常工作。 STRAIGHT_JOIN这个提示可以放置在SELECT语句的SELECT关键字之后,也可以放置在任何两个关联表的名字之间。第一个用法是让查询中所有的表按照在语句中出现的顺序进行关联。第二个用法则是固定其前后两个表的关联顺序。 当 MySQL 没能选择正确的关联顺序的时候,或者由于可能的顺序太多导致 MySQL 无法评估所有的关联顺序的时候,STRAIGHT_JOIN都会很有用。在后面这种情况, MySQL 可能会花费大量时间在statistics状态,加上这个提示则会大大减少优化器的搜索空间。可以先使用 EXPLAIN 语句来查看优化器选择的关联顺序,然后使用该提示来重写查询,再看看它的关联顺序。当你确定无论怎样的where条件,某个固定的关联顺序始终是最佳的时候,使用这个提示可以大大提高优化器的效率。但是在升级 MySQL 版本的时候,需要重新审视下这类查询,某些新的优化特性可能会因为该提示而失效。 SQL_SMALL_RESULT 和 SQL_BIG_RESULTSQL_BUFFER_RESULT这个提示告诉优化器将查询结果放入到一个临时表,然后尽可能快地释放表锁。 这和前面提到的由客户端缓存结果不同。当你没法使用客户端缓存的时候,使用服务器端的缓存通常很有效。带来的好处是无须在客户端上消耗太多的内存,还可以尽可能快地释放对应的表锁。代价是,服务器端将需要更多的内存。 SQL_BIG_RESULT告诉优化器结果集可能会非常大,建议使用磁盘临时表做排序操作。 SQL_CACHE 和 SQL_NO_CACHE这个提示告诉 MySQL 这个结果集是否应该缓存在查询缓存中,下一章我们将详细介绍如何使用。 SQL_CALC_FOUND_ROWS严格来说,这并不是一个优化器提示。它不会告诉优化器任何关于执行计划的东西。它会让 MySQL 返回的结果集包含更多的信息。查询中加上该提示 MySQL 会计算除去LIMIT子句后这个查询要返回的结果集的总数,而实际上只返回LIMIT要求的结果集。可以通过函数FOUND_ROW()获得这个值。（参阅后面的SQL_CALC_FOUND_ROWS优化部分,了解下为什么不应该使用该提示。） FOR UPDATE 和 LOCK IN SHARE MODE这也不是真正的优化器提示。这两个提示主要控制SELECT语句的锁机制,但只对实现了行级锁的存储引擎有效。使用该提示会对符合查询条件的数据行加锁。对于INSERT...SELECT语句是不需要这两个提示的,因为对于 MySQL 5.0和更新版本会默认给这些记录加上读锁。（可以禁用该默认行为,但不是个好主意,在后面关于复制和备份的章节中将解释这一点。） 唯一内置的支持这两个提示的引擎就是 InnoDB 。另外需要记住的是,这两个提示会让某些优化无法正常使用,例如索引覆盖扫描。 InnoDB 不能在不访问主键的情况下排他地锁定行,因为行的版本信息保存在主键中。 USE INDEX、IGNORE INDEX 和 FORCE INDEXUSE INDEX则建议优化器使用该索引,但是如果优化器认为它会更快,则可以使用表扫描。如果使用,FORCE INDEX则即使它认为表扫描更有效,让优化器也可以使用此索引。 一些参数用来控制优化器的行为optimizer_search_depth 这个参数控制优化器在穷举执行计划时的限度。如果查询长时间处于Statistics状态,那么可以考虑调低此参数。 optimizer_prune_level 该参数默认是打开的,这让优化器会根据需要扫描的行数来决定是否跳过某些执行计划。 optimizer_switch 这个变量包含了一些开启/关闭优化器特性的标志位。例如在 MySQL 5.1中可以通过这个参数来控制禁用索引合并的特性。前两个参数是用来控制优化器可以走的一些捷径。这些捷径可以让优化器在处理非常复杂的SQL语句时,仍然可以很高效,但这也可能让优化器错过一些真正最优的执行计划。所以应该根据实际需要来修改这些参数。 七、优化特定类型的查询优化COUNT()查询COUNT()的作用 统计某个列值的数量 在统计列值时要求列值是非空的（不统计NULL）。如果在COUNT()的括号中指定了列或者列的表达式,则统计的就是这个表达式有值的结果数 统计行数 统计结果集的行数。当 MySQL 确认括号内的表达式值不可能为空时,实际上就是在统计行数。最简单的就是当我们使用COUNT（*）的时候,这种情况下通配符*并不会像我们猜想的那样扩展成所有的列,实际上,它会忽略所有的列而直接统计所有的行数。 关于 MyISAM 的神话一个容易产生的误解就是： MyISAM 的COUNT()函数总是非常快,不过这是有前提条件的,即只有没有任何WHERE条件的COUNT（*）才非常快,因为此时无须实际地去计算表的行数。 MySQL 可以利用存储引擎的特性直接获得这个值。如果 MySQL 知道某列col不可能为NULL值,那么 MySQL 内部会将COUNT（col）表达式优化为COUNT（*）。当统计带WHERE子句的结果集行数,可以是统计某个列值的数量时, MyISAM 的COUNT()和其他存储引擎没有任何不同,就不再有神话般的速度了。所以在 MyISAM 引擎表上执行COUNT()有时候比别的引擎快,有时候比别的引擎慢,这受很多因素影响,要视具体情况而定。 简单的优化反转条件,来减少需要扫描的行数 使用近似值30秒统计一次,或者更久长时间的一次时间统计,如果业务对数值不那么敏感的话 更复杂的优化增加类似Memcached这样的外部缓存系统 优化关联查询 确保ON或者USING子句中的列上有索引。在创建索引的时候就要考虑到关联的顺序。当表A和表B用列c关联的时候,如果优化器的关联顺序是B、A,那么就不需要在B表的对应列上建上索引。没有用到的索引只会带来额外的负担。一般来说,除非有其他理由,否则只需要在关联顺序中的第二个表的相应列上创建索引。 确保任何的group by和ORDER BY中的表达式只涉及到一个表中的列,这样 MySQL 才有可能使用索引来优化这个过程。 当升级 MySQL 的时候需要注意：关联语法、运算符优先级等其他可能会发生变化的地方。因为以前是普通关联的地方可能会变成笛卡儿积,不同类型的关联可能会生成不同的结果等。 优化子查询关于子查询优化我们给出的最重要的优化建议就是尽可能使用关联查询代替,至少当前的 MySQL 版本需要这样。本章的前面章节已经详细介绍了这点。尽可能使用关联并不是绝对的,如果使用的是 MySQL 5.6或更新的版本或者 MariaDB ,那么就可以直接忽略关于子查询的这些建议了。 优化GROUP BY和DISTINCTGROUP BY GROUP BY使用两种策略 使用临时表 文件排序 通常采用查找表的标识列分组的效率会比其他列更高。 优化GROUP BY WITH ROLLUP分组查询的一个变种就是要求 MySQL 对返回的分组结果再做一次超级聚合。 解决办法 可以使用WITH ROLLUP子句来实现这种逻辑,但可能会不够优化。可以通过 EXPLAIN 来观察其执行计划,特别要注意分组是否是通过文件排序或者临时表实现的。然后再去掉WITH ROLLUP子句看执行计划是否相同。也可以通过本节前面介绍的优化器提示来固定执行计划。 也可以在 FROM 子句中嵌套使用子查询,或者是通过一个临时表存放中间数据,然后和临时表执行UNION来得到最终结果。 最好的办法是尽可能的将WITH ROLLUP功能转移到应用程序中处理 优化LIMIT分页问题原因 在偏移量非常大的时候(27),例如可能是LIMIT 1000,20这样的查询,这时 MySQL 需要查询10 020条记录然后只返回最后20条,前面10 000条记录都将被抛弃,这样的代价非常高。 解决办法 在页面中限制分页的数量 优化大偏移量的性能 优化此类分页查询的一个最简单的办法就是尽可能地使用索引覆盖扫描,而不是查询所有的列。然后根据需要做一次关联操作再返回所需的列。对于偏移量很大的时候,这样做的效率会提升非常大。 案例 原始sql SELECT film_id, description FROM sakila.film ORDER BY title LIMIT 50, 5; 优化1 123456SELECT film.film_id, film.description FROM sakila.film INNER JOIN ( SELECT film_id FROM sakila.film ORDER BY title LIMIT 50, 5 ) AS lim USING(film_id); 这里的延迟关联将大大提升查询效率,它让 MySQL 扫描尽可能少的页面,获取需要访问的记录后再根据关联列回原表查询需要的所有列。这个技术也可以用于优化关联查询中的LIMIT子句。 优化2 12SELECT film_id, description FROM sakila.film WHERE position BETWEEN 50 AND 54 ORDER BY position 有时候也可以将LIMIT查询转换为已知位置的查询,让 MySQL 通过范围扫描获得到对应的结果。例如,如果在一个位置列上有索引,并且预先计算出了边界值 优化3 12SELECT * FROM sakila.rental ORDER BY rental_id DESC`LIMIT`20; LIMIT和OFFSET的问题,其实是OFFSET的问题,它会导致 MySQL 扫描大量不需要的行然后再抛弃掉。如果可以使用书签记录上次取数据的位置,那么下次就可以直接从该书签记录的位置开始扫描,这样就可以避免使用OFFSET。 优化SQL_CALC_FOUND_ROWS问题原因 MySQL 只有在扫描了所有满足条件的行以后,才会知道行数,所以加上这个提示以后,不管是否需要, MySQL 都会扫描所有满足条件的行,然后再抛弃掉不需要的行,而不是在满足LIMIT的行数后就终止扫描。所以该提示的代价可能非常高。 解决办法 一个更好的设计是将具体的页数换成下一页按钮,假设每页显示20条记录,那么我们每次查询时都是用LIMIT返回21条记录并只显示20条,如果第21条存在,那么我们就显示下一页按钮,否则就说明没有更多的数据,也就无须显示下一页按钮了。 另一种做法是先获取并缓存较多的数据——例如,缓存1000条——然后每次分页都从这个缓存中获取。这样做可以让应用程序根据结果集的大小采取不同的策略,如果结果集少于1000,就可以在页面上显示所有的分页链接,因为数据都在缓存中,所以这样做性能不会有问题。如果结果集大于1000,则可以在页面上设计一个额外的找到的结果多于1000条之类的按钮。这两种策略都比每次生成全部结果集再抛弃掉不需要的数据的效率要高很多。 优化UNION查询问题原因 MySQL 总是通过创建并填充临时表的方式来执行UNION查询。因此很多优化策略在UNION查询中都没法很好地使用。经常需要手工地将WHERE、LIMIT、ORDER BY等子句下推到UNION的各个子查询中,以便优化器可以充分利用这些条件进行优化（例如,直接将这些子句冗余地写一份到各个子查询）。 注意:除非确实需要服务器消除重复的行,否则就一定要使用UNION ALL,这一点很重要。如果没有ALL关键字, MySQL 会给临时表加上DISTINCT选项,这会导致对整个临时表的数据做唯一性检查。这样做的代价非常高。即使有ALL关键字, MySQL 仍然会使用临时表存储结果。事实上, MySQL 总是将结果放入临时表,然后再读出,再返回给客户端。 静态查询分析 Percona Toolkit中的pt-query-advisor能够解析查询日志、分析查询模式,然后给出所有可能存在潜在问题的查询,并给出足够详细的建议。 使用用户自定义变量在哪些场景下我们不能使用用户自定义变量 使用自定义变量的查询,无法使用查询缓存。 不能在使用常量或者标识符的地方使用自定义变量,例如表名、列名和LIMIT子句中。 用户自定义变量的生命周期是在一个连接中有效,所以不能用它们来做连接间的通信。 如果使用连接池或者持久化连接,自定义变量可能让看起来毫无关系的代码发生交互（如果是这样,通常是代码bug或者连接池bug,这类情况确实可能发生）。 在5.0之前的版本,是大小写敏感的,所以要注意代码在不同 MySQL 版本间的兼容性问题。 不能显式地声明自定义变量的类型。确定未定义变量的具体类型的时机在不同 MySQL 版本中也可能不一样。如果你希望变量是整数类型,那么最好在初始化的时候就赋值为0,如果希望是浮点型则赋值为0.0,如果希望是字符串则赋值为’’,用户自定义变量的类型在赋值的时候会改变。 MySQL 的用户自定义变量是一个动态类型。 MySQL 优化器在某些场景下可能会将这些变量优化掉,这可能导致代码不按预想的方式运行。 赋值的顺序和赋值的时间点并不总是固定的,这依赖于优化器的决定。实际情况可能很让人困惑,后面我们将看到这一点。 赋值符号:=的优先级非常低,所以需要注意,赋值表达式应该使用明确的括号。使用未定义变量不会产生任何语法错误,如果没有意识到这一点,非常容易犯错。 优化排名语句 避免重复查询刚刚更新的数据 统计更新和插入的数量 确定取值的顺序 编写偷懒的UNION 用户自定义变量的其他用处","link":"/2020/05/03/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/%E9%AB%98%E6%80%A7%E8%83%BDmysql(4)/"},{"title":"高性能 MySQL ｜ 创建高性能的索引","text":"索引对于良好的性能非常关键,尤其是当表中的数据量越来越大时,索引对性能的影响愈发重要。在数据量较小且负载较低时,不恰当的索引对性能的影响可能还不明显,但当数据量逐渐增大时,性能则会急剧下降。 一、索引的类型1.B+Tree索引B-Tree索引使用B-Tree来存储数据,当然不同存储引擎的实现方式不同。B-Tree通常意味着所有的值都是按顺序存储的,并且每一个叶子页到根的距离相同。 索引特点 叶子节点比较特别,它们的指针指向的是被索引的数据 B-Tree通常意味着所有的值都是按顺序存储的 每一个叶子页到根的距离相同 适用范围 全值匹配 匹配最左前缀 匹配列前缀 匹配范围值 精确匹配某一列并范围匹配另外一列 只访问索引的查询 B-Tree索引的限制 如果不是按照索引的最左列开始查找,则无法使用索引。例如上面例子中的索引无法用于查找名字为Bill的人,也无法查找某个特定生日的人,因为这两列都不是最左数据列。类似地,也无法查找姓氏以某个字母结尾的人。 不能跳过索引中的列。也就是说,前面所述的索引无法用于查找姓为Smith并且在某个特定日期出生的人。如果不指定名（first_name）,则MySQL只能使用索引的第一列。 如果查询中有某个列的范围查询,则其右边所有列都无法使用索引优化查找。例如有查询WHERE last_name=’Smith’ AND frst_name LIKE ‘J％’ AND dob=’1976-12-23’,这个查询只能使用索引的前两列,因为这里LIKE是一个范围条件（但是服务器可以把其余列用于其他目的）。如果范围查询列值的数量有限,那么可以通过使用多个等于条件来代替范围条件。在本章的索引案例学习部分,我们将演示一个详细的案例。 2.哈希索引哈希索引（hash index）基于哈希表实现,只有精确匹配索引所有列的查询才有效(4)。对于每一行数据,存储引擎都会对所有的索引列计算一个哈希码（hash code）,哈希码是一个较小的值,并且不同键值的行计算出来的哈希码也不一样。哈希索引将所有的哈希码存储在索引中,同时在哈希表中保存指向每个数据行的指针。 使用范围只有精确匹配索引所有列的查询才有效 哈希索引的限制 哈希索引只包含哈希值和行指针,而不存储字段值,所以不能使用索引中的值来避免读取行。不过,访问内存中的行的速度很快,所以大部分情况下这一点对性能的影响并不明显。 哈希索引数据并不是按照索引值顺序存储的,所以也就无法用于排序。 哈希索引也不支持部分索引列匹配查找,因为哈希索引始终是使用索引列的全部内容来计算哈希值的。例如,在数据列（A,B）上建立哈希索引,如果查询只有数据列A,则无法使用该索引。 哈希索引只支持等值比较查询,包括=、IN()、&lt;=&gt;（注意&lt;&gt;和&lt;=&gt;是不同的操作）。也不支持任何范围查询,例如WHERE price&gt;100。 访问哈希索引的数据非常快,除非有很多哈希冲突（不同的索引列值却有相同的哈希值）。当出现哈希冲突的时候,存储引擎必须遍历链表中所有的行指针,逐行进行比较,直到找到所有符合条件的行。 如果哈希冲突很多的话,一些索引维护操作的代价也会很高。例如,如果在某个选择性很低（哈希冲突很多）的列上建立哈希索引,那么当从表中删除一行时,存储引擎需要遍历对应哈希值的链表中的每一行,找到并删除对应行的引用,冲突越多,代价越大。 3.空间数据索引（R-Tree）MyISAM表支持空间索引,可以用作地理数据存储。和B-Tree索引不同,这类索引无须前缀查询。空间索引会从所有维度来索引数据。查询时,可以有效地使用任意维度来组合查询。必须使用MySQL的GIS相关函数如MBRCONTAINS()等来维护数据。MySQL的GIS支持并不完善,所以大部分人都不会使用这个特性。开源关系数据库系统中对GIS的解决方案做得比较好的是PostgreSQL的PostGIS。 4.全文索引全文索引是一种特殊类型的索引,它查找的是文本中的关键词,而不是直接比较索引中的值。全文搜索和其他几类索引的匹配方式完全不一样。它有许多需要注意的细节,如停用词、词干和复数、布尔搜索等。全文索引更类似于搜索引擎做的事情,而不是简单的WHERE条件匹配。 5.其他索引类别还有很多第三方的存储引擎使用不同类型的数据结构来存储索引。例如TokuDB使用分形树索引（fractal tree index）,这是一类较新开发的数据结构,既有B-Tree的很多优点,也避免了B-Tree的一些缺点。如果通读完本章,可以看到很多关于InnoDB的主题,包括聚簇索引、覆盖索引等。多数情况下,针对InnoDB的讨论也都适用于TokuDB。ScaleDB使用Patricia tries（这个词不是拼写错误）,其他一些存储引擎技术如InfiniDB和Infobright则使用了一些特殊的数据结构来优化某些特殊的查询。 索引的优点 索引大大减少了服务器需要扫描的数据量。 索引可以帮助服务器避免排序和临时表。 索引可以将随机I/O变为顺序I/O。 二、高性能的索引策略例如,下面这个查询无法使用actor_id列的索引： mysql&gt; SELECT actor_id FROM sakila.actor WHERE actor_id + 1 = 5; 1.前缀索引和索引选择性有时候需要索引很长的字符列,这会让索引变得大且慢。一个策略是前面提到过的模拟哈希索引。但有时候这样做还不够,还可以做些什么呢？通常可以索引开始的部分字符,这样可以大大节约索引空间,从而提高索引效率。但这样也会降低索引的选择性。索引的选择性是指,不重复的索引值（也称为基数,cardinality）和数据表的记录总数（#T）的比值,范围从1/#T到1之间。索引的选择性越高则查询效率越高,因为选择性高的索引可以让MySQL在查找时过滤掉更多的行。唯一索引的选择性是1,这是最好的索引选择性,性能也是最好的。 前缀索引 优点 一种能使索引更小、更快的有效办法 缺点 MySQL无法使用前缀索引做ORDER BY和GROUP BY,也无法使用前缀索引做覆盖扫描 独立的列如果查询中的列不是独立的,则MySQL就不会使用索引。“独立的列”是指索引列不能是表达式的一部分,也不能是函数的参数。例如,下面这个查询无法使用actor_id列的索引： mysql&gt; SELECT actor_id FROM sakila.actor WHERE actor_id + 1 = 5; 凭肉眼很容易看出WHERE中的表达式其实等价于actor_id=4,但是MySQL无法自动解析这个方程式。 多列索引索引合并 查询能够同时使用这两个单列索引进行扫描,并将结果进行合并。 是什么 当WHERE子句中包含多个复杂条件的时候,MySQL能够访问单个表的多个索引以合并和交叉过滤的方式来定位需要查找的行 使用方法 UNION ALL OR条件的联合（union） AND条件的相交（intersection） 组合前两种情况的联合及相交 类型 type:index_merge 说明结果 当出现服务器对多个索引做相交操作时（通常有多个AND条件）,通常意味着需要一个包含所有相关列的多列索引,而不是多个独立的单列索引。 当服务器需要对多个索引做联合操作时（通常有多个OR条件）,通常需要耗费大量CPU和内存资源在算法的缓存、排序和合并操作上。特别是当其中有些索引的选择性不高,需要合并扫描返回的大量数据的时候。 更重要的是,优化器不会把这些计算到“查询成本”（cost）中,优化器只关心随机页面读取。这会使得查询的成本被“低估”,导致该执行计划还不如直接走全表扫描。这样做不但会消耗更多的CPU和内存资源,还可能会影响查询的并发性,但如果是单独运行这样的查询则往往会忽略对并发性的影响。通常来说,还不如像在MySQL 4.1或者更早的时代一样,将查询改写成UNION的方式往往更好。 2.选择合适的索引列顺序当不需要考虑排序和分组办法 将选择性最高的列放在前面通常是很好的。这时候索引的作用只是用于优化WHERE条件的查找。在这种情况下,这样设计的索引确实能够最快地过滤出需要的行,对于在WHERE子句中只使用了索引部分前缀列的查询来说选择性也更高。 计算选择性 看看各个WHERE条件的分支对应的数据基数有多大 1SELECT SUM(staff_id = 2), SUM(customer_id = 584) FROM payment\\G 1SELECT COUNT(DISTINCT staff_id)/COUNT(*) AS staff_id_selectivity, &gt; COUNT(DISTINCT customer_id)/COUNT(*) AS customer_id_selectivity, &gt; COUNT(*) &gt; FROM payment\\G 需要考虑排序和分组聚簇索引 一种数据存储方式,聚簇索引的每一个叶子节点都包含了主键值、事务ID、用于事务和MVCC的回滚指针以及所有的剩余列（在这个例子中是col2） 实现方式 InnoDB的聚簇索引实际上在同一个结构中保存了B-Tree索引和数据行。当表有聚簇索引时,它的数据行实际上存放在索引的叶子页（leaf page）中。 限制 因为无法同时把数据行存放在两个不同的地方,所以一个表只能有一个聚簇索引 使用方式 InnoDB将通过主键聚集数据,“被索引的列”就是主键列。如果没有定义主键,InnoDB会选择一个唯一的非空索引代替。如果没有这样的索引,InnoDB会隐式定义一个主键来作为聚簇索引。 聚簇索引的优点和缺点 优点 可以把相关数据保存在一起。例如实现电子邮箱时,可以根据用户ID来聚集数据,这样只需要从磁盘读取少数的数据页就能获取某个用户的全部邮件。如果没有使用聚簇索引,则每封邮件都可能导致一次磁盘I/O。 数据访问更快。聚簇索引将索引和数据保存在同一个B-Tree中,因此从聚簇索引中获取数据通常比在非聚簇索引中查找要快。 使用覆盖索引扫描的查询可以直接使用页节点中的主键值。 缺点 聚簇数据最大限度地提高了I/O密集型应用的性能,但如果数据全部都放在内存中,则访问的顺序就没那么重要了,聚簇索引也就没什么优势了。 插入速度严重依赖于插入顺序。按照主键的顺序插入是加载数据到InnoDB表中速度最快的方式。但如果不是按照主键顺序加载数据,那么在加载完成后最好使用OPTIMIZE TABLE命令重新组织一下表。 更新聚簇索引列的代价很高,因为会强制InnoDB将每个被更新的行移动到新的位置。 基于聚簇索引的表在插入新行,或者主键被更新导致需要移动行的时候,可能面临“页分裂（page split）”的问题。当行的主键值要求必须将这一行插入到某个已满的页中时,存储引擎会将该页分裂成两个页面来容纳该行,这就是一次页分裂操作。页分裂会导致表占用更多的磁盘空间。 聚簇索引可能导致全表扫描变慢,尤其是行比较稀疏,或者由于页分裂导致数据存储不连续的时候。 二级索引（非聚簇索引）可能比想象的要更大,因为在二级索引的叶子节点包含了引用行的主键列。 二级索引访问需要两次索引查找,而不是一次。 答案在于二级索引中保存的“行指针”的实质。要记住,二级索引叶子节点保存的不是指向行的物理位置的指针,而是行的主键值。 3.InnoDB和MyISAM的数据分布对比MyISAM数据分布顺序 MyISAM按照数据插入的顺序存储在磁盘上 索引 索引中的每个叶子节点包含“行号”。 key : 键值 value: 行号 MyISAM中主键索引和其他索引在结构上没有什么不同。主键索引就是一个名为PRIMARY的唯一非空索引。 InnoDB数据分布顺序 聚簇索引“就是”表 索引 InnoDB二级索引的叶子节点中存储的不是“行指针”,而是主键值 好处 减少了当出现行移动或者数据页分裂时二级索引的维护工作,InnoDB在移动行时无须更新二级索引中的这个“指针”。 坏处 使用主键值当作指针会让二级索引占用更多的空间 在InnoDB表中按主键顺序插入行的策略 使用AUTO_INCREMENT自增列 最好避免随机的（不连续且值的分布范围非常大）聚簇索引,特别是对于I/O密集型的应用 使用UUID来作为聚簇索引则会很糟糕：它使得聚簇索引的插入变得完全随机,这是最坏的情况,使得数据没有任何聚集特性 结果 索引占用的空间也更大 花费的时间更长 原因 因为写入是乱序的,InnoDB不得不频繁地做页分裂操作,以便为新的行分配空间。页分裂会导致移动大量数据,一次插入最少需要修改三个页而不是一个页。 由于频繁的页分裂,页会变得稀疏并被不规则地填充,所以最终数据会有碎片。 写入的目标页可能已经刷到磁盘上并从缓存中移除,或者是还没有被加载到缓存中,InnoDB在插入之前不得不先找到并从磁盘读取目标页到内存中。这将导致大量的随机I/O。 页的最大填充因子（InnoDB默认的最大填充因子是页大小的15/16,留出部分空间用于以后修改） 顺序的主键什么时候会造成更坏的结果 高并发工作负载,在InnoDB中按主键顺序插入可能会造成明显的争用 原因 并发插入可能导致间隙锁竞争 AUTO_INCREMENT锁机制 解决办法 更改innodb_autoinc_lock_mode配置 二级索引（辅助索引） 二级索引存储的是记录的主键,而不是数据存储的地址。 覆盖索引 如果一个索引包含（或者说覆盖）所有需要查询的字段的值,我们就称之为“覆盖索引”。 索引类型 Using index 成为覆盖索引的条件 WHERE条件中的列是有索引可以覆盖的,因此MySQL可以使用该索引找到对应的actor并检查title是否匹配,过滤之后再读取需要的数据行 覆盖索引必须要存储索引列的值,而哈希索引、空间索引和全文索引等都不存储索引列的值,所以MySQL只能使用B-Tree索引做覆盖索 不同的存储引擎实现覆盖索引的方式也不同,而且不是所有的引擎都支持覆盖索引（在写作本书时,Memory存储引擎就不支持覆盖索引） 如何使用覆盖索引 MySQL不能在索引中执行LIKE操作。这是底层存储引擎API的限制,MySQL 5.5和更早的版本中只允许在索引中做简单比较操作（例如等于、不等于以及大于）。MySQL能在索引中做最左前缀匹配的LIKE比较,因为该操作可以转换为简单的比较操作,但是如果是通配符开头的LIKE查询,存储引擎就无法做比较匹配。这种情况下,MySQL服务器只能提取数据行的值而不是索引值来做比较。 覆盖索引的好处 索引条目通常远小于数据行大小,所以如果只需要读取索引,那MySQL就会极大地减少数据访问量。这对缓存的负载非常重要,因为这种情况下响应时间大部分花费在数据拷贝上。覆盖索引对于I/O密集型的应用也有帮助,因为索引比数据更小,更容易全部放入内存中（这对于MyISAM尤其正确,因为MyISAM能压缩索引以变得更小）。 因为索引是按照列值顺序存储的（至少在单个页内是如此）,所以对于I/O密集型的范围查询会比随机从磁盘读取每一行数据的I/O要少得多。对于某些存储引擎,例如MyISAM和Percona XtraDB,甚至可以通过OPTIMIZE命令使得索引完全顺序排列,这让简单的范围查询能使用完全顺序的索引访问。 一些存储引擎如MyISAM在内存中只缓存索引,数据则依赖于操作系统来缓存,因此要访问数据需要一次系统调用。这可能会导致严重的性能问题,尤其是那些系统调用占了数据访问中的最大开销的场景。 由于InnoDB的聚簇索引,覆盖索引对InnoDB表特别有用。InnoDB的二级索引在叶子节点中保存了行的主键值,所以如果二级主键能够覆盖查询,则可以避免对主键索引的二次查询。 使用技巧 延迟关联延迟了对列的访问。在查询的第一阶段MySQL可以使用覆盖索引 4.索引条件推送ICP（index condition pushdown）是mysql利用索引（二级索引）元组和筛字段在索引中的where条件从表中提取数据记录的一种优化操作 实现原理存储引擎在访问索引的时候检查筛选字段在索引中的where条件（pushed index condition,推送的索引条件）,如果索引元组中的数据不满足推送的索引条件,那么就过滤掉该条数据记录。ICP（优化器）尽可能的把index condition的处理从server层下推到storage engine层。storage engine使用索引过滤不相关的数据,仅返回符合index condition条件的数据给server层。也是说数据过滤尽可能在storage engine层进行,而不是返回所有数据给server层,然后后再根据where条件进行过滤。 使用方法set optimizer_switch = &quot;index_condition_pushdown=on&quot; 5.使用索引扫描来做排序判断是否使用了索引来做排序如果EXPLAIN出来的type列的值为“index” 使用条件单表 只有当索引的列顺序和ORDER BY子句的顺序完全一致,并且所有列的排序方向（倒序或正序）都一样时 关联多张表 只有当ORDER BY子句引用的字段全部为第一个表时,才能使用索引做排序 6.压缩（前缀压缩）索引MyISAM使用前缀压缩来减少索引的大小,从而让更多的索引可以放入内存中,这在某些情况下能极大地提高性能 实现原理MyISAM压缩每个索引块的方法是,先完全保存索引块中的第一个值,然后将其他值和第一个值进行比较得到相同前缀的字节数和剩余的不同后缀部分,把这部分存储起来即可 例子例如,索引块中的第一个值是“perform”,第二个值是“performance”,那么第二个值的前缀压缩后存储的是类似“7,ance”这样的形式。MyISAM对行指针也采用类似的前缀压缩方式。 优点和缺点 优点 压缩块使用更少的空间 这在某些情况下能极大地提高性能 缺点 代价是某些操作可能更慢 适用范围 对于CPU密集型应用,因为扫描需要随机查找,压缩索引使得MyISAM在索引查找上要慢好几倍。压缩索引的倒序扫描就更慢了。压缩索引需要在CPU内存资源与磁盘之间做权衡。压缩索引可能只需要十分之一大小的磁盘空间,如果是I/O密集型应用,对某些查询带来的好处会比成本多很多 使用方法 在CREATE TABLE语句中指定PACK_KEYS参数来控制索引压缩的方式 7.冗余和重复索引重复索引重复索引是指在相同的列上按照相同的顺序创建的相同类型的索引。 使用范围 应该避免这样创建重复索引,发现以后也应该立即移除 冗余索引如果创建了索引（A,B）,再创建索引（A）就是冗余索引,因为这只是前一个索引的前缀索引。 适用范围 大多数情况下都不需要冗余索引,应该尽量扩展已有的索引而不是创建新索引。但也有时候出于性能方面的考虑需要冗余索引,因为扩展已有的索引会导致其变得太大,从而影响其他使用该索引的查询的性能。 缺点 表中的索引越多插入速度会越慢 解决办法 首先要做的是找出这样的索引。可以通过写一些复杂的访问INFORMATION_SCHEMA表的查询来找,不过还有两个更简单的方法。可使用Shlomi Noach的common_schema中的一些视图来定位 8.未使用的索引适用范围 这样的索引完全是累赘,建议考虑删除(18) 解决办法 有两个工具可以帮助定位未使用的索引。最简单有效的办法是在Percona Server或者MariaDB中先打开userstates服务器变量（默认是关闭的）,然后让服务器正常运行一段时间,再通过查询INFORMATION_SCHEMA.INDEX_STATISTICS就能查到每个索引的使用频率。 9.索引和锁索引可以让查询锁定更少的行 实现原理InnoDB只有在访问行的时候才会对其加锁,而索引能够减少InnoDB访问的行数,从而减少锁的数量。但这只有当InnoDB在存储引擎层能够过滤掉所有不需要的行时才有效。 释放锁时机 在早期的MySQL版本中 InnoDB只有在事务提交后才能释放锁 在MySQL 5.1和更新的版本及以后 InnoDB可以在服务器端过滤掉行后就释放锁 注意:InnoDB在二级索引上使用共享（读）锁,但访问主键索引需要排他（写）锁。这消除了使用覆盖索引的可能性,并且使得SELECT FOR UPDATE比LOCK IN SHARE MODE 或非锁定查询要慢很多 三、索引案例学习1.支持多种过滤条件事例country列的选择性通常不高,但可能很多查询都会用到。sex列的选择性肯定很低,但也会在很多查询中用到。所以考虑到使用的频率,还是建议在创建不同组合索引的时候将（sex,country）列作为前缀。 疑问但根据传统的经验不是说不应该在选择性低的列上创建索引的吗？那为什么这里要将两个选择性都很低的字段作为索引的前缀列?我们的脑子坏了? 理由如前所述几乎所有的查询都会用到sex列。前面曾提到,几乎每一个查询都会用到sex列,甚至会把网站设计成每次都只能按某一种性别搜索用户,索引中加上这一列也没有坏处,即使查询没有使用sex列也可以通过下面的“诀窍”绕过。 诀窍如果某个查询不限制性别,那么可以通过在查询条件中新增AND SEX IN（’m’,’f’） 但这种技巧也不能滥用,否则可能会带来麻烦。因为每额外增加一个IN()条件,优化器需要做的组合都将以指数形式增加,最终可能会极大地降低查询性能。考虑下面的WHERE子句： WHERE eye_color IN(‘brown’,’blue’,’hazel’) AND hair_color IN(‘black’,’red’,’blonde’,’brown’) AND sex IN(‘M’,’F’) 优化器则会转化成4×3×2=24种组合,执行计划需要检查WHERE子句中所有的24种组合。对于MySQL来说,24种组合并不是很夸张,但如果组合数达到上千个则需要特别小心。老版本的MySQL在IN()组合条件过多的时候会有很多问题。查询优化可能需要花很多时间,并消耗大量的内存。 2.避免多个范围条件 范围条件查询(x &gt; ? ) 多个等值条件查询 (in(xxx)) 类型 type:range 效率 范围条件查询无法再使用范围列后面的其他索引列了 “多个等值条件查询”则没有这个限制 3.优化排序案例使用了ORDER BY和LIMIT,如果没有索引的话会很慢。 原因如果用户界面上需要翻页,并且翻页翻到比较靠后时查询也可能非常慢 方法 对于那些选择性非常低的列,可以增加一些特殊的索引来做排序 反范式化、预先计算和缓存可能是解决这类查询的仅有策略 一个更好的办法是限制用户能够翻页的数量 使用延迟关联,通过使用覆盖索引查询返回需要的主键,再根据这些主键关联原表获得需要的行 四、维护索引和表1.找到并修复损坏的表检查是否发生了表损坏CHECK TABLE 修复损坏的表REPAIR TABLE 如果InnoDB引擎的表出现了损坏 原因 如果发生损坏,一般要么是数据库的硬件问题例如内存或者磁盘问题（有可能）,要么是由于数据库管理员的错误例如在MySQL外部操作了数据文件（有可能）,抑或是InnoDB本身的缺陷（不太可能）。 常见的类似错误通常是由于尝试使用rsync备份InnoDB导致的。 解决步骤 可以通过设置innodb_force_recovery参数进入InnoDB的强制恢复模式来修复数据 2.更新索引统计信息新版本的InnoDB可以通过参数innodb_stats_sample_pages来设置样本页的数量。设置更大的值,理论上来说可以帮助生成更准确的索引信息 减少索引和数据的碎片 碎片产生的原因 B-Tree索引可能会碎片化,这会降低查询的效率。碎片化的索引可能会以很差或者无序的方式存储在磁盘上。 有三种类型的数据碎片 行碎片（Row fragmentation） 这种碎片指的是数据行被存储为多个地方的多个片段中。即使查询只从索引中访问一行记录,行碎片也会导致性能下降。 行间碎片（Intra-row fragmentation） 行间碎片是指逻辑上顺序的页,或者行在磁盘上不是顺序存储的。行间碎片对诸如全表扫描和聚簇索引扫描之类的操作有很大的影响,因为这些操作原本能够从磁盘上顺序存储的数据中获益。 剩余空间碎片（Free space fragmentation） 剩余空间碎片是指数据页中有大量的空余空间。这会导致服务器读取大量不需要的数据,从而造成浪费。 产生范围 对于MyISAM表,这三类碎片化都可能发生。但InnoDB不会出现短小的行碎片；InnoDB会移动短小的行并重写到一个片段中。 解决办法 通过执行OPTIMIZE TABLE或者导出再导入的方式来重新整理数据。对于那些不支持OPTIMIZE TABLE的存储引擎,可以通过一个不做任何操作（no-op）的ALTER TABLE操作来重建表。只需要将表的存储引擎修改为当前的引擎即可： ALTER TABLE &lt;table&gt; ENGINE=&lt;engine&gt;; 五、总结1.在选择索引和编写利用这些索引的查询时,有如下三个原则 单行访问是很慢的。特别是在机械硬盘存储中（SSD的随机I/O要快很多,不过这一点仍然成立）。如果服务器从存储中读取一个数据块只是为了获取其中一行,那么就浪费了很多工作。最好读取的块中能包含尽可能多所需要的行。使用索引可以创建位置引用以提升效率。 按顺序访问范围数据是很快的,顺序I/O不需要多次磁盘寻道,所以比随机I/O要快很多（特别是对机械硬盘）。 第二,如果服务器能够按需要顺序读取数据,那么就不再需要额外的排序操作,并且GROUP BY查询也无须再做排序和将行按组进行聚合计算了。 索引覆盖查询是很快的。如果一个索引包含了查询需要的所有列,那么存储引擎就不需要再回表查找行。这避免了大量的单行访问,而上面的第1点已经写明单行访问是很慢的。 2.如何判断一个系统创建的索引是合理的呢？一般来说,我们建议按响应时间来对查询进行分析。找出那些消耗最长时间的查询或者那些给服务器带来最大压力的查询。","link":"/2020/05/02/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/%E9%AB%98%E6%80%A7%E8%83%BDmysql(3)/"},{"title":"人性的弱点","text":"学习了很多技术,无论工作还是生活需要的并不仅仅只是技术,99%的工作都需要和人打交道,与人相处是非常重要的事情,我们也并不例外,今天想整理一下关于人性的弱点的笔记,很多人认为是鸡汤,本质上他们大多对这类书不屑一顾。 我现在经历了不少也不经想感叹一句： 气傲皆因经历少,心平只为折磨多。 一、笔记内容1.与人相处的技巧 不要批评,责怪或抱怨他人,而是去了解别人 真心诚意的赞美别人 设身处地为他人着想 2.平安快乐的要诀 无须模仿他人,发现自我 养成良好的工作习惯 让我们晕头转向的不是繁重的工作,而是我们没有搞清楚自己有多少工作,应该先做什么工作 将你桌上所有的纸张收拾好,只留下你正要处理的问题 根据事情的重要程度来安排做事的先后顺序 当你遇到必须当场做决定的问题时,就当场解决,不要犹豫不决 学会如何组织,分级负责和监督 没人愿意踢一只死狗,他人之所以对你作出令人不愉快的反应,可能是因为你所说的话以及你说这些话的方式或态度不当 永远不要对敌人心存报复,这样对你自己的伤害将大过对别人的 享受付出的快乐,不要期望他人感恩 牢记你所得的恩惠 在人生中反败为胜,遇到挫折,从为什么是我遇到这些挫折？ 转变为 我可以从这些挫折中学到什么 每天都要给别人快乐,只有帮助别人,并付出我们的爱,才能克服忧虑,悲伤以及自怜 懂得欣赏别人对自己的评价,凡事尽力,不必太在意指责 记下自己干的蠢事,自我批评 3.如何使别人喜欢你 真诚地关心别人 别忘记带上你的微笑 记住他人的姓名,这将有助于加深对方对你的印象 学会倾听他人说话 谈论他人感兴趣的话题 让他人感到自身的重要性 4.如何赢得他人的赞同 避免与人争论 千万不要指责他人的错误,对他人的意见表示尊重,别说“你错了” 你错了,就迅速而真诚地承认 待人为善 使对方一开始就说是 让对方多表现自己 把你的意见变成对方的 换位思考,从对方的立场看问题 真诚的同情他人 激发他人高尚的动机 巧妙地表达你的意愿 给他人提出挑战 5.如何更好的说服他人 从赞美和欣赏他人开始 间接而委婉的提醒对方的错点 指责别人前,先想想自己的错误 不要命令别人 给对方留面子 激励赞赏创造最伟大的力量 让他人有个好名声 鼓励使他人更易改正错误 善于向他人授权：给别人一个头衔,使他有一种权威的感觉,那他便会乐意去做你所建议的事情 6.让你的家庭生活幸福快乐 切勿喋喋不休 不要试图改变你到伴侣 在家庭中杜绝批评 发自内心的欣赏别人 对家人殷勤有礼 掌握基本的婚姻婚姻: 婚姻失败的四种原因: 性生活不和谐 彼此意见不同 经济困难 心理,身体或情绪的反常现象 不要忽略家中小事 7.如何使你变得成熟 为自己的行为负责 不要在乎困难,或许它也是一种机遇 摆脱不幸福: 原因 生活中的种种苦难,都是人生必经的阶段,只有是实实在在的面对才是成熟的表现。 方法 提升自我帮助别人 坚定的信念付诸行动 做独一无二的自己 先了解自己,再了解别人 不喜欢自己的人,表现出来的症状之一就是过度挑剔 学会喜欢自己,要想获得健康,成熟,喜欢自己是必备的条件之一 不要盲从因袭,听从你内心的声音 不要做让人生厌的人 不停谈论小孩或宠物 谈话没有重点 完全不理会他人的话题 不要一直争论不休 永远唱反调的人 要让别人喜欢你,先得使自己让人喜欢 8.走出孤独忧虑的人生 摆脱孤独的方法：首先伸出友谊只手,将自己的快乐尽量与别人分享 幸福不来自于他人的布施,而是你自己去赢得别人对你的需求和喜爱 不要让忧虑扼杀幸福的生活 活在今天 对于忧虑的问题,考虑最坏情况,接受这种可能,冷静处理善后 克服忧虑的四个步骤： 清楚的写下我们所担心的是什么 写下我们可以怎么办以及发生的结果 决定怎么办 马上按照决定去做 在繁忙中遗忘忧虑：工作 不要为小事烦恼。摒弃愚蠢的担忧 接受并适应不可避免的事实 9.不要为工作和金钱烦恼 将工作的忧虑减半的四个步骤: 问题是什么？ 问题的起因是什么？ 解决问题的方法有那些? 你建议用哪一种办法 选择自己的喜欢的工作 正确处理金钱的烦恼：记录开销并做预算：存应急的钱 解决夫妻的职业冲突：互相支持 把事实记在纸上 拟出一个合适你的预算 学习如何聪明地花钱 不要为你的收入增加而头痛 如果需要借贷,选择银行贷款 投保意外保险 人寿保险的收益不要一次现金付给受益人 教导子女对金钱养成负责任的态度 不要赌博-永远不要 合理规划你的收入,杜绝浪费,量入为出 10.防止疲劳,永葆活力 经常休息,在你感到倦怠之前 和你信任的人说出自己的心事 消除烦闷心理 摆脱失眠的困扰：让自己身体达到疲劳的程度","link":"/2020/05/05/%E8%BD%AF%E6%8A%80%E8%83%BD/%E4%BA%BA%E9%99%85%E5%85%B3%E7%B3%BB/%E4%BA%BA%E6%80%A7%E7%9A%84%E5%BC%B1%E7%82%B9/"},{"title":"(译) 编写可维护 Go 语言代码建议","text":"正文1. 指导原则如果我要谈论任何编程语言的最佳实践,我需要一些方法来定义“什么是最佳”。如果你昨天来到我的主题演讲,你会看到 Go 团队负责人 Russ Cox 的这句话： Software engineering is what happens to programming when you add time and other programmers. (软件工程就是你和其他程序员花费时间在编程上所发生的事情。) — Russ Cox Russ 作出了软件编程与软件工程的区分。 前者是你自己写的一个程序。 后者是很多人会随着时间的推移而开发的产品。 工程师们来来去去,团队会随着时间增长与缩小,需求会发生变化,功能会被添加,错误也会得到修复。 这是软件工程的本质。 我可能是这个房间里 Go 最早的用户之一,~但要争辩说我的资历给我的看法更多是假的~。相反,今天我要提的建议是基于我认为的 Go 语言本身的指导原则： 简单性 可读性 生产力 注意:你会注意到我没有说性能或并发。 有些语言比 Go 语言快一点,但它们肯定不像 Go 语言那么简单。 有些语言使并发成为他们的最高目标,但它们并不具有可读性及生产力。性能和并发是重要的属性,但不如简单性,可读性和生产力那么重要。 1.1. 简单性我们为什么要追求简单？ 为什么 Go 语言程序的简单性很重要？ 我们都曾遇到过这样的情况: “我不懂这段代码”,不是吗？ 我们都做过这样的项目:你害怕做出改变,因为你担心它会破坏程序的另一部分; 你不理解的部分,不知道如何修复。 这就是复杂性。 复杂性把可靠的软件中变成不可靠。 复杂性是杀死软件项目的罪魁祸首。 简单性是 Go 语言的最高目标。 无论我们编写什么程序,我们都应该同意这一点:它们很简单。 1.2. 可读性 Readability is essential for maintainability. (可读性对于可维护性是至关重要的。) — Mark Reinhold (2018 JVM 语言高层会议) 为什么 Go 语言的代码可读性是很重要的？我们为什么要争取可读性？ Programs must be written for people to read, and only incidentally for machines to execute. (程序应该被写来让人们阅读,只是顺便为了机器执行。) — Hal Abelson 与 Gerald Sussman (计算机程序的结构与解释) 可读性很重要,因为所有软件不仅仅是 Go 语言程序,都是由人类编写的,供他人阅读。执行软件的计算机则是次要的。 代码的读取次数比写入次数多。一段代码在其生命周期内会被读取数百次,甚至数千次。 The most important skill for a programmer is the ability to effectively communicate ideas. (程序员最重要的技能是有效沟通想法的能力。) — Gastón Jorquera [1] 可读性是能够理解程序正在做什么的关键。如果你无法理解程序正在做什么,那你希望如何维护它？如果软件无法维护,那么它将被重写;最后这可能是你的公司最后一次投资 Go 语言。 ~如果你正在为自己编写一个程序,也许它只需要运行一次,或者你是唯一一个曾经看过它的人,然后做任何对你有用的事。~但是,如果是一个不止一个人会贡献编写的软件,或者在很长一段时间内需求、功能或者环境会改变,那么你的目标必须是你的程序可被维护。 编写可维护代码的第一步是确保代码可读。 1.3. 生产力 Design is the art of arranging code to work today, and be changeable forever. (设计是安排代码到工作的艺术,并且永远可变。)— Sandi Metz 我要强调的最后一个基本原则是生产力。开发人员的工作效率是一个庞大的主题,但归结为此; 你花多少时间做有用的工作,而不是等待你的工具或迷失在一个外国的代码库里。 Go 程序员应该觉得他们可以通过 Go 语言完成很多工作。 有人开玩笑说, Go 语言是在等待 C++ 语言程序编译时设计的。快速编译是 Go 语言的一个关键特性,也是吸引新开发人员的关键工具。虽然编译速度仍然是一个持久的战场,但可以说,在其他语言中需要几分钟的编译,在 Go 语言中只需几秒钟。这有助于 Go 语言开发人员感受到与使用动态语言的同行一样的高效,而且没有那些语言固有的可靠性问题。 对于开发人员生产力问题更为基础的是,Go 程序员意识到编写代码是为了阅读,因此将读代码的行为置于编写代码的行为之上。Go 语言甚至通过工具和自定义强制执行所有代码以特定样式格式化。这就消除了项目中学习特定格式的摩擦,并帮助发现错误,因为它们看起来不正确。 Go 程序员不会花费整天的时间来调试不可思议的编译错误。他们也不会将浪费时间在复杂的构建脚本或在生产中部署代码。最重要的是,他们不用花费时间来试图了解他们的同事所写的内容。 当他们说语言必须扩展时,Go 团队会谈论生产力。 2. 标识符我们要讨论的第一个主题是标识符。 标识符是一个用来表示名称的花哨单词; 变量的名称,函数的名称,方法的名称,类型的名称,包的名称等。 Poor naming is symptomatic of poor design. — Dave Cheney 拙劣的名称是拙劣的设计的表征。 鉴于 Go 的语法限制,我们为程序中的事物选择的名称对我们程序的可读性产生了过大的影响。良好的可读性是评判代码质量的关键,因此选择好名称对于 Go 代码的可读性至关重要。 2.1. 选择标识符是为了清晰,而不是简洁 Obvious code is important. What you can do in one line you should do in three. — Ukiah Smith 代码要明确这很重要,您在一行中能做的事,应该拆到三行里做。 Go 不是专注于将代码精巧优化为一行的那种语言,Go 也不是致力于将代码精炼到最小行数的语言。我们并不追求源码在磁盘上占用的空间更少,也不关心录入代码需要多长时间。 Good naming is like a good joke. If you have to explain it, it’s not funny. (好的命名就像一个好笑话。如果你必须解释它,那就不好笑了。)— Dave Cheney 清晰的关键是在 Go 语言程序中我们选择的标识名称。让我们谈一谈所谓好的名字： 好的名字很简洁。 好的名字不一定是最短的名字,但好的名字不会浪费在无关的东西上。好名字具有高的信噪比。 好的名字是描述性的。 好的名字会描述变量或常量的应用,而不是它们的内容。好的名字应该描述函数的结果或方法的行为,而不是它们的操作。好的名字应该描述包的目的而非它的内容。描述东西越准确的名字就越好。 好的名字应该是可预测的。 你能够从名字中推断出使用方式。~这是选择描述性名称的功能,但它也遵循传统。~这是 Go 程序员在谈到习惯用语时所谈论的内容。 让我们深入讨论以下这些属性。 2.2. 标识符长度有时候人们批评 Go 语言推荐短变量名的风格。正如 Rob Pike 所说,“ Go 程序员想要正确的长度的标识符”。 1 Andrew Gerrand 建议通过对某些事物使用更长的标识,向读者表明它们具有更高的重要性。 The greater the distance between a name’s declaration and its uses, the longer the name should be. (名字的声明与其使用之间的距离越大,名字应该越长。) — Andrew Gerrand [2] 由此我们可以得出一些指导方针： 短变量名称在声明和上次使用之间的距离很短时效果很好。 长变量名需要证明其不同的合理性：越长的变量名,越需要更多的理由来证明其合理。冗长、繁琐的名称与他们在页面上的权重相比,携带的信息很低。 请勿在变量名称中包含类型名称。 常量应该描述它们持有的值,而不是该如何使用。 对于循环和分支使用单字母变量,参数和返回值使用单个字,函数和包级别声明使用多个单词。 单词可用于方法、接口和包。 请记住,包的名称是调用者用来引用名称的一部分,因此要好好利用这一点。 我们来举个栗子:12345678910111213141516171819type Person struct { Name string Age int}// AverageAge returns the average age of people.func AverageAge(people []Person) int { if len(people) == 0 { return 0 } var count, sum int for _, p := range people { sum += p.Age count += 1 } return sum / count}在此示例中,变量p的在第10行被声明并且也只在接下来的一行中被引用。p在执行函数期间存在时间很短。如果要了解p的作用只需阅读两行代码。 相比之下,people在函数第7行参数中被声明。sum和count也是如此,他们用了更长的名字。读者必须查看更多的行数来定位它们,因此他们名字更为独特。 我可以选择s替代sum以及c（或可能是n）替代count,但是这样做会将程序中的所有变量份量降低到同样的级别。我可以选择p来代替people,但是用什么来调用for ... range迭代变量。如果用person的话看起来很奇怪,生存时间极短命名却比导出它的那个值更长。 Austin Luo：这里说的是,若数组people用变量名p,那么从数组中获取的每一个元素取名就成了问题,比如用person,即使使用person看起来也很奇怪,一方面是单数,一方面person的生存周期只有两行（很短）,命名比生存周期更长的p（people）还长了。 小窍门：跟使用空行在文档中分段一样,使用空行将函数执行过程分段。在函数AverageAge中有按顺序的三个操作。第一个是先决条件,检查当people为空时我们不会除零,第二个是累加总和和计数,最后一个是计算平均数。 2.2.1. 上下文是关键重要的是要意识到关于命名的大多数建议都是需要考虑上下文的。 我想说这是一个原则,而不是一个规则。 两个标识符i和index之间有什么区别。 我们不能断定一个就比另一个好,例如 123for index := 0; index &lt; len(s); index++ { //} 上述代码的可读性,基本上都会认为比下面这段要强：123for i := 0; i &lt; len(s); i++ { //}我认为它不是,因为就此事而论,i和index的范围很大可能上仅限于 for 循环的主体,后者的额外冗长性(指index)几乎没有增加对于程序的理解。 但是,哪些功能更具可读性？ 1func (s *SNMP) Fetch(oid []int, index int) (int, error) 或 1func (s *SNMP) Fetch(o []int, i int) (int, error) 在此示例中,oid是SNMP对象ID的缩写,因此将其缩短为o意味着程序员必须要将文档中常用符号转换为代码中较短的符号。 类似地将index替换成i,模糊了i所代表的含义,因为在SNMP消息中,每个OID的子值称为索引。 小窍门：在参数声明中不要混用长、短不同的命名风格。 2.3. 命名中不要包含所属类型的名称正如您给宠物取名一样,您会给狗取名“汪汪”,给猫取名为“咪咪”,但不会取名为“汪汪狗”、“咪咪猫”。出于同样的原因,您也不应在变量名称中包含其类型的名称。 变量命名应该体现它的内容,而不是类型。我们来看下面这个例子： 1var usersMap map[string]*User 这个声明有什么好处？ 我们可以看到它是一个map,它与*User类型有关。 但是usersMap是一个map,而 Go 语言是一种静态类型的语言,如果没有定义变量,它并不会允许我们在需要标量变量的地方意外地使用到这个变量,因此Map后缀是多余的。 接下来, 如果我们像这样来声明其他变量： 1234var ( companiesMap map[string]*Company productsMap map[string]*Products) usersMap,companiesMap和productsMap三个map类型变量,所有映射字符串都是不同的类型。 我们知道它们是map,我们也知道我们不能使用其中一个来代替另一个 - 如果我们在需要map[string]*User的地方尝试使用companiesMap, 编译器将抛出错误异常。 在这种情况下,很明显变量中Map后缀并没有提高代码的清晰度,它只是增加了要输入的额外样板代码。 我的建议是避免使用任何类似变量类型的后缀。 小窍门:如果users的描述性都不够用,那么usersMap也不会。 此建议也适用于函数参数。 例如：12345type Config struct { //}func WriteConfig(w io.Writer, config *Config)命名*Config参数config是多余的。 我们知道它是*Config类型,就是这样。 在这种情况下,如果变量的生命周期足够短,请考虑使用conf或c。 如果有更多的*Config,那么将它们称为original和updated比conf1和conf2会更具描述性,因为前者不太可能被互相误解。 NOTE：不要让包名占用了更适合变量的名称。 导入标识符的名称包括其包名称。 例如,context包中的Context类型将被称为context.Context。 这使得无法将context用作包中的变量或类型。1func WriteLog(context context.Context, message string) 上面的栗子将会编译出错。 这就是为什么context.Context类型的通常的本地声明是ctx,例如： 1func WriteLog(ctx context.Context, message string) 2.4. 使用一致的命名方式一个好名字的另一个属性是它应该是可预测的。 在第一次遇到该名字时读者就能够理解名字的使用。 当他们遇到常见的名字时,他们应该能够认为自从他们上次看到它以来它没有改变意义。 例如,如果您的代码在处理数据库请确保每次出现参数时,它都具有相同的名称。 与其使用d * sql.DB,dbase * sql.DB,DB * sql.DB和database * sql.DB的组合,倒不如统一使用: 1db *sql.DB 这样做使读者更为熟悉; 如果你看到db,你知道它就是*sql.DB并且它已经在本地声明或者由调用者为你提供。 类似地,对于方法接收器: 在该类型的每个方法上使用相同的接收者名称。 在这种类型的方法内部可以使读者更容易使用。 注意:Go 中对接收者的短命名规则惯例与目前提供的建议不一致。这只是早期做出的选择之一,并且已经成为首选的风格,就像使用CamelCase而不是snake_case一样。 小窍门：Go 的命名风格规定接收器具有单个字母名称或其派生类型的首字母缩略词。有时您可能会发现接收器的名称有时会与方法中参数的名称冲突,在这种情况下,请考虑使参数名称稍长,并且仍然不要忘记一致地使用这个新名称。 最后,某些单字母变量传统上与循环和计数相关联。 例如,i,j和k通常是简单for循环的循环归纳变量。n通常与计数器或累加器相关联。v是通用编码函数中值的常用简写,k通常用于map的键,s通常用作字符串类型参数的简写。 与上面的db示例一样,程序员认为i是一个循环归纳变量。 如果确保i始终是循环变量,而且不在for循环之外的其他地方中使用。 当读者遇到一个名为i或j的变量时,他们知道循环就在附近。 小窍门:如果你发现自己有如此多的嵌套循环,i,j和k变量都无法满足时,这个时候可能就是需要将函数分解成更小的函数。 2.5. 使用一致的声明样式Go 至少有六种不同的方式来声明变量 var x int = 1 var x = 1var x int; x = 1 var x = int(1)*x := 1 我确信还有更多我没有想到的。 这可能是 Go 语言的设计师意识到的一个错误,但现在改变它为时已晚。 通过所有这些不同的方式来声明变量,我们如何避免每个 Go 程序员选择自己的风格？ 我想就如何在程序中声明变量提出建议。 这是我尽可能使用的风格。 声明变量但没有初始化时,请使用var。 当声明变量稍后将在函数中初始化时,请使用var关键字。 123456var players int // 0var things []Thing // an empty slice of Thingsvar thing Thing // empty Thing structjson.Unmarshall(reader, &amp;thing) var表示此变量已被声明为指定类型的零值。 这也与使用var而不是短声明语法在包级别声明变量的要求一致 - 尽管我稍后会说你根本不应该使用包级变量。 在声明和初始化时,使用:=。 在同时声明和初始化变量时,也就是说我们不会将变量初始化为零值,我建议使用短变量声明。 这使得读者清楚地知道:=左侧的变量是初始化过的。 为了解释原因,让我们看看前面的例子,但这次是初始化每个变量：123456var players int = 0var things []Thing = nilvar thing *Thing = new(Thing)json.Unmarshall(reader, thing)在第一个和第三个例子中,因为在 Go 语言中没有从一种类型到另一种类型的自动转换; 赋值运算符左侧的类型必须与右侧的类型相同。 编译器可以从右侧的类型推断出声明的变量的类型,上面的例子可以更简洁地写为： 123456var players = 0var things []Thing = nilvar thing = new(Thing)json.Unmarshall(reader, thing) 我们将players初始化为0,但这是多余的,因为0是players的零值。 因此,要明确地表示使用零值, 我们将上面例子改写为:1var players int第二个声明如何？ 我们不能省略类型而写作:1var things = nil因为nil没有类型。 [2]相反,我们有一个选择,如果我们要使用切片的零值则写作:1var things []Thing或者我们要创建一个有零元素的切片则写作:1var things = make([]Thing, 0)如果我们想要后者那么这不是切片的零值,所以我们应该向读者说明我们通过使用简短的声明形式做出这个选择：1things := make([]Thing, 0)这告诉读者我们已选择明确初始化事物。 下面是第三个声明,1var thing = new(Thing)既是初始化了变量又引入了一些 Go 程序员不喜欢的new关键字的罕见用法。 如果我们用推荐地简短声明语法,那么就变成了: 1thing := new(Thing) 这清楚地表明thing被初始化为new(Thing)的结果 - 一个指向Thing的指针 - 但依旧我们使用了new地罕见用法。 我们可以通过使用紧凑的文字结构初始化形式来解决这个问题,1thing := &amp;Thing{}与new(Thing)相同,这就是为什么一些 Go 程序员对重复感到不满。 然而,这意味着我们使用指向Thing{}的指针初始化了thing,也就是Thing的零值。 相反,我们应该认识到thing被声明为零值,并使用地址运算符将thing的地址传递给json.Unmarshall12var thing Thingjson.Unmarshall(reader, &amp;thing) 小窍门:当然,任何经验法则,都有例外。 例如,有时两个变量密切相关,这样写会很奇怪: 12var min intmax := 1000 如果这样声明可能更具可读性 1min, max := 0, 1000 综上所述： 在没有初始化的情况下声明变量时,请使用var语法。 声明并初始化变量时,请使用:=。 小窍门:使复杂的声明显而易见。当事情变得复杂时,它看起来就会很复杂。例如 1var length uint32 = 0x80 这里length可能要与特定数字类型的库一起使用,并且length明确选择为uint32类型而不是短声明形式： 1length := uint32(0x80) 在第一个例子中,我故意违反了规则, 使用var声明带有初始化变量的。 这个决定与我的常用的形式不同,这给读者一个线索,告诉他们一些不寻常的事情将会发生。 2.6. 成为团队合作者我谈到了软件工程的目标,即编写可读及可维护的代码。 因此,您可能会将大部分职业生涯用于你不是唯一作者的项目。 我在这种情况下的建议是遵循项目自身风格。 在文件中间更改样式是不和谐的。 即使不是你喜欢的方式,对于维护而言一致性比你的个人偏好更有价值。 我的经验法则是: 如果它通过了gofmt,那么通常不值得再做代码审查。 小窍门:如果要在代码库中进行重命名,请不要将其混合到另一个更改中。 如果有人使用git bisect,他们不想通过数千行重命名来查找您更改的代码。 3. 注释在我们继续讨论更大的项目之前,我想花几分钟时间谈论一下注释。 Good code has lots of comments, bad code requires lots of comments.(好的代码有很多注释,坏代码需要很多注释。) — Dave Thomas and Andrew Hunt (The Pragmatic Programmer) 代码注释对 Go 程序的可读性极为重要。一个注释应该做到如下三个方面的至少一个： 注释应该解释“做什么”。 注释应该解释“怎么做的”。 注释应该解释“为什么这么做”。 第一种形式是公共符号注释的理想选择：12// Open opens the named file for reading.// If successful, methods on the returned file can be used for reading.第二种形式非常适合在方法中注释：12345// queue all dependant actionsvar results []chan errorfor _, dep := range a.Deps { results = append(results, execute(seen, dep))} 第三种形式是独一无二的,因为它不会取代前两种形式,但与此同时它并不能代替前两种形式。 此形式的注解用以解释代码的外部因素。 这些因素脱离上下文后通常很难理解,此注释的为了提供这种上下文。 123456return &amp;v2.Cluster_CommonLbConfig{ // Disable HealthyPanicThreshold HealthyPanicThreshold: &amp;envoy_type.Percent{ Value: 0, },} 在此示例中,无法清楚地明白HealthyPanicThreshold设置为零百分比的效果。 需要注释0值将禁用panic阀值。 3.1. 关于变量和常量的注释应描述其内容而非其目的我之前谈过,变量或常量的名称应描述其目的。 向变量或常量添加注释时,该注释应描述变量内容,而不是变量目的。 1const randomNumber = 6 // determined from an unbiased die 在此示例中,注释描述了为什么randomNumber被赋值为6,以及6来自哪里。 注释没有描述randomNumber的使用位置。 还有更多的栗子：123456const ( StatusContinue = 100 // RFC 7231, 6.2.1 StatusSwitchingProtocols = 101 // RFC 7231, 6.2.2 StatusProcessing = 102 // RFC 2518, 10.1 StatusOK = 200 // RFC 7231, 6.3.1在HTTP的上下文中,数字100被称为StatusContinue,如 RFC 7231 第 6.2.1 节中所定义。 小窍门:对于没有初始值的变量,注释应描述谁负责初始化此变量。 123// sizeCalculationDisabled indicates whether it is safe// to calculate Types' widths and alignments. See dowidth.var sizeCalculationDisabled bool 这里的注释让读者知道dowidth函数负责维护sizeCalculationDisabled的状态。 隐藏一目了然的东西 这个提示来自Kate Gregory[3]。有时你会发现一个更好的变量名称隐藏在注释中。12// registry of SQL driversvar registry = make(map[string]*sql.Driver) 注释是由作者添加的,因为registry没有充分解释其目的 - 它是一个注册表,但注册的是什么？ 通过将变量重命名为sqlDrivers,现在可以清楚地知道此变量的目的是保存SQL驱动程序。 1var sqlDrivers = make(map[string]*sql.Driver) 现在注释已经多余了,可以移除。 3.2. 总是为公开符号写文档说明godoc是包的文档,所以应该始终为包中声明的每个公共符号 —​ 变量、常量、函数以及方法添加注释。 以下是Google Style指南中的两条规则: 任何既不明显也不简短的公共功能必须予以注释。 无论长度或复杂程度如何,对库中的任何函数都必须进行注释 1234567package ioutil// ReadAll reads from r until an error or EOF and returns the data it read.// A successful call returns err == nil, not err == EOF. Because ReadAll is// defined to read from src until EOF, it does not treat an EOF from Read// as an error to be reported.func ReadAll(r io.Reader) ([]byte, error) 这条规则有一个例外; 您不需要注释实现接口的方法。 具体不要像下面这样做： 12// Read implements the io.Reader interfacefunc (r *FileReader) Read(buf []byte) (int, error) 这个注释什么也没说。 它没有告诉你这个方法做了什么,更糟糕是它告诉你去看其他地方的文档。 在这种情况下,我建议完全删除该注释。 这是io包中的一个例子 12345678910111213141516171819202122232425// LimitReader returns a Reader that reads from r// but stops with EOF after n bytes.// The underlying implementation is a *LimitedReader.func LimitReader(r Reader, n int64) Reader { return &amp;LimitedReader{r, n} }// A LimitedReader reads from R but limits the amount of// data returned to just N bytes. Each call to Read// updates N to reflect the new amount remaining.// Read returns EOF when N &lt;= 0 or when the underlying R returns EOF.type LimitedReader struct { R Reader // underlying reader N int64 // max bytes remaining}func (l *LimitedReader) Read(p []byte) (n int, err error) { if l.N &lt;= 0 { return 0, EOF } if int64(len(p)) &gt; l.N { p = p[0:l.N] } n, err = l.R.Read(p) l.N -= int64(n) return} 请注意,LimitedReader的声明就在使用它的函数之前,而LimitedReader.Read的声明遵循LimitedReader本身的声明。 尽管LimitedReader.Read本身没有文档,但它清楚地表明它是io.Reader的一个实现。 小窍门:在编写函数之前,请编写描述函数的注释。 如果你发现很难写出注释,那么这就表明你将要编写的代码很难理解。 3.2.1. 不要为坏的代码写注释,重写它 Don’t comment bad code — rewrite it — Brian Kernighan 不要为坏的代码写注释——重写它 为粗制滥造的代码片段着重写注释是不够的,如果您遭遇到一段这样的注释,您应该发起一个问题（issue）从而记得后续重构它。技术债务只要不是过多就没有关系。 标准库中的惯例是注意到它的人用TODO(username)的样式来注释。 1// TODO(dfc) this is O(N^2), find a faster way to do this. 注释中的姓名并不意味着承诺去修复问题,但在解决问题时,他可能是最合适的人选。其他批注内容一般还有日期或者问题编号。 3.2.2. 与其为一大段代码写注释,不如重构它 Good code is its own best documentation. As you’re about to add a comment, ask yourself, ‘How can I improve the code so that this comment isn’t needed?’ Improve the code and then document it to make it even clearer.好的代码是最好的文档。 在即将添加注释时,请问下自己,“如何改进代码以便不需要此注释？’ 改进代码使其更清晰。 — Steve McConnell 函数应该只做一件事。如果您发现一段代码因为与函数的其他部分不相关因而需要注释时,考虑将这段代码拆分为独立的函数。 除了更容易理解之外,较小的函数更容易单独测试,现在您将不相关的代码隔离拆分到不同的函数中,估计只有函数名才是唯一需要的文档注释了。 4. 包的设计 Write shy code - modules that don’t reveal anything unnecessary to other modules and that don’t rely on other modules’ implementations.编写谨慎的代码 - 不向其他模块透露任何不必要的模块,并且不依赖于其他模块的实现。 — Dave Thomas 每个 Go 语言的包实际上都是它一个小小的 Go 语言程序。 正如函数或方法的实现对调用者而言并不重要一样,包的公共API-其函数、方法以及类型的实现对于调用者来说也并不重要。 一个好的 Go 语言包应该具有低程度的源码级耦合,这样,随着项目的增长,对一个包的更改不会跨代码库级联。 这些世界末日的重构严格限制了代码库的变化率以及在该代码库中工作的成员的生产率。 在本节中,我们将讨论如何设计包,包括包的名称,命名类型以及编写方法和函数的技巧。 4.1. 一个好的包从它的名字开始编写一个好的 Go 语言包从包的名称开始。将你的包名用一个词来描述它。 正如我在上一节中谈到变量的名称一样,包的名称也非常重要。我遵循的经验法则不是“我应该在这个包中放入什么类型的？”。相反,我要问是“该包提供的服务是什么？”通常这个问题的答案不是“这个包提供X类型”,而是“这个包提供HTTP”。 小窍门:以包所提供的内容来命名,而不是它包含的内容。 4.1.1. 好的包名应该是唯一的。在项目中,每个包名称应该是唯一的。包的名称应该描述其目的的建议很容易理解 - 如果你发现有两个包需要用相同名称,它可能是: 包的名称太通用了。 该包与另一个类似名称的包重叠了。在这种情况下,您应该检查你的设计,或考虑合并包。 4.2. 避免使用类似base,common或util的包名称不好的包名的常见情况是utility包。这些包通常是随着时间的推移一些帮助程序和工具类的包。由于这些包包含各种不相关的功能,因此很难根据包提供的内容来描述它们。这通常会导致包的名称来自包含的内容 - utilities。 像utils或helper这样的包名称通常出现在较大的项目中,这些项目已经开发了深层次包的结构,并且希望在不遇到导入循环的情况下共享helper函数。通过将utility程序函数提取到新的包中,导入循环会被破坏,但由于该包源于项目中的设计问题,因此其包名称不反映其目的,仅反映其为了打破导入循环。 我建议改进utils或helpers包的名称是分析它们的调用位置,如果可能的话,将相关的函数移动到调用者的包中。即使这涉及复制一些helper程序代码,这也比在两个程序包之间引入导入依赖项更好。 [A little] duplication is far cheaper than the wrong abstraction.([一点点]重复比错误的抽象的性价比高很多。) — Sandy Metz 在使用utility程序的情况下,最好选多个包,每个包专注于单个方面,而不是选单一的整体包。 小窍门:使用复数形式命名工具包。比如strings是字符串的处理工具。 当两个或多个实现共有的功能或客户端和服务器的常见类型被重构为单独的包时,通常会找到名称类似于base或common的包。我相信解决方案是减少包的数量,将客户端,服务器和公共代码组合到一个以包的功能命名的包中。 例如,net/http包没有client和server的分包,而是有一个client.go和server.go文件,每个文件都有各自的类型,还有一个transport.go文件,用于公共消息传输代码。 小窍门:标识符的名称包括其包名称。重要的是标识符的名称包括其包的名称。 当由另一个包引用时,net/http包中的 Get 函数变为http.Get。 当导入到其他包中时,strings包中的Reader类型变为strings.Reader。*net包中的Error接口显然与网络错误有关。 4.3. 尽早return而不是深度嵌套由于 Go 语言的控制流不使用exception,因此不需要为try和catch块提供顶级结构而深度缩进代码。Go 语言代码不是成功的路径越来越深地嵌套到右边,而是以一种风格编写,其中随着函数的进行,成功路径继续沿着屏幕向下移动。 我的朋友 Mat Ryer 将这种做法称为“视线”编码。[4] 这是通过使用guard clauses来实现的; 在进入函数时是具有断言前提条件的条件块。 这是一个来自bytes包的例子:12345678910func (b *Buffer) UnreadRune() error { if b.lastRead &lt;= opInvalid { return errors.New(\"bytes.Buffer: UnreadRune: previous operation was not a successful ReadRune\") } if b.off &gt;= int(b.lastRead) { b.off -= int(b.lastRead) } b.lastRead = opInvalid return nil}进入UnreadRune后,将检查b.lastRead的状态,如果之前的操作不是ReadRune,则会立即返回错误。 之后,函数的其余部分继续进行b.lastRead大于opInvalid的断言。 与没有guard clause的相同函数进行比较,12345678910func (b *Buffer) UnreadRune() error { if b.lastRead &gt; opInvalid { if b.off &gt;= int(b.lastRead) { b.off -= int(b.lastRead) } b.lastRead = opInvalid return nil } return errors.New(\"bytes.Buffer: UnreadRune: previous operation was not a successful ReadRune\")}最常见的执行成功的情况是嵌套在第一个if条件内,成功的退出条件是return nil,而且必须通过仔细匹配大括号来发现。 函数的最后一行是返回一个错误,并且被调用者必须追溯到匹配的左括号,以了解何时执行到此点。 对于读者和维护程序员来说,这更容易出错,因此 Go 语言更喜欢使用guard clauses并尽早返回错误。 4.4. 让零值更有用假设变量没有初始化,每个变量声明都会自动初始化为与零内存的内容相匹配的值。 这就是零值。 值的类型决定了其零值; 对于数字类型,它为0,对于指针类型为nil,slices、map和channel同样是nil。 始终设置变量为已知默认值的属性对于程序的安全性和正确性非常重要,并且可以使 Go 语言程序更简单、更紧凑。 这就是 Go 程序员所说的“给你的结构一个有用的零值”。 对于sync.Mutex类型。sync.Mutex包含两个未公开的整数字段,它们用来表示互斥锁的内部状态。 每当声明sync.Mutex时,其字段会被设置为0初始值。sync.Mutex利用此属性来编写,使该类型可直接使用而无需初始化。12345678910111213type MyInt struct { mu sync.Mutex val int}func main() { var i MyInt // i.mu is usable without explicit initialisation. i.mu.Lock() i.val++ i.mu.Unlock()} Austin Luo：原文为“useful”,我在此译为“有意义”而不是“有用”,意在强调其零值是符合业务的、符合逻辑的,并且也是初始的、默认的,而不是“不用管它,让它为零好了”。 这与变量的命名也息息相关,比如： isCacheEnabled bool // 缓存是否被启用 isCacheDisabled bool // 缓存是否被禁用 对于上述两个变量,看起来都差不多,随意定义其中一个即可,唯一的差别只是一个表示启用一个表示禁用而已。但是结合考虑“业务要求默认启用缓存”和“bool 的零值为 false”,那么显然我们应该定义isCacheDisabled bool而不是前者。一方面,调用者不显式赋值时默认零值为false,另一方面值为false时表达的含义与业务要求默认启用缓存一致。 这才使得零值真正地有意义,正如示例中注释的那行i.mu一样,不显示初始化其代表的是默认锁是可用的。 另一个利用零值的类型是bytes.Buffer。您可以声明bytes.Buffer然后就直接写入而无需初始化。12345func main() { var b bytes.Buffer b.WriteString(\"Hello, world!\\n\") io.Copy(os.Stdout, &amp;b)} 切片的一个有用属性是它们的零值nil。如果我们看一下切片运行时header的定义就不难理解: 12345type slice struct { array *[...]T // pointer to the underlying array len int cap int} 此结构的零值意味着len和cap的值为0,而array（指向保存切片的内容数组的指针）将为nil。这意味着你不需要make切片,你只需声明它即可。 123456789func main() { // s := make([]string, 0) // s := []string{} var s []string s = append(s, \"Hello\") s = append(s, \"world\") fmt.Println(strings.Join(s, \" \"))} 注意:var s []string类似于它上面的两条注释行,但并不完全相同。值为nil的切片与具有零长度的切片就可以来相互比较。以下代码将输出false。 12345func main() { var s1 = []string{} var s2 []string fmt.Println(reflect.DeepEqual(s1, s2))} 一个意外但是有用的惊喜是未初始化的指针——nil指针,您可以在nil值的类型上调用方法,这可以简单地用于提供默认值。 123456789101112131415161718type Config struct { path string}func (c *Config) Path() string { if c == nil { return \"/usr/home\" } return c.path}func main() { var c1 *Config var c2 = &amp;Config{ path: \"/export\", } fmt.Println(c1.Path(), c2.Path())} 4.5. 避免包级别状态编写可维护程序的关键是它们应该是松散耦合的 - 对一个程序包的更改应该很少影响另一个不直接依赖于第一个程序包的程序包。 在 Go 语言中有两种很好的方法可以实现松散耦合 使用接口来描述函数或方法所需的行为。 避免使用全局状态。 在 Go 语言中,我们可以在函数或方法范围以及包范围内声明变量。当变量是公共的时,给定一个以大写字母开头的标识符,那么它的范围对于整个程序来说实际上是全局的 - 任何包都可以随时观察该变量的类型和内容。 可变全局状态引入程序的独立部分之间的紧密耦合,因为全局变量成为程序中每个函数的不可见参数！如果该变量的类型发生更改,则可以破坏依赖于全局变量的任何函数。如果程序的另一部分更改了该变量,则可以破坏依赖于全局变量状态的任何函数。 如果要减少全局变量所带来的耦合, 将相关变量作为字段移动到需要它们的结构上。 使用接口来减少行为与实现之间的耦合。 5. 项目结构我们来谈谈如何将包组合到项目中。 通常一个项目是一个git仓库,但在未来 Go 语言开发人员会交替地使用module和project。 就像一个包,每个项目都应该有一个明确的目的。 如果你的项目是一个库,它应该提供一件事,比如XML解析或记录。 您应该避免在一个包实现多个目的,这将有助于避免成为common库。 小窍门:据我的经验,common库最终会与其最大的调用者紧密相连,在没有升级该库与最大调用者的情况下是很难修复的,还会带来了许多无关的更改以及API破坏。 如果你的项目是应用程序,如Web应用程序,Kubernetes控制器等,那么项目中可能有一个或多个main程序包。 例如,我编写的Kubernetes控制器有一个cmd/contour包,既可以作为部署到Kubernetes集群的服务器,也可以作为调试目的的客户端。 5.1. 考虑更少,更大的包对于从其他语言过渡到 Go 语言的程序员来说,我倾向于在代码审查中提到的一件事是他们会过度使用包。 Go 语言没有提供有关可见性的详细方法; Java有public、protected、private以及隐式default的访问修饰符。 没有C++的friend类概念。 在 Go 语言中,我们只有两个访问修饰符,public和private,由标识符的第一个字母的大小写表示。 如果标识符是公共的,则其名称以大写字母开头,该标识符可用于任何其他 Go 语言包的引用。 注意:你可能会听到人们说exported与not exported, 跟public和private是同义词。 鉴于包的符号的访问有限控件,Go 程序员应遵循哪些实践来避免创建过于复杂的包层次结构？ 小窍门:除cmd/和internal/之外的每个包都应包含一些源代码。 我的建议是选择更少,更大的包。 你应该做的是不创建新的程序包。 这将导致太多类型被公开,为你的包创建一个宽而浅的API。 以下部分将更为详细地探讨这一建议。 小窍门:来自Java？如果您来自Java或C#,请考虑这一经验法则 –Java包相当于单个.go源文件。 - Go 语言包相当于整个Maven模块或.NET程序集。 5.1.1. 通过import语句将代码排列到文件中如果你按照包提供的内容来安排你的程序包,是否需要对 Go 包中的文件也执行相同的操作？什么时候应该将.go文件拆分成多个文件？什么时候应该考虑整合.go文件？ 以下是我的经验法则： 开始时使用一个.go文件。为该文件指定与文件夹名称相同的名称。例如:package http应放在名为http的目录中名为http.go的文件中。 随着包的增长,您可能决定将各种职责任务拆分为不同的文件。例如：messages.go包含Request和Response类型,client.go包含Client类型,server.go包含Server类型。 如果你的文件中import的声明类似,请考虑将它们组合起来。或者确定import集之间的差异并移动它们。 不同的文件应该负责包的不同区域。messages.go可能负责网络的HTTP请求和响应,http.go可能包含底层网络处理逻辑,client.go和server.go实现HTTP业务逻辑请求的实现或路由等等。 小窍门:首选名词为源文件命名。 注意:Go编译器并行编译每个包。 在一个包中,编译器并行编译每个函数（方法只是 Go 语言中函数的另一种写法）。 更改包中代码的布局不会影响编译时间。 5.1.2. 优先内部测试再到外部测试go tool支持在两个地方编写testing包测试。假设你的包名为http2,您可以编写http2_test.go文件并使用包http2声明。这样做会编译http2_test.go中的代码,就像它是http2包的一部分一样。这就是内部测试。 go tool还支持一个特殊的包声明,以test为结尾,即package http_test。这允许你的测试文件与代码一起存放在同一个包中,但是当编译时这些测试不是包的代码的一部分,它们存在于自己的包中。就像调用另一个包的代码一样来编写测试。这被称为外部测试。 我建议在编写单元测试时使用内部测试。这样你就可以直接测试每个函数或方法,避免外部测试干扰。 但是,你应该将Example测试函数放在外部测试文件中。这确保了在godoc中查看时,示例具有适当的包名前缀并且可以轻松地进行复制粘贴。 小窍门:避免复杂的包层次结构,抵制应用分类法Go 语言包的层次结构对于go tool没有任何意义除了下一节要说的。 例如,net/http包不是一个子包或者net包的子包。 如果在项目中创建了不包含.go文件的中间目录,则可能无法遵循此建议。 5.1.3. 使用internal包来减少公共API如果项目包含多个包,可能有一些公共的函数,这些函数旨在供项目中的其他包使用,但不打算成为项目的公共API的一部分。 如果你发现是这种情况,那么go tool会识别一个特殊的文件夹名称 - 而非包名称 - internal/可用于放置对项目公开的代码,但对其他项目是私有的。 要创建此类包,请将其放在名为internal/的目录中,或者放在名为internal/的目录的子目录中。 当go命令在其路径中看到导入包含internal的包时,它会验证执行导入的包是否位于internal目录。 例如,.../a/b/c/internal/d/e/f的包只能通过以.../a/b/c/为根目录的代码被导入。 它无法通过.../a/b/g或任何其他仓库中的代码导入。[5] 5.2. 确保main包内容尽可能的少main函数和main包的内容应尽可能少。 这是因为main.main充当单例; 程序中只能有一个main函数,包括tests。 因为main.main是一个单例,假设main函数中需要执行很多事情,main.main只会在main.main或main.init中调用它们并且只调用一次。 这使得为main.main编写代码测试变得很困难,因此你应该将所有业务逻辑从main函数中移出,最好是从main包中移出。 小窍门:Austin Luo：这里主要是讲,由于整个程序（包括单元测试在内）只允许存在一个 main.main,因此在 main.main 中编写过多的代码将导致这些代码很难被测试覆盖,因此应当将这些代码从 main.main 中——甚至从 main 包中——独立出来,以便能够写单元测试进行测试。（文中的“假定”是针对测试而言,“假定” main 中的代码可以正常运行。）main应该做解析flags,开启数据库连接、开启日志等,然后将执行交给更高一级的对象。 6. API 设计我今天要给出的最后一条建议是设计, 我认为也是最重要的。 到目前为止我提出的所有建议都是建议。 这些是我尝试编写 Go 语言的方式,但我不打算在代码审查中拼命推广。 但是,在审查 API 时, 我就不会那么宽容了。 这是因为到目前为止我所谈论的所有内容都是可以修复而且不会破坏向后兼容性; 它们在很大程度上是实现的细节。 当涉及到软件包的公共 API 时,在初始设计中投入大量精力是值得的,因为稍后更改该设计对于已经使用 API 的人来说会是破坏性的。 6.1. 设计难以被误用的 API APIs should be easy to use and hard to misuse.(API 应该易于使用且难以被误用) — Josh Bloch [3] 如果你从这个演讲中带走任何东西,那应该是 Josh Bloch 的建议。 如果一个 API 很难用于简单的事情,那么 API 的每次调用都会很复杂。 当 API 的实际调用很复杂时,它就会便得不那么明显,而且会更容易被忽视。 6.1.1. 警惕采用几个相同类型参数的函数简单, 但难以正确使用的 API 是采用两个或更多相同类型参数的 API。 让我们比较两个函数签名：12func Max(a, b int) intfunc CopyFile(to, from string) error这两个函数有什么区别？ 显然,一个返回两个数字最大的那个,另一个是复制文件,但这不重要。12Max(8, 10) // 10Max(10, 8) // 10 Max是可交换的; 参数的顺序无关紧要。 无论是 8 比 10 还是 10 比 8,最大的都是 10。 但是,却不适用于CopyFile。12CopyFile(\"/tmp/backup\", \"presentation.md\")CopyFile(\"presentation.md\", \"/tmp/backup\") 这些声明中哪一个备份了presentation.md,哪一个用上周的版本覆盖了presentation.md？ 没有文档,你无法分辨。 如果没有查阅文档,代码审查员也无法知道你写对了顺序。 一种可能的解决方案是引入一个helper类型,它会负责如何正确地调用CopyFile。12345678910type Source stringfunc (src Source) CopyTo(dest string) error { return CopyFile(dest, string(src))}func main() { var from Source = \"presentation.md\" from.CopyTo(\"/tmp/backup\")}通过这种方式,CopyFile总是能被正确调用 - 还可以通过单元测试 - 并且可以被设置为私有,进一步降低了误用的可能性。 小窍门:具有多个相同类型参数的API难以正确使用。 6.2. 为其默认用例设计 API几年前,我就对functional options[7] 进行过讨论[6],使 API 更易用于默认用例。 本演讲的主旨是你应该为常见用例设计 API。 另一方面, API 不应要求调用者提供他们不在乎参数。 6.2.1. 不鼓励使用nil作为参数本章开始时我建议是不要强迫提供给 API 的调用者他们不在乎的参数。 这就是我要说的为默认用例设计 API。 这是net/http包中的一个例子12345678910package http// ListenAndServe listens on the TCP network address addr and then calls// Serve with handler to handle requests on incoming connections.// Accepted connections are configured to enable TCP keep-alives.//// The handler is typically nil, in which case the DefaultServeMux is used.//// ListenAndServe always returns a non-nil error.func ListenAndServe(addr string, handler Handler) error {ListenAndServe有两个参数,一个用于监听传入连接的TCP地址,另一个用于处理HTTP请求的http.Handler。Serve允许第二个参数为nil,需要注意的是调用者通常会传递nil,表示他们想要使用http.DefaultServeMux作为隐含参数。 现在,Serve的调用者有两种方式可以做同样的事情。12http.ListenAndServe(\"0.0.0.0:8080\", nil)http.ListenAndServe(\"0.0.0.0:8080\", http.DefaultServeMux)两者完全相同。 这种nil行为是病毒式的。http包也有一个http.Serve帮助类,你可以合理地想象一下ListenAndServe是这样构建的12345678func ListenAndServe(addr string, handler Handler) error { l, err := net.Listen(\"tcp\", addr) if err != nil { return err } defer l.Close() return Serve(l, handler)}因为ListenAndServe允许调用者为第二个参数传递nil,所以http.Serve也支持这种行为。 事实上,http.Serve实现了如果handler是nil,使用DefaultServeMux的逻辑。 参数可为nil可能会导致调用者认为他们可以为两个参数都使用nil。 像下面这样:1http.Serve(nil, nil)会导致panic。 小窍门:不要在同一个函数签名中混合使用可为nil和不能为nil的参数。 http.ListenAndServe的作者试图在常见情况下让使用 API 的用户更轻松些,但很可能会让该程序包更难以被安全地使用。 使用DefaultServeMux或使用nil没有什么区别。123const root = http.Dir(\"/htdocs\")http.Handle(\"/\", http.FileServer(root))http.ListenAndServe(\"0.0.0.0:8080\", nil)对比123const root = http.Dir(\"/htdocs\")http.Handle(\"/\", http.FileServer(root))http.ListenAndServe(\"0.0.0.0:8080\", http.DefaultServeMux)这种混乱值得拯救吗？1234const root = http.Dir(\"/htdocs\")mux := http.NewServeMux()http.Handle(\"/\", http.FileServer(root))http.ListenAndServe(\"0.0.0.0:8080\", mux) 小窍门:认真考虑helper函数会节省不少时间。 清晰要比简洁好。 小窍门:避免公共 API 使用测试参数避免在公开的 API 上使用仅在测试范围上不同的值。 相反,使用Public wrappers隐藏这些参数,使用辅助方式来设置测试范围中的属性。 6.2.2. 首选可变参数（var args）而非切片参数（[]T）编写一个带有切片参数的函数或方法是很常见的。1func ShutdownVMs(ids []string) error这仅仅是我举的一个例子,但在我工作中更加常见。像这样的签名的问题是,他们假设被调用时会有多个实体。但是,我发现很多时候这些类型的函数却只有一个参数,为了满足函数签名的要求,它必须在一个切片内“装箱”。（Austin Luo：如示例,函数定义时预期会有多个 id,但实际调用时往往只有一个 id,为了满足前面,必须构造一个切片,并把 id 装进去。） 另外,因为ids参数是切片,所以你可以将一个空切片或nil传递给该函数,编译也没什么错误。 但是这会增加额外的测试负载,因为你应该涵盖这些情况在测试中。 举一个这类 API 的例子,最近我重构了一条逻辑,要求我设置一些额外的字段,如果一组参数中至少有一个非零。 逻辑看起来像这样：123if svc.MaxConnections &gt; 0 || svc.MaxPendingRequests &gt; 0 || svc.MaxRequests &gt; 0 || svc.MaxRetries &gt; 0 { // apply the non zero parameters}由于if语句变得很长,我想将签出的逻辑拉入其自己的函数中。 这就是我提出的：123456789// anyPostive indicates if any value is greater than zero.func anyPositive(values ...int) bool { for _, v := range values { if v &gt; 0 { return true } } return false}这就能够向读者明确内部块的执行条件：123if anyPositive(svc.MaxConnections, svc.MaxPendingRequests, svc.MaxRequests, svc.MaxRetries) { // apply the non zero parameters}但是anyPositive还存在一个问题,有人可能会这样调用它:1if anyPositive() { ... }在这种情况下,anyPositive将返回false,因为它不会执行迭代而是立即返回false。对比起如果anyPositive在没有传递参数时返回true, 这还不算世界上最糟糕的事情。 然而,如果我们可以更改anyPositive的签名以强制调用者应该传递至少一个参数,那会更好。我们可以通过组合正常和可变参数来做到这一点,如下所示：123456789101112// anyPostive indicates if any value is greater than zero.func anyPositive(first int, rest ...int) bool { if first &gt; 0 { return true } for _, v := range rest { if v &gt; 0 { return true } } return false}现在不能使用少于一个参数来调用anyPositive。 6.3. 让函数定义它们所需的行为假设我需要编写一个将Document结构保存到磁盘的函数的任务。12// Save writes the contents of doc to the file f.func Save(f *os.File, doc *Document) error我可以指定这个函数Save,它将*os.File作为写入Document的目标。但这样做会有一些问题 Save的签名排除了将数据写入网络位置的选项。假设网络存储可能在以后成为需求,则此功能的签名必须改变,从而影响其所有调用者。 Save测试起来也很麻烦,因为它直接操作磁盘上的文件。因此,为了验证其操作,测试时必须在写入文件后再读取该文件的内容。 而且我必须确保f被写入临时位置并且随后要将其删除。 *os.File还定义了许多与Save无关的方法,比如读取目录并检查路径是否是符号链接。 如果Save函数的签名只用*os.File的相关内容,那将会很有用。 我们能做什么 ？123// Save writes the contents of doc to the supplied// ReadWriterCloser.func Save(rwc io.ReadWriteCloser, doc *Document) error使用io.ReadWriteCloser,我们可以应用接口隔离原则来重新定义Save以获取更通用文件形式。 通过此更改,任何实现io.ReadWriteCloser接口的类型都可以替换以前的*os.File。 这使Save在其应用程序中更广泛,并向Save的调用者阐明*os.File类型的哪些方法与其操作有关。 而且,Save的作者也不可以在*os.File上调用那些不相关的方法,因为它隐藏在io.ReadWriteCloser接口后面。 但我们可以进一步采用接口隔离原则。 首先,如果Save遵循单一功能原则,它不可能读取它刚刚写入的文件来验证其内容 - 这应该是另一段代码的功能。123// Save writes the contents of doc to the supplied// WriteCloser.func Save(wc io.WriteCloser, doc *Document) error因此,我们可以将我们传递给Save的接口的规范缩小到只写和关闭。 其次,通过向Save提供一个关闭其流的机制,使其看起来仍然像一个文件,这就提出了在什么情况下关闭wc的问题。 可能Save会无条件地调用Close,或者在成功的情况下调用Close。 这给Save的调用者带来了问题,因为它可能希望在写入文档后将其他数据写入流。123// Save writes the contents of doc to the supplied// Writer.func Save(w io.Writer, doc *Document) error一个更好的解决方案是重新定义Save仅使用io.Writer,它只负责将数据写入流。 将接口隔离原则应用于我们的Save功能,同时, 就需求而言, 得出了最具体的一个函数 - 它只需要一个可写的东西 - 并且它的功能最通用,现在我们可以使用Save将我们的数据保存到实现io.Writer的任何事物中。 [译注: 不理解设计原则部分的同学可以阅读 Dave 大神的另一篇《Go 语言 SOLID 设计》] 7. 错误处理我已经给出了几个关于错误处理的演示文稿[8],并在我的博客上写了很多关于错误处理的文章。我在昨天的会议上也讲了很多关于错误处理的内容,所以在这里不再赘述。 https://dave.cheney.net/2014/12/24/inspecting-errors https://dave.cheney.net/2016/04/07/constant-errors 相反,我想介绍与错误处理相关的两个其他方面。 7.1. 通过消除错误来消除错误处理如果你昨天在我的演讲中,我谈到了改进错误处理的提案。但是你知道有什么比改进错误处理的语法更好吗？那就是根本不需要处理错误。 注意:我不是说“删除你的错误处理”。我的建议是,修改你的代码,这样就不用处理错误了。 本节从 John Ousterhout 最近的著作“软件设计哲学”[9]中汲取灵感。该书的其中一章是“定义不存在的错误”。我们将尝试将此建议应用于 Go 语言。 7.1.1. 计算行数让我们编写一个函数来计算文件中的行数。1234567891011121314151617181920func CountLines(r io.Reader) (int, error) { var ( br = bufio.NewReader(r) lines int err error ) for { _, err = br.ReadString('\\n') lines++ if err != nil { break } } if err != io.EOF { return 0, err } return lines, nil}由于我们遵循前面部分的建议,CountLines需要一个io.Reader,而不是一个*File；它的任务是调用者为我们想要计算的内容提供io.Reader。 我们构造一个bufio.Reader,然后在一个循环中调用ReadString方法,递增计数器直到我们到达文件的末尾,然后我们返回读取的行数。 至少这是我们想要编写的代码,但是这个函数由于需要错误处理而变得更加复杂。 例如,有这样一个奇怪的结构:12345_, err = br.ReadString('\\n')lines++if err != nil { break}我们在检查错误之前增加了行数,这样做看起来很奇怪。 我们必须以这种方式编写它的原因是,如果在遇到换行符之前就读到文件结束,则ReadString将返回错误。如果文件中没有换行符,同样会出现这种情况。 为了解决这个问题,我们重新排列逻辑增来加行数,然后查看是否需要退出循环。 注意:这个逻辑仍然不完美,你能发现错误吗？ 但是我们还没有完成检查错误。当ReadString到达文件末尾时,预期它会返回io.EOF。ReadString需要某种方式在没有什么可读时来停止。因此,在我们将错误返回给CountLine的调用者之前,我们需要检查错误是否是io.EOF,如果不是将其错误返回,否则我们返回nil说一切正常。 我认为这是 Russ Cox 观察到错误处理可能会模​​糊函数操作的一个很好的例子。我们来看一个改进的版本。123456789func CountLines(r io.Reader) (int, error) { sc := bufio.NewScanner(r) lines := 0 for sc.Scan() { lines++ } return lines, sc.Err()}这个改进的版本从bufio.Reader切换到bufio.Scanner。 在bufio.Scanner内部使用bufio.Reader,但它添加了一个很好的抽象层,它有助于通过隐藏CountLines的操作来消除错误处理。 注意:bufio.Scanner可以扫描任何模式,但默认情况下它会查找换行符。 如果扫描程序匹配了一行文本并且没有遇到错误,则sc.Scan()方法返回true。因此,只有当扫描仪的缓冲区中有一行文本时,才会调用for循环的主体。这意味着我们修改后的CountLines正确处理没有换行符的情况,并且还处理文件为空的情况。 其次,当sc.Scan在遇到错误时返回false,我们的for循环将在到达文件结尾或遇到错误时退出。bufio.Scanner类型会记住遇到的第一个错误,一旦我们使用sc.Err()方法退出循环,我们就可以获取该错误。 最后,sc.Err()负责处理io.EOF并在达到文件末尾时将其转换为nil,而不会遇到其他错误。 小窍门:当遇到难以忍受的错误处理时,请尝试将某些操作提取到辅助程序类型中。 7.1.2. WriteResponse我的第二个例子受到了Errors are values博客文章[10]的启发。 在本章前面我们已经看过处理打开、写入和关闭文件的示例。错误处理是存在的,但是接收范围内的,因为操作可以封装在诸如ioutil.ReadFile和ioutil.WriteFile之类的辅助程序中。但是,在处理底层网络协议时,有必要使用I/O原始的错误处理来直接构建响应,这样就可能会变得重复。看一下构建HTTP响应的HTTP服务器的这个片段。1234567891011121314151617181920212223242526272829type Header struct { Key, Value string}type Status struct { Code int Reason string}func WriteResponse(w io.Writer, st Status, headers []Header, body io.Reader) error { _, err := fmt.Fprintf(w, \"HTTP/1.1 %d %s\\r\\n\", st.Code, st.Reason) if err != nil { return err } for _, h := range headers { _, err := fmt.Fprintf(w, \"%s: %s\\r\\n\", h.Key, h.Value) if err != nil { return err } } if _, err := fmt.Fprint(w, \"\\r\\n\"); err != nil { return err } _, err = io.Copy(w, body) return err}首先,我们使用fmt.Fprintf构造状态码并检查错误。 然后对于每个标题,我们写入键值对,每次都检查错误。 最后,我们使用额外的\\r\\n终止标题部分,检查错误之后将响应主体复制到客户端。 最后,虽然我们不需要检查io.Copy中的错误,但我们需要将io.Copy返回的两个返回值形式转换为WriteResponse的单个返回值。 这里很多重复性的工作。 我们可以通过引入一个包装器类型errWriter来使其更容易。 errWriter实现io.Writer接口,因此可用于包装现有的io.Writer。errWriter写入传递给其底层writer,直到检测到错误。 从此时起,它会丢弃任何写入并返回先前的错误。1234567891011121314151617181920212223242526type errWriter struct { io.Writer err error}func (e *errWriter) Write(buf []byte) (int, error) { if e.err != nil { return 0, e.err } var n int n, e.err = e.Writer.Write(buf) return n, nil}func WriteResponse(w io.Writer, st Status, headers []Header, body io.Reader) error { ew := &amp;errWriter{Writer: w} fmt.Fprintf(ew, \"HTTP/1.1 %d %s\\r\\n\", st.Code, st.Reason) for _, h := range headers { fmt.Fprintf(ew, \"%s: %s\\r\\n\", h.Key, h.Value) } fmt.Fprint(ew, \"\\r\\n\") io.Copy(ew, body) return ew.err}将errWriter应用于WriteResponse可以显着提高代码的清晰度。 每个操作不再需要自己做错误检查。 通过检查ew.err字段,将错误报告移动到函数末尾,从而避免转换从io.Copy的两个返回值。 7.2. 错误只处理一次最后,我想提一下你应该只处理错误一次。 处理错误意味着检查错误值并做出单一决定。1234// WriteAll writes the contents of buf to the supplied writer.func WriteAll(w io.Writer, buf []byte) { w.Write(buf)}如果你做出的决定少于一个,则忽略该错误。 正如我们在这里看到的那样,w.WriteAll的错误被丢弃。 但是,针对单个错误做出多个决策也是有问题的。 以下是我经常遇到的代码。12345678func WriteAll(w io.Writer, buf []byte) error { _, err := w.Write(buf) if err != nil { log.Println(\"unable to write:\", err) // annotated error goes to log file return err // unannotated error returned to caller } return nil}在此示例中,如果在w.Write期间发生错误,则会写入日志文件,注明错误发生的文件与行数,并且错误也会返回给调用者,调用者可能会记录该错误并将其返回到上一级,一直回到程序的顶部。 调用者可能正在做同样的事情123456789101112func WriteConfig(w io.Writer, conf *Config) error { buf, err := json.Marshal(conf) if err != nil { log.Printf(\"could not marshal config: %v\", err) return err } if err := WriteAll(w, buf); err != nil { log.Println(\"could not write config: %v\", err) return err } return nil}因此你在日志文件中得到一堆重复的内容,12unable to write: io.EOFcould not write config: io.EOF但在程序的顶部,虽然得到了原始错误,但没有相关内容。12err := WriteConfig(f, &amp;conf)fmt.Println(err) // io.EOF我想深入研究这一点,因为作为个人偏好, 我并没有看到logging和返回的问题。123456789101112func WriteConfig(w io.Writer, conf *Config) error { buf, err := json.Marshal(conf) if err != nil { log.Printf(\"could not marshal config: %v\", err) // oops, forgot to return } if err := WriteAll(w, buf); err != nil { log.Println(\"could not write config: %v\", err) return err } return nil}很多问题是程序员忘记从错误中返回。正如我们之前谈到的那样,Go 语言风格是使用guard clauses 以及检查前提条件作为函数进展并提前返回。 在这个例子中,作者检查了错误,记录了它,但忘了返回。这就引起了一个微妙的错误。 Go 语言中的错误处理规定,如果出现错误,你不能对其他返回值的内容做出任何假设。由于JSON解析失败,buf的内容未知,可能它什么都没有,但更糟的是它可能包含解析的JSON片段部分。 由于程序员在检查并记录错误后忘记返回,因此损坏的缓冲区将传递给WriteAll,这可能会成功,因此配置文件将被错误地写入。但是,该函数会正常返回,并且发生问题的唯一日志行是有关JSON解析错误,而与写入配置失败有关。 7.2.1. 为错误添加相关内容发生错误的原因是作者试图在错误消息中添加context。 他们试图给自己留下一些线索,指出错误的根源。 让我们看看使用fmt.Errorf的另一种方式。123456789101112131415161718func WriteConfig(w io.Writer, conf *Config) error { buf, err := json.Marshal(conf) if err != nil { return fmt.Errorf(\"could not marshal config: %v\", err) } if err := WriteAll(w, buf); err != nil { return fmt.Errorf(\"could not write config: %v\", err) } return nil}func WriteAll(w io.Writer, buf []byte) error { _, err := w.Write(buf) if err != nil { return fmt.Errorf(\"write failed: %v\", err) } return nil}通过将注释与返回的错误组合起来,就更难以忘记错误的返回来避免意外继续。 如果写入文件时发生I/O错误,则error的Error()方法会报告以下类似的内容;1could not write config: write failed: input/output error 7.2.2. 使用github.com/pkg/errors包装errorsfmt.Errorf模式适用于注释错误message,但这样做的代价是模糊了原始错误的类型。 我认为将错误视为不透明值对于松散耦合的软件非常重要,因此如果你使用错误值做的唯一事情是原始错误的类型应该无关紧要的面孔 检查它是否为nil。 输出或记录它。 但是在某些情况下,我认为它们并不常见,您需要恢复原始错误。 在这种情况下,使用类似我的errors包来注释这样的错误, 如下123456789101112131415161718192021222324252627func ReadFile(path string) ([]byte, error) { f, err := os.Open(path) if err != nil { return nil, errors.Wrap(err, \"open failed\") } defer f.Close() buf, err := ioutil.ReadAll(f) if err != nil { return nil, errors.Wrap(err, \"read failed\") } return buf, nil}func ReadConfig() ([]byte, error) { home := os.Getenv(\"HOME\") config, err := ReadFile(filepath.Join(home, \".settings.xml\")) return config, errors.WithMessage(err, \"could not read config\")}func main() { _, err := ReadConfig() if err != nil { fmt.Println(err) os.Exit(1) }}现在报告的错误就是K＆D[11]样式错误,1could not read config: open failed: open /Users/dfc/.settings.xml: no such file or directory并且错误值保留对原始原因的引用。12345678func main() { _, err := ReadConfig() if err != nil { fmt.Printf(\"original error: %T %v\\n\", errors.Cause(err), errors.Cause(err)) fmt.Printf(\"stack trace:\\n%+v\\n\", err) os.Exit(1) }}因此,你可以恢复原始错误并打印堆栈跟踪;123456789101112131415original error: *os.PathError open /Users/dfc/.settings.xml: no such file or directorystack trace:open /Users/dfc/.settings.xml: no such file or directoryopen failedmain.ReadFile /Users/dfc/devel/practical-go/src/errors/readfile2.go:16main.ReadConfig /Users/dfc/devel/practical-go/src/errors/readfile2.go:29main.main /Users/dfc/devel/practical-go/src/errors/readfile2.go:35runtime.main /Users/dfc/go/src/runtime/proc.go:201runtime.goexit /Users/dfc/go/src/runtime/asm_amd64.s:1333could not read config使用errors包,你可以以人和机器都可检查的方式向错误值添加上下文。 如果昨天你来听我的演讲,你会知道这个库在被移植到即将发布的 Go 语言版本的标准库中。 8. 并发由于 Go 语言的并发功能,经常被选作项目编程语言。 Go 语言团队已经竭尽全力以廉价（在硬件资源方面）和高性能来实现并发,但是 Go 语言的并发功能也可以被用来编写性能不高同时也不太可靠的代码。在结尾,我想留下一些建议,以避免 Go 语言的并发功能带来的一些陷阱。 Go 语言以channels以及select和go语句来支持并发。如果你已经从书籍或培训课程中正式学习了 Go 语言,你可能已经注意到并发部分始终是这些课程的最后一部分。这个研讨会也没有什么不同,我选择最后覆盖并发,好像它是 Go 程序员应该掌握的常规技能的额外补充。 这里有一个二分法; Go 语言的最大特点是简单、轻量级的并发模型。作为一种产品,我们的语言几乎只推广这个功能。另一方面,有一种说法认为并发使用起来实际上并不容易,否则作者不会把它作为他们书中的最后一章,我们也不会遗憾地来回顾其形成过程。 本节讨论了 Go 语言的并发功能的“坑”。 8.1. 保持自己忙碌或做自己的工作这个程序有什么问题？123456789101112131415161718192021package mainimport ( \"fmt\" \"log\" \"net/http\")func main() { http.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) { fmt.Fprintln(w, \"Hello, GopherCon SG\") }) go func() { if err := http.ListenAndServe(\":8080\", nil); err != nil { log.Fatal(err) } }() for { }}该程序实现了我们的预期,它提供简单的 Web 服务。 然而,它同时也做了其他事情,它在无限循环中浪费 CPU 资源。 这是因为main的最后一行上的for {}将阻塞main goroutine,因为它不执行任何 IO、等待锁定、发送或接收通道数据或以其他方式与调度器通信。 由于 Go 语言运行时主要是协同调度,该程序将在单个 CPU 上做无效地旋转,并可能最终实时锁定。 我们如何解决这个问题？ 这是一个建议。1234567891011121314151617181920212223package mainimport ( \"fmt\" \"log\" \"net/http\" \"runtime\")func main() { http.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) { fmt.Fprintln(w, \"Hello, GopherCon SG\") }) go func() { if err := http.ListenAndServe(\":8080\", nil); err != nil { log.Fatal(err) } }() for { runtime.Gosched() }}这看起来很愚蠢,但这是我看过的一种常见解决方案。 这是不了解潜在问题的症状。 现在,如果你有更多的经验,你可能会写这样的东西。1234567891011121314151617181920package mainimport ( \"fmt\" \"log\" \"net/http\")func main() { http.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) { fmt.Fprintln(w, \"Hello, GopherCon SG\") }) go func() { if err := http.ListenAndServe(\":8080\", nil); err != nil { log.Fatal(err) } }() select {}}空的select语句将永远阻塞。 这是一个有用的属性,因为现在我们不再调用runtime.GoSched()而耗费整个 CPU。 但是这也只是治疗了症状,而不是病根。 我想向你提出另一种你可能在用的解决方案。 与其在goroutine中运行http.ListenAndServe,会给我们留下处理main goroutine的问题,不如在main goroutine本身上运行http.ListenAndServe。 小窍门:如果 Go 语言程序的main.main函数返回,无论程序在一段时间内启动的其他goroutine在做什么, Go 语言程序会无条件地退出。 12345678910111213141516package mainimport ( \"fmt\" \"log\" \"net/http\")func main() { http.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) { fmt.Fprintln(w, \"Hello, GopherCon SG\") }) if err := http.ListenAndServe(\":8080\", nil); err != nil { log.Fatal(err) }} 所以这是我的第一条建议：如果你的goroutine在得到另一个结果之前无法取得进展,那么让自己完成此工作而不是委托给其他goroutine会更简单。 这通常会消除将结果从goroutine返回到其启动程序所需的大量状态跟踪和通道操作。 小窍门:许多 Go 程序员过度使用goroutine,特别是刚开始时。与生活中的所有事情一样,适度是成功的关键。 8.2. 将并发性留给调用者以下两个 API 有什么区别？12// ListDirectory returns the contents of dir.func ListDirectory(dir string) ([]string, error)1234// ListDirectory returns a channel over which// directory entries will be published. When the list// of entries is exhausted, the channel will be closed.func ListDirectory(dir string) chan string首先,最明显的不同: 第一个示例将目录读入切片然后返回整个切片,如果出错则返回错误。这是同步发生的,ListDirectory的调用者会阻塞,直到读取了所有目录条目。根据目录的大小,这可能需要很长时间,并且可能会分配大量内存来构建目录条目。 让我们看看第二个例子。 这个示例更像是 Go 语言风格,ListDirectory返回一个通道,通过该通道传递目录条目。当通道关闭时,表明没有更多目录条目。由于在ListDirectory返回后发生了通道的填充,ListDirectory可能会启动一个goroutine来填充通道。 注意:第二个版本实际上不必使用 Go 协程; 它可以分配一个足以保存所有目录条目而不阻塞的通道,填充通道,关闭它,然后将通道返回给调用者。但这样做不太现实,因为会消耗大量内存来缓冲通道中的所有结果。 通道版本的ListDirectory还有两个问题： 通过使用关闭通道作为没有其他项目要处理的信号,在中途遇到了错误时,ListDirectory无法告诉调用者通过通道返回的项目集是否完整。调用者无法区分空目录和读取目录的错误。两者都导致从ListDirectory返回的通道立即关闭。 调用者必须持续从通道中读取,直到它被关闭,因为这是调用者知道此通道的是否停止的唯一方式。这是对ListDirectory使用的严重限制,即使可能已经收到了它想要的答案,调用者也必须花时间从通道中读取。就中型到大型目录的内存使用而言,它可能更有效,但这种方法并不比原始的基于切片的方法快。 以上两种实现所带来的问题的解决方案是使用回调,该回调是在执行时在每个目录条目的上下文中调用函数。1func ListDirectory(dir string, fn func(string))毫不奇怪,这就是filepath.WalkDir函数的工作方式。 小窍门:如果你的函数启动了goroutine,你必须为调用者提供一种明确停止goroutine的方法。 把异步执行函数的决定留给该函数的调用者通常会更容易些。 8.3. 永远不要启动一个停止不了的 goroutine。前面的例子显示当一个任务时没有必要时使用goroutine。但使用 Go 语言的原因之一是该语言提供的并发功能。实际上,很多情况下你希望利用硬件中可用的并行性。为此,你必须使用goroutines。 这个简单的应用程序在两个不同的端口上提供http服务,端口8080用于应用程序服务,端口8001用于访问/debug/pprof终端。12345678910111213141516package mainimport ( \"fmt\" \"net/http\" _ \"net/http/pprof\")func main() { mux := http.NewServeMux() mux.HandleFunc(\"/\", func(resp http.ResponseWriter, req *http.Request) { fmt.Fprintln(resp, \"Hello, QCon!\") }) go http.ListenAndServe(\"127.0.0.1:8001\", http.DefaultServeMux) // debug http.ListenAndServe(\"0.0.0.0:8080\", mux) // app traffic}虽然这个程序不是很复杂,但它代表了真实应用程序的基础。 该应用程序存在一些问题,因为它随着应用程序的增长而显露出来,所以我们现在来解决其中的一些问题。12345678910111213141516func serveApp() { mux := http.NewServeMux() mux.HandleFunc(\"/\", func(resp http.ResponseWriter, req *http.Request) { fmt.Fprintln(resp, \"Hello, QCon!\") }) http.ListenAndServe(\"0.0.0.0:8080\", mux)}func serveDebug() { http.ListenAndServe(\"127.0.0.1:8001\", http.DefaultServeMux)}func main() { go serveDebug() serveApp()}通过将serveApp和serveDebug处理程序分解成为它们自己的函数,我们将它们与main.main分离。 也遵循了上面的建议,并确保serveApp和serveDebug将它们的并发性留给调用者。 但是这个程序存在一些可操作性问题。 如果serveApp返回,那么main.main将返回,导致程序关闭并由你使用的进程管理器来重新启动。 小窍门:正如 Go 语言中的函数将并发性留给调用者一样,应用程序应该将监视其状态和检测是否重启的工作留给另外的程序来做。 不要让你的应用程序负责重新启动自己,最好从应用程序外部处理该过程。 然而,serveDebug是在一个单独的goroutine中运行的,返回后该goroutine将退出,而程序的其余部分继续。 由于/debug处理程序已停止工作很久,因此操作人员不会很高兴发现他们无法在你的应用程序中获取统计信息。 我们想要确保的是,如果任何负责提供此应用程序的goroutine停止,我们将关闭该应用程序。123456789101112131415161718192021func serveApp() { mux := http.NewServeMux() mux.HandleFunc(\"/\", func(resp http.ResponseWriter, req *http.Request) { fmt.Fprintln(resp, \"Hello, QCon!\") }) if err := http.ListenAndServe(\"0.0.0.0:8080\", mux); err != nil { log.Fatal(err) }}func serveDebug() { if err := http.ListenAndServe(\"127.0.0.1:8001\", http.DefaultServeMux); err != nil { log.Fatal(err) }}func main() { go serveDebug() go serveApp() select {}}现在serverApp和serveDebug检查从ListenAndServe返回的错误,并在需要时调用log.Fatal。因为两个处理程序都在goroutine中运行,所以我们将main goroutine停在select{}中。 这种方法存在许多问题： 如果ListenAndServer返回nil错误,则不会调用log.Fatal,并且该端口上的 HTTP 服务将在不停止应用程序的情况下关闭。 log.Fatal调用os.Exit,它将无条件地退出程序;defer不会被调用,其他goroutines也不会被通知关闭,程序就停止了。 这使得编写这些函数的测试变得困难。 小窍门:只在main.main或init函数中的使用log.Fatal。 我们真正想要的是任何错误发送回goroutine的调用者,以便它可以知道goroutine停止的原因,可以干净地关闭程序进程。123456789101112131415161718192021222324252627func serveApp() error { mux := http.NewServeMux() mux.HandleFunc(\"/\", func(resp http.ResponseWriter, req *http.Request) { fmt.Fprintln(resp, \"Hello, QCon!\") }) return http.ListenAndServe(\"0.0.0.0:8080\", mux)}func serveDebug() error { return http.ListenAndServe(\"127.0.0.1:8001\", http.DefaultServeMux)}func main() { done := make(chan error, 2) go func() { done &lt;- serveDebug() }() go func() { done &lt;- serveApp() }() for i := 0; i &lt; cap(done); i++ { if err := &lt;-done; err != nil { fmt.Println(\"error: %v\", err) } }}我们可以使用通道来收集goroutine的返回状态。通道的大小等于我们想要管理的goroutine的数量,这样发送到done通道就不会阻塞,因为这会阻止goroutine的关闭,导致它泄漏。 由于没有办法安全地关闭done通道,我们不能使用for range来循环通道直到获取所有goroutine发来的报告,而是循环我们开启的多个goroutine,即通道的容量。 现在我们有办法等待每个goroutine干净地退出并记录他们遇到的错误。所需要的只是一种从第一个goroutine转发关闭信号到其他goroutine的方法。 事实证明,要求http.Server关闭是有点牵扯的,所以我将这个逻辑转给辅助函数。serve助手使用一个地址和http.Handler,类似于http.ListenAndServe,还有一个stop通道,我们用它来触发Shutdown方法。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647func serve(addr string, handler http.Handler, stop &lt;-chan struct{}) error { s := http.Server{ Addr: addr, Handler: handler, } go func() { &lt;-stop // wait for stop signal s.Shutdown(context.Background()) }() return s.ListenAndServe()}func serveApp(stop &lt;-chan struct{}) error { mux := http.NewServeMux() mux.HandleFunc(\"/\", func(resp http.ResponseWriter, req *http.Request) { fmt.Fprintln(resp, \"Hello, QCon!\") }) return serve(\"0.0.0.0:8080\", mux, stop)}func serveDebug(stop &lt;-chan struct{}) error { return serve(\"127.0.0.1:8001\", http.DefaultServeMux, stop)}func main() { done := make(chan error, 2) stop := make(chan struct{}) go func() { done &lt;- serveDebug(stop) }() go func() { done &lt;- serveApp(stop) }() var stopped bool for i := 0; i &lt; cap(done); i++ { if err := &lt;-done; err != nil { fmt.Println(\"error: %v\", err) } if !stopped { stopped = true close(stop) } }}现在,每次我们在done通道上收到一个值时,我们关闭stop通道,这会导致在该通道上等待的所有goroutine关闭其http.Server。 这反过来将导致其余所有的ListenAndServe`goroutines返回。 一旦我们开启的所有goroutine都停止了,main.main`就会返回并且进程会干净地停止。 小窍门:自己编写这种逻辑是重复而微妙的。 参考下这个包: https://github.com/heptio/workgroup,它会为你完成大部分工作。 引用: 1. https://gaston.life/books/effective-programming/ 2. https://talks.golang.org/2014/names.slide#4 3. https://www.infoq.com/articles/API-Design-Joshua-Bloch 1. https://www.lysator.liu.se/c/pikestyle.html 2. https://speakerdeck.com/campoy/understanding-nil 3. https://www.youtube.com/watch?v=Ic2y6w8lMPA 4. https://medium.com/@matryer/line-of-sight-in-code-186dd7cdea88 5. https://golang.org/doc/go1.4#internalpackages 6. https://dave.cheney.net/2014/10/17/functional-options-for-friendly-apis 7. https://commandcenter.blogspot.com/2014/01/self-referential-functions-and-design.html 8. https://dave.cheney.net/2016/04/27/dont-just-check-errors-handle-them-gracefully 9. https://www.amazon.com/Philosophy-Software-Design-John-Ousterhout/dp/1732102201 10. https://blog.golang.org/errors-are-values 11. http://www.gopl.io/ 原文链接：Practical Go: Real world advice for writing maintainable Go programs","link":"/2019/05/31/Go/Golang%E8%AF%91%E6%96%87/%E7%BC%96%E5%86%99%E5%8F%AF%E7%BB%B4%E6%8A%A4Go%E8%AF%AD%E8%A8%80%E4%BB%A3%E7%A0%81%E5%BB%BA%E8%AE%AE/"},{"title":"(译) Raft 论文","text":"摘要Raft 是一种为了管理复制日志的一致性算法。它提供了和 Paxos 算法相同的功能和性能,但是它的算法结构和 Paxos 不同,使得 Raft 算法更加容易理解并且更容易构建实际的系统。为了提升可理解性,Raft 将一致性算法分解成了几个关键模块,例如领导人选举、日志复制和安全性。同时它通过实施一个更强的一致性来减少需要考虑的状态的数量。从一个用户研究的结果可以证明,对于学生而言,Raft 算法比 Paxos 算法更加容易学习。Raft 算法还包括一个新的机制来允许集群成员的动态改变,它利用重叠的大多数来保证安全性。 1 介绍一致性算法允许一组机器像一个整体一样工作,即使其中一些机器出现故障也能够继续工作下去。正因为如此,一致性算法在构建可信赖的大规模软件系统中扮演着重要的角色。在过去的 10 年里,Paxos 算法统治着一致性算法这一领域：绝大多数的实现都是基于 Paxos 或者受其影响。同时 Paxos 也成为了教学领域里讲解一致性问题时的示例。 但是不幸的是,尽管有很多工作都在尝试降低它的复杂性,但是 Paxos 算法依然十分难以理解。并且,Paxos 自身的算法结构需要进行大幅的修改才能够应用到实际的系统中。这些都导致了工业界和学术界都对 Paxos 算法感到十分头疼。 和 Paxos 算法进行过努力之后,我们开始寻找一种新的一致性算法,可以为构建实际的系统和教学提供更好的基础。我们的做法是不寻常的,我们的首要目标是可理解性：我们是否可以在实际系统中定义一个一致性算法,并且能够比 Paxos 算法以一种更加容易的方式来学习。此外,我们希望该算法方便系统构建者的直觉的发展。不仅一个算法能够工作很重要,而且能够显而易见的知道为什么能工作也很重要。 Raft 一致性算法就是这些工作的结果。在设计 Raft 算法的时候,我们使用一些特别的技巧来提升它的可理解性,包括算法分解（Raft 主要被分成了领导人选举,日志复制和安全三个模块）和减少状态机的状态（相对于 Paxos,Raft 减少了非确定性和服务器互相处于非一致性的方式）。一份针对两所大学 43 个学生的研究表明 Raft 明显比 Paxos 算法更加容易理解。在这些学生同时学习了这两种算法之后,和 Paxos 比起来,其中 33 个学生能够回答有关于 Raft 的问题。 Raft 算法在许多方面和现有的一致性算法都很相似（主要是 Oki 和 Liskov 的 Viewstamped Replication）,但是它也有一些独特的特性： 强领导者：和其他一致性算法相比,Raft 使用一种更强的领导能力形式。比如,日志条目只从领导者发送给其他的服务器。这种方式简化了对复制日志的管理并且使得 Raft 算法更加易于理解。 领导选举：Raft 算法使用一个随机计时器来选举领导者。这种方式只是在任何一致性算法都必须实现的心跳机制上增加了一点机制。在解决冲突的时候会更加简单快捷。 成员关系调整：Raft 使用一种共同一致的方法来处理集群成员变换的问题,在这种方法下,处于调整过程中的两种不同的配置集群中大多数机器会有重叠,这就使得集群在成员变换的时候依然可以继续工作。 我们相信,Raft 算法不论出于教学目的还是作为实践项目的基础都是要比 Paxos 或者其他一致性算法要优异的。它比其他算法更加简单,更加容易理解；它的算法描述足以实现一个现实的系统；它有好多开源的实现并且在很多公司里使用；它的安全性已经被证明；它的效率和其他算法比起来也不相上下。 接下来,这篇论文会介绍以下内容：复制状态机问题（第 2 节）,讨论 Paxos 的优点和缺点（第 3 节）,讨论我们为了可理解性而采取的方法（第 4 节）,阐述 Raft 一致性算法（第 5-8 节）,评价 Raft 算法（第 9 节）,以及一些相关的工作（第 10 节）。 2 复制状态机一致性算法是从复制状态机的背景下提出的（参考英文原文引用37）。在这种方法中,一组服务器上的状态机产生相同状态的副本,并且在一些机器宕掉的情况下也可以继续运行。复制状态机在分布式系统中被用于解决很多容错的问题。例如,大规模的系统中通常都有一个集群领导者,像 GFS、HDFS 和 RAMCloud,典型应用就是一个独立的的复制状态机去管理领导选举和存储配置信息并且在领导人宕机的情况下也要存活下来。比如 Chubby 和 ZooKeeper。 图 1 ：复制状态机的结构。一致性算法管理着来自客户端指令的复制日志。状态机从日志中处理相同顺序的相同指令,所以产生的结果也是相同的。 复制状态机通常都是基于复制日志实现的,如图 1。每一个服务器存储一个包含一系列指令的日志,并且按照日志的顺序进行执行。每一个日志都按照相同的顺序包含相同的指令,所以每一个服务器都执行相同的指令序列。因为每个状态机都是确定的,每一次执行操作都产生相同的状态和同样的序列。 感悟：这种机制类似于redis的aof实现,用日志来恢复状态,将日志放到复制状态中执行,最终会得到一个状态,也和redis很像,到一定程度到时候会进行日志压缩,生成快照 保证复制日志相同就是一致性算法的工作了。在一台服务器上,一致性模块接收客户端发送来的指令然后增加到自己的日志中去。它和其他服务器上的一致性模块进行通信来保证每一个服务器上的日志最终都以相同的顺序包含相同的请求,尽管有些服务器会宕机。一旦指令被正确的复制,每一个服务器的状态机按照日志顺序处理他们,然后输出结果被返回给客户端。因此,服务器集群看起来形成一个高可靠的状态机。 实际系统中使用的一致性算法通常含有以下特性： 安全性保证（绝对不会返回一个错误的结果）：在非拜占庭错误情况下,包括网络延迟、分区、丢包、冗余和乱序等错误都可以保证正确。 可用性：集群中只要有大多数的机器可运行并且能够相互通信、和客户端通信,就可以保证可用。因此,一个典型的包含 5 个节点的集群可以容忍两个节点的失败。服务器被停止就认为是失败。他们当有稳定的存储的时候可以从状态中恢复回来并重新加入集群。 不依赖时序来保证一致性：物理时钟错误或者极端的消息延迟只有在最坏情况下才会导致可用性问题。 通常情况下,一条指令可以尽可能快的在集群中大多数节点响应一轮远程过程调用时完成。小部分比较慢的节点不会影响系统整体的性能。 3 Paxos 算法的问题在过去的 10 年里,Leslie Lamport 的 Paxos 算法几乎已经成为一致性的代名词：Paxos 是在课程教学中最经常使用的算法,同时也是大多数一致性算法实现的起点。Paxos 首先定义了一个能够达成单一决策一致的协议,比如单条的复制日志项。我们把这一子集叫做单决策 Paxos。然后通过组合多个 Paxos 协议的实例来促进一系列决策的达成。Paxos 保证安全性和活性,同时也支持集群成员关系的变更。Paxos 的正确性已经被证明,在通常情况下也很高效。 不幸的是,Paxos 有两个明显的缺点。第一个缺点是 Paxos 算法特别的难以理解。完整的解释是出了名的不透明；通过极大的努力之后,也只有少数人成功理解了这个算法。因此,有了几次用更简单的术语来解释 Paxos 的尝试。尽管这些解释都只关注了单决策的子集问题,但依然很具有挑战性。在 2012 年 NSDI 的会议中的一次调查显示,很少有人对 Paxos 算法感到满意,甚至在经验老道的研究者中也是如此。我们自己也尝试去理解 Paxos；我们一直没能理解 Paxos 直到我们读了很多对 Paxos 的简化解释并且设计了我们自己的算法之后,这一过程花了近一年时间。 我们假设 Paxos 的不透明性来自它选择单决策问题作为它的基础。单决策 Paxos 是晦涩微妙的,它被划分成了两种没有简单直观解释和无法独立理解的情景。因此,这导致了很难建立起直观的感受为什么单决策 Paxos 算法能够工作。构成多决策 Paxos 增加了很多错综复杂的规则。我们相信,在多决策上达成一致性的问题（一份日志而不是单一的日志记录）能够被分解成其他的方式并且更加直接和明显。 Paxos算法的第二个问题就是它没有提供一个足够好的用来构建一个现实系统的基础。一个原因是还没有一种被广泛认同的多决策问题的算法。Lamport 的描述基本上都是关于单决策 Paxos 的；他简要描述了实施多决策 Paxos 的方法,但是缺乏很多细节。当然也有很多具体化 Paxos 的尝试,但是他们都互相不一样,和 Paxos 的概述也不同。例如 Chubby 这样的系统实现了一个类似于 Paxos 的算法,但是大多数的细节并没有被公开。 而且,Paxos 算法的结构也不是十分易于构建实践的系统；单决策分解也会产生其他的结果。例如,独立的选择一组日志条目然后合并成一个序列化的日志并没有带来太多的好处,仅仅增加了不少复杂性。围绕着日志来设计一个系统是更加简单高效的；新日志条目以严格限制的顺序增添到日志中去。另一个问题是,Paxos 使用了一种对等的点对点的方式作为它的核心（尽管它最终提议了一种弱领导人的方法来优化性能）。在只有一个决策会被制定的简化世界中是很有意义的,但是很少有现实的系统使用这种方式。如果有一系列的决策需要被制定,首先选择一个领导人,然后让他去协调所有的决议,会更加简单快速。 因此,实际的系统中很少有和 Paxos 相似的实践。每一种实现都是从 Paxos 开始研究,然后发现很多实现上的难题,再然后开发了一种和 Paxos 明显不一样的结构。这样是非常费时和容易出错的,并且理解 Paxos 的难度使得这个问题更加糟糕。Paxos 算法在理论上被证明是正确可行的,但是现实的系统和 Paxos 差别是如此的大,以至于这些证明没有什么太大的价值。下面来自 Chubby 实现非常典型： 在Paxos算法描述和实现现实系统中间有着巨大的鸿沟。最终的系统建立在一种没有经过证明的算法之上。 由于以上问题,我们认为 Paxos 算法既没有提供一个良好的基础给实践的系统,也没有给教学很好的帮助。基于一致性问题在大规模软件系统中的重要性,我们决定看看我们是否可以设计一个拥有更好特性的替代 Paxos 的一致性算法。Raft算法就是这次实验的结果。 4 为了可理解性的设计设计 Raft 算法我们有几个初衷：它必须提供一个完整的实际的系统实现基础,这样才能大大减少开发者的工作；它必须在任何情况下都是安全的并且在大多数的情况下都是可用的；并且它的大部分操作必须是高效的。但是我们最重要也是最大的挑战是可理解性。它必须保证对于普遍的人群都可以十分容易的去理解。另外,它必须能够让人形成直观的认识,这样系统的构建者才能够在现实中进行必然的扩展。 在设计 Raft 算法的时候,有很多的点需要我们在各种备选方案中进行选择。在这种情况下,我们评估备选方案基于可理解性原则：解释各个备选方案有多大的难度（例如,Raft 的状态空间有多复杂,是否有微妙的暗示）？对于一个读者而言,完全理解这个方案和暗示是否容易？ 我们意识到对这种可理解性分析上具有高度的主观性；尽管如此,我们使用了两种通常适用的技术来解决这个问题。第一个技术就是众所周知的问题分解：只要有可能,我们就将问题分解成几个相对独立的,可被解决的、可解释的和可理解的子问题。例如,Raft 算法被我们分成领导人选举,日志复制,安全性和角色改变几个部分。 我们使用的第二个方法是通过减少状态的数量来简化需要考虑的状态空间,使得系统更加连贯并且在可能的时候消除不确定性。特别的,所有的日志是不允许有空洞的,并且 Raft 限制了日志之间变成不一致状态的可能。尽管在大多数情况下我们都试图去消除不确定性,但是也有一些情况下不确定性可以提升可理解性。尤其是,随机化方法增加了不确定性,但是他们有利于减少状态空间数量,通过处理所有可能选择时使用相似的方法。我们使用随机化去简化 Raft 中领导人选举算法。 5 Raft 一致性算法Raft 是一种用来管理章节 2 中描述的复制日志的算法。图 2 为了参考之用,总结这个算法的简略版本,图 3 列举了这个算法的一些关键特性。图中的这些元素会在剩下的章节逐一介绍。 Raft 通过选举一个高贵的领导人,然后给予他全部的管理复制日志的责任来实现一致性。领导人从客户端接收日志条目,把日志条目复制到其他服务器上,并且当保证安全性的时候告诉其他的服务器应用日志条目到他们的状态机中。拥有一个领导人大大简化了对复制日志的管理。例如,领导人可以决定新的日志条目需要放在日志中的什么位置而不需要和其他服务器商议,并且数据都从领导人流向其他服务器。一个领导人可以宕机,可以和其他服务器失去连接,这时一个新的领导人会被选举出来。 通过领导人的方式,Raft 将一致性问题分解成了三个相对独立的子问题,这些问题会在接下来的子章节中进行讨论： 领导选举：一个新的领导人需要被选举出来,当现存的领导人宕机的时候（章节 5.2） 日志复制：领导人必须从客户端接收日志然后复制到集群中的其他节点,并且强制要求其他节点的日志保持和自己相同。 安全性：在 Raft 中安全性的关键是在图 3 中展示的状态机安全：如果有任何的服务器节点已经应用了一个确定的日志条目到它的状态机中,那么其他服务器节点不能在同一个日志索引位置应用一个不同的指令。章节 5.4 阐述了 Raft 算法是如何保证这个特性的；这个解决方案涉及到一个额外的选举机制（5.2 节）上的限制。 在展示一致性算法之后,这一章节会讨论可用性的一些问题和计时在系统的作用。 状态： 状态 所有服务器上持久存在的 currentTerm 服务器最后一次知道的任期号（初始化为 0,持续递增） votedFor 在当前获得选票的候选人的 Id log[] 日志条目集；每一个条目包含一个用户状态机执行的指令,和收到时的任期号 状态 所有服务器上经常变的 commitIndex 已知的最大的已经被提交的日志条目的索引值 lastApplied 最后被应用到状态机的日志条目索引值（初始化为 0,持续递增） 感悟：commitIndex &gt; lastApplied ,已经被提交的日志不一定会被应用到状态机中,只是代表我已经提交了这个日志要分为两个独立的索引的原因是因为,提交需要被大部分节点所接受才可以应用,否则不能保证集群的安全性 状态 在领导人里经常改变的 （选举后重新初始化） nextIndex[] 对于每一个服务器,需要发送给他的下一个日志条目的索引值（初始化为领导人最后索引值加一） matchIndex[] 对于每一个服务器,已经复制给他的日志的最高索引值 附加日志 RPC： 由领导人负责调用来复制日志指令；也会用作heartbeat 参数 解释 term 领导人的任期号 leaderId 领导人的 Id,以便于跟随者重定向请求 prevLogIndex 新的日志条目紧随之前的索引值 prevLogTerm prevLogIndex 条目的任期号 entries[] 准备存储的日志条目（表示心跳时为空；一次性发送多个是为了提高效率） leaderCommit 领导人已经提交的日志的索引值 返回值 解释 term 当前的任期号,用于领导人去更新自己 success 跟随者包含了匹配上 prevLogIndex 和 prevLogTerm 的日志时为真 接收者实现： 如果term &lt; currentTerm就返回 false （5.1 节） 如果日志在 prevLogIndex 位置处的日志条目的任期号和 prevLogTerm 不匹配,则返回 false （5.3 节） 如果已经存在的日志条目和新的产生冲突（索引值相同但是任期号不同）,删除这一条和之后所有的 （5.3 节） 附加日志中尚未存在的任何新条目 如果leaderCommit &gt; commitIndex,令 commitIndex 等于 leaderCommit 和 新日志条目索引值中较小的一个 请求投票 RPC： 由候选人负责调用用来征集选票（5.2 节） 参数 解释 term 候选人的任期号 candidateId 请求选票的候选人的 Id lastLogIndex 候选人的最后日志条目的索引值 lastLogTerm 候选人最后日志条目的任期号 返回值 解释 term 当前任期号,以便于候选人去更新自己的任期号 voteGranted 候选人赢得了此张选票时为真 接收者实现： 如果term &lt; currentTerm返回 false （5.2 节） 如果 votedFor 为空或者为 candidateId,并且候选人的日志至少和自己一样新,那么就投票给他（5.2 节,5.4 节） 感悟：因为候选人到term肯定是要大于当前跟随者到term的,否则的话,候选人的日志进度肯定是落后的,肯定不能作为领导者,否则会导致日志丢失 所有服务器需遵守的规则： 所有服务器： 如果commitIndex &gt; lastApplied,那么就 lastApplied 加一,并把log[lastApplied]应用到状态机中（5.3 节） 如果接收到的 RPC 请求或响应中,任期号T &gt; currentTerm,那么就令 currentTerm 等于 T,并切换状态为跟随者（5.1 节） 感悟：T &gt; currentTerm对于领导者也是适用的,所以在etcd的实现中,增加prevote来防止因为网络分区的原因,导致不必要的重新选举 跟随者（5.2 节）： 响应来自候选人和领导者的请求 如果在超过选举超时时间的情况之前都没有收到领导人的心跳,或者是候选人请求投票的,就自己变成候选人 候选人（5.2 节）： 在转变成候选人后就立即开始选举过程 自增当前的任期号（currentTerm） 给自己投票 重置选举超时计时器 发送请求投票的 RPC 给其他所有服务器 如果接收到大多数服务器的选票,那么就变成领导人 如果接收到来自新的领导人的附加日志 RPC,转变成跟随者 如果选举过程超时,再次发起一轮选举 感悟：先增加自己的任期号,这样的话,当前候选人的任期应该是比跟随者大的,这样的话就会被投,然后候选人都是要先给自己投才行,然后让大家投票 领导人： 一旦成为领导人：发送空的附加日志 RPC（心跳）给其他所有的服务器；在一定的空余时间之后不停的重复发送,以阻止跟随者超时（5.2 节） 如果接收到来自客户端的请求：附加条目到本地日志中,在条目被应用到状态机后响应客户端（5.3 节） 如果对于一个跟随者,最后日志条目的索引值大于等于 nextIndex,那么：发送从 nextIndex 开始的所有日志条目： 如果成功：更新相应跟随者的 nextIndex 和 matchIndex 如果因为日志不一致而失败,减少 nextIndex 重试 如果存在一个满足N &gt; commitIndex的 N,并且大多数的matchIndex[i] ≥ N成立,并且log[N].term == currentTerm成立,那么令 commitIndex 等于这个 N （5.3 和 5.4 节） 感悟：在etcd的raft实现中不是一下一下减少nextIndex的值来实现的,而是通过返回一个 rejectHint 拒绝同步日志请求时返回的当前节点日志ID,用于被拒绝方快速定位到下一次合适的同步日志位置N &gt; commitIndex表示的是大部分节点都拥有都共同日志,作为leader节点都commitIndex 图 2：一个关于 Raft 一致性算法的浓缩总结（不包括成员变换和日志压缩）。 特性 解释 选举安全特性 对于一个给定的任期号,最多只会有一个领导人被选举出来（5.2 节） 领导人只附加原则 领导人绝对不会删除或者覆盖自己的日志,只会增加（5.3 节） 日志匹配原则 如果两个日志在相同的索引位置的日志条目的任期号相同,那么我们就认为这个日志从头到这个索引位置之间全部完全相同（5.3 节） 领导人完全特性 如果某个日志条目在某个任期号中已经被提交,那么这个条目必然出现在更大任期号的所有领导人中（5.4 节） 状态机安全特性 如果一个领导人已经在给定的索引值位置的日志条目应用到状态机中,那么其他任何的服务器在这个索引位置不会提交一个不同的日志（5.4.3 节） 图 3：Raft 在任何时候都保证以上的各个特性。 5.1 Raft 基础一个 Raft 集群包含若干个服务器节点；通常是 5 个,这允许整个系统容忍 2 个节点的失效。在任何时刻,每一个服务器节点都处于这三个状态之一：领导人、跟随者或者候选人。在通常情况下,系统中只有一个领导人并且其他的节点全部都是跟随者。跟随者都是被动的：他们不会发送任何请求,只是简单的响应来自领导者或者候选人的请求。领导人处理所有的客户端请求（如果一个客户端和跟随者联系,那么跟随者会把请求重定向给领导人）。第三种状态,候选人,是用来在 5.2 节描述的选举新领导人时使用。图 4 展示了这些状态和他们之间的转换关系；这些转换关系会在接下来进行讨论。 图 4：服务器状态。跟随者只响应来自其他服务器的请求。如果跟随者接收不到消息,那么他就会变成候选人并发起一次选举。获得集群中大多数选票的候选人将成为领导者。在一个任期内,领导人一直都会是领导人直到自己宕机了。 图 5：时间被划分成一个个的任期,每个任期开始都是一次选举。在选举成功后,领导人会管理整个集群直到任期结束。有时候选举会失败,那么这个任期就会没有领导人而结束。任期之间的切换可以在不同的时间不同的服务器上观察到。 Raft 把时间分割成任意长度的任期,如图 5。任期用连续的整数标记。每一段任期从一次选举开始,就像章节 5.2 描述的一样,一个或者多个候选人尝试成为领导者。如果一个候选人赢得选举,然后他就在接下来的任期内充当领导人的职责。在某些情况下,一次选举过程会造成选票的瓜分。在这种情况下,这一任期会以没有领导人结束；一个新的任期（和一次新的选举）会很快重新开始。Raft 保证了在一个给定的任期内,最多只有一个领导者。 不同的服务器节点可能多次观察到任期之间的转换,但在某些情况下,一个节点也可能观察不到任何一次选举或者整个任期全程。任期在 Raft 算法中充当逻辑时钟的作用,这会允许服务器节点查明一些过期的信息比如陈旧的领导者。每一个节点存储一个当前任期号,这一编号在整个时期内单调的增长。当服务器之间通信的时候会交换当前任期号；如果一个服务器的当前任期号比其他人小,那么他会更新自己的编号到较大的编号值。如果一个候选人或者领导者发现自己的任期号过期了,那么他会立即恢复成跟随者状态。如果一个节点接收到一个包含过期的任期号的请求,那么他会直接拒绝这个请求。 Raft 算法中服务器节点之间通信使用远程过程调用（RPCs）,并且基本的一致性算法只需要两种类型的 RPCs。请求投票（RequestVote） RPCs 由候选人在选举期间发起（章节 5.2）,然后附加条目（AppendEntries）RPCs 由领导人发起,用来复制日志和提供一种心跳机制（章节 5.3）。第 7 节为了在服务器之间传输快照增加了第三种 RPC。当服务器没有及时的收到 RPC 的响应时,会进行重试, 并且他们能够并行的发起 RPCs 来获得最佳的性能。 感悟：有可能在一个任期内没有领导人,因为领导人没有被选出来（可能是多个候选人通过竞争这个领导人都位置,但是都得到了一样都票数,并没有得到大多数人都票数,所以超过了选举时间,重新开始一轮选举） 5.2 领导人选举Raft 使用一种心跳机制来触发领导人选举。当服务器程序启动时,他们都是跟随者身份。一个服务器节点继续保持着跟随者状态只要他从领导人或者候选者处接收到有效的 RPCs。领导者周期性的向所有跟随者发送心跳包（即不包含日志项内容的附加日志项 RPCs）来维持自己的权威。如果一个跟随者在一段时间里没有接收到任何消息,也就是选举超时,那么他就会认为系统中没有可用的领导者,并且发起选举以选出新的领导者。 要开始一次选举过程,跟随者先要增加自己的当前任期号并且转换到候选人状态。然后他会并行的向集群中的其他服务器节点发送请求投票的 RPCs 来给自己投票。候选人会继续保持着当前状态直到以下三件事情之一发生： (a) 他自己赢得了这次的选举 (b) 其他的服务器成为领导者 (c) 一段时间之后没有任何一个获胜的人。这些结果会分别的在下面的段落里进行讨论。 当一个候选人从整个集群的大多数服务器节点获得了针对同一个任期号的选票,那么他就赢得了这次选举并成为领导人。每一个服务器最多会对一个任期号投出一张选票,按照先来先服务的原则（注意：5.4 节在投票上增加了一点额外的限制）。要求大多数选票的规则确保了最多只会有一个候选人赢得此次选举（图 3 中的选举安全性）。一旦候选人赢得选举,他就立即成为领导人。然后他会向其他的服务器发送心跳消息来建立自己的权威并且阻止新的领导人的产生。 在等待投票的时候,候选人可能会从其他的服务器接收到声明它是领导人的附加日志项 RPC。如果这个领导人的任期号（包含在此次的 RPC中）不小于候选人当前的任期号,那么候选人会承认领导人合法并回到跟随者状态。 如果此次 RPC 中的任期号比自己小,那么候选人就会拒绝这次的 RPC 并且继续保持候选人状态。 第三种可能的结果是候选人既没有赢得选举也没有输：如果有多个跟随者同时成为候选人,那么选票可能会被瓜分以至于没有候选人可以赢得大多数人的支持。当这种情况发生的时候,每一个候选人都会超时,然后通过增加当前任期号来开始一轮新的选举。然而,没有其他机制的话,选票可能会被无限的重复瓜分。 Raft 算法使用随机选举超时时间的方法来确保很少会发生选票瓜分的情况,就算发生也能很快的解决。为了阻止选票起初就被瓜分,选举超时时间是从一个固定的区间（例如 150-300 毫秒）随机选择。这样可以把服务器都分散开以至于在大多数情况下只有一个服务器会选举超时；然后他赢得选举并在其他服务器超时之前发送心跳包。同样的机制被用在选票瓜分的情况下。每一个候选人在开始一次选举的时候会重置一个随机的选举超时时间,然后在超时时间内等待投票的结果；这样减少了在新的选举中另外的选票瓜分的可能性。9.3 节展示了这种方案能够快速的选出一个领导人。 领导人选举这个例子,体现了可理解性原则是如何指导我们进行方案设计的。起初我们计划使用一种排名系统：每一个候选人都被赋予一个唯一的排名,供候选人之间竞争时进行选择。如果一个候选人发现另一个候选人拥有更高的排名,那么他就会回到跟随者状态,这样高排名的候选人能够更加容易的赢得下一次选举。但是我们发现这种方法在可用性方面会有一点问题（如果高排名的服务器宕机了,那么低排名的服务器可能会超时并再次进入候选人状态。而且如果这个行为发生得足够快,则可能会导致整个选举过程都被重置掉）。我们针对算法进行了多次调整,但是每次调整之后都会有新的问题。最终我们认为随机重试的方法是更加明显和易于理解的。 感悟：领导者产生的原因是因为集群里没有领导者,跟随者没有收到心跳,超过了弹性超时时间,所以跟随者变为候选人开始竞选,但竞选候选人有一个问题,如果弹性超时时间设置为一个统一但时间, 那么同时会有很多候选人开始竞争,这样会导致一直没有领导人选出来,对性能有很大对影响,解决的方法就是使用随机弹性时间,把随机实现分布了,这样先产生的候选人,就会成为领导人,避免多个候选人同时竞争。 5.3 日志复制一旦一个领导人被选举出来,他就开始为客户端提供服务。客户端的每一个请求都包含一条被复制状态机执行的指令。领导人把这条指令作为一条新的日志条目附加到日志中去,然后并行的发起附加条目 RPCs 给其他的服务器,让他们复制这条日志条目。当这条日志条目被安全的复制（下面会介绍）,领导人会应用这条日志条目到它的状态机中然后把执行的结果返回给客户端。如果跟随者崩溃或者运行缓慢,再或者网络丢包,领导人会不断的重复尝试附加日志条目 RPCs （尽管已经回复了客户端）直到所有的跟随者都最终存储了所有的日志条目。 感悟：当跟随者的日志是落后的情况下,领导人会不断的重复尝试附加日志条目 RPCs 图 6：日志由有序序号标记的条目组成。每个条目都包含创建时的任期号（图中框中的数字）,和一个状态机需要执行的指令。一个条目当可以安全的被应用到状态机中去的时候,就认为是可以提交了。 日志以图 6 展示的方式组织。每一个日志条目存储一条状态机指令和从领导人收到这条指令时的任期号。日志中的任期号用来检查是否出现不一致的情况,同时也用来保证图 3 中的某些性质。每一条日志条目同时也都有一个整数索引值来表明它在日志中的位置。 领导人来决定什么时候把日志条目应用到状态机中是安全的；这种日志条目被称为已提交。Raft 算法保证所有已提交的日志条目都是持久化的并且最终会被所有可用的状态机执行。在领导人将创建的日志条目复制到大多数的服务器上的时候,日志条目就会被提交（例如在图 6 中的条目 7）。同时,领导人的日志中之前的所有日志条目也都会被提交,包括由其他领导人创建的条目。5.4 节会讨论某些当在领导人改变之后应用这条规则的隐晦内容,同时他也展示了这种提交的定义是安全的。领导人跟踪了最大的将会被提交的日志项的索引,并且索引值会被包含在未来的所有附加日志 RPCs （包括心跳包）,这样其他的服务器才能最终知道领导人的提交位置。一旦跟随者知道一条日志条目已经被提交,那么他也会将这个日志条目应用到本地的状态机中（按照日志的顺序）。 感悟：被提交的日志都是持久化的并且都最终会被所有可用状态机执行 我们设计了 Raft 的日志机制来维护一个不同服务器的日志之间的高层次的一致性。这么做不仅简化了系统的行为也使得更加可预计,同时他也是安全性保证的一个重要组件。Raft 维护着以下的特性,这些同时也组成了图 3 中的日志匹配特性： 如果在不同的日志中的两个条目拥有相同的索引和任期号,那么他们存储了相同的指令。 如果在不同的日志中的两个条目拥有相同的索引和任期号,那么他们之前的所有日志条目也全部相同。 第一个特性来自这样的一个事实,领导人最多在一个任期里在指定的一个日志索引位置创建一条日志条目,同时日志条目在日志中的位置也从来不会改变。第二个特性由附加日志 RPC 的一个简单的一致性检查所保证。在发送附加日志 RPC 的时候,领导人会把新的日志条目紧接着之前的条目的索引位置和任期号包含在里面。如果跟随者在它的日志中找不到包含相同索引位置和任期号的条目,那么他就会拒绝接收新的日志条目。一致性检查就像一个归纳步骤：一开始空的日志状态肯定是满足日志匹配特性的,然后一致性检查保护了日志匹配特性当日志扩展的时候。因此,每当附加日志 RPC 返回成功时,领导人就知道跟随者的日志一定是和自己相同的了。 感悟：一致性检查过程是一个递推过程,dp[i] = dp[i-1]+1 在正常的操作中,领导人和跟随者的日志保持一致性,所以附加日志 RPC 的一致性检查从来不会失败。然而,领导人崩溃的情况会使得日志处于不一致的状态（老的领导人可能还没有完全复制所有的日志条目）。这种不一致问题会在领导人和跟随者的一系列崩溃下加剧。图 7 展示了跟随者的日志可能和新的领导人不同的方式。跟随者可能会丢失一些在新的领导人中有的日志条目,他也可能拥有一些领导人没有的日志条目,或者两者都发生。丢失或者多出日志条目可能会持续多个任期。 图 7：当一个领导人成功当选时,跟随者可能是任何情况（a-f）。每一个盒子表示是一个日志条目；里面的数字表示任期号。跟随者可能会缺少一些日志条目（a-b）,可能会有一些未被提交的日志条目（c-d）,或者两种情况都存在（e-f）。例如,场景 f 可能会这样发生,某服务器在任期 2 的时候是领导人,已附加了一些日志条目到自己的日志中,但在提交之前就崩溃了；很快这个机器就被重启了,在任期 3 重新被选为领导人,并且又增加了一些日志条目到自己的日志中；在任期 2 和任期 3 的日志被提交之前,这个服务器又宕机了,并且在接下来的几个任期里一直处于宕机状态。 在 Raft 算法中,领导人处理不一致是通过强制跟随者直接复制自己的日志来解决了。这意味着在跟随者中的冲突的日志条目会被领导人的日志覆盖。5.4 节会阐述如何通过增加一些限制来使得这样的操作是安全的。 要使得跟随者的日志进入和自己一致的状态,领导人必须找到最后两者达成一致的地方,然后删除从那个点之后的所有日志条目,发送自己的日志给跟随者。所有的这些操作都在进行附加日志 RPCs 的一致性检查时完成。领导人针对每一个跟随者维护了一个 nextIndex,这表示下一个需要发送给跟随者的日志条目的索引地址。当一个领导人刚获得权力的时候,他初始化所有的 nextIndex 值为自己的最后一条日志的index加1（图 7 中的 11）。如果一个跟随者的日志和领导人不一致,那么在下一次的附加日志 RPC 时的一致性检查就会失败。在被跟随者拒绝之后,领导人就会减小 nextIndex 值并进行重试。最终 nextIndex 会在某个位置使得领导人和跟随者的日志达成一致。当这种情况发生,附加日志 RPC 就会成功,这时就会把跟随者冲突的日志条目全部删除并且加上领导人的日志。一旦附加日志 RPC 成功,那么跟随者的日志就会和领导人保持一致,并且在接下来的任期里一直继续保持。 如果需要的话,算法可以通过减少被拒绝的附加日志 RPCs 的次数来优化。例如,当附加日志 RPC 的请求被拒绝的时候,跟随者可以包含冲突的条目的任期号和自己存储的那个任期的最早的索引地址。借助这些信息,领导人可以减小 nextIndex 越过所有那个任期冲突的所有日志条目；这样就变成每个任期需要一次附加条目 RPC 而不是每个条目一次。在实践中,我们十分怀疑这种优化是否是必要的,因为失败是很少发生的并且也不大可能会有这么多不一致的日志。 通过这种机制,领导人在获得权力的时候就不需要任何特殊的操作来恢复一致性。他只需要进行正常的操作,然后日志就能自动的在回复附加日志 RPC 的一致性检查失败的时候自动趋于一致。领导人从来不会覆盖或者删除自己的日志（图 3 的领导人只附加特性）。 日志复制机制展示出了第 2 节中形容的一致性特性：Raft 能够接受,复制并应用新的日志条目只要大部分的机器是工作的；在通常的情况下,新的日志条目可以在一次 RPC 中被复制给集群中的大多数机器；并且单个的缓慢的跟随者不会影响整体的性能。 感悟：如果领导者日志和跟随者日志产生来冲突,会强制覆盖领导人的日志到跟随者的日志,与etcd的raft实现中不一样的情况是领导人不会见效nextIndex中的值来进行重试,而是通过跟随者响应的一个rejectHint值快速定位到下一次同步日志d位置 5.4 安全性前面的章节里描述了 Raft 算法是如何选举和复制日志的。然而,到目前为止描述的机制并不能充分的保证每一个状态机会按照相同的顺序执行相同的指令。例如,一个跟随者可能会进入不可用状态同时领导人已经提交了若干的日志条目,然后这个跟随者可能会被选举为领导人并且覆盖这些日志条目；因此,不同的状态机可能会执行不同的指令序列。 这一节通过在领导选举的时候增加一些限制来完善 Raft 算法。这一限制保证了任何的领导人对于给定的任期号,都拥有了之前任期的所有被提交的日志条目（图 3 中的领导人完整特性）。增加这一选举时的限制,我们对于提交时的规则也更加清晰。最终,我们将展示对于领导人完整特性的简要证明,并且说明领导人是如何领导复制状态机的做出正确行为的。 5.4.1 选举限制在任何基于领导人的一致性算法中,领导人都必须存储所有已经提交的日志条目。在某些一致性算法中,例如 Viewstamped Replication,某个节点即使是一开始并没有包含所有已经提交的日志条目,它也能被选为领导者。这些算法都包含一些额外的机制来识别丢失的日志条目并把他们传送给新的领导人,要么是在选举阶段要么在之后很快进行。不幸的是,这种方法会导致相当大的额外的机制和复杂性。Raft 使用了一种更加简单的方法,它可以保证所有之前的任期号中已经提交的日志条目在选举的时候都会出现在新的领导人中,不需要传送这些日志条目给领导人。这意味着日志条目的传送是单向的,只从领导人传给跟随者,并且领导人从不会覆盖自身本地日志中已经存在的条目。 Raft 使用投票的方式来阻止一个候选人赢得选举除非这个候选人包含了所有已经提交的日志条目。候选人为了赢得选举必须联系集群中的大部分节点,这意味着每一个已经提交的日志条目在这些服务器节点中肯定存在于至少一个节点上。如果候选人的日志至少和大多数的服务器节点一样新（这个新的定义会在下面讨论）,那么他一定持有了所有已经提交的日志条目。请求投票 RPC 实现了这样的限制： RPC 中包含了候选人的日志信息,然后投票人会拒绝掉那些日志没有自己新的投票请求。 Raft 通过比较两份日志中最后一条日志条目的索引值和任期号定义谁的日志比较新。如果两份日志最后的条目的任期号不同,那么任期号大的日志更加新。如果两份日志最后的条目任期号相同,那么日志比较长的那个就更加新。 5.4.2 提交之前任期内的日志条目如同 5.3 节介绍的那样,领导人知道一条当前任期内的日志记录是可以被提交的,只要它被存储到了大多数的服务器上。如果一个领导人在提交日志条目之前崩溃了,未来后续的领导人会继续尝试复制这条日志记录。然而,一个领导人不能断定一个之前任期里的日志条目被保存到大多数服务器上的时候就一定已经提交了。图 8 展示了一种情况,一条已经被存储到大多数节点上的老日志条目,也依然有可能会被未来的领导人覆盖掉。 感悟：领导人在提交日志条目之前崩溃了,未来后续的领导人会继续尝试复制这条日志记录。一条已经被存储到大多数节点上的老日志条目,也依然有可能会被未来的领导人覆盖掉,因为无法断定之前任期里面到日志已经被大多数服务器提交。 图 8：如图的时间序列展示了为什么领导人无法决定对老任期号的日志条目进行提交。在 (a) 中,S1 是领导者,部分的复制了索引位置 2 的日志条目。在 (b) 中,S1 崩溃了,然后 S5 在任期 3 里通过 S3、S4 和自己的选票赢得选举,然后从客户端接收了一条不一样的日志条目放在了索引 2 处。然后到 (c),S5 又崩溃了；S1 重新启动,选举成功,开始复制日志。在这时,来自任期 2 的那条日志已经被复制到了集群中的大多数机器上,但是还没有被提交。如果 S1 在 (d) 中又崩溃了,S5 可以重新被选举成功（通过来自 S2,S3 和 S4 的选票）,然后覆盖了他们在索引 2 处的日志。反之,如果在崩溃之前,S1 把自己主导的新任期里产生的日志条目复制到了大多数机器上,就如 (e) 中那样,那么在后面任期里面这些新的日志条目就会被提交（因为S5 就不可能选举成功）。 这样在同一时刻就同时保证了,之前的所有老的日志条目就会被提交。 为了消除图 8 里描述的情况,Raft 永远不会通过计算副本数目的方式去提交一个之前任期内的日志条目。只有领导人当前任期里的日志条目通过计算副本数目可以被提交；一旦当前任期的日志条目以这种方式被提交,那么由于日志匹配特性,之前的日志条目也都会被间接的提交。在某些情况下,领导人可以安全的知道一个老的日志条目是否已经被提交（例如,该条目是否存储到所有服务器上）,但是 Raft 为了简化问题使用一种更加保守的方法。 当领导人复制之前任期里的日志时,Raft 会为所有日志保留原始的任期号, 这在提交规则上产生了额外的复杂性。在其他的一致性算法中,如果一个新的领导人要重新复制之前的任期里的日志时,它必须使用当前新的任期号。Raft 使用的方法更加容易辨别出日志,因为它可以随着时间和日志的变化对日志维护着同一个任期编号。另外,和其他的算法相比,Raft 中的新领导人只需要发送更少日志条目（其他算法中必须在他们被提交之前发送更多的冗余日志条目来为他们重新编号）。 感悟： 只有领导人当前任期里的日志条目通过计算副本数目可以被提交 5.4.3 安全性论证在给定了完整的 Raft 算法之后,我们现在可以更加精确的讨论领导人完整性特性（这一讨论基于 9.2 节的安全性证明）。我们假设领导人完全性特性是不存在的,然后我们推出矛盾来。假设任期 T 的领导人（领导人 T）在任期内提交了一条日志条目,但是这条日志条目没有被存储到未来某个任期的领导人的日志中。设大于 T 的最小任期 U 的领导人 U 没有这条日志条目。 图 9：如果 S1 （任期 T 的领导者）提交了一条新的日志在它的任期里,然后 S5 在之后的任期 U 里被选举为领导人,然后至少会有一个机器,如 S3,既拥有来自 S1 的日志,也给 S5 投票了。 在领导人 U 选举的时候一定没有那条被提交的日志条目（领导人从不会删除或者覆盖任何条目）。 领导人 T 复制这条日志条目给集群中的大多数节点,同时,领导人U 从集群中的大多数节点赢得了选票。因此,至少有一个节点（投票者、选民）同时接受了来自领导人T 的日志条目,并且给领导人U 投票了,如图 9。这个投票者是产生这个矛盾的关键。 这个投票者必须在给领导人 U 投票之前先接受了从领导人 T 发来的已经被提交的日志条目；否则他就会拒绝来自领导人 T 的附加日志请求（因为此时他的任期号会比 T 大）。 投票者在给领导人 U 投票时依然保存有这条日志条目,因为任何中间的领导人都包含该日志条目（根据上述的假设）,领导人从不会删除条目,并且跟随者只有在和领导人冲突的时候才会删除条目。 投票者把自己选票投给领导人 U 时,领导人 U 的日志必须和投票者自己一样新。这就导致了两者矛盾之一。 首先,如果投票者和领导人 U 的最后一条日志的任期号相同,那么领导人 U 的日志至少和投票者一样长,所以领导人 U 的日志一定包含所有投票者的日志。这是另一处矛盾,因为投票者包含了那条已经被提交的日志条目,但是在上述的假设里,领导人 U 是不包含的。 除此之外,领导人 U 的最后一条日志的任期号就必须比投票人大了。此外,他也比 T 大,因为投票人的最后一条日志的任期号至少和 T 一样大（他包含了来自任期 T 的已提交的日志）。创建了领导人 U 最后一条日志的之前领导人一定已经包含了那条被提交的日志（根据上述假设,领导人 U 是第一个不包含该日志条目的领导人）。所以,根据日志匹配特性,领导人 U 一定也包含那条被提交的日志,这里产生矛盾。 这里完成了矛盾。因此,所有比 T 大的领导人一定包含了所有来自 T 的已经被提交的日志。 日志匹配原则保证了未来的领导人也同时会包含被间接提交的条目,例如图 8 (d) 中的索引 2。 通过领导人完全特性,我们就能证明图 3 中的状态机安全特性,即如果服务器已经在某个给定的索引值应用了日志条目到自己的状态机里,那么其他的服务器不会应用一个不一样的日志到同一个索引值上。在一个服务器应用一条日志条目到他自己的状态机中时,他的日志必须和领导人的日志,在该条目和之前的条目上相同,并且已经被提交。现在我们来考虑在任何一个服务器应用一个指定索引位置的日志的最小任期；日志完全特性保证拥有更高任期号的领导人会存储相同的日志条目,所以之后的任期里应用某个索引位置的日志条目也会是相同的值。因此,状态机安全特性是成立的。 最后,Raft 要求服务器按照日志中索引位置顺序应用日志条目。和状态机安全特性结合起来看,这就意味着所有的服务器会应用相同的日志序列集到自己的状态机中,并且是按照相同的顺序。 5.5 跟随者和候选人崩溃到目前为止,我们都只关注了领导人崩溃的情况。跟随者和候选人崩溃后的处理方式比领导人要简单的多,并且他们的处理方式是相同的。如果跟随者或者候选人崩溃了,那么后续发送给他们的 RPCs 都会失败。Raft 中处理这种失败就是简单的通过无限的重试；如果崩溃的机器重启了,那么这些 RPC 就会完整的成功。如果一个服务器在完成了一个 RPC,但是还没有响应的时候崩溃了,那么在他重新启动之后就会再次收到同样的请求。Raft 的 RPCs 都是幂等的,所以这样重试不会造成任何问题。例如一个跟随者如果收到附加日志请求但是他已经包含了这一日志,那么他就会直接忽略这个新的请求。 感悟：跟随者或者候选人崩溃了,领导者会通过无限重试到方式给他们发送RPC,直到他们能够响应 5.6 时间和可用性Raft 的要求之一就是安全性不能依赖时间：整个系统不能因为某些事件运行的比预期快一点或者慢一点就产生了错误的结果。但是,可用性（系统可以及时的响应客户端）不可避免的要依赖于时间。例如,如果消息交换比服务器故障间隔时间长,候选人将没有足够长的时间来赢得选举；没有一个稳定的领导人,Raft 将无法工作。 领导人选举是 Raft 中对时间要求最为关键的方面。Raft 可以选举并维持一个稳定的领导人,只要系统满足下面的时间要求： 广播时间（broadcastTime） &lt;&lt; 选举超时时间（electionTimeout） &lt;&lt; 平均故障间隔时间（MTBF） 在这个不等式中,广播时间指的是从一个服务器并行的发送 RPCs 给集群中的其他服务器并接收响应的平均时间；选举超时时间就是在 5.2 节中介绍的选举的超时时间限制；然后平均故障间隔时间就是对于一台服务器而言,两次故障之间的平均时间。广播时间必须比选举超时时间小一个量级,这样领导人才能够发送稳定的心跳消息来阻止跟随者开始进入选举状态；通过随机化选举超时时间的方法,这个不等式也使得选票瓜分的情况变得不可能。选举超时时间应该要比平均故障间隔时间小上几个数量级,这样整个系统才能稳定的运行。当领导人崩溃后,整个系统会大约相当于选举超时的时间里不可用；我们希望这种情况在整个系统的运行中很少出现。 广播时间和平均故障间隔时间是由系统决定的,但是选举超时时间是我们自己选择的。Raft 的 RPCs 需要接收方将信息持久化的保存到稳定存储中去,所以广播时间大约是 0.5 毫秒到 20 毫秒,取决于存储的技术。因此,选举超时时间可能需要在 10 毫秒到 500 毫秒之间。大多数的服务器的平均故障间隔时间都在几个月甚至更长,很容易满足时间的需求。 6 集群成员变化到目前为止,我们都假设集群的配置（加入到一致性算法的服务器集合）是固定不变的。但是在实践中,偶尔是会改变集群的配置的,例如替换那些宕机的机器或者改变复制级别。尽管可以通过暂停整个集群,更新所有配置,然后重启整个集群的方式来实现,但是在更改的时候集群会不可用。另外,如果存在手工操作步骤,那么就会有操作失误的风险。为了避免这样的问题,我们决定自动化配置改变并且将其纳入到 Raft 一致性算法中来。 为了让配置修改机制能够安全,那么在转换的过程中不能够存在任何时间点使得两个领导人同时被选举成功在同一个任期里。不幸的是,任何服务器直接从旧的配置直接转换到新的配置的方案都是不安全的。一次性自动的转换所有服务器是不可能的,所以在转换期间整个集群存在划分成两个独立的大多数群体的可能性（见图 10）。 图 10：直接从一种配置转到新的配置是十分不安全的,因为各个机器可能在任何的时候进行转换。在这个例子中,集群配额从 3 台机器变成了 5 台。不幸的是,存在这样的一个时间点,两个不同的领导人在同一个任期里都可以被选举成功。一个是通过旧的配置,一个通过新的配置。 为了保证安全性,配置更改必须使用两阶段方法。目前有很多种两阶段的实现。例如,有些系统在第一阶段停掉旧的配置所以集群就不能处理客户端请求；然后在第二阶段在启用新的配置。在 Raft 中,集群先切换到一个过渡的配置,我们称之为共同一致；一旦共同一致已经被提交了,那么系统就切换到新的配置上。共同一致是老配置和新配置的结合： 日志条目被复制给集群中新、老配置的所有服务器。 新、旧配置的服务器都可以成为领导人。 达成一致（针对选举和提交）需要分别在两种配置上获得大多数的支持。 共同一致允许独立的服务器在不影响安全性的前提下,在不同的时间进行配置转换过程。此外,共同一致可以让集群在配置转换的过程人依然响应客户端的请求。 集群配置在复制日志中以特殊的日志条目来存储和通信；图 11 展示了配置转换的过程。当一个领导人接收到一个改变配置从 C-old 到 C-new 的请求,他会为了共同一致存储配置（图中的 C-old,new）,以前面描述的日志条目和副本的形式。一旦一个服务器将新的配置日志条目增加到它的日志中,他就会用这个配置来做出未来所有的决定（服务器总是使用最新的配置,无论他是否已经被提交）。这意味着领导人要使用 C-old,new 的规则来决定日志条目 C-old,new 什么时候需要被提交。如果领导人崩溃了,被选出来的新领导人可能是使用 C-old 配置也可能是 C-old,new 配置,这取决于赢得选举的候选人是否已经接收到了 C-old,new 配置。在任何情况下, C-new 配置在这一时期都不会单方面的做出决定。 一旦 C-old,new 被提交,那么无论是 C-old 还是 C-new,在没有经过他人批准的情况下都不可能做出决定,并且领导人完全特性保证了只有拥有 C-old,new 日志条目的服务器才有可能被选举为领导人。这个时候,领导人创建一条关于 C-new 配置的日志条目并复制给集群就是安全的了。再者,每个服务器在见到新的配置的时候就会立即生效。当新的配置在 C-new 的规则下被提交,旧的配置就变得无关紧要,同时不使用新的配置的服务器就可以被关闭了。如图 11,C-old 和 C-new 没有任何机会同时做出单方面的决定；这保证了安全性。 图 11：一个配置切换的时间线。虚线表示已经被创建但是还没有被提交的条目,实线表示最后被提交的日志条目。领导人首先创建了 C-old,new 的配置条目在自己的日志中,并提交到 C-old,new 中（C-old 的大多数和 C-new 的大多数）。然后他创建 C-new 条目并提交到 C-new 中的大多数。这样就不存在 C-new 和 C-old 可以同时做出决定的时间点。 在关于重新配置还有三个问题需要提出。 第一个问题是,新的服务器可能初始化没有存储任何的日志条目。当这些服务器以这种状态加入到集群中,那么他们需要一段时间来更新追赶,这时还不能提交新的日志条目。为了避免这种可用性的间隔时间,Raft 在配置更新的时候使用了一种额外的阶段,在这个阶段,新的服务器以没有投票权身份加入到集群中来（领导人复制日志给他们,但是不考虑他们是大多数）。一旦新的服务器追赶上了集群中的其他机器,重新配置可以像上面描述的一样处理。 第二个问题是,集群的领导人可能不是新配置的一员。在这种情况下,领导人就会在提交了 C-new 日志之后退位（回到跟随者状态）。这意味着有这样的一段时间,领导人管理着集群,但是不包括他自己；他复制日志但是不把他自己算作是大多数之一。当 C-new 被提交时,会发生领导人过渡,因为这时是最早新的配置可以独立工作的时间点（将总是能够在 C-new 配置下选出新的领导人）。在此之前,可能只能从 C-old 中选出领导人。 第三个问题是,移除不在 C-new 中的服务器可能会扰乱集群。这些服务器将不会再接收到心跳,所以当选举超时,他们就会进行新的选举过程。他们会发送拥有新的任期号的请求投票 RPCs,这样会导致当前的领导人回退成跟随者状态。新的领导人最终会被选出来,但是被移除的服务器将会再次超时,然后这个过程会再次重复,导致整体可用性大幅降低。 为了避免这个问题,当服务器确认当前领导人存在时,服务器会忽略请求投票 RPCs。特别的,当服务器在当前最小选举超时时间内收到一个请求投票 RPC,他不会更新当前的任期号或者投出选票。这不会影响正常的选举,每个服务器在开始一次选举之前,至少等待一个最小选举超时时间。然而,这有利于避免被移除的服务器扰乱：如果领导人能够发送心跳给集群,那么他就不会被更大的任期号废黜。 感悟：当确认有领导人当时候,会忽略投票请求 7 日志压缩Raft 的日志在正常操作中不断的增长,但是在实际的系统中,日志不能无限制的增长。随着日志不断增长,他会占用越来越多的空间,花费越来越多的时间来重置。如果没有一定的机制去清除日志里积累的陈旧的信息,那么会带来可用性问题。 快照是最简单的压缩方法。在快照系统中,整个系统的状态都以快照的形式写入到稳定的持久化存储中,然后到那个时间点之前的日志全部丢弃。快照技术被使用在 Chubby 和 ZooKeeper 中,接下来的章节会介绍 Raft 中的快照技术。 增量压缩的方法,例如日志清理或者日志结构合并树,都是可行的。这些方法每次只对一小部分数据进行操作,这样就分散了压缩的负载压力。首先,他们先选择一个已经积累的大量已经被删除或者被覆盖对象的区域,然后重写那个区域还活跃的对象,之后释放那个区域。和简单操作整个数据集合的快照相比,需要增加复杂的机制来实现。状态机可以实现 LSM tree 使用和快照相同的接口,但是日志清除方法就需要修改 Raft 了。 图 12：一个服务器用新的快照替换了从 1 到 5 的条目,快照值存储了当前的状态。快照中包含了最后的索引位置和任期号。 图 12 展示了 Raft 中快照的基础思想。每个服务器独立的创建快照,只包括已经被提交的日志。主要的工作包括将状态机的状态写入到快照中。Raft 也包含一些少量的元数据到快照中：最后被包含索引指的是被快照取代的最后的条目在日志中的索引值（状态机最后应用的日志）,最后被包含的任期指的是该条目的任期号。保留这些数据是为了支持快照后紧接着的第一个条目的附加日志请求时的一致性检查,因为这个条目需要前一日志条目的索引值和任期号。为了支持集群成员更新（第 6 节）,快照中也将最后的一次配置作为最后一个条目存下来。一旦服务器完成一次快照,他就可以删除最后索引位置之前的所有日志和快照了。 尽管通常服务器都是独立的创建快照,但是领导人必须偶尔的发送快照给一些落后的跟随者。这通常发生在当领导人已经丢弃了下一条需要发送给跟随者的日志条目的时候。幸运的是这种情况不是常规操作：一个与领导人保持同步的跟随者通常都会有这个条目。然而一个运行非常缓慢的跟随者或者新加入集群的服务器（第 6 节）将不会有这个条目。这时让这个跟随者更新到最新的状态的方式就是通过网络把快照发送给他们。 安装快照 RPC： 由领导人调用以将快照的分块发送给跟随者。领导者总是按顺序发送分块。 参数 解释 term 领导人的任期号 leaderId 领导人的 Id,以便于跟随者重定向请求 lastIncludedIndex 快照中包含的最后日志条目的索引值 lastIncludedTerm 快照中包含的最后日志条目的任期号 offset 分块在快照中的字节偏移量 data[] 原始数据 done 如果这是最后一个分块则为 true 结果 解释 term 当前任期号（currentTerm）,便于领导人更新自己 接收者实现： 如果term &lt; currentTerm就立即恢复 如果是第一个分块（offset 为 0）就创建一个新的快照 在指定偏移量写入数据 如果 done 是 false,则继续等待更多的数据 保存快照文件,丢弃具有较小索引的任何现有或部分快照 如果现存的日志条目与快照中最后包含的日志条目具有相同的索引值和任期号,则保留其后的日志条目并进行回复 丢弃整个日志 使用快照重置状态机（并加载快照的集群配置） 图 13：一个关于安装快照的简要概述。为了便于传输,快照都是被分成分块的；每个分块都给了跟随者生命的迹象,所以跟随者可以重置选举超时计时器。 在这种情况下领导人使用一种叫做安装快照的新的 RPC 来发送快照给太落后的跟随者；见图 13。当跟随者通过这种 RPC 接收到快照时,他必须自己决定对于已经存在的日志该如何处理。通常快照会包含没有在接收者日志中存在的信息。在这种情况下,跟随者丢弃其整个日志；它全部被快照取代,并且可能包含与快照冲突的未提交条目。如果接收到的快照是自己日志的前面部分（由于网络重传或者错误）,那么被快照包含的条目将会被全部删除,但是快照后面的条目仍然有效,必须保留。 这种快照的方式背离了 Raft 的强领导人原则,因为跟随者可以在不知道领导人情况下创建快照。但是我们认为这种背离是值得的。领导人的存在,是为了解决在达成一致性的时候的冲突,但是在创建快照的时候,一致性已经达成,这时不存在冲突了,所以没有领导人也是可以的。数据依然是从领导人传给跟随者,只是跟随者可以重新组织他们的数据了。 我们考虑过一种替代的基于领导人的快照方案,即只有领导人创建快照,然后发送给所有的跟随者。但是这样做有两个缺点。 第一,发送快照会浪费网络带宽并且延缓了快照处理的时间。每个跟随者都已经拥有了所有产生快照需要的信息,而且很显然,自己从本地的状态中创建快照比通过网络接收别人发来的要经济。 第二,领导人的实现会更加复杂。例如,领导人需要发送快照的同时并行的将新的日志条目发送给跟随者,这样才不会阻塞新的客户端请求。 还有两个问题影响了快照的性能。 首先,服务器必须决定什么时候应该创建快照。如果快照创建的过于频繁,那么就会浪费大量的磁盘带宽和其他资源；如果创建快照频率太低,他就要承受耗尽存储容量的风险,同时也增加了从日志重建的时间。一个简单的策略就是当日志大小达到一个固定大小的时候就创建一次快照。如果这个阈值设置的显著大于期望的快照的大小,那么快照对磁盘压力的影响就会很小了。 第二个影响性能的问题就是写入快照需要花费显著的一段时间,并且我们还不希望影响到正常操作。解决方案是通过写时复制的技术,这样新的更新就可以被接收而不影响到快照。例如,具有函数式数据结构的状态机天然支持这样的功能。另外,操作系统的写时复制技术的支持（如 Linux 上的 fork）可以被用来创建完整的状态机的内存快照（我们的实现就是这样的）。 8 客户端交互这一节将介绍客户端是如何和 Raft 进行交互的,包括客户端如何发现领导人和 Raft 是如何支持线性化语义的。这些问题对于所有基于一致性的系统都存在,并且 Raft 的解决方案和其他的也差不多。 Raft 中的客户端发送所有请求给领导人。当客户端启动的时候,他会随机挑选一个服务器进行通信。如果客户端第一次挑选的服务器不是领导人,那么那个服务器会拒绝客户端的请求并且提供他最近接收到的领导人的信息（附加条目请求包含了领导人的网络地址）。如果领导人已经崩溃了,那么客户端的请求就会超时；客户端之后会再次重试随机挑选服务器的过程。 我们 Raft 的目标是要实现线性化语义（每一次操作立即执行,只执行一次,在他调用和收到回复之间）。但是,如上述,Raft 是可以执行同一条命令多次的：例如,如果领导人在提交了这条日志之后,但是在响应客户端之前崩溃了,那么客户端会和新的领导人重试这条指令,导致这条命令就被再次执行了。解决方案就是客户端对于每一条指令都赋予一个唯一的序列号。然后,状态机跟踪每条指令最新的序列号和相应的响应。如果接收到一条指令,它的序列号已经被执行了,那么就立即返回结果,而不重新执行指令。 感悟：通过序列号实现线性化语义,如果序列号被执行过了,就立即返回结果 只读的操作可以直接处理而不需要记录日志。但是,在不增加任何限制的情况下,这么做可能会冒着返回脏数据的风险,因为领导人响应客户端请求时可能已经被新的领导人作废了,但是他还不知道。线性化的读操作必须不能返回脏数据,Raft 需要使用两个额外的措施在不使用日志的情况下保证这一点。 首先,领导人必须有关于被提交日志的最新信息。领导人完全特性保证了领导人一定拥有所有已经被提交的日志条目,但是在他任期开始的时候,他可能不知道那些是已经被提交的。为了知道这些信息,他需要在他的任期里提交一条日志条目。Raft 中通过领导人在任期开始的时候提交一个空白的没有任何操作的日志条目到日志中去来实现。 第二,领导人在处理只读的请求之前必须检查自己是否已经被废黜了（他自己的信息已经变脏了如果一个更新的领导人被选举出来）。Raft 中通过让领导人在响应只读请求之前,先和集群中的大多数节点交换一次心跳信息来处理这个问题。 可选的,领导人可以依赖心跳机制来实现一种租约的机制,但是这种方法依赖时间来保证安全性（假设时间误差是有界的）。 感悟：etcd中就使用了租约机制,来实现线性化当读操作 9 算法实现和评估我们已经为 RAMCloud 实现了 Raft 算法作为存储配置信息的复制状态机的一部分,并且帮助 RAMCloud 协调故障转移。这个 Raft 实现包含大约 2000 行 C++ 代码,其中不包括测试、注释和空行。这些代码是开源的。同时也有大约 25 个其他独立的第三方的基于这篇论文草稿的开源实现,针对不同的开发场景。同时,很多公司已经部署了基于 Raft 的系统。 这一节会从三个方面来评估 Raft 算法：可理解性、正确性和性能。 9.1 可理解性为了和 Paxos 比较 Raft 算法的可理解能力,我们针对高层次的本科生和研究生,在斯坦福大学的高级操作系统课程和加州大学伯克利分校的分布式计算课程上,进行了一次学习的实验。我们分别拍了针对 Raft 和 Paxos 的视频课程,并准备了相应的小测验。Raft 的视频讲课覆盖了这篇论文的所有内容除了日志压缩；Paxos 讲课包含了足够的资料来创建一个等价的复制状态机,包括单决策 Paxos,多决策 Paxos,重新配置和一些实际系统需要的性能优化（例如领导人选举）。小测验测试一些对算法的基本理解和解释一些边角的示例。每个学生都是看完第一个视频,回答相应的测试,再看第二个视频,回答相应的测试。大约有一半的学生先进行 Paxos 部分,然后另一半先进行 Raft 部分,这是为了说明两者从第一部分的算法学习中获得的表现和经验的差异。我们计算参加人员的每一个小测验的得分来看参与者是否在 Raft 算法上更加容易理解。 我们尽可能的使得 Paxos 和 Raft 的比较更加公平。这个实验偏爱 Paxos 表现在两个方面：43 个参加者中有 15 个人在之前有一些 Paxos 的经验,并且 Paxos 的视频要长 14%。如表格 1 总结的那样,我们采取了一些措施来减轻这种潜在的偏见。我们所有的材料都可供审查。 关心 缓和偏见采取的手段 可供查看的材料 相同的讲课质量 两者使用同一个讲师。Paxos 使用的是现在很多大学里经常使用的。Paxos 会长 14%。 视频 相同的测验难度 问题以难度分组,在两个测验里成对出现。 小测验 公平评分 使用评价量规。随机顺序打分,两个测验交替进行。 评价量规（rubric） 表 1：考虑到可能会存在的偏见,对于每种情况的解决方法,和相应的材料。 参加者平均在 Raft 的测验中比 Paxos 高 4.9 分（总分 60,那么 Raft 的平均得分是 25.7,而 Paxos 是 20.8）；图 14 展示了每个参与者的得分。配置t-检验（又称student‘s t-test）表明,在 95% 的可信度下,真实的 Raft 分数分布至少比 Paxos 高 2.5 分。 图 14：一个散点图表示了 43 个学生在 Paxos 和 Raft 的小测验中的成绩。在对角线之上的点表示在 Raft 获得了更高分数的学生。 我们也建立了一个线性回归模型来预测一个新的学生的测验成绩,基于以下三个因素：他们使用的是哪个小测验,之前对 Paxos 的经验,和学习算法的顺序。模型预测,对小测验的选择会产生 12.5 分的差别。这显著的高于之前的 4.9 分,因为很多学生在之前都已经有了对于 Paxos 的经验,这相当明显的帮助 Paxos,对 Raft 就没什么太大影响了。但是奇怪的是,模型预测对于先进行 Paxos 小测验的人而言,Raft的得分低了6.3分; 虽然我们不知道为什么,这似乎在统计上是有意义的。 我们同时也在测验之后调查了参与者,他们认为哪个算法更加容易实现和解释；这个的结果在图 15 上。压倒性的结果表明 Raft 算法更加容易实现和解释（41 人中的 33个）。但是,这种自己报告的结果不如参与者的成绩更加可信,并且参与者可能因为我们的 Raft 更加易于理解的假说而产生偏见。 图 15：通过一个 5 分制的问题,参与者（左边）被问哪个算法他们觉得在一个高效正确的系统里更容易实现,右边被问哪个更容易向学生解释。 关于 Raft 用户学习有一个更加详细的讨论。 9.2 正确性在第 5 节,我们已经制定了正式的规范,和对一致性机制的安全性证明。这个正式规范使用 TLA+ 规范语言使图 2 中总结的信息非常清晰。它长约400行,并作为证明的主题。同时对于任何想实现 Raft 的人也是十分有用的。我们通过 TLA 证明系统非常机械的证明了日志完全特性。然而,这个证明依赖的约束前提还没有被机械证明（例如,我们还没有证明规范的类型安全）。而且,我们已经写了一个非正式的证明关于状态机安全性是完备的,并且是相当清晰的（大约 3500 个词）。 9.3 性能Raft 和其他一致性算法例如 Paxos 有着差不多的性能。在性能方面,最重要的关注点是,当领导人被选举成功时,什么时候复制新的日志条目。Raft 通过很少数量的消息包（一轮从领导人到集群大多数机器的消息）就达成了这个目的。同时,进一步提升 Raft 的性能也是可行的。例如,很容易通过支持批量操作和管道操作来提高吞吐量和降低延迟。对于其他一致性算法已经提出过很多性能优化方案；其中有很多也可以应用到 Raft 中来,但是我们暂时把这个问题放到未来的工作中去。 我们使用我们自己的 Raft 实现来衡量 Raft 领导人选举的性能并且回答两个问题。首先,领导人选举的过程收敛是否快速？第二,在领导人宕机之后,最小的系统宕机时间是多久？ 图 16：发现并替换一个已经崩溃的领导人的时间。上面的图考察了在选举超时时间上的随机化程度,下面的图考察了最小选举超时时间。每条线代表了 1000 次实验（除了 150-150 毫秒只试了 100 次）,和相应的确定的选举超时时间。例如,150-155 毫秒意思是,选举超时时间从这个区间范围内随机选择并确定下来。这个实验在一个拥有 5 个节点的集群上进行,其广播时延大约是 15 毫秒。对于 9 个节点的集群,结果也差不多。 为了衡量领导人选举,我们反复的使一个拥有五个节点的服务器集群的领导人宕机,并计算需要多久才能发现领导人已经宕机并选出一个新的领导人（见图 16）。为了构建一个最坏的场景,在每一的尝试里,服务器都有不同长度的日志,意味着有些候选人是没有成为领导人的资格的。另外,为了促成选票瓜分的情况,我们的测试脚本在终止领导人之前同步的发送了一次心跳广播（这大约和领导人在崩溃前复制一个新的日志给其他机器很像）。领导人均匀的随机的在心跳间隔里宕机,也就是最小选举超时时间的一半。因此,最小宕机时间大约就是最小选举超时时间的一半。 图 16 中上面的图表明,只需要在选举超时时间上使用很少的随机化就可以大大避免选票被瓜分的情况。在没有随机化的情况下,在我们的测试里,选举过程往往都需要花费超过 10 秒钟由于太多的选票瓜分的情况。仅仅增加 5 毫秒的随机化时间,就大大的改善了选举过程,现在平均的宕机时间只有 287 毫秒。增加更多的随机化时间可以大大改善最坏情况：通过增加 50 毫秒的随机化时间,最坏的完成情况（1000 次尝试）只要 513 毫秒。 图 16 中下面的图显示,通过减少选举超时时间可以减少系统的宕机时间。在选举超时时间为 12-24 毫秒的情况下,只需要平均 35 毫秒就可以选举出新的领导人（最长的一次花费了 152 毫秒）。然而,进一步降低选举超时时间的话就会违反 Raft 的时间不等式需求：在选举新领导人之前,领导人就很难发送完心跳包。这会导致没有意义的领导人改变并降低了系统整体的可用性。我们建议使用更为保守的选举超时时间,比如 150-300 毫秒；这样的时间不大可能导致没有意义的领导人改变,而且依然提供不错的可用性。 10 相关工作已经有很多关于一致性算法的工作被发表出来,其中很多都可以归到下面的类别中： Lamport 关于 Paxos 的原始描述,和尝试描述的更清晰。 关于 Paxos 的更详尽的描述,补充遗漏的细节并修改算法,使得可以提供更加容易的实现基础。 实现一致性算法的系统,例如 Chubby,ZooKeeper 和 Spanner。对于 Chubby 和 Spanner 的算法并没有公开发表其技术细节,尽管他们都声称是基于 Paxos 的。ZooKeeper 的算法细节已经发表,但是和 Paxos 着实有着很大的差别。 Paxos 可以应用的性能优化。 Oki 和 Liskov 的 Viewstamped Replication（VR）,一种和 Paxos 差不多的替代算法。原始的算法描述和分布式传输协议耦合在了一起,但是核心的一致性算法在最近的更新里被分离了出来。VR 使用了一种基于领导人的方法,和 Raft 有很多相似之处。 Raft 和 Paxos 最大的不同之处就在于 Raft 的强领导特性：Raft 使用领导人选举作为一致性协议里必不可少的部分,并且将尽可能多的功能集中到了领导人身上。这样就可以使得算法更加容易理解。例如,在 Paxos 中,领导人选举和基本的一致性协议是正交的：领导人选举仅仅是性能优化的手段,而且不是一致性所必须要求的。但是,这样就增加了多余的机制：Paxos 同时包含了针对基本一致性要求的两阶段提交协议和针对领导人选举的独立的机制。相比较而言,Raft 就直接将领导人选举纳入到一致性算法中,并作为两阶段一致性的第一步。这样就减少了很多机制。 像 Raft 一样,VR 和 ZooKeeper 也是基于领导人的,因此他们也拥有一些 Raft 的优点。但是,Raft 比 VR 和 ZooKeeper 拥有更少的机制因为 Raft 尽可能的减少了非领导人的功能。例如,Raft 中日志条目都遵循着从领导人发送给其他人这一个方向：附加条目 RPC 是向外发送的。在 VR 中,日志条目的流动是双向的（领导人可以在选举过程中接收日志）；这就导致了额外的机制和复杂性。根据 ZooKeeper 公开的资料看,它的日志条目也是双向传输的,但是它的实现更像 Raft。 和上述我们提及的其他基于一致性的日志复制算法中,Raft 的消息类型更少。例如,我们数了一下 VR 和 ZooKeeper 使用的用来基本一致性需要和成员改变的消息数（排除了日志压缩和客户端交互,因为这些都比较独立且和算法关系不大）。VR 和 ZooKeeper 都分别定义了 10 中不同的消息类型,相对的,Raft 只有 4 中消息类型（两种 RPC 请求和对应的响应）。Raft 的消息都稍微比其他算法的要信息量大,但是都很简单。另外,VR 和 ZooKeeper 都在领导人改变时传输了整个日志；所以为了能够实践中使用,额外的消息类型就很必要了。 Raft 的强领导人模型简化了整个算法,但是同时也排斥了一些性能优化的方法。例如,平等主义 Paxos （EPaxos）在某些没有领导人的情况下可以达到很高的性能。平等主义 Paxos 充分发挥了在状态机指令中的交换性。任何服务器都可以在一轮通信下就提交指令,除非其他指令同时被提出了。然而,如果指令都是并发的被提出,并且互相之间不通信沟通,那么 EPaxos 就需要额外的一轮通信。因为任何服务器都可以提交指令,所以 EPaxos 在服务器之间的负载均衡做的很好,并且很容易在 WAN 网络环境下获得很低的延迟。但是,他在 Paxos 上增加了非常明显的复杂性。 一些集群成员变换的方法已经被提出或者在其他的工作中被实现,包括 Lamport 的原始的讨论,VR 和 SMART。我们选择使用共同一致的方法因为他对一致性协议的其他部分影响很小,这样我们只需要很少的一些机制就可以实现成员变换。Lamport 的基于 α 的方法之所以没有被 Raft 选择是因为它假设在没有领导人的情况下也可以达到一致性。和 VR 和 SMART 相比较,Raft 的重新配置算法可以在不限制正常请求处理的情况下进行；相比较的,VR 需要停止所有的处理过程,SMART 引入了一个和 α 类似的方法,限制了请求处理的数量。Raft 的方法同时也需要更少的额外机制来实现,和 VR、SMART 比较而言。 11 结论算法的设计通常会把正确性,效率或者简洁作为主要的目标。尽管这些都是很有意义的目标,但是我们相信,可理解性也是一样的重要。在开发者把算法应用到实际的系统中之前,这些目标没有一个会被实现,这些都会必然的偏离发表时的形式。除非开发人员对这个算法有着很深的理解并且有着直观的感觉,否则将会对他们而言很难在实现的时候保持原有期望的特性。 在这篇论文中,我们尝试解决分布式一致性问题,但是一个广为接受但是十分令人费解的算法 Paxos 已经困扰了无数学生和开发者很多年了。我们创造了一种新的算法 Raft,显而易见的比 Paxos 要容易理解。我们同时也相信,Raft 也可以为实际的实现提供坚实的基础。把可理解性作为设计的目标改变了我们设计 Raft 的方式；随着设计的进展,我们发现自己重复使用了一些技术,比如分解问题和简化状态空间。这些技术不仅提升了 Raft 的可理解性,同时也使我们坚信其正确性。 12 感谢这项研究必须感谢以下人员的支持：Ali Ghodsi,David Mazie`res,和伯克利 CS 294-91 课程、斯坦福 CS 240 课程的学生。Scott Klemmer 帮我们设计了用户调查,Nelson Ray 建议我们进行统计学的分析。在用户调查时使用的关于 Paxos 的幻灯片很大一部分是从 Lorenzo Alvisi 的幻灯片上借鉴过来的。特别的,非常感谢 DavidMazieres 和 Ezra Hoch,他们找到了 Raft 中一些难以发现的漏洞。许多人提供了关于这篇论文十分有用的反馈和用户调查材料,包括 Ed Bugnion,Michael Chan,Hugues Evrard,Daniel Giffin,Arjun Gopalan,Jon Howell,Vimalkumar Jeyakumar,Ankita Kejriwal,Aleksandar Kracun,Amit Levy,Joel Martin,Satoshi Matsushita,Oleg Pesok,David Ramos,Robbert van Renesse,Mendel Rosenblum,Nicolas Schiper,Deian Stefan,Andrew Stone,Ryan Stutsman,David Terei,Stephen Yang,Matei Zaharia 以及 24 位匿名的会议审查人员（可能有重复）,并且特别感谢我们的领导人 Eddie Kohler。Werner Vogels 发了一条早期草稿链接的推特,给 Raft 带来了极大的关注。我们的工作由 Gigascale 系统研究中心和 Multiscale 系统研究中心给予支持,这两个研究中心由关注中心研究程序资金支持,一个是半导体研究公司的程序,由 STARnet 支持,一个半导体研究公司的程序由 MARCO 和 DARPA 支持,在国家科学基金会的 0963859 号批准,并且获得了来自 Facebook,Google,Mellanox,NEC,NetApp,SAP 和 Samsung 的支持。Diego Ongaro 由 Junglee 公司,斯坦福的毕业团体支持。","link":"/2019/09/09/Algorithm/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/Raft%E8%AE%BA%E6%96%87(%E8%AF%91%E6%96%87)/"}],"tags":[{"name":"工具","slug":"工具","link":"/tags/%E5%B7%A5%E5%85%B7/"},{"name":"爬虫","slug":"爬虫","link":"/tags/%E7%88%AC%E8%99%AB/"},{"name":"Go","slug":"Go","link":"/tags/Go/"},{"name":"Algorithm","slug":"Algorithm","link":"/tags/Algorithm/"},{"name":"设计模式","slug":"设计模式","link":"/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"Rust","slug":"Rust","link":"/tags/Rust/"},{"name":"面试","slug":"面试","link":"/tags/%E9%9D%A2%E8%AF%95/"},{"name":"Network","slug":"Network","link":"/tags/Network/"},{"name":"Etcd","slug":"Etcd","link":"/tags/Etcd/"},{"name":"Raft","slug":"Raft","link":"/tags/Raft/"},{"name":"算法","slug":"算法","link":"/tags/%E7%AE%97%E6%B3%95/"},{"name":"数据结构与算法","slug":"数据结构与算法","link":"/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"kmp","slug":"kmp","link":"/tags/kmp/"},{"name":"数据结构","slug":"数据结构","link":"/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"Golang源码分析","slug":"Golang源码分析","link":"/tags/Golang%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"name":"Go中的垃圾收集","slug":"Go中的垃圾收集","link":"/tags/Go%E4%B8%AD%E7%9A%84%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86/"},{"name":"错误处理","slug":"错误处理","link":"/tags/%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86/"},{"name":"GC","slug":"GC","link":"/tags/GC/"},{"name":"Go中的调度","slug":"Go中的调度","link":"/tags/Go%E4%B8%AD%E7%9A%84%E8%B0%83%E5%BA%A6/"},{"name":"Golang译文","slug":"Golang译文","link":"/tags/Golang%E8%AF%91%E6%96%87/"},{"name":"编程规范","slug":"编程规范","link":"/tags/%E7%BC%96%E7%A8%8B%E8%A7%84%E8%8C%83/"},{"name":"原理","slug":"原理","link":"/tags/%E5%8E%9F%E7%90%86/"},{"name":"调优","slug":"调优","link":"/tags/%E8%B0%83%E4%BC%98/"},{"name":"K8s","slug":"K8s","link":"/tags/K8s/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"},{"name":"人际关系","slug":"人际关系","link":"/tags/%E4%BA%BA%E9%99%85%E5%85%B3%E7%B3%BB/"}],"categories":[{"name":"Go","slug":"Go","link":"/categories/Go/"},{"name":"Linux","slug":"Linux","link":"/categories/Linux/"},{"name":"Rust","slug":"Rust","link":"/categories/Rust/"},{"name":"面试","slug":"面试","link":"/categories/%E9%9D%A2%E8%AF%95/"},{"name":"Network","slug":"Network","link":"/categories/Network/"},{"name":"Algorithm","slug":"Algorithm","link":"/categories/Algorithm/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"容器技术","slug":"容器技术","link":"/categories/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"数据库","slug":"数据库","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"软技能","slug":"软技能","link":"/categories/%E8%BD%AF%E6%8A%80%E8%83%BD/"},{"name":"Golang源码分析","slug":"Go/Golang源码分析","link":"/categories/Go/Golang%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"name":"Golang译文","slug":"Go/Golang译文","link":"/categories/Go/Golang%E8%AF%91%E6%96%87/"},{"name":"数据结构与算法","slug":"Algorithm/数据结构与算法","link":"/categories/Algorithm/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"MySQL","slug":"数据库/MySQL","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/"}]}